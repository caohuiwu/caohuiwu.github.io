{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/touxiang.jpg","path":"images/touxiang.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1728912368176},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1728912368177},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1728912368177},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1728912368178},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1728912368178},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1728912368179},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1728912368179},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1728912368179},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1728912368179},{"_id":"themes/next/README.cn.md","hash":"263b74f1ac7c0f6f9424b8cced4b0b320ae61efc","modified":1728912368180},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1728912368183},{"_id":"themes/next/README.md","hash":"287c7e6b7a6ddf75d815dda0df8bd228e3f285c5","modified":1728912368180},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1728912368185},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1728912368204},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1728912368179},{"_id":"themes/next/_config.yml","hash":"fbf4b4cdca426a2147963dcdca52ca8f67266fc5","modified":1731576324784},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident.md","hash":"169102fb47ac2fa6e849e5a383d650c8fc7af4a2","modified":1729216636881},{"_id":"source/_posts/2019-03-05-单点登录现状.md","hash":"c56a7480b21e75a405cd5125fb858d1925989d2d","modified":1728898691851},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程.md","hash":"106dfbf8cd51df301353466c1475ef2a24262627","modified":1733714330888},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题.md","hash":"e9e89061b9de9e85cda97a160f02def66cd8246c","modified":1733714777306},{"_id":"source/_posts/2019-03-15-单点登录优化方案一.md","hash":"a8100c1bb8a3cab76b5e4f247c25e164c29406d7","modified":1728898691857},{"_id":"source/_posts/2019-03-22-单点登录优化方案二.md","hash":"279f179678da283ead7794b39d0bce3f35950d61","modified":1728898691858},{"_id":"source/_posts/2019-04-11-Linux-io模型.md","hash":"8a061cca1ede54803e6c9b3b67232630a5d7164f","modified":1733714522685},{"_id":"source/_posts/2019-04-24-MySQL-连接异常问题.md","hash":"174d0b084531d0adf324a40673ad7702e981a15a","modified":1733714777278},{"_id":"source/_posts/2019-05-18-bio.md","hash":"ff4d736161d0823dd9bbe9bf186814ca4074de12","modified":1728898691898},{"_id":"source/_posts/2019-06-14-nio.md","hash":"05174d563717085df498afcf20e56291920b063a","modified":1728898691900},{"_id":"source/_posts/2019-06-16-socket创建过程.md","hash":"ff512e612c70b7afffbf15609a0d10a7030c97f7","modified":1728898691901},{"_id":"source/_posts/2019-06-18-netty.md","hash":"5ff27c165816dff956b4565db7549959fe96dd4a","modified":1728898691902},{"_id":"source/_posts/2019-06-28-hadoop.md","hash":"eafc9f76501679735412497e5bbcd2286c3495bd","modified":1728898691902},{"_id":"source/_posts/2019-07-03-hbase.md","hash":"0f7a62e499c17cc5eead0aa065805e1697091bb3","modified":1728898691912},{"_id":"source/_posts/2019-07-20-HIVE.md","hash":"40fca5e36412b37c86a5096e03dbb27e464f3b90","modified":1728898691982},{"_id":"source/_posts/2019-07-13-zookeeper.md","hash":"1a2993f8366a5a0719c9fb2001dfc039833bf981","modified":1728898691945},{"_id":"source/_posts/2019-07-24-DMQ.md","hash":"01755d1a81a77df5d1038fcdef8466818738d151","modified":1728898691987},{"_id":"source/_posts/2019-08-01-MQ对比.md","hash":"80e0ffbaa5b6aa9a569f25bb62415242a9dcfb2e","modified":1728898691997},{"_id":"source/_posts/2019-08-19-RPC.md","hash":"00f11e5baf41e0928fe1f16489823193aefe4068","modified":1728898692006},{"_id":"source/_posts/2019-08-21-熔断降级.md","hash":"6f4a136bf3a5acb77623ed30d00f009fbb442660","modified":1728898692014},{"_id":"source/_posts/2019-11-30-tomcat架构.md","hash":"b955ef0bf9478e647c8b4bfea390856f022c044d","modified":1728898692014},{"_id":"source/_posts/2019-12-20-tomcat启动过程.md","hash":"9012998d6e2a0e6c2c8c63f42b9bba8f1f977b9e","modified":1728898692019},{"_id":"source/_posts/2019-12-21-tomcat启动过程2.md","hash":"3516c3697f9ba10f3ff8921cce0d37f4babd2b83","modified":1728898692028},{"_id":"source/_posts/2019-07-07-hbase梳理.md","hash":"5812c0baa0f890b8c3aa270ec64c1a682c231e30","modified":1728898691919},{"_id":"source/_posts/2019-12-22-tomcat-webxml解析.md","hash":"53f657c09880a14a9e253efab2f7507f151014b0","modified":1728898692034},{"_id":"source/_posts/2020-01-01-tomcat-netty对比.md","hash":"32aff4ff3f807611f814b95e2d0bba217d3fed4f","modified":1728898692043},{"_id":"source/_posts/2020-03-29-磁盘局部性原理.md","hash":"2b1dcf003d7f273dda069d028342cb956cb85113","modified":1728898692044},{"_id":"source/_posts/2020-04-04-cpu.md","hash":"ba179ddaa28e0e5889ba56367a86db44c95f23e8","modified":1733714623272},{"_id":"source/_posts/2020-04-06-volatile.md","hash":"d4073d4597224ab4cf223394d2a225656e6c7396","modified":1733714522693},{"_id":"source/_posts/2019-12-22-tomcat请求过程.md","hash":"142d746625fba989bd5c0f424b3c9395459dfa74","modified":1728898692040},{"_id":"source/_posts/2020-04-10-linux-pagecache.md","hash":"db41b414df4957606c4cfb50b679b6a779792912","modified":1733714610948},{"_id":"source/_posts/2020-04-09-Linux-thread.md","hash":"8fd5a21c57ab892025f95c5c61d0d6de5da84a41","modified":1733714610958},{"_id":"source/_posts/2020-04-11-java-虚拟机规范.md","hash":"99c038de0d83377ad006dd7cb53f28078b0c4dba","modified":1733731050124},{"_id":"source/_posts/2020-04-13-ThreadLocal.md","hash":"b15ea3f5197afcff5919fd9a22944e7746fd2dc1","modified":1733714522516},{"_id":"source/_posts/2020-04-13-强弱软虚.md","hash":"38ba83f0d34b976a09e2890c76fb53c6fe59e4c7","modified":1733714522545},{"_id":"source/_posts/2020-04-12-线程池.md","hash":"2384a0c1a319ffac65d9dd8a7984cac287214dbc","modified":1733714522665},{"_id":"source/_posts/2020-05-10-JMM.md","hash":"f7a9e30739cb89a12f4062965eaf6256ab93f057","modified":1733714522628},{"_id":"source/_posts/2020-05-07-零拷贝.md","hash":"8dab627c66857ffa02654ccef61cc212f52538f8","modified":1728898692218},{"_id":"source/_posts/2020-05-11-类加载.md","hash":"b6da48ad015a5174aa7d4426766ef520d267fe00","modified":1733714522617},{"_id":"source/_posts/2020-05-14-枚举.md","hash":"fec2deb6dbf7153e3a81bfcc0eba3f9c75d386f7","modified":1733714522525},{"_id":"source/_posts/2020-05-13-单例.md","hash":"f1df8b2151101bcb9d151f7d7769e40ba8f3fa03","modified":1733714522648},{"_id":"source/_posts/2020-05-15-泛型.md","hash":"750da61d41b5e29d913c6efd7a7851be90b1de9c","modified":1733714522658},{"_id":"source/_posts/2020-05-16-java对象.md","hash":"f917041482f5b159e4d5d811259d3afac48b7324","modified":1733714522674},{"_id":"source/_posts/2020-06-01-es.md","hash":"b2e367a774199fce20fbff953bbb13b842bb969f","modified":1728898692303},{"_id":"source/_posts/2020-06-14-分布式主键ID.md","hash":"52010a17b9b5782555546b7a289664254b541370","modified":1728898692312},{"_id":"source/_posts/2020-06-07-订单ES.md","hash":"157205a4136cb1fc24a223f256147b595cc2eb06","modified":1728898692309},{"_id":"source/_posts/2020-07-01-分库分表.md","hash":"ba3b6ba791a0af8e6f016f905d31dd9b08b03fa7","modified":1728898692323},{"_id":"source/_posts/2020-10-19-交易账单.md","hash":"05824e5bf5626e57f0e6a81dd90e941bcca12bf8","modified":1728898692330},{"_id":"source/_posts/2021-01-04-springmvc.md","hash":"9cac1be6c42e97ab3beff94acaf72f755a825767","modified":1729216589763},{"_id":"source/_posts/2024-03-01-性能优化-启动优化.md","hash":"f91e7c2ec1d0fb0e3c4c77c937d0844a8807fc69","modified":1733714777297},{"_id":"source/_posts/2024-03-03-性能优化-MySQL查询优化.md","hash":"0596e37e547454294bd1123dc5c2fb9a12837431","modified":1733714777288},{"_id":"source/_posts/2024-03-05-性能优化-多线程优化.md","hash":"e6d1c30632426b295744ee9a61560fc3bc63e040","modified":1729325318485},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化.md","hash":"a7ea16efcd4310342359c141ea368de285f4aba5","modified":1733714554493},{"_id":"source/_posts/2024-03-20-性能优化-服务RT上升.md","hash":"daa94df67e764420836a0037780cb163674b5d6a","modified":1733714522564},{"_id":"source/_posts/2024-04-10-性能优化-日志优化.md","hash":"a8d346c2db1acd18fa498477c8b108b542c83b73","modified":1729514381072},{"_id":"source/_posts/2024-05-04-系统重构-资产管理系统重构.md","hash":"1a5df6890bef1096055bff2df01ab41714250266","modified":1733714777258},{"_id":"source/_posts/2024-05-29-稳定性-高可用建设.md","hash":"f1a4fef416e3cf3cebea942a8a5841c9cedd9b45","modified":1729827118726},{"_id":"source/_posts/2024-06-03-稳定性-线程池监控.md","hash":"152844b24b07f2ae5cac52b0f5a69905066b91a9","modified":1729827713543},{"_id":"source/_posts/2024-06-05-Linux-CPU负载和利用率.md","hash":"2e085c13e59710f372563033606e1244fc93a177","modified":1733714573878},{"_id":"source/_posts/2024-06-09-稳定性-订单拉单.md","hash":"9e12f9620e221f1f711c7db0a5a4765798f79460","modified":1729846292956},{"_id":"source/_posts/2024-06-15-稳定性-线程池要设置多大.md","hash":"6d9416c40cf47bbcb9d4749d76838933b6818715","modified":1730106048584},{"_id":"source/_posts/2024-06-29-稳定性-变更三板斧.md","hash":"4b37ea538e689f5657549af051520153cc3f6a90","modified":1730105711909},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念.md","hash":"6e7838ffce8133f3282ad1dc24ee376dde5cb9a6","modified":1730277084403},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例.md","hash":"ec009c7c319706cea8298d46b790f4c0fe125146","modified":1730366744771},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控.md","hash":"ce9f9dd2c617bf6699f099d18ca187d422651bed","modified":1731036704484},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结.md","hash":"993a403441aeb8df8cbdaafa7f22c5171cc3e7be","modified":1730971432023},{"_id":"source/_posts/2020-04-11-java-thread.md","hash":"d7cbcf2cf4f07b4272ecfda595b8885abc538f88","modified":1733714522679},{"_id":"source/_posts/2024-08-20-架构-架构.md","hash":"4e921369d8322d1488428ff6f0cc86935f5ec876","modified":1732160531915},{"_id":"source/_posts/2021-01-10-Mybatis.md","hash":"bc9d6c7f46a5d17cfab876b7aad3bc090f1804ba","modified":1729216432179},{"_id":"source/_posts/2020-12-28-spring启动过程.md","hash":"8bea2031f9043189847a85c85a35ba624d092b0b","modified":1729216614324},{"_id":"source/_posts/2024-08-25-架构-常见架构.md","hash":"6d160fdcfb32b8f1bddaed8c180665d97dfd75bc","modified":1732872291709},{"_id":"source/_posts/2024-08-21-架构-三高.md","hash":"749de77769e5aa8151c52e54c9a51852e9a3de69","modified":1732589988793},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程.md","hash":"23e1b34636295d885edeeb8e50f001795f13057d","modified":1733195635191},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构.md","hash":"5fda8d483f50d73c0ed6138d8b07c9da1aa7aeaf","modified":1733239214909},{"_id":"source/_posts/本博客搭建.md","hash":"bfa3d3a607959c1394c4f1085c623764bdd0b3a0","modified":1729136691416},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD.md","hash":"5a974a4bc34424e113039e2f82145698a77f8d2d","modified":1733474005288},{"_id":"source/categories/index.md","hash":"fa7a8261e492ea2dd318d68a1e644b71cc03173b","modified":1728898692374},{"_id":"source/tags/index.md","hash":"c28f7765f0db60695ece80a5478253847b8749a0","modified":1728898692376},{"_id":"themes/next/.git/COMMIT_EDITMSG","hash":"3b76ea13ba2d9611af22b59c1d1a83a65758a71b","modified":1729085305078},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1728912368163},{"_id":"themes/next/.git/config","hash":"bf7d1df65cf34d0f25a7184a58c37a09f72e4be7","modified":1728912368170},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1728912256872},{"_id":"source/_posts/2024-08-23-架构-常见技术框架性能.md","hash":"c28a0e057202e2cbf92084f727bdbaf36f4e3024","modified":1732632311647},{"_id":"source/_posts/2024-08-28-架构-DDD概念.md","hash":"01a7153217a0d4842780eb0879a1787d8e2db7be","modified":1733237507059},{"_id":"themes/next/.git/index","hash":"d40ee532edf148cb1e922116d0135f477a57c4bc","modified":1729085305073},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1728912368178},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"50d48c47162817a3810a9d9ad51104e83947419a","modified":1728912368177},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1728912368177},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1728912368178},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1728912368189},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1728912368203},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1728912368203},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1728912368203},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1728912368203},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1728912368203},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1728912368203},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1728912368204},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1728912368185},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1728912368186},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1728912368186},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1728912368186},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1728912368186},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1728912368187},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1728912368187},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1728912368187},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1728912368187},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1728912368187},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1728912368187},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1728912368188},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1728912368188},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1728912368188},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1728912368204},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1728912368188},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1728912368205},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1728912368188},{"_id":"themes/next/.git/packed-refs","hash":"f83040a26e919c4b3e4cad7c71b8b52137356707","modified":1728912368154},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1728912368471},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1728912368471},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1728912368471},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1728912368372},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident/redis-connect.jpg","hash":"ad962246bd2fe6d3cd53dc6dae7af1728b4cfc6c","modified":1728898691809},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/redis-connect.jpg","hash":"ad962246bd2fe6d3cd53dc6dae7af1728b4cfc6c","modified":1728898691842},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql-explain.png","hash":"a0b6bfed09b96a64ff28f2498ea780148d040e12","modified":1728898691847},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-cos-time.png","hash":"3b5e726bbf50cb18582357a0f9f8ae57b8c178b6","modified":1728898691850},{"_id":"source/_posts/2019-03-05-单点登录现状/cas-logout.svg","hash":"be32bbdf4f061d23cdf440726e50db040943b2ec","modified":1728898691854},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-explain.png","hash":"631884a67afce89668847190404dbd22136b6e34","modified":1728898691850},{"_id":"source/_posts/2019-03-05-单点登录现状/cas-login.svg","hash":"b1b1bf97733a3c5fed4785ffeb5b1b7fcb7d79fc","modified":1728898691854},{"_id":"source/_posts/2019-05-18-bio/bio.png","hash":"1a1e8de6329fa900b6e3b8e82c5dadf9be1a8b11","modified":1728898691899},{"_id":"source/_posts/2019-06-28-hadoop/BlockManager.jpg","hash":"f6e79fe63489471cd174d12f893eacaaabdc231d","modified":1728898691903},{"_id":"source/_posts/2019-06-28-hadoop/namespace.png","hash":"f7956a00ec81d39b3d701359c48ddbe5bc8db528","modified":1728898691907},{"_id":"source/_posts/2019-06-28-hadoop/hdfs-整体图.jpg","hash":"f3338ff7a160bd0be81508badf1cd4015a8e0c17","modified":1728898691905},{"_id":"source/_posts/2019-06-28-hadoop/namespace1.jpg","hash":"a66df1f3ff186fbadafd2aed0316f7117c8a2705","modified":1728898691907},{"_id":"source/_posts/2019-06-28-hadoop/hdfs-架构.png","hash":"4ef8e2544cab79cae364f6ac8c6d4bbd93b6dfba","modified":1728898691906},{"_id":"source/_posts/2019-07-03-hbase/HBASE工作原理.png","hash":"fe2a2bad7313760d171fd15e29f705796470ec10","modified":1728898691915},{"_id":"source/_posts/2019-07-03-hbase/businesslog.png","hash":"b081121d54c327406a1452a804d8d9a17a40a503","modified":1728898691915},{"_id":"source/_posts/2019-07-07-hbase梳理/businesslog.png","hash":"b081121d54c327406a1452a804d8d9a17a40a503","modified":1728898691921},{"_id":"source/_posts/2019-07-07-hbase梳理/HBASE工作原理.png","hash":"fe2a2bad7313760d171fd15e29f705796470ec10","modified":1728898691921},{"_id":"source/_posts/2019-07-13-zookeeper/选举1.png","hash":"c755ccdada61803323961cc55b37074f09b3cb8d","modified":1728898691981},{"_id":"source/_posts/2019-07-13-zookeeper/选举2.png","hash":"f5f9464d851deba7c65df352bc8d8053c63b6d6f","modified":1728898691982},{"_id":"source/_posts/2019-07-24-dmq/mq-server-send.png","hash":"075e6984a206b0a6e99852073c1a314121babf31","modified":1728898691995},{"_id":"source/_posts/2019-07-24-dmq/mq-server-sub.png","hash":"7b383887066f1190d984fa88726b2ccdef8f915e","modified":1728898691996},{"_id":"source/_posts/2019-07-24-dmq/mq-server-resend.png","hash":"b7fe990c5d9902c4f745512febb03155966d4a62","modified":1728898691995},{"_id":"source/_posts/2019-07-24-dmq/mq-server-start.png","hash":"468b8cfad6b5a46eacbca3e0242f712e006255d3","modified":1728898691995},{"_id":"source/_posts/2019-08-01-MQ对比/rocketmq-messagequeue.jpeg","hash":"f33685bf12aa2d13b657fe3218e40d6a59daa2bb","modified":1728898692003},{"_id":"source/_posts/2019-08-19-RPC/RPC.png","hash":"dd976ca54a397e5bad5fe4788b4f5ea46d7c51fa","modified":1728898692007},{"_id":"source/_posts/2019-08-01-MQ对比/kafka-consumer注册.jpeg","hash":"5015cfc95937e7645ae034e33d9a9041c1e45a45","modified":1728898691999},{"_id":"source/_posts/2019-08-19-RPC/客户端架构.png","hash":"c1dbbd365209107218abe4343c9367a53d3497f9","modified":1728898692012},{"_id":"source/_posts/2019-11-30-tomcat架构/container-framework.jpeg","hash":"2e388226e337166944f6dd4440ba4181205044b8","modified":1728898692017},{"_id":"source/_posts/2019-11-30-tomcat架构/connect-flow.jpeg","hash":"abe023e88f2033d1928164dbc870517fe83f8535","modified":1728898692015},{"_id":"source/_posts/2019-11-30-tomcat架构/tomcat-framework.jpg","hash":"aae590fe1a3e62dd2aabeb189b6dd4266a03348a","modified":1728898692019},{"_id":"source/_posts/2020-04-06-volatile/cache_sync.png","hash":"0cccbe36d666728e1445cf5600cad13ea00f327d","modified":1728898692085},{"_id":"source/_posts/2020-04-10-linux-pagecache/27_file_page_device_block.png","hash":"936ace83f004d4bfd913271854a4c275ebe6cacf","modified":1728898692159},{"_id":"source/_posts/2020-06-01-es/存储目录结构图.png","hash":"1ee40983632ca288462c9a70e0b43173dd2876ad","modified":1728898692306},{"_id":"source/_posts/2020-06-01-es/数据逻辑结构.png","hash":"312a1b22d21e1e67d3335e7d12c7c33704099d6b","modified":1728898692307},{"_id":"source/_posts/2020-06-01-es/集群架构.png","hash":"bbd0f8a28af26fe77c14c5e0035dc3ec6e2fe27b","modified":1728898692308},{"_id":"source/_posts/2020-07-01-分库分表/方案一.png","hash":"3ee0905a124b5ae266a89643c1c7a019a64c7839","modified":1728898692324},{"_id":"source/_posts/2020-07-01-分库分表/方案二.png","hash":"3e18fde719e3155a82471a22f1ddf47b2a6210d8","modified":1728898692327},{"_id":"source/_posts/2020-10-19-交易账单/交易流程图.png","hash":"5a889184413d5665521b5073f6be9bfc18506b3f","modified":1728898692334},{"_id":"source/_posts/2020-10-19-交易账单/交易状态流转.png","hash":"da8e6df67921be01f09b543059619f2e83345222","modified":1728898692334},{"_id":"source/_posts/2020-10-19-交易账单/表结构关系图.png","hash":"397da858fe56d390c9273bff6908162996cb9eeb","modified":1728898692335},{"_id":"source/_posts/2020-10-19-交易账单/账单状态流转.png","hash":"97d462b0a3bc05a9ca6e19b0dd1b23d9e5606cb1","modified":1728898692337},{"_id":"source/_posts/2020-12-28-spring启动过程/ApplicationContext.png","hash":"5fb16e8173389e7251fd63e086523a35daba2349","modified":1728898692338},{"_id":"source/_posts/2021-01-04-springmvc/springmvc-流程.png","hash":"59b19265f56d6af381cfea663aa8c7fab5e3c6b5","modified":1728898692374},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/AsyncInitBeanFactoryPostProcessor-registerAsyncInitBean.png","hash":"ca0aec6171c819ab54fd1a8b8f4ebed1f086f9c6","modified":1729071909748},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/启动加速-自动扫描异步类.png","hash":"3a8d0f43b007835efb84745677282f7b4a64fa67","modified":1729067941050},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/spring初始化流程.png","hash":"0a4ff6bc57efbe00dc70535772bc2f815a2bcd4a","modified":1729068889504},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/注解解析.png","hash":"a447e8ff2bcdebe2aabdc0493b53ad3924e35cbe","modified":1729072233770},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/业务日志.png","hash":"7c4b2884952d16809512faa7f3cf8788e8236b4f","modified":1729255752218},{"_id":"source/_posts/2024-05-04-系统重构-资产管理系统重构/技术架构.png","hash":"a1d2402a4f194127715670f384730abe94fc6b78","modified":1729516158416},{"_id":"source/_posts/2024-06-05-Linux-CPU负载和利用率/CPU利用率.png","hash":"4281c9cea104abc250e2aeb2fde17b02799efb6a","modified":1729842005898},{"_id":"source/_posts/2024-06-05-Linux-CPU负载和利用率/CPU负载示例.png","hash":"99d6ce68f95ec56d27763ed451c2dd834a0d2960","modified":1729823190381},{"_id":"source/_posts/2024-06-05-Linux-CPU负载和利用率/cpu负载.png","hash":"d3c9c98d0a0fea0e03b353489a73acb3219e8258","modified":1729823597713},{"_id":"source/_posts/2024-06-15-稳定性-线程池要设置多大/队列和流量的关系.png","hash":"4dcfd1259ea1da111d0cced3e3cf9e57b4af6f59","modified":1729999080576},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念/什么是单元化.png","hash":"fe7068b0c842b33f818856ddf1a8f3e2d32ee33a","modified":1730107296009},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/4阶段.png","hash":"8dafb92666e597f847dce40cc9784cdecda0c98a","modified":1730299372569},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/常见的数据一致性方案.png","hash":"6997f4223f366a4f4ab845da725cf657266c5d79","modified":1730366437055},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/现状.png","hash":"539a0be822750c1f117301c74a02948855e62474","modified":1730276877287},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/目标.png","hash":"909542c2fa88607c0f2368bb24496eb422243899","modified":1730277271096},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控/数据同步工作原理.png","hash":"da8e9566e3c3086c0eebed8350d2eba4197197b5","modified":1730970677198},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控/数据迁移工作原理.png","hash":"b288bb6b62f9feb0b0b38c0c88aaf44c4b66c4da","modified":1730968972219},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/数据一致性_存量.png","hash":"20fe094c423d3ca9a384122b2da83fe0bd6f4741","modified":1730430780784},{"_id":"source/_posts/2024-08-21-架构-三高/并发度公式.png","hash":"be6bbfa1cfa097738c960d4e8b4d8d8c67494df0","modified":1732505400267},{"_id":"source/_posts/2024-08-20-架构-架构/装饰者模式.png","hash":"ab5bf6d8cecdc5829adc3f0165bc457ad436e3ef","modified":1731380308147},{"_id":"source/_posts/2024-08-25-架构-常见架构/系统架构-分布式架构.png","hash":"b5689a1b261f030680122315f5a9f06b31e25099","modified":1731919910586},{"_id":"source/_posts/2024-08-25-架构-常见架构/系统架构-单体架构.png","hash":"d2b644ec6fdc50463ed0514258f57a7c836e8dad","modified":1731919729437},{"_id":"source/_posts/2024-08-25-架构-常见架构/三层架构.png","hash":"235ececf0cefcca41a03fd04c0e6b72f32875ede","modified":1731917302346},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/分层架构_代码指示.png","hash":"d88a543bfa95b4827f3ed7afa5928c8a46379803","modified":1733191943265},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/分层架构_代码指示.png","hash":"d88a543bfa95b4827f3ed7afa5928c8a46379803","modified":1733191943265},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/DDD包结构展开.png","hash":"3eaf64d80fad10b0f7e0930be7709124b7b53462","modified":1733473038801},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/传统分层代码结构.png","hash":"7087347d137766da51e748e8b9e08faca58f6a23","modified":1733471673314},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1728912256874},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1728912256876},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1728912256872},{"_id":"themes/next/.git/hooks/fsmonitor-watchman.sample","hash":"118ff5509f187039734d04456bf01e44c933ac19","modified":1728912256875},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"a79d057388ee2c2fe6561d7697f1f5efcff96f23","modified":1728912256873},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1728912256877},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"a599b773b930ca83dbc3a5c7c13059ac4a6eaedc","modified":1728912256877},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1728912256875},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1728912256875},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1728912256873},{"_id":"themes/next/.git/hooks/update.sample","hash":"730e6bd5225478bab6147b7a62a6e2ae21d40507","modified":1728912256878},{"_id":"themes/next/.git/hooks/push-to-checkout.sample","hash":"508240328c8b55f8157c93c43bf5e291e5d2fbcb","modified":1728912256878},{"_id":"themes/next/.git/logs/HEAD","hash":"615146476f799c8425a8acb9dd584858de6f3c11","modified":1729085305085},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1728912256872},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1728912368189},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1728912368189},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1728912368200},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1728912368200},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1728912368200},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1728912368200},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1728912368201},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1728912368200},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1728912368201},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1728912368191},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1728912368192},{"_id":"themes/next/layout/_partials/footer.swig","hash":"fb3b1c4f444343d953ba845671e027406ee4ffba","modified":1729083809241},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1728912368192},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1729084492881},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1728912368193},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1728912368192},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1728912368189},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1728912368189},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1728912368190},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1728912368190},{"_id":"source/images/touxiang.jpg","hash":"5831ff48e6fa41ae20250879f29ed1f1526e99ab","modified":1728898692376},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1728912368191},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1728912368205},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1728912368205},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1728912368205},{"_id":"themes/next/scripts/tags/exturl.js","hash":"919ab7496c0031020c7b7242486531b1f7a135a7","modified":1728912368205},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1728912368206},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1728912368206},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1728912368206},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1728912368207},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1728912368207},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1728912368371},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1728912368376},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1728912368375},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1728912368376},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1728912368378},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1728912368377},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1728912368379},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1728912368382},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1728912368383},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1728912368388},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1728912368388},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1728912368389},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1728912368389},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1728912368393},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1728912368395},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1728912368396},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1728912368389},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1728912368396},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1728912368396},{"_id":"themes/next/.git/hooks/pre-merge-commit.sample","hash":"04c64e58bc25c149482ed45dbd79e40effb89eb7","modified":1728912256876},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1728912368190},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident/redis-io.jpg","hash":"86c4c028b471e81912ebce5465f0d98db1f51dcd","modified":1728898691810},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/内存情况.png","hash":"95faa70a5a9d5085d8c8d035cdbeb518eace2230","modified":1728898691846},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/mysql.png","hash":"80bc72acdbebf0432a58a61871fdc406238a7143","modified":1728898691849},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/redis-io.jpg","hash":"86c4c028b471e81912ebce5465f0d98db1f51dcd","modified":1728898691844},{"_id":"source/_posts/2019-03-05-单点登录现状/CAS基础协议.png","hash":"0b1975b3c9736239ddf8c6684d2dc23dd69a88bd","modified":1728898691853},{"_id":"source/_posts/2019-03-05-单点登录现状/uum现状.png","hash":"b76f6255317d336533c0c284b77d8f8a602e96d8","modified":1728898691857},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql.png","hash":"74d78cce562e196a998cd2bbf891da8dd405b9f7","modified":1728898691848},{"_id":"source/_posts/2019-06-14-nio/nio-common.png","hash":"19e860cad01af1e5ce3b3e48241601d9d377fd22","modified":1728898691901},{"_id":"source/_posts/2019-06-28-hadoop/hadoop-架构.png","hash":"5c5e79a2222bc680b437ced866b76ea90dc9cab8","modified":1728898691905},{"_id":"source/_posts/2019-07-03-hbase/HBASE存储.png","hash":"26709b0635c3f79a4847a3e2ce770295ee7a5cc7","modified":1728898691914},{"_id":"source/_posts/2019-07-07-hbase梳理/HBASE存储.png","hash":"26709b0635c3f79a4847a3e2ce770295ee7a5cc7","modified":1728898691920},{"_id":"source/_posts/2019-07-03-hbase/uumsize.jpg","hash":"b02b79fd7c12839eb33b781079b7b210330b5797","modified":1728898691919},{"_id":"source/_posts/2019-07-07-hbase梳理/uumsize.jpg","hash":"b02b79fd7c12839eb33b781079b7b210330b5797","modified":1728898691927},{"_id":"source/_posts/2019-07-13-zookeeper/实现分布式锁流程.png","hash":"3594e09eed5e1cf8de5fe1ba59d3be482c5768fe","modified":1728898691969},{"_id":"source/_posts/2019-07-13-zookeeper/分布式锁.png","hash":"f80dc75a7dc2ba8e9c18120df3ee96546611d59a","modified":1728898691967},{"_id":"source/_posts/2019-07-24-dmq/mq-center.png","hash":"a4988a6da4b2dcfc255f138ec77a4ab79010be60","modified":1728898691988},{"_id":"source/_posts/2019-07-20-HIVE/HIVE架构.jpeg","hash":"0e5a0a8f3273937153315ff1f4f99d65157cb79e","modified":1728898691983},{"_id":"source/_posts/2019-07-24-dmq/mq-client-center.png","hash":"f0de98fdfc22df465c3a0444b12ea5e997a161c6","modified":1728898691990},{"_id":"source/_posts/2019-08-01-MQ对比/kafka-broker.png","hash":"38bbce01f3ce9450bb3585125a184dea81d01dcb","modified":1728898691998},{"_id":"source/_posts/2019-08-01-MQ对比/mq-center.png","hash":"a4988a6da4b2dcfc255f138ec77a4ab79010be60","modified":1728898691999},{"_id":"source/_posts/2019-08-01-MQ对比/rocketmq_design_1.png","hash":"ac4e43b881bb32198802e7b09bde7a6d44db3f02","modified":1728898692005},{"_id":"source/_posts/2019-08-01-MQ对比/rocketmq_architecture_3.png","hash":"8721a713506b200b6bf1278a4063b66d3f0895f5","modified":1728898692004},{"_id":"source/_posts/2019-08-19-RPC/方法调用过程.png","hash":"8cf8e1d9c18ea292bb652409b267e45e7556141d","modified":1728898692014},{"_id":"source/_posts/2019-11-30-tomcat架构/connect-framework.jpeg","hash":"341bea3b387297e5c86d8741ac324ba818134628","modified":1728898692016},{"_id":"source/_posts/2019-12-20-tomcat启动过程/tomcat-starting-procedure.jpeg","hash":"9592d6760dedd76dfc6a51794a3d74915976b029","modified":1728898692020},{"_id":"source/_posts/2019-11-30-tomcat架构/coyote-frame.png","hash":"62ee67973539c82dd6bd6eeb9b2ef4284faf9cba","modified":1728898692018},{"_id":"source/_posts/2019-12-21-tomcat启动过程2/tomcat-starting-procedure.jpeg","hash":"9592d6760dedd76dfc6a51794a3d74915976b029","modified":1728898692029},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1728912368194},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1728912368194},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1728912368195},{"_id":"source/_posts/2020-04-06-volatile/volatile字节码.png","hash":"efda39b957f01ed89f65cfa4123953e652cfedbe","modified":1728898692094},{"_id":"source/_posts/2020-04-12-线程池/定时任务-数据结构.png","hash":"2832ca12c768c99339883269d5a59e5389cb9f46","modified":1728898692189},{"_id":"source/_posts/2020-06-07-订单ES/数据同步方案.png","hash":"7721b11ce95b37a17c8f7d327c13cbc9d1fd1d11","modified":1728898692311},{"_id":"source/_posts/2020-07-01-分库分表/方案二优缺点.png","hash":"5f685f087501ea29fc85a3185a59eb36536e8a19","modified":1728898692328},{"_id":"source/_posts/2020-06-01-es/倒排索引组成.png","hash":"f7a3b297a7ee239313ecff323e19ca5f0e3e58a1","modified":1728898692306},{"_id":"source/_posts/2020-07-01-分库分表/方案一优缺点.png","hash":"ebe56cd0589639b7d86899944b0f5402d16306bf","modified":1728898692325},{"_id":"source/_posts/2020-07-01-分库分表/方案二对比.png","hash":"8c31aa190b1213e511178ee965355cf05baa31b3","modified":1728898692329},{"_id":"source/_posts/2020-07-01-分库分表/方案一对比.png","hash":"b7c27ffbe2bf4f437e8e9e7e6bc7c8dc2d06447b","modified":1728898692326},{"_id":"source/_posts/2020-10-19-交易账单/表结构具体内容.png","hash":"e27d06e83c691152088e02913dfb13b4cc85a394","modified":1728898692336},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/registerAsyncInitBean具体实现.png","hash":"1321cb45159f1e72f0a57c408de57b8499474ab0","modified":1729072028524},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/beanpostprocessor.png","hash":"02d7526c94001f56a995db06c7a7be894fa5d816","modified":1729080595053},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/异步化.png","hash":"47a8fa7eb8abfc3bcccd535d1b2b404551ef396f","modified":1729080724918},{"_id":"source/_posts/2024-03-03-性能优化-MySQL查询优化/异构索引表.png","hash":"f61ab1f6bd9a8e2313213dafc0fc784fcf717b46","modified":1729167828728},{"_id":"source/_posts/2024-05-29-稳定性-高可用建设/防.png","hash":"ba70900b914c159f743134e770b613c3b2f299c5","modified":1729777607017},{"_id":"source/_posts/2024-06-03-稳定性-线程池监控/ThreadPoolExecutor加锁.png","hash":"c92d797efb8f0dd4d453853159b65abcf1ac1484","modified":1729739959169},{"_id":"source/_posts/2024-06-03-稳定性-线程池监控/线程池监控大盘.png","hash":"e454612dbd9563147a89b1e8a42518f5d676f985","modified":1729740262403},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/切流方案.png","hash":"e4eb644533b032976b1bf155edba3b05ed1857e9","modified":1730363484396},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/切流流程.png","hash":"5a744705710ccd724e13784053616ddd1835b0f0","modified":1730365987186},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/路由逻辑.png","hash":"a012979f289522f6f1018cd631e4cc9498034f76","modified":1730300038419},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控/数据处理流程.png","hash":"5fe307b416d86d5d564d0b429a3166e4f5c8d339","modified":1731033497907},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/先双写后存量.png","hash":"0c73b7d75ac9a7753b6536466e970d3123158a4a","modified":1730964901919},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/双写先.png","hash":"de2212a95962717203334fa88561e7095c4b5b59","modified":1730971335577},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/数据一致性_增量.png","hash":"ee76d8e2eac687d201e3a245c067ef7825cf1721","modified":1730430796256},{"_id":"source/_posts/2024-08-20-架构-架构/观察者模式.png","hash":"46fca98d47d12ac68ce95d5ae0d7c4d589a5d9b2","modified":1731639363811},{"_id":"source/_posts/2024-08-23-架构-常见技术框架性能/正反向代理.png","hash":"7d6a40d105dbd3430ee280cfbbfdd24528203486","modified":1732612370491},{"_id":"source/_posts/2024-08-25-架构-常见架构/MVC架构工作流程.png","hash":"e850200cf744ca29b0b6b3feaf05e3ee9e2f5d46","modified":1731916964401},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/传统4层架构.png","hash":"1289d18faeabdee8f1f6ce147388f51f893e35d5","modified":1733189135415},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/洋葱架构.png","hash":"f975f675c5bdc5e4c3a340ecd3a60598b4e4f9d6","modified":1733193684655},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/战略战术结果.png","hash":"21d75ee7f15ae16e7adf907f68977a03d2ae7ca0","modified":1732850102760},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/商品领域.png","hash":"ac160b0cfd05b6518aa73c31b18090ea22056447","modified":1732782933729},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/DDD包结构.png","hash":"d0139e738b9d9354155f34bd73b2a41824cf83f0","modified":1733473178845},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/DDD完整设计流程.png","hash":"0cfa01ed70a489523d1611bf507e5d196597f329","modified":1732782266051},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1728912368370},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1728912368371},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1728912368321},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1728912368321},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1728912368328},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/jmap.png","hash":"81c6142583af566f7e1d1094e9c504c790d3414f","modified":1728898691822},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident/sqlsession-class-relation.jpg","hash":"1d886da4e99324b85f546b7dcc058c46f1ade1b8","modified":1728898691813},{"_id":"source/_posts/2019-04-11-Linux-io模型/sync-block.png","hash":"28049a44fae989f2e1064c513ac693787e085429","modified":1728898691892},{"_id":"source/_posts/2019-04-24-MySQL-连接异常问题/mysql-error.png","hash":"1caf67afb836e3fc9ae4ec64fdff7132d50ab7d8","modified":1728898691898},{"_id":"source/_posts/2019-07-13-zookeeper/watch.png","hash":"490b4b0cc81e39bd8d1276fd590b6d6144009dc8","modified":1728898691950},{"_id":"source/_posts/2019-07-24-dmq/mq-总结.png","hash":"f282086c871edb6b2c1e5f9ef819dea6234da9c0","modified":1728898691997},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1728912368195},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1728912368195},{"_id":"source/_posts/2020-04-09-Linux-thread/slab.png","hash":"78ecc66cb1d473ea4005f115e39ce36c739c1066","modified":1728898692124},{"_id":"source/_posts/2020-04-12-线程池/定时任务.png","hash":"041d9ee297c559a5ccf959a8382619a45dd26212","modified":1728898692191},{"_id":"source/_posts/2020-06-01-es/倒排索引.png","hash":"9bfa70acde2f72b77fd788a2dd55c90278f113e2","modified":1728898692305},{"_id":"source/_posts/2020-06-01-es/正排索引.png","hash":"2c2d88cceefd1b1cd7f6590823add38a5dcff5ea","modified":1728898692308},{"_id":"source/_posts/2020-06-07-订单ES/常见问题及解决方案.png","hash":"e088de536ad25aaf3b9d8c29a9d2ae5718ce1196","modified":1728898692310},{"_id":"source/_posts/2020-10-19-交易账单/业务模式.png","hash":"3162dbc53ecca4c9c03c1ab12e2f8302d26dd94b","modified":1728898692332},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/spring实例初始化流程.png","hash":"7dc300fd0d05d91ce69386ad8dde724494e29bf1","modified":1729069246639},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/性能效果.png","hash":"a9c26b271873a58ab6646bbd76d01872fc106496","modified":1729080392608},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/编译发布流程图.png","hash":"867e6c3943a55e281e8d35714dd2b54163dc3ed6","modified":1729049812228},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/metaspaceoom.png","hash":"bd1596935253c1e609cd1c3e52a4968cc6ca62ed","modified":1729254554681},{"_id":"source/_posts/2024-04-10-性能优化-日志优化/AsyncAppender.png","hash":"3e7caa165e293c1e4d2511cbe8be131f9c162d2c","modified":1729501280384},{"_id":"source/_posts/2024-06-03-稳定性-线程池监控/总监控.png","hash":"9e66566541bb6a85611b17573db14870e3db13c7","modified":1729757924114},{"_id":"source/_posts/2024-06-15-稳定性-线程池要设置多大/线程池参数配置方案.png","hash":"0a8da38ef6924ada3a1fde9ca01b7ebd017b222e","modified":1729863568478},{"_id":"source/_posts/2024-06-29-稳定性-变更三板斧/可监控.png","hash":"ddde0216474480d9b41f6bb0001e7d21592e8637","modified":1730085259315},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/数据库层.png","hash":"5c6dd3376ac6e3140d2953e3513ede90e60be602","modified":1730361709131},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控/延迟时间.png","hash":"5fec922567613f82e7f376316840d40c6878ca20","modified":1731034819101},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/三层架构到DDD.png","hash":"d4023488909be55e39ea8b0288ea7f54d06ddb74","modified":1732872612544},{"_id":"themes/next/.git/refs/heads/master","hash":"8f87f9a32e0aa2ee6b5235b745a7cf9aa67094c5","modified":1729085305085},{"_id":"themes/next/.git/objects/4e/4dbdcf7029b426557330b915e045cf04d6a118","hash":"7b2f8723992a439385f61c1ae423e7675a26f901","modified":1729085305014},{"_id":"themes/next/.git/objects/1a/b82263cd8ac2f62632fc6aa0db9e3c21081c80","hash":"b990fe28a90800afce25402cacd17dbeca1b7ec1","modified":1729085305079},{"_id":"themes/next/.git/objects/a4/72597a5680f60b6ed510d6ad161e0929c68bdc","hash":"91e60f4ec2cd9b795ecc3dbf4a26823d6cd0f2a1","modified":1729085305057},{"_id":"themes/next/.git/objects/84/c805e9e4bfbb9046a792ee51994443eb607d17","hash":"c4af974f3de423279a817010f4fa033ee3941e40","modified":1729085305006},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1728912368196},{"_id":"themes/next/.git/objects/f1/7d38a16538f147449f5e49b5e8791828b49ef2","hash":"5c99316fec621fc16ce1b48ad473c1b83119e4c0","modified":1729085305067},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1728912368196},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1728912368196},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1728912368196},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1728912368197},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1728912368197},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1728912368197},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1728912368198},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1728912368197},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1728912368198},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1728912368198},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1728912368198},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1728912368196},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1728912368199},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1728912368199},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1728912368199},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1728912368199},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1728912368199},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1728912368199},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1728912368199},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1728912368200},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1728912368202},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1728912368200},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1728912368202},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1728912368202},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1728912368202},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1728912368192},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1728912368192},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1728912368193},{"_id":"themes/next/.git/objects/f6/724214b70ec719af9ef832a07aee640bed7ef4","hash":"92627b5bf4c6dcc7c1609d48b7cb43b44e7c3581","modified":1729085305072},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1728912368193},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1728912368193},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1728912368193},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1728912368193},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1728912368194},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1728912368194},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1728912368370},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1728912368366},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1728912368369},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1728912368371},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1728912368320},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1728912368323},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1728912368321},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1728912368327},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1728912368399},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1728912368399},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1728912368398},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1728912368397},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1728912368402},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1728912368401},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1728912368403},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1728912368402},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1728912368402},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1728912368403},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1728912368403},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1728912368420},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1728912368421},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1728912368414},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1728912368421},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1728912368421},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1728912368428},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1728912368427},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1728912368427},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1728912368428},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1728912368429},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1728912368429},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1728912368430},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1728912368430},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1728912368429},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1728912368444},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1728912368446},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1728912368445},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1728912368445},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1728912368446},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1728912368446},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1728912368446},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1728912368447},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1728912368453},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1728912368454},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1728912368454},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1728912368455},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1728912368455},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1728912368455},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1728912368456},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1728912368455},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1728912368456},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1728912368456},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1728912368456},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1728912368456},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1728912368457},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1728912368457},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1728912368457},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1728912368459},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1728912368458},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1728912368458},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1728912368465},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1728912368465},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1728912368470},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1728912368469},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1728912368468},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1728912368455},{"_id":"source/_posts/2019-06-28-hadoop/文件读取.jpg","hash":"5de81cf695d0b460c533708b0f3af8aa510b080e","modified":1728898691912},{"_id":"source/_posts/2019-07-03-hbase/hregion.png","hash":"cd826e88378909934877b52950e8c17799763cd7","modified":1728898691918},{"_id":"source/_posts/2019-07-07-hbase梳理/hregion.png","hash":"cd826e88378909934877b52950e8c17799763cd7","modified":1728898691924},{"_id":"source/_posts/2019-07-07-hbase梳理/数据表格.png","hash":"b4f855623f4568d55a66449154ecf604a28926f4","modified":1728898691934},{"_id":"source/_posts/2024-04-10-性能优化-日志优化/磁盘利用率.jpeg","hash":"6a829b3f3a4252169232812a2d502fd83e80bd33","modified":1729502171000},{"_id":"source/_posts/2019-07-20-HIVE/HIVE架构.png","hash":"0b150d8a009c71facdc93c2982d3274b2ac3d9e0","modified":1728898691987},{"_id":"source/_posts/2019-08-01-MQ对比/rocketmq-broker.png","hash":"ef012fda155f089ca8e8f0397e501f62c27cdac6","modified":1728898692002},{"_id":"source/_posts/2019-08-19-RPC/server方法过程.png","hash":"561a1a047bb1d3eb37b6055d0437d15e60428928","modified":1728898692009},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1728912368194},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1728912368194},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1728912368195},{"_id":"source/_posts/2020-04-09-Linux-thread/internal.png","hash":"df2d16ad564c2a85258340f896b326ef204f0b72","modified":1728898692116},{"_id":"source/_posts/2020-04-12-线程池/线程池.png","hash":"36d48f757a3cbc5ee8edfb44d864a69b4d62b6ef","modified":1728898692194},{"_id":"source/_posts/2020-04-06-volatile/volatile-jvm.png","hash":"6d2649ae31dcc76a0eda4b83482716f73471abcb","modified":1728898692093},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/urm-1.png","hash":"30c611386b3756b834244e255077e2b1d6f1d047","modified":1728898691879},{"_id":"source/_posts/2020-05-07-零拷贝/直接内存回收和分配.png","hash":"4fa39d7beb0b3f08d380760e0b0d2d71cabb5b4b","modified":1728898692261},{"_id":"source/_posts/2020-04-12-线程池/DelayedWorkQueue.png","hash":"bba3a9c04cecc2e96408cb0dff005263c82c8064","modified":1728898692188},{"_id":"source/_posts/2020-06-14-分布式主键ID/数据库水平拆分ID.png","hash":"240b446d1d5bcbde83c5e0dec28679c7c0fea5c9","modified":1728898692319},{"_id":"source/_posts/2020-05-11-类加载/类生命周期.png","hash":"3ee6974071af13320cbd49f0dbe7f50c967c9bc5","modified":1728898692271},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念/中间件改造.png","hash":"42431d4bd971762b4906fe144ba4e8f42af50695","modified":1730171299569},{"_id":"source/_posts/2024-08-21-架构-三高/高可用衡量指标.png","hash":"7a3f897caa1103d4e62b27810a846d581b41b65c","modified":1732523940508},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/分层架构.png","hash":"49e6e102859dcfce656aee5cc5409ff9aa9fcace","modified":1733189279287},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1728912368445},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident/redis-cache.jpg","hash":"1735050cc855a4512f14f387e343152b765f109c","modified":1728898691807},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/uum-1.png","hash":"95997f3fd7bafad027e6444a4782f55e451e6e00","modified":1728898691882},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/jmap-heap.png","hash":"e764e175946496028d1ef07982356ae06dc2c73a","modified":1728898691818},{"_id":"source/_posts/2019-04-11-Linux-io模型/async-block.png","hash":"3f50f85745fc5405dfec8a4d31e9337e8649de98","modified":1728898691889},{"_id":"source/_posts/2019-04-11-Linux-io模型/sync-nonblock.png","hash":"e706080387623abcbce59b0853564c411812fc6d","modified":1728898691895},{"_id":"source/_posts/2019-06-28-hadoop/文件写入.jpg","hash":"b4e218c1e070c371b6215fc6e5d04864465a794a","modified":1728898691910},{"_id":"source/_posts/2019-07-07-hbase梳理/hfile结构.png","hash":"680bdfebbd644546f70e3f73d8eab18f79002239","modified":1728898691924},{"_id":"source/_posts/2019-07-07-hbase梳理/keyvalue结构.png","hash":"c6cedd6fc5dcca15164e97d2908256ef97d3fdf1","modified":1728898691926},{"_id":"source/_posts/2020-04-04-cpu/CPU指令重排.png","hash":"3a28e9b34e57a332bbabab0054cde70011923ba8","modified":1728898692059},{"_id":"source/_posts/2020-04-13-ThreadLocal/threadlocal.png","hash":"e057d6193eaaf3cb9b9e5a1e77083f90c213ed26","modified":1728898692217},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/old-sso-out.png","hash":"6bd803f200c5cfde59b33d5202b4e6458c0eedae","modified":1728898691876},{"_id":"source/_posts/2020-04-13-ThreadLocal/jvm-share.png","hash":"3c6c43208c46ba054d8d87fcd9e65f1d1e2824c4","modified":1728898692201},{"_id":"source/_posts/2020-04-12-线程池/线程池状态.png","hash":"60808b7fcaa82cbbd38af3a581c85a0f64931ede","modified":1728898692197},{"_id":"source/_posts/2024-03-20-性能优化-服务RT上升/trace.png","hash":"f0a9bbf85dd2a89a0051d86410fbb576aa192866","modified":1729431891336},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/tair单元化.png","hash":"930887259fe48e9cf7d1a82b30bfcee373a3e936","modified":1730361829207},{"_id":"source/_posts/2024-08-28-架构-DDD概念/什么是DDD.png","hash":"02c0fc77564244ebdf06f4faf58a9c5702b3a43d","modified":1732782813860},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/分层架构_系统架构.png","hash":"92d837431632676a5222c243c84d838008cd7b24","modified":1733190590146},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/DDD设计流程总览图.png","hash":"df928d9fc6581d8c7528c88002c555d07bf55567","modified":1732782146939},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"615146476f799c8425a8acb9dd584858de6f3c11","modified":1729085305086},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1728912368162},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1728912368201},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1728912368201},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1728912368331},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1728912368335},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1728912368335},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1728912368337},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1728912368344},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1728912368338},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1728912368337},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1728912368329},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1728912368352},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1728912368354},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1728912368361},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1728912368357},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1728912368363},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1728912368364},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1728912368366},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1728912368365},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1728912368207},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1728912368208},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1728912368208},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1728912368208},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1728912368208},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1728912368350},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1728912368351},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1728912368351},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1728912368216},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1728912368242},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1728912368301},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1728912368319},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1728912368319},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1728912368319},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1728912368320},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1728912368402},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1728912368301},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1728912368319},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1728912368414},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1728912368413},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1728912368412},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1728912368421},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1728912368422},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1728912368422},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1728912368423},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1728912368423},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1728912368423},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1728912368426},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1728912368426},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1728912368428},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1728912368426},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1728912368428},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1728912368431},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1728912368430},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1728912368431},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1728912368464},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1728912368465},{"_id":"source/_posts/2024-04-10-性能优化-日志优化/日志入队列流程.png","hash":"63c40734c5822da02a735bd7a045b2acdacc540d","modified":1729501720500},{"_id":"source/_posts/2019-07-13-zookeeper/datastruct.png","hash":"7fb6ae1784171f0623765bee349f5c6ce82a2ac2","modified":1728898691948},{"_id":"source/_posts/2020-04-06-volatile/volatile汇编代码.png","hash":"079168b526dc9b5cadbeef15dc43a900f8629493","modified":1728898692113},{"_id":"source/_posts/2019-07-24-dmq/mq-client-server-3.png","hash":"96929b0f74291d7f0742a38c5ad66596a1ee7454","modified":1728898691994},{"_id":"source/_posts/2020-04-09-Linux-thread/task_struct.png","hash":"f22d4b216f339258184553c996d311825c97f873","modified":1728898692132},{"_id":"source/_posts/2020-04-09-Linux-thread/vm-实现.png","hash":"37da6e1e223cbb60d4897f0d4005cbac6a594c59","modified":1728898692147},{"_id":"source/_posts/2020-06-14-分布式主键ID/数据库批量生成分配.png","hash":"842dd986623b50a6942be5198b84a824faf9dc72","modified":1728898692316},{"_id":"source/_posts/2020-06-14-分布式主键ID/雪花算法.png","hash":"786df545c6c9dc459ad9b079bae455fdbb8be3bc","modified":1728898692323},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/spring三级缓存.png","hash":"7ecdddd56c0435b56f77565178e1962e5e7f3a8c","modified":1729069105909},{"_id":"source/_posts/2024-03-20-性能优化-服务RT上升/profiler.png","hash":"bdfa35474c15e671166d70f51e4be6ddf04974b0","modified":1729432502570},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/六边形架构.png","hash":"94d4c247cba3f0b7bc33c0184a0d31cbfe13ac7c","modified":1733193092303},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/实施总结.png","hash":"df928d9fc6581d8c7528c88002c555d07bf55567","modified":1733195603829},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1728912368413},{"_id":"source/_posts/2024-05-04-系统重构-资产管理系统重构/MVC三层架构.png","hash":"af450fe23300bf575c8296530bf827395a090384","modified":1729521393750},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/old-permission.png","hash":"d1e67e5bd4d873134a5de5b1d45b2428ca6b9323","modified":1728898691868},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1728912368467},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/new-permission.png","hash":"00cb084e72f40d92dcd87500544a15e6c5568b79","modified":1728898691861},{"_id":"source/_posts/2019-08-19-RPC/server线程模型.png","hash":"2fbb0923166e407e6d48d52bd175d0a10771f6fc","modified":1728898692012},{"_id":"source/_posts/2019-12-21-tomcat启动过程2/启动过程.png","hash":"dab3d4b6eb33f51b677691fa374373a337861059","modified":1728898692032},{"_id":"source/_posts/2020-04-09-Linux-thread/stack.png","hash":"15600edcbd973d88e70f1159c0f694c137e69d18","modified":1728898692130},{"_id":"source/_posts/2020-05-07-零拷贝/直接内存.png","hash":"afee371104c4336ab0c21d0e69440d077d34d700","modified":1728898692259},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/old-sso-1.png","hash":"5a5c53653acca4fecbcf6eab9698eb0525dae08f","modified":1728898691873},{"_id":"source/_posts/2020-05-11-类加载/类加载过程.png","hash":"a18db5472200ac04b921b93f08a25f1aba19e461","modified":1728898692269},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/先存量后增量.png","hash":"ac21e1f7c361676c0fdb108363708d845ff1faea","modified":1730884316717},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/项目管理流程.png","hash":"549e7f93c030e58e84f9aea020c7f9b1aca88a9d","modified":1730948079456},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/整洁架构.png","hash":"553a9f7b029a624d1fd9d2f823e2822cc6eb9313","modified":1733194024204},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1728912368348},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1728912368345},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1728912368208},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1728912368209},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1728912368209},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1728912368210},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"09d26e0603dc95a44db9589ab9353ec718b43db8","modified":1728912368162},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1728912368210},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1728912368211},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1728912368211},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1728912368213},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1728912368355},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1728912368215},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1728912368214},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1728912368217},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1728912368218},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1728912368219},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1728912368219},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1728912368220},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1728912368212},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1728912368214},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1728912368222},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1728912368212},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1728912368224},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1728912368226},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1728912368227},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1728912368221},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1728912368222},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1728912368220},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1728912368227},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1728912368227},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1728912368223},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1728912368231},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1728912368234},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1728912368229},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1728912368236},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1728912368231},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1728912368235},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1728912368238},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1728912368238},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1728912368235},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1728912368236},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1728912368248},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1728912368253},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1728912368254},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1728912368254},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1728912368268},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1728912368281},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1728912368248},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1728912368282},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1728912368243},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1728912368253},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1728912368284},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1728912368281},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1728912368288},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1728912368290},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1728912368297},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1728912368294},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1728912368300},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1728912368208},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1728912368299},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1728912368405},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1728912368269},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1728912368404},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1728912368405},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1728912368410},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1728912368411},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1728912368424},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1728912368424},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1728912368424},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1728912368425},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1728912368425},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1728912368441},{"_id":"source/_posts/2019-12-20-tomcat启动过程/启动过程.png","hash":"dab3d4b6eb33f51b677691fa374373a337861059","modified":1728898692024},{"_id":"source/_posts/2020-05-07-零拷贝/DMA-优化.png","hash":"e2e25a40e6af8e5c7e2416173269c357da38b3bf","modified":1728898692221},{"_id":"source/_posts/2020-05-07-零拷贝/DMA.png","hash":"b0c4509afdc6a373a76a40a0f91f74e0530099dd","modified":1728898692226},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1728912368434},{"_id":"source/_posts/2024-08-25-架构-常见架构/MVC和三层架构的联系与区别.png","hash":"1492a347336d3e0d58a92c675ce8ec5a0671bf6d","modified":1731918042669},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/消息通信层.png","hash":"f65f465b01aa6b7025a1638827227ad4594caac8","modified":1730362168963},{"_id":"source/_posts/2024-04-10-性能优化-日志优化/日志框架_日志系统.png","hash":"78d6280c06450ca197458111ac9b9ee0163a3d64","modified":1729496119469},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/类视图.png","hash":"bc212a13ff73a22f7b0415ccd859931be9083340","modified":1729256958590},{"_id":"themes/next/.git/objects/pack/pack-729a0f24e9ccc21ccf853cab6387b746749eea37.idx","hash":"8b062e0ddd5ea72126e520006180e10d012b2cd5","modified":1728912368112},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1728912368423},{"_id":"source/_posts/2019-07-13-zookeeper/zk.png","hash":"6bd0bdbcf0662ecebe33459b799d4750f7801ae9","modified":1728898691953},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1728912368442},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1728912368443},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1728912368436},{"_id":"source/_posts/2019-12-20-tomcat启动过程/连接器.png","hash":"49d7ccdbb8c34839bba7199a111ff5314e78a753","modified":1728898692028},{"_id":"source/_posts/2020-04-09-Linux-thread/缺页.png","hash":"a98286f3ceef6afff2c5aaae24849b61ea11e3a4","modified":1728898692157},{"_id":"source/_posts/2020-04-13-ThreadLocal/jvm-thread-memory.png","hash":"d567852e4e5e1438df7e0615b40de9922d003d10","modified":1728898692206},{"_id":"source/_posts/2020-05-07-零拷贝/sendfile.png","hash":"027b6cbf70cc1560f0affe161ef0972c285412cc","modified":1728898692246},{"_id":"source/_posts/2020-05-07-零拷贝/sendfile_DMA.png","hash":"58f436d06722d678c3132c20625ee43cac46f5c6","modified":1728898692251},{"_id":"source/_posts/2019-12-21-tomcat启动过程2/连接器.png","hash":"49d7ccdbb8c34839bba7199a111ff5314e78a753","modified":1728898692033},{"_id":"source/_posts/2024-08-20-架构-架构/数据架构.png","hash":"a63ae42cc967347477bf6cc02d298b90a4089c58","modified":1731375975877},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念/单元化产品组成.png","hash":"99a8340131592b98a8527cbbfcf838db791068c2","modified":1730186447133},{"_id":"source/_posts/2019-07-07-hbase梳理/数据写入过程.png","hash":"08d969f4b60d3341d91cc29d1203891165826717","modified":1728898691932},{"_id":"source/_posts/2019-12-22-tomcat-webxml解析/启动过程.png","hash":"76488c7dfe83b7f38ae62ab07fb18261f5c90375","modified":1728898692040},{"_id":"source/_posts/2020-04-09-Linux-thread/vm.png","hash":"427f0e8c00c27f78429a033338fe6208163f2511","modified":1728898692151},{"_id":"source/_posts/2020-04-11-java-thread/线程状态流转.png","hash":"1f06a3d45448ffabfbe2e6463bcbf82c08ba63e4","modified":1728898692173},{"_id":"source/_posts/2020-05-07-零拷贝/基本方式.png","hash":"e9fd9f72b2e506510741d220e5cb837f171a0414","modified":1728898692255},{"_id":"source/_posts/2019-12-22-tomcat请求过程/启动过程.png","hash":"76488c7dfe83b7f38ae62ab07fb18261f5c90375","modified":1728898692043},{"_id":"source/_posts/2020-05-07-零拷贝/mmp.png","hash":"5daef1f2e96997d833791677c0aa84e075bd52b7","modified":1728898692241},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/分层架构_包结构划分.png","hash":"24c4374d5e905793d212a9d016df63b912dd63e5","modified":1733190720151},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1728912368420},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/new-sso-1.png","hash":"32fa16195278159868a2e0ee85a541e274a37ed8","modified":1728898691865},{"_id":"source/_posts/2019-07-13-zookeeper/zknode.png","hash":"6484444ea2e28104936ae266797ef4abed9da155","modified":1728898691966},{"_id":"source/_posts/2020-05-07-零拷贝/jmm.png","hash":"ffad3b9dd49e0771c9f4335c9672929f465cb4d9","modified":1728898692235},{"_id":"source/_posts/2024-08-20-架构-架构/业务架构.png","hash":"b2de1dcd8a4be8aad7837056dbbadf426a7bb3b6","modified":1731375530303},{"_id":"source/_posts/2020-04-04-cpu/CPU缓存.png","hash":"4f7eaaef808c0c37a5b4c90b1e3ee4760595dd0a","modified":1728898692064},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/jstat-GC情况.png","hash":"4c6d096e87b1da10f467deac5be67f4eb501ef3e","modified":1728898691839},{"_id":"source/_posts/2020-04-09-Linux-thread/thread-info.png","hash":"6f7bba2e77690cedb6527bd28a987aac4eaac86e","modified":1728898692143},{"_id":"source/_posts/2020-05-16-java对象/对象继承.png","hash":"caeab4681ea26492ec1a39339a0a27f860b0037a","modified":1728898692302},{"_id":"source/_posts/2020-04-11-java-thread/jvm线程-Linux进程.png","hash":"5c6ee2e9bf6cd81f27e4f881524bcd340a5be241","modified":1728898692167},{"_id":"source/_posts/2024-08-21-架构-三高/高可用设计.png","hash":"79641218e229e0a3268cb82f2c9ad3cf6f9d1ebb","modified":1732589955217},{"_id":"source/_posts/2024-08-20-架构-架构/应用架构.png","hash":"72247a5eac8d211b59c160afaf8febf07a65e326","modified":1731375715309},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念/底层数据同步.png","hash":"7235ab4eda26165a67d4aa5a71e57cf0cf0f8cb2","modified":1730172466785},{"_id":"source/_posts/2020-04-04-cpu/基本组成.png","hash":"f7610e50301f5e621c1a94f13491d74f0f581618","modified":1728898692070},{"_id":"source/_posts/2019-07-13-zookeeper/zknode-example.png","hash":"181adf0056daeac497b64b91a8b08aac9eba9e20","modified":1728898691959},{"_id":"source/_posts/2020-04-04-cpu/大概布局.png","hash":"8da7c91b67b4329d35824fb0a39d8dc975b4fe71","modified":1728898692076},{"_id":"source/_posts/2020-04-04-cpu/缓存问题.png","hash":"bb4d4d1f805ddbe1afe766240757dbf006f02154","modified":1728898692084},{"_id":"source/_posts/2020-05-10-JMM/jmm.png","hash":"ffad3b9dd49e0771c9f4335c9672929f465cb4d9","modified":1728898692265},{"_id":"source/_posts/2024-08-20-架构-架构/技术架构.png","hash":"3a18fe1fe285c6bd3a8ab413b9aa823d04c9a8a9","modified":1731375871349},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1728912368463},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/classloader.png","hash":"bc3ca14f8dc57f3fae46317b381b088588cbfbb6","modified":1729256622931},{"_id":"source/_posts/2020-03-29-磁盘局部性原理/磁盘.png","hash":"78c438bb1c741c1cd6316b679e7d31402f402e83","modified":1728898692055},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/GC日志.png","hash":"050dba0ae64973e51eddf720e17060c8d070f739","modified":1729255967864},{"_id":"source/_posts/2020-04-09-Linux-thread/piepline.png","hash":"82878875d3d706db8874122c8e3c9c9d3a6b3b58","modified":1728898692122},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1728912368439},{"_id":"source/_posts/2020-04-11-java-thread/线程进程关系.png","hash":"6a0642da4235ba504e4af3fcb3c5d831e1b97564","modified":1728898692182},{"_id":"source/_posts/2020-05-16-java对象/内存分配.png","hash":"28eb7e40209433fb38ddc1e49f1595523f9cede1","modified":1728898692280},{"_id":"source/_posts/2020-04-13-ThreadLocal/threadlocal-memory.png","hash":"7d5ad7b4aaaad88b4edc5feb1f94f54de21494f5","modified":1728898692214},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/清晰架构.png","hash":"ed6eccb3725db27c5c0887deb97c0ab9dff2e296","modified":1733194137046},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/总的架构演进图.png","hash":"06a800c9b4416df792e0ac721a4451240c2ebed4","modified":1733194734457},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/DDD演进.png","hash":"06a800c9b4416df792e0ac721a4451240c2ebed4","modified":1732870172999},{"_id":"source/_posts/2019-07-07-hbase梳理/逻辑存储.png","hash":"13b684066411e0076518d6e3bab622f2894ee64b","modified":1728898691944},{"_id":"source/_posts/2019-07-13-zookeeper/注册过程.png","hash":"99d3254d5a79a4b915648076bf73c7e3fc763b5d","modified":1728898691980},{"_id":"source/_posts/2020-05-16-java对象/对象头.png","hash":"fbe4e0e20da3f2fc5b93152659e2736216130d84","modified":1728898692297},{"_id":"source/_posts/2021-01-04-springmvc/springmvc-handlermapping.png","hash":"a48881b3543a71f0ba0d2a6f9a341e3501046283","modified":1728898692372},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/商品数据模型图.png","hash":"2b77d4e71ef4fe9d222f7cc96e7e8f3a6f882c3e","modified":1732850891391},{"_id":"source/_posts/2024-08-28-架构-DDD概念/DDD基本概念图.png","hash":"019262c47d3446e3d6ed7c59ed6d9ea8b6aac1ef","modified":1733111079620},{"_id":"source/_posts/2020-12-28-spring启动过程/beanDefination.png","hash":"cc4cd024a0aac2b88aded99bbf2e8959924c35a7","modified":1728898692358},{"_id":"themes/next/.git/objects/pack/pack-729a0f24e9ccc21ccf853cab6387b746749eea37.pack","hash":"a02cc7ff3d310efe2b1639e488bc3a28e0769414","modified":1728912368105}],"Category":[{"name":"mybatis","_id":"cm4gqpntw0006a13k3jmzcm39"},{"name":"单点登录","_id":"cm4gqpnud000aa13k22a7grsm"},{"name":"java","_id":"cm4gqpnuk000fa13k35r2uycm"},{"name":"数据库","_id":"cm4gqpnuo000la13k8uzw230q"},{"name":"线上问题","parent":"cm4gqpntw0006a13k3jmzcm39","_id":"cm4gqpnut000sa13k9zrqbmsi"},{"name":"io","_id":"cm4gqpnvj0018a13kwqeqde75"},{"name":"jvm","parent":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnw4001ja13kkwz91n8m"},{"name":"mysql","parent":"cm4gqpnuo000la13k8uzw230q","_id":"cm4gqpnwg001qa13kzk7yy5fu"},{"name":"RPC","_id":"cm4gqpnwr001wa13k4ojnoeqw"},{"name":"MQ","_id":"cm4gqpnwz0028a13k7ncjq662"},{"name":"线上问题","parent":"cm4gqpnwg001qa13kzk7yy5fu","_id":"cm4gqpnx2002ea13kut6u44p5"},{"name":"linux","_id":"cm4gqpnx6002ka13klrtm2szt"},{"name":"线程池","parent":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxj003da13k14orzex6"},{"name":"jmm","parent":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxm003la13kmd4qm25w"},{"name":"ES","_id":"cm4gqpnxp003sa13kvtxg9x65"},{"name":"对象","parent":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnxr003za13ktdyk41ng"},{"name":"spring","_id":"cm4gqpnxx004ea13k7g2kju5x"},{"name":"性能优化","parent":"cm4gqpnwg001qa13kzk7yy5fu","_id":"cm4gqpny0004ma13kxqrasbav"},{"name":"多线程","_id":"cm4gqpny40050a13k48j2lo8d"},{"name":"oom","parent":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpny60057a13kay13xikf"},{"name":"RT","parent":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpny9005fa13k3afobg9k"},{"name":"日志","_id":"cm4gqpnyb005ma13kcuxb3br3"},{"name":"线程池","_id":"cm4gqpnyf005sa13ki8tlklgn"},{"name":"分布式数据库","parent":"cm4gqpnuo000la13k8uzw230q","_id":"cm4gqpnyh005xa13khp9qwqul"},{"name":"springmvc","parent":"cm4gqpnxx004ea13k7g2kju5x","_id":"cm4gqpnyk0063a13kdkv4nuc9"},{"name":"稳定性","_id":"cm4gqpnym0067a13kj33t8fmq"},{"name":"性能优化","_id":"cm4gqpnyq006ja13k31ljmnq5"},{"name":"并发","parent":"cm4gqpny40050a13k48j2lo8d","_id":"cm4gqpnyw006za13k9qljlf7v"},{"name":"系统重构","_id":"cm4gqpnyw0073a13kwbdxwh8q"},{"name":"架构","_id":"cm4gqpnyx0076a13k5j3upi8t"},{"name":"ygc","parent":"cm4gqpny60057a13kay13xikf","_id":"cm4gqpnyx0079a13k9l1lvapj"},{"name":"ygc","parent":"cm4gqpny9005fa13k3afobg9k","_id":"cm4gqpnyz007ga13ky1ixom1s"},{"name":"原理","parent":"cm4gqpntw0006a13k3jmzcm39","_id":"cm4gqpnz0007na13krvmzf81p"},{"name":"原理","parent":"cm4gqpnxx004ea13k7g2kju5x","_id":"cm4gqpnz2007za13k8nwvsopw"},{"name":"高可用","_id":"cm4gqpnz20080a13k93f8qyka"},{"name":"hexo","_id":"cm4gqpnz30084a13klnr0qt5c"},{"name":"高可用","parent":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnz4008ca13k3naw392e"},{"name":"阿里","_id":"cm4gqpnz5008da13kuu46gmbb"},{"name":"安全生产","parent":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnz6008ga13kcmlzl4lz"},{"name":"高可用、单元化","parent":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnz7008ia13kikaps65e"},{"name":"美团","_id":"cm4gqpnz8008ra13kt3orfibz"},{"name":"设计模式","parent":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnz9008ua13krn5f7l0e"},{"name":"DDD","parent":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnzf0094a13kexf2bp1c"},{"name":"三高","parent":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnzg0097a13koz9mpj17"}],"Data":[],"Page":[{"title":"分类","date":"2019-03-12T14:07:58.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2019-03-12 22:07:58\ntype: \"categories\"\ncomments: false\n---\n","updated":"2024-10-14T09:38:12.374Z","path":"categories/index.html","layout":"page","_id":"cm4gqpntq0001a13kpsjtemw2","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"标签","date":"2019-03-12T14:14:34.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2019-03-12 22:14:34\ntype: \"tags\"\ncomments: false\n---\n","updated":"2024-10-14T09:38:12.376Z","path":"tags/index.html","layout":"page","_id":"cm4gqpnts0003a13kg0qkfxv4","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Mybatis线上事故解析(一、二级缓存)","date":"2018-12-11T15:00:42.000Z","_content":"\n# 一、问题场景：统一登录平台出现无法登录和菜单异常问题。\n\n# 二、问题原因：\n   \n    1、mybatis二级缓存组件使用不当：在高并发情况下，mybatis二级缓存组件实现方式会在数据更新，修改和删除时，\n        频繁调用redis中的keysByScan去获取当前库中全局匹配到的key，当key数量足够多时，执行时间会十分漫长，\n        导致整个redis服务并夯住，出于不可用状态\n    2、redis超时时间设置过长，redis超时后，不能将请求漏给mysql数据库做兜底支撑\n    3、线索系统，每5分钟，全量刷新一次所有用户权限数据，一天调用量达到2000w以上，占整个权限服务的调用量的75%以上 \n\n反思总结：\n    \n    1、并发场景下掉所有的mybatis二级缓存组件，在服务层做精准缓存，而不是dao层做数据缓存\n    2、负责同学对系统中引入的组件具体实现和参数配置不了解\n    3、负责同学对系统日志配置不了解，日志配置不当导致引入的组件的日志未能打印出来，影响问题的排期方向和时间\n    4、配置文件不要打入jar包，而是以文件方式统一放在服务的config目录中，方便修改 \n\n<!--more-->    \n![redis-cache](2018-12-11-Mybatis-online-accident/redis-cache.jpg)    \n![redis-connect](2018-12-11-Mybatis-online-accident/redis-connect.jpg)\n![redis-io](2018-12-11-Mybatis-online-accident/redis-io.jpg)\n   \n    \n# 三、Mybatis一、二级缓存原理解析\n\nmybaits 一共有两级缓存：一级缓存的配置 key 是 localCacheScope，而二级缓存的配置 key 是 cacheEnabled，从名字上可以得出以下信息：\n一级缓存是本地或者说局部缓存，它不能被关闭，只能配置缓存范围。SESSION 或者 STATEMENT。\n二级缓存才是 mybatis 的正统，功能会更强大些。\n\n#### 3.1、一级缓存\n配置：\n开发者只需在MyBatis的配置文件中，添加如下语句，就可以使用一级缓存。共有两个选项，SESSION或者STATEMENT，默认是SESSION级别，即在一个MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是STATEMENT级别，可以理解为缓存只对当前执行的这一个Statement有效。\n\n    <setting name=\"localCacheScope\" value=\"SESSION\"/>\n\n#### 3.2、二级缓存\n配置：\n\n1.在MyBatis的配置文件中开启二级缓存。\n    \n    <setting name=\"cacheEnabled\" value=\"true\"/>\n    \n2.在MyBatis的映射XML中配置cache或者 cache-ref 。\ncache标签用于声明这个namespace使用二级缓存，并且可以自定义配置。\n\n    <mapper namespace=\"com..mapper.RoleMapper\">\n        <cache type=\"com.mybatis.RedisCache\">\n            <property name=\"expireSeconds\" value=\"14400\"/>\n        </cache>\n    </mapper>   \n    \n    type：cache使用的类型，默认是PerpetualCache，这在一级缓存中提到过。\n    eviction： 定义回收的策略，常见的有FIFO，LRU。\n    flushInterval： 配置一定时间自动刷新缓存，单位是毫秒。\n    size： 最多缓存对象的个数。\n    readOnly： 是否只读，若配置可读写，则需要对应的实体类能够序列化。\n    blocking： 若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。\n    cache-ref代表引用别的命名空间的Cache配置，两个命名空间的操作使用的是同一个Cache。\n\n    <cache-ref namespace=\"mapper.StudentMapper\"/>\n\nspring+mybatis的执行过程：\n\n    <!--mybatis设置-->\n\t<bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\" />\n        <property name=\"dataSource\" ref=\"mysqlDataSource\" /> <!--必须有-->\n        <property name=\"mapperLocations\" value=\"classpath:mapper/**/*.xml\" />\n        <property name=\"typeAliasesPackage\" value=\"contract.model\" />\n        <property name=\"resultTypesPackage\" value=\"contract\" />\n    </bean>\n\nSpring对SqlSessionFactroyBean的初始化过程\n\n    首先SqlSessionFactoryBean 实现了了Spring 的FacatoryBean，顾名思义就是Spring的对象创建工厂，Spring在创建对象的时候会调用对象工厂的getObject()方法。\n\n    public SqlSessionFactory getObject() throws Exception {\n        if (this.sqlSessionFactory == null) {\n            this.afterPropertiesSet();\n        }\n        return this.sqlSessionFactory;\n    }\n    \n    public void afterPropertiesSet() throws Exception {\n        Assert.notNull(this.dataSource, \"Property 'dataSource' is required\");\n        Assert.notNull(this.sqlSessionFactoryBuilder, \"Property 'sqlSessionFactoryBuilder' is required\");\n        Assert.state(this.configuration == null && this.configLocation == null || this.configuration == null || this.configLocation == null, \"Property 'configuration' and 'configLocation' can not specified with together\");\n        this.sqlSessionFactory = this.buildSqlSessionFactory();\n    }\n    \n    protected SqlSessionFactory buildSqlSessionFactory() throws IOException {\n        //配置文件读取\n        ....\n        return this.sqlSessionFactoryBuilder.build(configuration);\n    }\n    \n    public SqlSessionFactory build(Configuration config) {\n        return new DefaultSqlSessionFactory(config);\n    }\n    \n在初始化SqlSesion时，会使用Configuration类创建一个全新的Executor，作为DefaultSqlSession构造函数的参数，创建Executor代码如下所示：\n    \n    public Executor newExecutor(Transaction transaction, ExecutorType executorType) {\n        executorType = executorType == null ? defaultExecutorType : executorType;\n        executorType = executorType == null ? ExecutorType.SIMPLE : executorType;\n        Executor executor;\n        if (ExecutorType.BATCH == executorType) {\n          executor = new BatchExecutor(this, transaction);\n        } else if (ExecutorType.REUSE == executorType) {\n          executor = new ReuseExecutor(this, transaction);\n        } else {\n          executor = new SimpleExecutor(this, transaction);\n        }\n        // 尤其可以注意这里，如果二级缓存开关开启的话，是使用CahingExecutor装饰BaseExecutor的子类\n        if (cacheEnabled) {\n          executor = new CachingExecutor(executor);                      \n        }\n        executor = (Executor) interceptorChain.pluginAll(executor);\n        return executor;\n    }\n    \n# 四、总结\n\n    1.MyBatis一级缓存的生命周期和SqlSession一致。\n    2.MyBatis一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。\n    3.MyBatis的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。    \n    \n#### 4.1、类关系图：\n![sqlsession-class-relation](2018-12-11-Mybatis-online-accident/sqlsession-class-relation.jpg)    \n    \n每个SqlSession中持有了Executor，每个Executor中有一个LocalCache。当用户发起查询时，MyBatis根据当前执行的语句生成MappedStatement，在Local Cache进行查询，如果缓存命中的话，直接返回结果给用户，如果缓存没有命中的话，查询数据库，结果写入Local Cache，最后返回结果给用户。    \n\n参考博客：\n[SpringBoot 下 Mybatis 的缓存](https://juejin.im/post/5cacaf2df265da03a97acd25)\n[聊聊MyBatis缓存机制](https://tech.meituan.com/2018/01/19/mybatis-cache.html)\n[深入浅出mybatis之与spring集成](https://www.cnblogs.com/nuccch/p/7693801.html)\n    ","source":"_posts/2018-12-11-Mybatis-online-accident.md","raw":"---\ntitle: Mybatis线上事故解析(一、二级缓存)\ndate: 2018-12-11 23:00:42\ntags: Mybatis\ncategories: \n  - [mybatis, 线上问题]\n---\n\n# 一、问题场景：统一登录平台出现无法登录和菜单异常问题。\n\n# 二、问题原因：\n   \n    1、mybatis二级缓存组件使用不当：在高并发情况下，mybatis二级缓存组件实现方式会在数据更新，修改和删除时，\n        频繁调用redis中的keysByScan去获取当前库中全局匹配到的key，当key数量足够多时，执行时间会十分漫长，\n        导致整个redis服务并夯住，出于不可用状态\n    2、redis超时时间设置过长，redis超时后，不能将请求漏给mysql数据库做兜底支撑\n    3、线索系统，每5分钟，全量刷新一次所有用户权限数据，一天调用量达到2000w以上，占整个权限服务的调用量的75%以上 \n\n反思总结：\n    \n    1、并发场景下掉所有的mybatis二级缓存组件，在服务层做精准缓存，而不是dao层做数据缓存\n    2、负责同学对系统中引入的组件具体实现和参数配置不了解\n    3、负责同学对系统日志配置不了解，日志配置不当导致引入的组件的日志未能打印出来，影响问题的排期方向和时间\n    4、配置文件不要打入jar包，而是以文件方式统一放在服务的config目录中，方便修改 \n\n<!--more-->    \n![redis-cache](2018-12-11-Mybatis-online-accident/redis-cache.jpg)    \n![redis-connect](2018-12-11-Mybatis-online-accident/redis-connect.jpg)\n![redis-io](2018-12-11-Mybatis-online-accident/redis-io.jpg)\n   \n    \n# 三、Mybatis一、二级缓存原理解析\n\nmybaits 一共有两级缓存：一级缓存的配置 key 是 localCacheScope，而二级缓存的配置 key 是 cacheEnabled，从名字上可以得出以下信息：\n一级缓存是本地或者说局部缓存，它不能被关闭，只能配置缓存范围。SESSION 或者 STATEMENT。\n二级缓存才是 mybatis 的正统，功能会更强大些。\n\n#### 3.1、一级缓存\n配置：\n开发者只需在MyBatis的配置文件中，添加如下语句，就可以使用一级缓存。共有两个选项，SESSION或者STATEMENT，默认是SESSION级别，即在一个MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是STATEMENT级别，可以理解为缓存只对当前执行的这一个Statement有效。\n\n    <setting name=\"localCacheScope\" value=\"SESSION\"/>\n\n#### 3.2、二级缓存\n配置：\n\n1.在MyBatis的配置文件中开启二级缓存。\n    \n    <setting name=\"cacheEnabled\" value=\"true\"/>\n    \n2.在MyBatis的映射XML中配置cache或者 cache-ref 。\ncache标签用于声明这个namespace使用二级缓存，并且可以自定义配置。\n\n    <mapper namespace=\"com..mapper.RoleMapper\">\n        <cache type=\"com.mybatis.RedisCache\">\n            <property name=\"expireSeconds\" value=\"14400\"/>\n        </cache>\n    </mapper>   \n    \n    type：cache使用的类型，默认是PerpetualCache，这在一级缓存中提到过。\n    eviction： 定义回收的策略，常见的有FIFO，LRU。\n    flushInterval： 配置一定时间自动刷新缓存，单位是毫秒。\n    size： 最多缓存对象的个数。\n    readOnly： 是否只读，若配置可读写，则需要对应的实体类能够序列化。\n    blocking： 若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。\n    cache-ref代表引用别的命名空间的Cache配置，两个命名空间的操作使用的是同一个Cache。\n\n    <cache-ref namespace=\"mapper.StudentMapper\"/>\n\nspring+mybatis的执行过程：\n\n    <!--mybatis设置-->\n\t<bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\" />\n        <property name=\"dataSource\" ref=\"mysqlDataSource\" /> <!--必须有-->\n        <property name=\"mapperLocations\" value=\"classpath:mapper/**/*.xml\" />\n        <property name=\"typeAliasesPackage\" value=\"contract.model\" />\n        <property name=\"resultTypesPackage\" value=\"contract\" />\n    </bean>\n\nSpring对SqlSessionFactroyBean的初始化过程\n\n    首先SqlSessionFactoryBean 实现了了Spring 的FacatoryBean，顾名思义就是Spring的对象创建工厂，Spring在创建对象的时候会调用对象工厂的getObject()方法。\n\n    public SqlSessionFactory getObject() throws Exception {\n        if (this.sqlSessionFactory == null) {\n            this.afterPropertiesSet();\n        }\n        return this.sqlSessionFactory;\n    }\n    \n    public void afterPropertiesSet() throws Exception {\n        Assert.notNull(this.dataSource, \"Property 'dataSource' is required\");\n        Assert.notNull(this.sqlSessionFactoryBuilder, \"Property 'sqlSessionFactoryBuilder' is required\");\n        Assert.state(this.configuration == null && this.configLocation == null || this.configuration == null || this.configLocation == null, \"Property 'configuration' and 'configLocation' can not specified with together\");\n        this.sqlSessionFactory = this.buildSqlSessionFactory();\n    }\n    \n    protected SqlSessionFactory buildSqlSessionFactory() throws IOException {\n        //配置文件读取\n        ....\n        return this.sqlSessionFactoryBuilder.build(configuration);\n    }\n    \n    public SqlSessionFactory build(Configuration config) {\n        return new DefaultSqlSessionFactory(config);\n    }\n    \n在初始化SqlSesion时，会使用Configuration类创建一个全新的Executor，作为DefaultSqlSession构造函数的参数，创建Executor代码如下所示：\n    \n    public Executor newExecutor(Transaction transaction, ExecutorType executorType) {\n        executorType = executorType == null ? defaultExecutorType : executorType;\n        executorType = executorType == null ? ExecutorType.SIMPLE : executorType;\n        Executor executor;\n        if (ExecutorType.BATCH == executorType) {\n          executor = new BatchExecutor(this, transaction);\n        } else if (ExecutorType.REUSE == executorType) {\n          executor = new ReuseExecutor(this, transaction);\n        } else {\n          executor = new SimpleExecutor(this, transaction);\n        }\n        // 尤其可以注意这里，如果二级缓存开关开启的话，是使用CahingExecutor装饰BaseExecutor的子类\n        if (cacheEnabled) {\n          executor = new CachingExecutor(executor);                      \n        }\n        executor = (Executor) interceptorChain.pluginAll(executor);\n        return executor;\n    }\n    \n# 四、总结\n\n    1.MyBatis一级缓存的生命周期和SqlSession一致。\n    2.MyBatis一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。\n    3.MyBatis的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。    \n    \n#### 4.1、类关系图：\n![sqlsession-class-relation](2018-12-11-Mybatis-online-accident/sqlsession-class-relation.jpg)    \n    \n每个SqlSession中持有了Executor，每个Executor中有一个LocalCache。当用户发起查询时，MyBatis根据当前执行的语句生成MappedStatement，在Local Cache进行查询，如果缓存命中的话，直接返回结果给用户，如果缓存没有命中的话，查询数据库，结果写入Local Cache，最后返回结果给用户。    \n\n参考博客：\n[SpringBoot 下 Mybatis 的缓存](https://juejin.im/post/5cacaf2df265da03a97acd25)\n[聊聊MyBatis缓存机制](https://tech.meituan.com/2018/01/19/mybatis-cache.html)\n[深入浅出mybatis之与spring集成](https://www.cnblogs.com/nuccch/p/7693801.html)\n    ","slug":"2018-12-11-Mybatis-online-accident","published":1,"updated":"2024-10-18T01:57:16.881Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpntj0000a13k2k3brwas","content":"<h1 id=\"一、问题场景：统一登录平台出现无法登录和菜单异常问题。\"><a href=\"#一、问题场景：统一登录平台出现无法登录和菜单异常问题。\" class=\"headerlink\" title=\"一、问题场景：统一登录平台出现无法登录和菜单异常问题。\"></a>一、问题场景：统一登录平台出现无法登录和菜单异常问题。</h1><h1 id=\"二、问题原因：\"><a href=\"#二、问题原因：\" class=\"headerlink\" title=\"二、问题原因：\"></a>二、问题原因：</h1><pre><code>1、mybatis二级缓存组件使用不当：在高并发情况下，mybatis二级缓存组件实现方式会在数据更新，修改和删除时，\n    频繁调用redis中的keysByScan去获取当前库中全局匹配到的key，当key数量足够多时，执行时间会十分漫长，\n    导致整个redis服务并夯住，出于不可用状态\n2、redis超时时间设置过长，redis超时后，不能将请求漏给mysql数据库做兜底支撑\n3、线索系统，每5分钟，全量刷新一次所有用户权限数据，一天调用量达到2000w以上，占整个权限服务的调用量的75%以上 </code></pre><p>反思总结：</p>\n<pre><code>1、并发场景下掉所有的mybatis二级缓存组件，在服务层做精准缓存，而不是dao层做数据缓存\n2、负责同学对系统中引入的组件具体实现和参数配置不了解\n3、负责同学对系统日志配置不了解，日志配置不当导致引入的组件的日志未能打印出来，影响问题的排期方向和时间\n4、配置文件不要打入jar包，而是以文件方式统一放在服务的config目录中，方便修改 </code></pre><a id=\"more\"></a>    \n<p><img src=\"/2018/12/11/2018-12-11-Mybatis-online-accident/redis-cache.jpg\" alt=\"redis-cache\"><br><img src=\"/2018/12/11/2018-12-11-Mybatis-online-accident/redis-connect.jpg\" alt=\"redis-connect\"><br><img src=\"/2018/12/11/2018-12-11-Mybatis-online-accident/redis-io.jpg\" alt=\"redis-io\"></p>\n<h1 id=\"三、Mybatis一、二级缓存原理解析\"><a href=\"#三、Mybatis一、二级缓存原理解析\" class=\"headerlink\" title=\"三、Mybatis一、二级缓存原理解析\"></a>三、Mybatis一、二级缓存原理解析</h1><p>mybaits 一共有两级缓存：一级缓存的配置 key 是 localCacheScope，而二级缓存的配置 key 是 cacheEnabled，从名字上可以得出以下信息：<br>一级缓存是本地或者说局部缓存，它不能被关闭，只能配置缓存范围。SESSION 或者 STATEMENT。<br>二级缓存才是 mybatis 的正统，功能会更强大些。</p>\n<h4 id=\"3-1、一级缓存\"><a href=\"#3-1、一级缓存\" class=\"headerlink\" title=\"3.1、一级缓存\"></a>3.1、一级缓存</h4><p>配置：<br>开发者只需在MyBatis的配置文件中，添加如下语句，就可以使用一级缓存。共有两个选项，SESSION或者STATEMENT，默认是SESSION级别，即在一个MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是STATEMENT级别，可以理解为缓存只对当前执行的这一个Statement有效。</p>\n<pre><code>&lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;</code></pre><h4 id=\"3-2、二级缓存\"><a href=\"#3-2、二级缓存\" class=\"headerlink\" title=\"3.2、二级缓存\"></a>3.2、二级缓存</h4><p>配置：</p>\n<p>1.在MyBatis的配置文件中开启二级缓存。</p>\n<pre><code>&lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;</code></pre><p>2.在MyBatis的映射XML中配置cache或者 cache-ref 。<br>cache标签用于声明这个namespace使用二级缓存，并且可以自定义配置。</p>\n<pre><code>&lt;mapper namespace=&quot;com..mapper.RoleMapper&quot;&gt;\n    &lt;cache type=&quot;com.mybatis.RedisCache&quot;&gt;\n        &lt;property name=&quot;expireSeconds&quot; value=&quot;14400&quot;/&gt;\n    &lt;/cache&gt;\n&lt;/mapper&gt;   \n\ntype：cache使用的类型，默认是PerpetualCache，这在一级缓存中提到过。\neviction： 定义回收的策略，常见的有FIFO，LRU。\nflushInterval： 配置一定时间自动刷新缓存，单位是毫秒。\nsize： 最多缓存对象的个数。\nreadOnly： 是否只读，若配置可读写，则需要对应的实体类能够序列化。\nblocking： 若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。\ncache-ref代表引用别的命名空间的Cache配置，两个命名空间的操作使用的是同一个Cache。\n\n&lt;cache-ref namespace=&quot;mapper.StudentMapper&quot;/&gt;</code></pre><p>spring+mybatis的执行过程：</p>\n<pre><code>&lt;!--mybatis设置--&gt;\n&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;\n    &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot; /&gt;\n    &lt;property name=&quot;dataSource&quot; ref=&quot;mysqlDataSource&quot; /&gt; &lt;!--必须有--&gt;\n    &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/**/*.xml&quot; /&gt;\n    &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;contract.model&quot; /&gt;\n    &lt;property name=&quot;resultTypesPackage&quot; value=&quot;contract&quot; /&gt;\n&lt;/bean&gt;</code></pre><p>Spring对SqlSessionFactroyBean的初始化过程</p>\n<pre><code>首先SqlSessionFactoryBean 实现了了Spring 的FacatoryBean，顾名思义就是Spring的对象创建工厂，Spring在创建对象的时候会调用对象工厂的getObject()方法。\n\npublic SqlSessionFactory getObject() throws Exception {\n    if (this.sqlSessionFactory == null) {\n        this.afterPropertiesSet();\n    }\n    return this.sqlSessionFactory;\n}\n\npublic void afterPropertiesSet() throws Exception {\n    Assert.notNull(this.dataSource, &quot;Property &apos;dataSource&apos; is required&quot;);\n    Assert.notNull(this.sqlSessionFactoryBuilder, &quot;Property &apos;sqlSessionFactoryBuilder&apos; is required&quot;);\n    Assert.state(this.configuration == null &amp;&amp; this.configLocation == null || this.configuration == null || this.configLocation == null, &quot;Property &apos;configuration&apos; and &apos;configLocation&apos; can not specified with together&quot;);\n    this.sqlSessionFactory = this.buildSqlSessionFactory();\n}\n\nprotected SqlSessionFactory buildSqlSessionFactory() throws IOException {\n    //配置文件读取\n    ....\n    return this.sqlSessionFactoryBuilder.build(configuration);\n}\n\npublic SqlSessionFactory build(Configuration config) {\n    return new DefaultSqlSessionFactory(config);\n}</code></pre><p>在初始化SqlSesion时，会使用Configuration类创建一个全新的Executor，作为DefaultSqlSession构造函数的参数，创建Executor代码如下所示：</p>\n<pre><code>public Executor newExecutor(Transaction transaction, ExecutorType executorType) {\n    executorType = executorType == null ? defaultExecutorType : executorType;\n    executorType = executorType == null ? ExecutorType.SIMPLE : executorType;\n    Executor executor;\n    if (ExecutorType.BATCH == executorType) {\n      executor = new BatchExecutor(this, transaction);\n    } else if (ExecutorType.REUSE == executorType) {\n      executor = new ReuseExecutor(this, transaction);\n    } else {\n      executor = new SimpleExecutor(this, transaction);\n    }\n    // 尤其可以注意这里，如果二级缓存开关开启的话，是使用CahingExecutor装饰BaseExecutor的子类\n    if (cacheEnabled) {\n      executor = new CachingExecutor(executor);                      \n    }\n    executor = (Executor) interceptorChain.pluginAll(executor);\n    return executor;\n}</code></pre><h1 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h1><pre><code>1.MyBatis一级缓存的生命周期和SqlSession一致。\n2.MyBatis一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。\n3.MyBatis的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。    </code></pre><h4 id=\"4-1、类关系图：\"><a href=\"#4-1、类关系图：\" class=\"headerlink\" title=\"4.1、类关系图：\"></a>4.1、类关系图：</h4><p><img src=\"/2018/12/11/2018-12-11-Mybatis-online-accident/sqlsession-class-relation.jpg\" alt=\"sqlsession-class-relation\">    </p>\n<p>每个SqlSession中持有了Executor，每个Executor中有一个LocalCache。当用户发起查询时，MyBatis根据当前执行的语句生成MappedStatement，在Local Cache进行查询，如果缓存命中的话，直接返回结果给用户，如果缓存没有命中的话，查询数据库，结果写入Local Cache，最后返回结果给用户。    </p>\n<p>参考博客：<br><a href=\"https://juejin.im/post/5cacaf2df265da03a97acd25\" target=\"_blank\" rel=\"noopener\">SpringBoot 下 Mybatis 的缓存</a><br><a href=\"https://tech.meituan.com/2018/01/19/mybatis-cache.html\" target=\"_blank\" rel=\"noopener\">聊聊MyBatis缓存机制</a><br><a href=\"https://www.cnblogs.com/nuccch/p/7693801.html\" target=\"_blank\" rel=\"noopener\">深入浅出mybatis之与spring集成</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、问题场景：统一登录平台出现无法登录和菜单异常问题。\"><a href=\"#一、问题场景：统一登录平台出现无法登录和菜单异常问题。\" class=\"headerlink\" title=\"一、问题场景：统一登录平台出现无法登录和菜单异常问题。\"></a>一、问题场景：统一登录平台出现无法登录和菜单异常问题。</h1><h1 id=\"二、问题原因：\"><a href=\"#二、问题原因：\" class=\"headerlink\" title=\"二、问题原因：\"></a>二、问题原因：</h1><pre><code>1、mybatis二级缓存组件使用不当：在高并发情况下，mybatis二级缓存组件实现方式会在数据更新，修改和删除时，\n    频繁调用redis中的keysByScan去获取当前库中全局匹配到的key，当key数量足够多时，执行时间会十分漫长，\n    导致整个redis服务并夯住，出于不可用状态\n2、redis超时时间设置过长，redis超时后，不能将请求漏给mysql数据库做兜底支撑\n3、线索系统，每5分钟，全量刷新一次所有用户权限数据，一天调用量达到2000w以上，占整个权限服务的调用量的75%以上 </code></pre><p>反思总结：</p>\n<pre><code>1、并发场景下掉所有的mybatis二级缓存组件，在服务层做精准缓存，而不是dao层做数据缓存\n2、负责同学对系统中引入的组件具体实现和参数配置不了解\n3、负责同学对系统日志配置不了解，日志配置不当导致引入的组件的日志未能打印出来，影响问题的排期方向和时间\n4、配置文件不要打入jar包，而是以文件方式统一放在服务的config目录中，方便修改 </code></pre>","more":"<p><img src=\"/2018/12/11/2018-12-11-Mybatis-online-accident/redis-cache.jpg\" alt=\"redis-cache\"><br><img src=\"/2018/12/11/2018-12-11-Mybatis-online-accident/redis-connect.jpg\" alt=\"redis-connect\"><br><img src=\"/2018/12/11/2018-12-11-Mybatis-online-accident/redis-io.jpg\" alt=\"redis-io\"></p>\n<h1 id=\"三、Mybatis一、二级缓存原理解析\"><a href=\"#三、Mybatis一、二级缓存原理解析\" class=\"headerlink\" title=\"三、Mybatis一、二级缓存原理解析\"></a>三、Mybatis一、二级缓存原理解析</h1><p>mybaits 一共有两级缓存：一级缓存的配置 key 是 localCacheScope，而二级缓存的配置 key 是 cacheEnabled，从名字上可以得出以下信息：<br>一级缓存是本地或者说局部缓存，它不能被关闭，只能配置缓存范围。SESSION 或者 STATEMENT。<br>二级缓存才是 mybatis 的正统，功能会更强大些。</p>\n<h4 id=\"3-1、一级缓存\"><a href=\"#3-1、一级缓存\" class=\"headerlink\" title=\"3.1、一级缓存\"></a>3.1、一级缓存</h4><p>配置：<br>开发者只需在MyBatis的配置文件中，添加如下语句，就可以使用一级缓存。共有两个选项，SESSION或者STATEMENT，默认是SESSION级别，即在一个MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是STATEMENT级别，可以理解为缓存只对当前执行的这一个Statement有效。</p>\n<pre><code>&lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt;</code></pre><h4 id=\"3-2、二级缓存\"><a href=\"#3-2、二级缓存\" class=\"headerlink\" title=\"3.2、二级缓存\"></a>3.2、二级缓存</h4><p>配置：</p>\n<p>1.在MyBatis的配置文件中开启二级缓存。</p>\n<pre><code>&lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;</code></pre><p>2.在MyBatis的映射XML中配置cache或者 cache-ref 。<br>cache标签用于声明这个namespace使用二级缓存，并且可以自定义配置。</p>\n<pre><code>&lt;mapper namespace=&quot;com..mapper.RoleMapper&quot;&gt;\n    &lt;cache type=&quot;com.mybatis.RedisCache&quot;&gt;\n        &lt;property name=&quot;expireSeconds&quot; value=&quot;14400&quot;/&gt;\n    &lt;/cache&gt;\n&lt;/mapper&gt;   \n\ntype：cache使用的类型，默认是PerpetualCache，这在一级缓存中提到过。\neviction： 定义回收的策略，常见的有FIFO，LRU。\nflushInterval： 配置一定时间自动刷新缓存，单位是毫秒。\nsize： 最多缓存对象的个数。\nreadOnly： 是否只读，若配置可读写，则需要对应的实体类能够序列化。\nblocking： 若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。\ncache-ref代表引用别的命名空间的Cache配置，两个命名空间的操作使用的是同一个Cache。\n\n&lt;cache-ref namespace=&quot;mapper.StudentMapper&quot;/&gt;</code></pre><p>spring+mybatis的执行过程：</p>\n<pre><code>&lt;!--mybatis设置--&gt;\n&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;\n    &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot; /&gt;\n    &lt;property name=&quot;dataSource&quot; ref=&quot;mysqlDataSource&quot; /&gt; &lt;!--必须有--&gt;\n    &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/**/*.xml&quot; /&gt;\n    &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;contract.model&quot; /&gt;\n    &lt;property name=&quot;resultTypesPackage&quot; value=&quot;contract&quot; /&gt;\n&lt;/bean&gt;</code></pre><p>Spring对SqlSessionFactroyBean的初始化过程</p>\n<pre><code>首先SqlSessionFactoryBean 实现了了Spring 的FacatoryBean，顾名思义就是Spring的对象创建工厂，Spring在创建对象的时候会调用对象工厂的getObject()方法。\n\npublic SqlSessionFactory getObject() throws Exception {\n    if (this.sqlSessionFactory == null) {\n        this.afterPropertiesSet();\n    }\n    return this.sqlSessionFactory;\n}\n\npublic void afterPropertiesSet() throws Exception {\n    Assert.notNull(this.dataSource, &quot;Property &apos;dataSource&apos; is required&quot;);\n    Assert.notNull(this.sqlSessionFactoryBuilder, &quot;Property &apos;sqlSessionFactoryBuilder&apos; is required&quot;);\n    Assert.state(this.configuration == null &amp;&amp; this.configLocation == null || this.configuration == null || this.configLocation == null, &quot;Property &apos;configuration&apos; and &apos;configLocation&apos; can not specified with together&quot;);\n    this.sqlSessionFactory = this.buildSqlSessionFactory();\n}\n\nprotected SqlSessionFactory buildSqlSessionFactory() throws IOException {\n    //配置文件读取\n    ....\n    return this.sqlSessionFactoryBuilder.build(configuration);\n}\n\npublic SqlSessionFactory build(Configuration config) {\n    return new DefaultSqlSessionFactory(config);\n}</code></pre><p>在初始化SqlSesion时，会使用Configuration类创建一个全新的Executor，作为DefaultSqlSession构造函数的参数，创建Executor代码如下所示：</p>\n<pre><code>public Executor newExecutor(Transaction transaction, ExecutorType executorType) {\n    executorType = executorType == null ? defaultExecutorType : executorType;\n    executorType = executorType == null ? ExecutorType.SIMPLE : executorType;\n    Executor executor;\n    if (ExecutorType.BATCH == executorType) {\n      executor = new BatchExecutor(this, transaction);\n    } else if (ExecutorType.REUSE == executorType) {\n      executor = new ReuseExecutor(this, transaction);\n    } else {\n      executor = new SimpleExecutor(this, transaction);\n    }\n    // 尤其可以注意这里，如果二级缓存开关开启的话，是使用CahingExecutor装饰BaseExecutor的子类\n    if (cacheEnabled) {\n      executor = new CachingExecutor(executor);                      \n    }\n    executor = (Executor) interceptorChain.pluginAll(executor);\n    return executor;\n}</code></pre><h1 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h1><pre><code>1.MyBatis一级缓存的生命周期和SqlSession一致。\n2.MyBatis一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。\n3.MyBatis的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。    </code></pre><h4 id=\"4-1、类关系图：\"><a href=\"#4-1、类关系图：\" class=\"headerlink\" title=\"4.1、类关系图：\"></a>4.1、类关系图：</h4><p><img src=\"/2018/12/11/2018-12-11-Mybatis-online-accident/sqlsession-class-relation.jpg\" alt=\"sqlsession-class-relation\">    </p>\n<p>每个SqlSession中持有了Executor，每个Executor中有一个LocalCache。当用户发起查询时，MyBatis根据当前执行的语句生成MappedStatement，在Local Cache进行查询，如果缓存命中的话，直接返回结果给用户，如果缓存没有命中的话，查询数据库，结果写入Local Cache，最后返回结果给用户。    </p>\n<p>参考博客：<br><a href=\"https://juejin.im/post/5cacaf2df265da03a97acd25\" target=\"_blank\" rel=\"noopener\">SpringBoot 下 Mybatis 的缓存</a><br><a href=\"https://tech.meituan.com/2018/01/19/mybatis-cache.html\" target=\"_blank\" rel=\"noopener\">聊聊MyBatis缓存机制</a><br><a href=\"https://www.cnblogs.com/nuccch/p/7693801.html\" target=\"_blank\" rel=\"noopener\">深入浅出mybatis之与spring集成</a></p>"},{"title":"单点登录现状","date":"2019-03-05T06:25:22.000Z","_content":"这篇文章，将从登陆、登出流程，详细讲解CAS+Shiro的执行过程。\n## 一、开始\nuum：一个基于RBAC（Role-Based Access Control ）的权限系统（CAS client + shiro）\nsso：CAS server，负责认证授权\n\n> ### 1、登陆流程:\n\n这里将以时序图的方式展现。\n\n<!--more-->\n![单点登录现状](2019-03-05-单点登录现状/cas-login.svg)\n\n\n![单点登录现状](2019-03-05-单点登录现状/CAS基础协议.png)\n总结：\n* 访问CAS client，再访问CAS server获得login token，作为登录的票据\n* 用户输入用户名密码，CAS server进行验证\n* 验证通过，CAS server返回Service token和TGT\n* CAS client拿service token 去CAS server进行验证。\n\n> ### 2、登出流程:\n\n这里将以时序图的方式展现。\n![单点登录现状](2019-03-05-单点登录现状/cas-logout.svg)\n\n\n## 二、使用现状及局限性\n![uum](2019-03-05-单点登录现状/uum现状.png)\n\n##### 2.1、部署方式：cas server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。\n    \n    问题一：单节点方式，服务压力大，响应慢，若主节点挂掉，此时所有登录的用户session将丢失，用户需重新登录，并且在备用节点启动完成之前造成服务不可用，造成的影响范围大。\n    问题二：cas server中获取用户的个人信息太多，如角色、菜单、归属城市、机构等数据都获取出来，多次DB查询耗时（6次），大数据传输耗带宽（多达1M），导致登录时间长，用户体验差。\n    \n##### 2.2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。\n    \n    问题一：为客户端提供了三种缓存策略（redis、memcache、local cache），各业务系统保存了用户信息，无统一保存用户信息容器，当用户改变，无法立即全局生效。\n    问题二：采用MQ通知其他业务系统退出清理登录信息，达到了一定的解耦，但是clientId多达65个，增大MQ压力并且亦产生死信消息。\n    问题三：接入方式繁杂，未做到服务的简易性、高内聚、低耦合。\n\n##### 2.3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。\n\n## 三、个人感悟\n针对上面现阶段系统的局限性，以下是个人优化想法：\n\n    1、认证过程，要做到耗时少，只验证用户的登录名密码，也只传输登录状态信息。\n    2、CAS client根据需要，再调用服务去获取用户授权信息，并将信息统一存放至Redis。\n    3、用户退出，清空Redis中的用户信息，不再依赖MQ逐一通知各业务系统。\n    4、RPC接口设计，要做到单一职责、高性能，让调用方接入方便快捷，做到高内聚、低耦合。\n\n参考博客：\n[shiro 登录授权过程详细解析](https://my.oschina.net/u/2415799/blog/865526)\n[CAS 4.1.10 版本服務端原始碼解讀](https://www.codetw.com/lyxepf.html)\n[从http验证流程解析CAS单点登录](https://www.jianshu.com/p/5ef9407c71af)\n[CAS的详细登录流程](https://blog.csdn.net/qq_34246546/article/details/79493208)\n[前端关于单点登录SSO的知识](https://juejin.im/post/5b8116afe51d4538d23db11e)","source":"_posts/2019-03-05-单点登录现状.md","raw":"---\ntitle: 单点登录现状\ndate: 2019-03-05 14:25:22\ntags: CAS Shiro SSO 权限控制\ncategories: 单点登录\n---\n这篇文章，将从登陆、登出流程，详细讲解CAS+Shiro的执行过程。\n## 一、开始\nuum：一个基于RBAC（Role-Based Access Control ）的权限系统（CAS client + shiro）\nsso：CAS server，负责认证授权\n\n> ### 1、登陆流程:\n\n这里将以时序图的方式展现。\n\n<!--more-->\n![单点登录现状](2019-03-05-单点登录现状/cas-login.svg)\n\n\n![单点登录现状](2019-03-05-单点登录现状/CAS基础协议.png)\n总结：\n* 访问CAS client，再访问CAS server获得login token，作为登录的票据\n* 用户输入用户名密码，CAS server进行验证\n* 验证通过，CAS server返回Service token和TGT\n* CAS client拿service token 去CAS server进行验证。\n\n> ### 2、登出流程:\n\n这里将以时序图的方式展现。\n![单点登录现状](2019-03-05-单点登录现状/cas-logout.svg)\n\n\n## 二、使用现状及局限性\n![uum](2019-03-05-单点登录现状/uum现状.png)\n\n##### 2.1、部署方式：cas server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。\n    \n    问题一：单节点方式，服务压力大，响应慢，若主节点挂掉，此时所有登录的用户session将丢失，用户需重新登录，并且在备用节点启动完成之前造成服务不可用，造成的影响范围大。\n    问题二：cas server中获取用户的个人信息太多，如角色、菜单、归属城市、机构等数据都获取出来，多次DB查询耗时（6次），大数据传输耗带宽（多达1M），导致登录时间长，用户体验差。\n    \n##### 2.2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。\n    \n    问题一：为客户端提供了三种缓存策略（redis、memcache、local cache），各业务系统保存了用户信息，无统一保存用户信息容器，当用户改变，无法立即全局生效。\n    问题二：采用MQ通知其他业务系统退出清理登录信息，达到了一定的解耦，但是clientId多达65个，增大MQ压力并且亦产生死信消息。\n    问题三：接入方式繁杂，未做到服务的简易性、高内聚、低耦合。\n\n##### 2.3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。\n\n## 三、个人感悟\n针对上面现阶段系统的局限性，以下是个人优化想法：\n\n    1、认证过程，要做到耗时少，只验证用户的登录名密码，也只传输登录状态信息。\n    2、CAS client根据需要，再调用服务去获取用户授权信息，并将信息统一存放至Redis。\n    3、用户退出，清空Redis中的用户信息，不再依赖MQ逐一通知各业务系统。\n    4、RPC接口设计，要做到单一职责、高性能，让调用方接入方便快捷，做到高内聚、低耦合。\n\n参考博客：\n[shiro 登录授权过程详细解析](https://my.oschina.net/u/2415799/blog/865526)\n[CAS 4.1.10 版本服務端原始碼解讀](https://www.codetw.com/lyxepf.html)\n[从http验证流程解析CAS单点登录](https://www.jianshu.com/p/5ef9407c71af)\n[CAS的详细登录流程](https://blog.csdn.net/qq_34246546/article/details/79493208)\n[前端关于单点登录SSO的知识](https://juejin.im/post/5b8116afe51d4538d23db11e)","slug":"2019-03-05-单点登录现状","published":1,"updated":"2024-10-14T09:38:11.851Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpntr0002a13kyhxx5tha","content":"<p>这篇文章，将从登陆、登出流程，详细讲解CAS+Shiro的执行过程。</p>\n<h2 id=\"一、开始\"><a href=\"#一、开始\" class=\"headerlink\" title=\"一、开始\"></a>一、开始</h2><p>uum：一个基于RBAC（Role-Based Access Control ）的权限系统（CAS client + shiro）<br>sso：CAS server，负责认证授权</p>\n<blockquote>\n<h3 id=\"1、登陆流程\"><a href=\"#1、登陆流程\" class=\"headerlink\" title=\"1、登陆流程:\"></a>1、登陆流程:</h3></blockquote>\n<p>这里将以时序图的方式展现。</p>\n<a id=\"more\"></a>\n<p><img src=\"/2019/03/05/2019-03-05-单点登录现状/cas-login.svg\" alt=\"单点登录现状\"></p>\n<p><img src=\"/2019/03/05/2019-03-05-单点登录现状/CAS%E5%9F%BA%E7%A1%80%E5%8D%8F%E8%AE%AE.png\" alt=\"单点登录现状\"><br>总结：</p>\n<ul>\n<li>访问CAS client，再访问CAS server获得login token，作为登录的票据</li>\n<li>用户输入用户名密码，CAS server进行验证</li>\n<li>验证通过，CAS server返回Service token和TGT</li>\n<li>CAS client拿service token 去CAS server进行验证。</li>\n</ul>\n<blockquote>\n<h3 id=\"2、登出流程\"><a href=\"#2、登出流程\" class=\"headerlink\" title=\"2、登出流程:\"></a>2、登出流程:</h3></blockquote>\n<p>这里将以时序图的方式展现。<br><img src=\"/2019/03/05/2019-03-05-单点登录现状/cas-logout.svg\" alt=\"单点登录现状\"></p>\n<h2 id=\"二、使用现状及局限性\"><a href=\"#二、使用现状及局限性\" class=\"headerlink\" title=\"二、使用现状及局限性\"></a>二、使用现状及局限性</h2><p><img src=\"/2019/03/05/2019-03-05-单点登录现状/uum%E7%8E%B0%E7%8A%B6.png\" alt=\"uum\"></p>\n<h5 id=\"2-1、部署方式：cas-server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。\"><a href=\"#2-1、部署方式：cas-server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。\" class=\"headerlink\" title=\"2.1、部署方式：cas server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。\"></a>2.1、部署方式：cas server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。</h5><pre><code>问题一：单节点方式，服务压力大，响应慢，若主节点挂掉，此时所有登录的用户session将丢失，用户需重新登录，并且在备用节点启动完成之前造成服务不可用，造成的影响范围大。\n问题二：cas server中获取用户的个人信息太多，如角色、菜单、归属城市、机构等数据都获取出来，多次DB查询耗时（6次），大数据传输耗带宽（多达1M），导致登录时间长，用户体验差。</code></pre><h5 id=\"2-2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。\"><a href=\"#2-2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。\" class=\"headerlink\" title=\"2.2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。\"></a>2.2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。</h5><pre><code>问题一：为客户端提供了三种缓存策略（redis、memcache、local cache），各业务系统保存了用户信息，无统一保存用户信息容器，当用户改变，无法立即全局生效。\n问题二：采用MQ通知其他业务系统退出清理登录信息，达到了一定的解耦，但是clientId多达65个，增大MQ压力并且亦产生死信消息。\n问题三：接入方式繁杂，未做到服务的简易性、高内聚、低耦合。</code></pre><h5 id=\"2-3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。\"><a href=\"#2-3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。\" class=\"headerlink\" title=\"2.3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。\"></a>2.3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。</h5><h2 id=\"三、个人感悟\"><a href=\"#三、个人感悟\" class=\"headerlink\" title=\"三、个人感悟\"></a>三、个人感悟</h2><p>针对上面现阶段系统的局限性，以下是个人优化想法：</p>\n<pre><code>1、认证过程，要做到耗时少，只验证用户的登录名密码，也只传输登录状态信息。\n2、CAS client根据需要，再调用服务去获取用户授权信息，并将信息统一存放至Redis。\n3、用户退出，清空Redis中的用户信息，不再依赖MQ逐一通知各业务系统。\n4、RPC接口设计，要做到单一职责、高性能，让调用方接入方便快捷，做到高内聚、低耦合。</code></pre><p>参考博客：<br><a href=\"https://my.oschina.net/u/2415799/blog/865526\" target=\"_blank\" rel=\"noopener\">shiro 登录授权过程详细解析</a><br><a href=\"https://www.codetw.com/lyxepf.html\" target=\"_blank\" rel=\"noopener\">CAS 4.1.10 版本服務端原始碼解讀</a><br><a href=\"https://www.jianshu.com/p/5ef9407c71af\" target=\"_blank\" rel=\"noopener\">从http验证流程解析CAS单点登录</a><br><a href=\"https://blog.csdn.net/qq_34246546/article/details/79493208\" target=\"_blank\" rel=\"noopener\">CAS的详细登录流程</a><br><a href=\"https://juejin.im/post/5b8116afe51d4538d23db11e\" target=\"_blank\" rel=\"noopener\">前端关于单点登录SSO的知识</a></p>\n","site":{"data":{}},"excerpt":"<p>这篇文章，将从登陆、登出流程，详细讲解CAS+Shiro的执行过程。</p>\n<h2 id=\"一、开始\"><a href=\"#一、开始\" class=\"headerlink\" title=\"一、开始\"></a>一、开始</h2><p>uum：一个基于RBAC（Role-Based Access Control ）的权限系统（CAS client + shiro）<br>sso：CAS server，负责认证授权</p>\n<blockquote>\n<h3 id=\"1、登陆流程\"><a href=\"#1、登陆流程\" class=\"headerlink\" title=\"1、登陆流程:\"></a>1、登陆流程:</h3></blockquote>\n<p>这里将以时序图的方式展现。</p>","more":"<p><img src=\"/2019/03/05/2019-03-05-单点登录现状/cas-login.svg\" alt=\"单点登录现状\"></p>\n<p><img src=\"/2019/03/05/2019-03-05-单点登录现状/CAS%E5%9F%BA%E7%A1%80%E5%8D%8F%E8%AE%AE.png\" alt=\"单点登录现状\"><br>总结：</p>\n<ul>\n<li>访问CAS client，再访问CAS server获得login token，作为登录的票据</li>\n<li>用户输入用户名密码，CAS server进行验证</li>\n<li>验证通过，CAS server返回Service token和TGT</li>\n<li>CAS client拿service token 去CAS server进行验证。</li>\n</ul>\n<blockquote>\n<h3 id=\"2、登出流程\"><a href=\"#2、登出流程\" class=\"headerlink\" title=\"2、登出流程:\"></a>2、登出流程:</h3></blockquote>\n<p>这里将以时序图的方式展现。<br><img src=\"/2019/03/05/2019-03-05-单点登录现状/cas-logout.svg\" alt=\"单点登录现状\"></p>\n<h2 id=\"二、使用现状及局限性\"><a href=\"#二、使用现状及局限性\" class=\"headerlink\" title=\"二、使用现状及局限性\"></a>二、使用现状及局限性</h2><p><img src=\"/2019/03/05/2019-03-05-单点登录现状/uum%E7%8E%B0%E7%8A%B6.png\" alt=\"uum\"></p>\n<h5 id=\"2-1、部署方式：cas-server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。\"><a href=\"#2-1、部署方式：cas-server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。\" class=\"headerlink\" title=\"2.1、部署方式：cas server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。\"></a>2.1、部署方式：cas server主备方式部署，采用nginx配置负载均衡，当主节点挂掉后，启动备用节点。</h5><pre><code>问题一：单节点方式，服务压力大，响应慢，若主节点挂掉，此时所有登录的用户session将丢失，用户需重新登录，并且在备用节点启动完成之前造成服务不可用，造成的影响范围大。\n问题二：cas server中获取用户的个人信息太多，如角色、菜单、归属城市、机构等数据都获取出来，多次DB查询耗时（6次），大数据传输耗带宽（多达1M），导致登录时间长，用户体验差。</code></pre><h5 id=\"2-2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。\"><a href=\"#2-2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。\" class=\"headerlink\" title=\"2.2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。\"></a>2.2、权限控制采用shiro，各业务系统都缓存了权限及登陆信息，若退出登陆，通过发送MQ通知其他系统进行登录信息清除。</h5><pre><code>问题一：为客户端提供了三种缓存策略（redis、memcache、local cache），各业务系统保存了用户信息，无统一保存用户信息容器，当用户改变，无法立即全局生效。\n问题二：采用MQ通知其他业务系统退出清理登录信息，达到了一定的解耦，但是clientId多达65个，增大MQ压力并且亦产生死信消息。\n问题三：接入方式繁杂，未做到服务的简易性、高内聚、低耦合。</code></pre><h5 id=\"2-3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。\"><a href=\"#2-3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。\" class=\"headerlink\" title=\"2.3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。\"></a>2.3、底层RPC服务臃肿，模块职责不清晰，查询基本信息时查询的其他信息过多，未做到接口的单一职责、高性能。</h5><h2 id=\"三、个人感悟\"><a href=\"#三、个人感悟\" class=\"headerlink\" title=\"三、个人感悟\"></a>三、个人感悟</h2><p>针对上面现阶段系统的局限性，以下是个人优化想法：</p>\n<pre><code>1、认证过程，要做到耗时少，只验证用户的登录名密码，也只传输登录状态信息。\n2、CAS client根据需要，再调用服务去获取用户授权信息，并将信息统一存放至Redis。\n3、用户退出，清空Redis中的用户信息，不再依赖MQ逐一通知各业务系统。\n4、RPC接口设计，要做到单一职责、高性能，让调用方接入方便快捷，做到高内聚、低耦合。</code></pre><p>参考博客：<br><a href=\"https://my.oschina.net/u/2415799/blog/865526\" target=\"_blank\" rel=\"noopener\">shiro 登录授权过程详细解析</a><br><a href=\"https://www.codetw.com/lyxepf.html\" target=\"_blank\" rel=\"noopener\">CAS 4.1.10 版本服務端原始碼解讀</a><br><a href=\"https://www.jianshu.com/p/5ef9407c71af\" target=\"_blank\" rel=\"noopener\">从http验证流程解析CAS单点登录</a><br><a href=\"https://blog.csdn.net/qq_34246546/article/details/79493208\" target=\"_blank\" rel=\"noopener\">CAS的详细登录流程</a><br><a href=\"https://juejin.im/post/5b8116afe51d4538d23db11e\" target=\"_blank\" rel=\"noopener\">前端关于单点登录SSO的知识</a></p>"},{"title":"统一登录线上事故排查过程","date":"2018-12-11T09:29:33.000Z","_content":"\n\n# 一、问题发现：\n上午9点开始CS系统出现登录异常和菜单和权限服务异常。 \n\n事故时间: 9:00到11:20\n\n影响范围：接入CS平台所有系统\n\n<!--more-->    \n\n# 二、排查过程\n服务出现登录异常，大范围不可使用，知道服务一定出问题了。\n    \n1、 排查服务最近是否有上线\n* ps -ef | grep uum，查看进程启动时间，近期没有上线，排除。\n\n2、 排查内存资源\n* free -m，如下图所示，系统内存资源不是很紧张，排除。\n![redis-io](2018-12-11-统一登录线上事故排查过程/内存情况.png)\n\n3、排查服务器情况\n* top，查看是否项目线程占用CPU过高，发现正常，排除。\n\n4、排查服务运行情况\n* 服务大范围不可用，怀疑是出现频繁的FGC，从而导致系统响应慢.\n* 排查GC情况：jstat命令查看GC情况\n    * jstat -gcutil 65168，查看GC情况。\n    ![redis-io](2018-12-11-统一登录线上事故排查过程/jstat-GC情况.png)\n    （具体排查时，没有保留图片，用上图表示）\n    * 结果：FGC频率实际没有很频繁，几分钟一次，实际不影响（还是查看FGC稍微频繁原因）\n\n* 排查大对象：jmap命令\n    * 实际在开发维护工程中，已经知道统一登录系统内部存在非常多的大对象（老系统，设计不合理）\n    * 查看堆对象：jmap -histo 65168 > /opt/backup/recycle/65168_jmap_histo.txt，重定向至文件内。\n    ![redis-io](2018-12-11-统一登录线上事故排查过程/jmap.png)\n    * 查看堆内存：jmap -heap\n    ![redis-io](2018-12-11-统一登录线上事故排查过程/jmap-heap.png)\n    查看堆及堆对象没有太大问题。\n    \n5、排查JVM参数\n* -Xms512m -Xmx512m -Xmn256m -Xss1024K -XX:PermSize=256m -XX:MaxPermSize=512m -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:SurvivorRatio=4 -XX:MaxTenuringThreshold=8 -XX:CMSInitiatingOccupancyFraction=80    \n    * 调整垃圾最大年龄：-XX:MaxTenuringThreshold=15（即对象最多经过几轮复制之后进入老年代），防止对象过快进入老年代\n    * 调整Eden比例：-XX:SurvivorRatio=8（伊甸区与存活区的From区或To区的比值，默认比值设置为8，即伊甸区占整个新生代的8/10，From和To各占1/10）\n    * 调整堆空间：-Xms512g -Xmx1g -Xmn256m，调大堆最大空间。\n\n6、以上步骤，实际并未解决问题，调整参数后重启，依旧无法登陆。  \n7、然后追踪数据库，发现数据库的磁盘IO及CPU都不是很高，并且没有宕机。   \n8、然后追踪Redis，发现出现问题\n* Redis连接情况 \n![redis-connect](2018-12-11-统一登录线上事故排查过程/redis-connect.jpg)\n异常时间内redis夯住，导致监控检查连接不能获取到运行信息\n* Redis的IO情况\n![redis-io](2018-12-11-统一登录线上事故排查过程/redis-io.jpg)\n\n9、找到了问题所在，Redis异常，导致服务不可用。\n\n10、总结\n* 查看线程情况，回过头来看，是否可以查看出毛病呢？\n* ps p 65168 -L -o pcpu,pid,tid,time，打印进程线程的耗时情况\n* 打印线程栈信息：jstack pid \n\n```\n1、ps Hh -eo pid,tid,pcpu |sort -nk3|tail //直接定位到占用CPU最大的进程pid-线程id\n2、printf \"0x%x\\n\" 线程pid  // 将线程PID转换为 16进制 0x1a2f ，为后面查找 jstack 日志做准备\n3、jstack pid | grep -A 20 'nid=0x1a2f' //查看对应线程堆栈，分析问题\n```\n\n\n\n\n\n# 三、问题原因：\n    1、mybatis二级缓存组件使用不当：在高并发情况下，mybatis二级缓存组件实现方式会在数据更新，修改和删除时，频繁调用redis中的keysByScan去获取当前库中全局匹配到的key，当key数量足够多时，执行时间会十分漫长，导致整个redis服务并夯住，出于不可用状态\n    2、redis超时时间设置过长，redis超时后，不能将请求漏给mysql数据库做兜底支撑\n    3、csrecruit线索系统，每5分钟，全量刷新一次所有用户权限数据，一天调用量达到2000w以上，占整个djuum的调用量的75%以上 \n\n\n# 四、问题解决\n做限流降级处理。对刷新用户权限数据接口，做限流降级处理。\n\n\n","source":"_posts/2018-12-11-统一登录线上事故排查过程.md","raw":"---\ntitle: 统一登录线上事故排查过程\ndate: 2018-12-11 17:29:33\ntags: jvm redis\ncategories: \n  - [java, jvm]\n---\n\n\n# 一、问题发现：\n上午9点开始CS系统出现登录异常和菜单和权限服务异常。 \n\n事故时间: 9:00到11:20\n\n影响范围：接入CS平台所有系统\n\n<!--more-->    \n\n# 二、排查过程\n服务出现登录异常，大范围不可使用，知道服务一定出问题了。\n    \n1、 排查服务最近是否有上线\n* ps -ef | grep uum，查看进程启动时间，近期没有上线，排除。\n\n2、 排查内存资源\n* free -m，如下图所示，系统内存资源不是很紧张，排除。\n![redis-io](2018-12-11-统一登录线上事故排查过程/内存情况.png)\n\n3、排查服务器情况\n* top，查看是否项目线程占用CPU过高，发现正常，排除。\n\n4、排查服务运行情况\n* 服务大范围不可用，怀疑是出现频繁的FGC，从而导致系统响应慢.\n* 排查GC情况：jstat命令查看GC情况\n    * jstat -gcutil 65168，查看GC情况。\n    ![redis-io](2018-12-11-统一登录线上事故排查过程/jstat-GC情况.png)\n    （具体排查时，没有保留图片，用上图表示）\n    * 结果：FGC频率实际没有很频繁，几分钟一次，实际不影响（还是查看FGC稍微频繁原因）\n\n* 排查大对象：jmap命令\n    * 实际在开发维护工程中，已经知道统一登录系统内部存在非常多的大对象（老系统，设计不合理）\n    * 查看堆对象：jmap -histo 65168 > /opt/backup/recycle/65168_jmap_histo.txt，重定向至文件内。\n    ![redis-io](2018-12-11-统一登录线上事故排查过程/jmap.png)\n    * 查看堆内存：jmap -heap\n    ![redis-io](2018-12-11-统一登录线上事故排查过程/jmap-heap.png)\n    查看堆及堆对象没有太大问题。\n    \n5、排查JVM参数\n* -Xms512m -Xmx512m -Xmn256m -Xss1024K -XX:PermSize=256m -XX:MaxPermSize=512m -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:SurvivorRatio=4 -XX:MaxTenuringThreshold=8 -XX:CMSInitiatingOccupancyFraction=80    \n    * 调整垃圾最大年龄：-XX:MaxTenuringThreshold=15（即对象最多经过几轮复制之后进入老年代），防止对象过快进入老年代\n    * 调整Eden比例：-XX:SurvivorRatio=8（伊甸区与存活区的From区或To区的比值，默认比值设置为8，即伊甸区占整个新生代的8/10，From和To各占1/10）\n    * 调整堆空间：-Xms512g -Xmx1g -Xmn256m，调大堆最大空间。\n\n6、以上步骤，实际并未解决问题，调整参数后重启，依旧无法登陆。  \n7、然后追踪数据库，发现数据库的磁盘IO及CPU都不是很高，并且没有宕机。   \n8、然后追踪Redis，发现出现问题\n* Redis连接情况 \n![redis-connect](2018-12-11-统一登录线上事故排查过程/redis-connect.jpg)\n异常时间内redis夯住，导致监控检查连接不能获取到运行信息\n* Redis的IO情况\n![redis-io](2018-12-11-统一登录线上事故排查过程/redis-io.jpg)\n\n9、找到了问题所在，Redis异常，导致服务不可用。\n\n10、总结\n* 查看线程情况，回过头来看，是否可以查看出毛病呢？\n* ps p 65168 -L -o pcpu,pid,tid,time，打印进程线程的耗时情况\n* 打印线程栈信息：jstack pid \n\n```\n1、ps Hh -eo pid,tid,pcpu |sort -nk3|tail //直接定位到占用CPU最大的进程pid-线程id\n2、printf \"0x%x\\n\" 线程pid  // 将线程PID转换为 16进制 0x1a2f ，为后面查找 jstack 日志做准备\n3、jstack pid | grep -A 20 'nid=0x1a2f' //查看对应线程堆栈，分析问题\n```\n\n\n\n\n\n# 三、问题原因：\n    1、mybatis二级缓存组件使用不当：在高并发情况下，mybatis二级缓存组件实现方式会在数据更新，修改和删除时，频繁调用redis中的keysByScan去获取当前库中全局匹配到的key，当key数量足够多时，执行时间会十分漫长，导致整个redis服务并夯住，出于不可用状态\n    2、redis超时时间设置过长，redis超时后，不能将请求漏给mysql数据库做兜底支撑\n    3、csrecruit线索系统，每5分钟，全量刷新一次所有用户权限数据，一天调用量达到2000w以上，占整个djuum的调用量的75%以上 \n\n\n# 四、问题解决\n做限流降级处理。对刷新用户权限数据接口，做限流降级处理。\n\n\n","slug":"2018-12-11-统一登录线上事故排查过程","published":1,"updated":"2024-12-09T03:18:50.888Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpntv0005a13ktkdgg3om","content":"<h1 id=\"一、问题发现：\"><a href=\"#一、问题发现：\" class=\"headerlink\" title=\"一、问题发现：\"></a>一、问题发现：</h1><p>上午9点开始CS系统出现登录异常和菜单和权限服务异常。 </p>\n<p>事故时间: 9:00到11:20</p>\n<p>影响范围：接入CS平台所有系统</p>\n<a id=\"more\"></a>    \n\n<h1 id=\"二、排查过程\"><a href=\"#二、排查过程\" class=\"headerlink\" title=\"二、排查过程\"></a>二、排查过程</h1><p>服务出现登录异常，大范围不可使用，知道服务一定出问题了。</p>\n<p>1、 排查服务最近是否有上线</p>\n<ul>\n<li>ps -ef | grep uum，查看进程启动时间，近期没有上线，排除。</li>\n</ul>\n<p>2、 排查内存资源</p>\n<ul>\n<li>free -m，如下图所示，系统内存资源不是很紧张，排除。<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/%E5%86%85%E5%AD%98%E6%83%85%E5%86%B5.png\" alt=\"redis-io\"></li>\n</ul>\n<p>3、排查服务器情况</p>\n<ul>\n<li>top，查看是否项目线程占用CPU过高，发现正常，排除。</li>\n</ul>\n<p>4、排查服务运行情况</p>\n<ul>\n<li><p>服务大范围不可用，怀疑是出现频繁的FGC，从而导致系统响应慢.</p>\n</li>\n<li><p>排查GC情况：jstat命令查看GC情况</p>\n<ul>\n<li>jstat -gcutil 65168，查看GC情况。<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/jstat-GC%E6%83%85%E5%86%B5.png\" alt=\"redis-io\"><br>（具体排查时，没有保留图片，用上图表示）</li>\n<li>结果：FGC频率实际没有很频繁，几分钟一次，实际不影响（还是查看FGC稍微频繁原因）</li>\n</ul>\n</li>\n<li><p>排查大对象：jmap命令</p>\n<ul>\n<li>实际在开发维护工程中，已经知道统一登录系统内部存在非常多的大对象（老系统，设计不合理）</li>\n<li>查看堆对象：jmap -histo 65168 &gt; /opt/backup/recycle/65168_jmap_histo.txt，重定向至文件内。<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/jmap.png\" alt=\"redis-io\"></li>\n<li>查看堆内存：jmap -heap<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/jmap-heap.png\" alt=\"redis-io\"><br>查看堆及堆对象没有太大问题。</li>\n</ul>\n</li>\n</ul>\n<p>5、排查JVM参数</p>\n<ul>\n<li>-Xms512m -Xmx512m -Xmn256m -Xss1024K -XX:PermSize=256m -XX:MaxPermSize=512m -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:SurvivorRatio=4 -XX:MaxTenuringThreshold=8 -XX:CMSInitiatingOccupancyFraction=80    <ul>\n<li>调整垃圾最大年龄：-XX:MaxTenuringThreshold=15（即对象最多经过几轮复制之后进入老年代），防止对象过快进入老年代</li>\n<li>调整Eden比例：-XX:SurvivorRatio=8（伊甸区与存活区的From区或To区的比值，默认比值设置为8，即伊甸区占整个新生代的8/10，From和To各占1/10）</li>\n<li>调整堆空间：-Xms512g -Xmx1g -Xmn256m，调大堆最大空间。</li>\n</ul>\n</li>\n</ul>\n<p>6、以上步骤，实际并未解决问题，调整参数后重启，依旧无法登陆。<br>7、然后追踪数据库，发现数据库的磁盘IO及CPU都不是很高，并且没有宕机。<br>8、然后追踪Redis，发现出现问题</p>\n<ul>\n<li>Redis连接情况<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/redis-connect.jpg\" alt=\"redis-connect\"><br>异常时间内redis夯住，导致监控检查连接不能获取到运行信息</li>\n<li>Redis的IO情况<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/redis-io.jpg\" alt=\"redis-io\"></li>\n</ul>\n<p>9、找到了问题所在，Redis异常，导致服务不可用。</p>\n<p>10、总结</p>\n<ul>\n<li>查看线程情况，回过头来看，是否可以查看出毛病呢？</li>\n<li>ps p 65168 -L -o pcpu,pid,tid,time，打印进程线程的耗时情况</li>\n<li>打印线程栈信息：jstack pid </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、ps Hh -eo pid,tid,pcpu |sort -nk3|tail //直接定位到占用CPU最大的进程pid-线程id</span><br><span class=\"line\">2、printf &quot;0x%x\\n&quot; 线程pid  // 将线程PID转换为 16进制 0x1a2f ，为后面查找 jstack 日志做准备</span><br><span class=\"line\">3、jstack pid | grep -A 20 &apos;nid=0x1a2f&apos; //查看对应线程堆栈，分析问题</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、问题原因：\"><a href=\"#三、问题原因：\" class=\"headerlink\" title=\"三、问题原因：\"></a>三、问题原因：</h1><pre><code>1、mybatis二级缓存组件使用不当：在高并发情况下，mybatis二级缓存组件实现方式会在数据更新，修改和删除时，频繁调用redis中的keysByScan去获取当前库中全局匹配到的key，当key数量足够多时，执行时间会十分漫长，导致整个redis服务并夯住，出于不可用状态\n2、redis超时时间设置过长，redis超时后，不能将请求漏给mysql数据库做兜底支撑\n3、csrecruit线索系统，每5分钟，全量刷新一次所有用户权限数据，一天调用量达到2000w以上，占整个djuum的调用量的75%以上 </code></pre><h1 id=\"四、问题解决\"><a href=\"#四、问题解决\" class=\"headerlink\" title=\"四、问题解决\"></a>四、问题解决</h1><p>做限流降级处理。对刷新用户权限数据接口，做限流降级处理。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、问题发现：\"><a href=\"#一、问题发现：\" class=\"headerlink\" title=\"一、问题发现：\"></a>一、问题发现：</h1><p>上午9点开始CS系统出现登录异常和菜单和权限服务异常。 </p>\n<p>事故时间: 9:00到11:20</p>\n<p>影响范围：接入CS平台所有系统</p>","more":"<h1 id=\"二、排查过程\"><a href=\"#二、排查过程\" class=\"headerlink\" title=\"二、排查过程\"></a>二、排查过程</h1><p>服务出现登录异常，大范围不可使用，知道服务一定出问题了。</p>\n<p>1、 排查服务最近是否有上线</p>\n<ul>\n<li>ps -ef | grep uum，查看进程启动时间，近期没有上线，排除。</li>\n</ul>\n<p>2、 排查内存资源</p>\n<ul>\n<li>free -m，如下图所示，系统内存资源不是很紧张，排除。<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/%E5%86%85%E5%AD%98%E6%83%85%E5%86%B5.png\" alt=\"redis-io\"></li>\n</ul>\n<p>3、排查服务器情况</p>\n<ul>\n<li>top，查看是否项目线程占用CPU过高，发现正常，排除。</li>\n</ul>\n<p>4、排查服务运行情况</p>\n<ul>\n<li><p>服务大范围不可用，怀疑是出现频繁的FGC，从而导致系统响应慢.</p>\n</li>\n<li><p>排查GC情况：jstat命令查看GC情况</p>\n<ul>\n<li>jstat -gcutil 65168，查看GC情况。<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/jstat-GC%E6%83%85%E5%86%B5.png\" alt=\"redis-io\"><br>（具体排查时，没有保留图片，用上图表示）</li>\n<li>结果：FGC频率实际没有很频繁，几分钟一次，实际不影响（还是查看FGC稍微频繁原因）</li>\n</ul>\n</li>\n<li><p>排查大对象：jmap命令</p>\n<ul>\n<li>实际在开发维护工程中，已经知道统一登录系统内部存在非常多的大对象（老系统，设计不合理）</li>\n<li>查看堆对象：jmap -histo 65168 &gt; /opt/backup/recycle/65168_jmap_histo.txt，重定向至文件内。<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/jmap.png\" alt=\"redis-io\"></li>\n<li>查看堆内存：jmap -heap<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/jmap-heap.png\" alt=\"redis-io\"><br>查看堆及堆对象没有太大问题。</li>\n</ul>\n</li>\n</ul>\n<p>5、排查JVM参数</p>\n<ul>\n<li>-Xms512m -Xmx512m -Xmn256m -Xss1024K -XX:PermSize=256m -XX:MaxPermSize=512m -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:SurvivorRatio=4 -XX:MaxTenuringThreshold=8 -XX:CMSInitiatingOccupancyFraction=80    <ul>\n<li>调整垃圾最大年龄：-XX:MaxTenuringThreshold=15（即对象最多经过几轮复制之后进入老年代），防止对象过快进入老年代</li>\n<li>调整Eden比例：-XX:SurvivorRatio=8（伊甸区与存活区的From区或To区的比值，默认比值设置为8，即伊甸区占整个新生代的8/10，From和To各占1/10）</li>\n<li>调整堆空间：-Xms512g -Xmx1g -Xmn256m，调大堆最大空间。</li>\n</ul>\n</li>\n</ul>\n<p>6、以上步骤，实际并未解决问题，调整参数后重启，依旧无法登陆。<br>7、然后追踪数据库，发现数据库的磁盘IO及CPU都不是很高，并且没有宕机。<br>8、然后追踪Redis，发现出现问题</p>\n<ul>\n<li>Redis连接情况<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/redis-connect.jpg\" alt=\"redis-connect\"><br>异常时间内redis夯住，导致监控检查连接不能获取到运行信息</li>\n<li>Redis的IO情况<br><img src=\"/2018/12/11/2018-12-11-统一登录线上事故排查过程/redis-io.jpg\" alt=\"redis-io\"></li>\n</ul>\n<p>9、找到了问题所在，Redis异常，导致服务不可用。</p>\n<p>10、总结</p>\n<ul>\n<li>查看线程情况，回过头来看，是否可以查看出毛病呢？</li>\n<li>ps p 65168 -L -o pcpu,pid,tid,time，打印进程线程的耗时情况</li>\n<li>打印线程栈信息：jstack pid </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、ps Hh -eo pid,tid,pcpu |sort -nk3|tail //直接定位到占用CPU最大的进程pid-线程id</span><br><span class=\"line\">2、printf &quot;0x%x\\n&quot; 线程pid  // 将线程PID转换为 16进制 0x1a2f ，为后面查找 jstack 日志做准备</span><br><span class=\"line\">3、jstack pid | grep -A 20 &apos;nid=0x1a2f&apos; //查看对应线程堆栈，分析问题</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、问题原因：\"><a href=\"#三、问题原因：\" class=\"headerlink\" title=\"三、问题原因：\"></a>三、问题原因：</h1><pre><code>1、mybatis二级缓存组件使用不当：在高并发情况下，mybatis二级缓存组件实现方式会在数据更新，修改和删除时，频繁调用redis中的keysByScan去获取当前库中全局匹配到的key，当key数量足够多时，执行时间会十分漫长，导致整个redis服务并夯住，出于不可用状态\n2、redis超时时间设置过长，redis超时后，不能将请求漏给mysql数据库做兜底支撑\n3、csrecruit线索系统，每5分钟，全量刷新一次所有用户权限数据，一天调用量达到2000w以上，占整个djuum的调用量的75%以上 </code></pre><h1 id=\"四、问题解决\"><a href=\"#四、问题解决\" class=\"headerlink\" title=\"四、问题解决\"></a>四、问题解决</h1><p>做限流降级处理。对刷新用户权限数据接口，做限流降级处理。</p>"},{"title":"记一次MYSQL服务器CPU爆了问题","date":"2019-01-10T07:32:50.000Z","_content":"# 一、背景\n数据库CPU爆满，负载高。\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/mysql.png)\n\n<!--more-->    \n\n# 二、查看具体问题SQL\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql.png)\n\n# 三、使用EXPLAIN解析SQL\n```\nEXPLAIN select * from sys_user\nleft join sys_office on sys_user.office_id = sys_office.id\nwhere  sys_office.del_flag = 0 and (sys_office.id=14691547965585801 or sys_office.parent_ids like '%,14691547965585801,%')\norder by sys_user.id ASC limit 20000,100;\n```\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql-explain.png)\n\n# 四、优化方案\n```\nEXPLAIN select sys_user.id from sys_user\nleft join sys_office on sys_user.office_id = sys_office.id\nwhere  sys_office.del_flag = 0 and (sys_office.id=14691547965585801 or sys_office.parent_ids like '0,1,14691547965585801,%')\norder by sys_user.id ASC limit 20000,100;\n```\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-explain.png)\n注意上图红框所示，用户表直接通过索引获取用户主键：解读MySQL执行计划的type列和extra列\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-cos-time.png)\n新SQL耗时\n","source":"_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题.md","raw":"---\ntitle: 记一次MYSQL服务器CPU爆了问题\ndate: 2019-01-10 15:32:50\ntags: mysql\ncategories:\n  - [数据库, mysql, 线上问题]\n---\n# 一、背景\n数据库CPU爆满，负载高。\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/mysql.png)\n\n<!--more-->    \n\n# 二、查看具体问题SQL\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql.png)\n\n# 三、使用EXPLAIN解析SQL\n```\nEXPLAIN select * from sys_user\nleft join sys_office on sys_user.office_id = sys_office.id\nwhere  sys_office.del_flag = 0 and (sys_office.id=14691547965585801 or sys_office.parent_ids like '%,14691547965585801,%')\norder by sys_user.id ASC limit 20000,100;\n```\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql-explain.png)\n\n# 四、优化方案\n```\nEXPLAIN select sys_user.id from sys_user\nleft join sys_office on sys_user.office_id = sys_office.id\nwhere  sys_office.del_flag = 0 and (sys_office.id=14691547965585801 or sys_office.parent_ids like '0,1,14691547965585801,%')\norder by sys_user.id ASC limit 20000,100;\n```\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-explain.png)\n注意上图红框所示，用户表直接通过索引获取用户主键：解读MySQL执行计划的type列和extra列\n![redis-io](2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-cos-time.png)\n新SQL耗时\n","slug":"2019-01-10-记一次MYSQL服务器CPU爆了问题","published":1,"updated":"2024-12-09T03:26:17.306Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnu70007a13k0j0ez2l6","content":"<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><p>数据库CPU爆满，负载高。<br><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/mysql.png\" alt=\"redis-io\"></p>\n<a id=\"more\"></a>    \n\n<h1 id=\"二、查看具体问题SQL\"><a href=\"#二、查看具体问题SQL\" class=\"headerlink\" title=\"二、查看具体问题SQL\"></a>二、查看具体问题SQL</h1><p><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql.png\" alt=\"redis-io\"></p>\n<h1 id=\"三、使用EXPLAIN解析SQL\"><a href=\"#三、使用EXPLAIN解析SQL\" class=\"headerlink\" title=\"三、使用EXPLAIN解析SQL\"></a>三、使用EXPLAIN解析SQL</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EXPLAIN select * from sys_user</span><br><span class=\"line\">left join sys_office on sys_user.office_id = sys_office.id</span><br><span class=\"line\">where  sys_office.del_flag = 0 and (sys_office.id=14691547965585801 or sys_office.parent_ids like &apos;%,14691547965585801,%&apos;)</span><br><span class=\"line\">order by sys_user.id ASC limit 20000,100;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql-explain.png\" alt=\"redis-io\"></p>\n<h1 id=\"四、优化方案\"><a href=\"#四、优化方案\" class=\"headerlink\" title=\"四、优化方案\"></a>四、优化方案</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EXPLAIN select sys_user.id from sys_user</span><br><span class=\"line\">left join sys_office on sys_user.office_id = sys_office.id</span><br><span class=\"line\">where  sys_office.del_flag = 0 and (sys_office.id=14691547965585801 or sys_office.parent_ids like &apos;0,1,14691547965585801,%&apos;)</span><br><span class=\"line\">order by sys_user.id ASC limit 20000,100;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-explain.png\" alt=\"redis-io\"><br>注意上图红框所示，用户表直接通过索引获取用户主键：解读MySQL执行计划的type列和extra列<br><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-cos-time.png\" alt=\"redis-io\"><br>新SQL耗时</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><p>数据库CPU爆满，负载高。<br><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/mysql.png\" alt=\"redis-io\"></p>","more":"<h1 id=\"二、查看具体问题SQL\"><a href=\"#二、查看具体问题SQL\" class=\"headerlink\" title=\"二、查看具体问题SQL\"></a>二、查看具体问题SQL</h1><p><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql.png\" alt=\"redis-io\"></p>\n<h1 id=\"三、使用EXPLAIN解析SQL\"><a href=\"#三、使用EXPLAIN解析SQL\" class=\"headerlink\" title=\"三、使用EXPLAIN解析SQL\"></a>三、使用EXPLAIN解析SQL</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EXPLAIN select * from sys_user</span><br><span class=\"line\">left join sys_office on sys_user.office_id = sys_office.id</span><br><span class=\"line\">where  sys_office.del_flag = 0 and (sys_office.id=14691547965585801 or sys_office.parent_ids like &apos;%,14691547965585801,%&apos;)</span><br><span class=\"line\">order by sys_user.id ASC limit 20000,100;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql-explain.png\" alt=\"redis-io\"></p>\n<h1 id=\"四、优化方案\"><a href=\"#四、优化方案\" class=\"headerlink\" title=\"四、优化方案\"></a>四、优化方案</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EXPLAIN select sys_user.id from sys_user</span><br><span class=\"line\">left join sys_office on sys_user.office_id = sys_office.id</span><br><span class=\"line\">where  sys_office.del_flag = 0 and (sys_office.id=14691547965585801 or sys_office.parent_ids like &apos;0,1,14691547965585801,%&apos;)</span><br><span class=\"line\">order by sys_user.id ASC limit 20000,100;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-explain.png\" alt=\"redis-io\"><br>注意上图红框所示，用户表直接通过索引获取用户主键：解读MySQL执行计划的type列和extra列<br><img src=\"/2019/01/10/2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-cos-time.png\" alt=\"redis-io\"><br>新SQL耗时</p>"},{"title":"单点登录优化方案一","date":"2019-03-15T11:54:22.000Z","_content":"针对现有统一登录系统问题，进行了一些尝试，这篇文章是尝试过程中使用的方案一。\n## 一、针对cas server单点问题\n\ncas交互流程大致如下：\n> * 拦截到web应用的请求，验证登录状态，若未登录则跳转到登录页\n> * 登录成功，web应用的tomcat存储session，cas-server保存TGT信息，cas-client-core保存ST和session的对应关系\n> * 登出时由cas-server返回ST信息，cas-client-core根据ST删除自己存储在内存的ST和session信息。（web应用在接入cas的时候需要继承cas-client-core）\n\n针对现有cas单点部署情况及会遇到的问题，进行了分布式集群部署的尝试。\n\n<!--more-->\n\n》》解决分布式，主要是解决session共享\n\n    1、Tomcat的session共享。\n    2、CAS的ST、TGT的共享。\n    3、cas-client-core共享ST和session的对应关系\n\n\n##### 1.1、tomcat-session-redis 共享\n1、引入tomcat-redis-session-manager插件。\n\n2、修改tomcat的 context.xml 配置文件，添加如下配置：\n\n    <!-- tomcat-redis-session共享配置 -->\n    <Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n    <Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n    sentinels=\"a.redis.dns.cn:58783,b.redis.dns.cn:58783,c.redis.dns.cn:58783\"\n    sentinelMaster=\"master\"\n    timeout=\"3000\"\n    maxInactiveInterval=\"60\" />\n\n3、在tomcat 的lib下添加以下包\n\n    tomcat-redis-cache-manager.jar\n    注意:tomcat8,与tomcat7包有所不同,请按版本添加，详细查看官网。\n\n\n##### 1.2、CAS的ST、TGT的共享\n\n1、ST根据TGT生成，然后保存\n\n    public ServiceTicket grantServiceTicket(\n            final String ticketGrantingTicketId,\n            final Service service, final Credential... credentials)\n            throws AuthenticationException, TicketException {\n\n        final TicketGrantingTicket ticketGrantingTicket = getTicket(ticketGrantingTicketId, TicketGrantingTicket.class);\n        final RegisteredService registeredService = this.servicesManager.findServiceBy(service);\n\n        ............省略代码\n\n        final String ticketPrefix = authentications.size() == 1 ? ServiceTicket.PREFIX : ServiceTicket.PROXY_TICKET_PREFIX;\n        final String ticketId = serviceTicketUniqueTicketIdGenerator.getNewTicketId(ticketPrefix);\n        final ServiceTicket serviceTicket = ticketGrantingTicket.grantServiceTicket(\n                ticketId,\n                service,\n                this.serviceTicketExpirationPolicy,\n                currentAuthentication != null);\n\n        this.ticketRegistry.addTicket(serviceTicket);//查看2中的DbTicketRegistry\n\n        logger.info(\"Granted ticket [{}] for service [{}] for user [{}]\",\n                serviceTicket.getId(), service.getId(), principal.getId());\n\n        return serviceTicket;\n    }\n\n2、实现自定义的TicketRegistry，以下为简略代码。\n\n    public final class DbTicketRegistry extends AbstractDistributedTicketRegistry implements DisposableBean {\n        private int tgtTimeout;\n        private int stTimeout;\n        @Override\n        public void addTicket(final Ticket ticket) {\n            logger.debug(\"Adding ticket {}\", ticket);\n            try {\n                this.saveTicket(ticket);\n            } catch (final Exception e) {\n                logger.error(\"Failed adding {} ，error:{} 。\", ticket,e);\n            }\n        }\n        \n        private void saveTicket(final Ticket ticket) throws Exception{\n             try {\n                ITicketGrantingTicketService ticketGrantingTicketService =  UumUtil.getApplicationContext().getBean(ITicketGrantingTicketService.class); \n                if(ticket instanceof ServiceTicketImpl){\n                    //st采用了Redis存储\n                    RedisCacheClientUtil.syncAdd(ticket.getId(), ticket, 1000, RedisCacheClientUtil.DEFAULT_TIMEOUT);\n                 }\n                if(ticket instanceof TicketGrantingTicketImpl){\n                    //TGT采用了DB存储\n                    TicketGrantingTicketDTO ticketGrantingTicketDTO = getDbTicket((TicketGrantingTicketImpl)ticket,ticketGrantingTicketService);\n                    ticketGrantingTicketService.save(ticketGrantingTicketDTO);\n                 }\n             } catch (final Exception e) {\n                 logger.error(\"Failed save {} ，error:{} 。\", ticket,e);\n             }\n        }\n    }\n\n\n3、cas-client-core共享ST和session的对应关系，退出票据删除\n\ncas-client-core利用HashMapBackedSessionMappingStorage实现了ST和session的内存存储\n    \n    //添加\n    @Override\n    public void addSessionById(String mappingId, HttpSession session) {\n        String STKey = getKey(mappingId);\n        StandardSessionFacade standardSessionFacade = (StandardSessionFacade) session;\n        RedisSession redisSession = null;\n        try {\n            redisSession = (RedisSession) getValue(standardSessionFacade, \"session\");\n        } catch (IllegalAccessException e) {\n            e.printStackTrace();\n        } catch (NoSuchFieldException e) {\n            e.printStackTrace();\n        }\n        if (null == redisSession) {\n            log.error(\"get redisSession fail\");\n            return;\n        }\n \n        sessionRedisTemplate.opsForValue().set(STKey, jdkSerializer.serialize(redisSession));\n        String sessionKey = getKey(session.getId());\n        stringRedisTemplate.opsForValue().set(sessionKey, STKey);\n        log.debug(\"cas-client add session, mappingId:\" + mappingId + \" sessionId:\" + session.getId());\n    }\n    \n    //删除\n    private void destroySession(final HttpServletRequest request) {\n        final String logoutMessage;\n        final String token = XmlUtils.getTextForElement(logoutMessage, \"SessionIndex\");\n        if (CommonUtils.isNotBlank(token)) {\n            final HttpSession session = this.sessionMappingStorage.removeSessionByMappingId(token);\n            if (session != null) {\n                final String sessionID = session.getId();\n                logger.debug(\"Invalidating session [{}] for token [{}]\", sessionID, token);\n                try {\n                    session.invalidate();\n                } catch (final IllegalStateException e) {\n                    logger.debug(\"Error invalidating session.\", e);\n                }\n                this.logoutStrategy.logout(request);\n            }\n        }\n    }\n    \n[参考文档](https://blog.csdn.net/dodolzg/article/details/43833545)    \n\n## 二、针对RPC接口\n\n    1、高耦合问题：确定接口的职责，例如只获取用户信息，只返回用户基本信息，但是改造成本高，业务改动大，不建议做。\n    2、数据量大问题：加入分页限制，不全部返回。\n\n\n## 三、成果\n\n    1、分布式改造后，解决了单点节点崩溃服务不可用问题。\n    2、加入分页限制后，解决了RPC调用造成的超时问题。\n    3、即使分布式+分页改造，依然没有解决登录耗时问题，主要是单点登录设计缺陷，需要获取的用户信息过多。\n\n\n\n","source":"_posts/2019-03-15-单点登录优化方案一.md","raw":"---\ntitle: 单点登录优化方案一\ndate: 2019-03-15 19:54:22\ntags: SSO CAS tomcat session\ncategories: 单点登录\n---\n针对现有统一登录系统问题，进行了一些尝试，这篇文章是尝试过程中使用的方案一。\n## 一、针对cas server单点问题\n\ncas交互流程大致如下：\n> * 拦截到web应用的请求，验证登录状态，若未登录则跳转到登录页\n> * 登录成功，web应用的tomcat存储session，cas-server保存TGT信息，cas-client-core保存ST和session的对应关系\n> * 登出时由cas-server返回ST信息，cas-client-core根据ST删除自己存储在内存的ST和session信息。（web应用在接入cas的时候需要继承cas-client-core）\n\n针对现有cas单点部署情况及会遇到的问题，进行了分布式集群部署的尝试。\n\n<!--more-->\n\n》》解决分布式，主要是解决session共享\n\n    1、Tomcat的session共享。\n    2、CAS的ST、TGT的共享。\n    3、cas-client-core共享ST和session的对应关系\n\n\n##### 1.1、tomcat-session-redis 共享\n1、引入tomcat-redis-session-manager插件。\n\n2、修改tomcat的 context.xml 配置文件，添加如下配置：\n\n    <!-- tomcat-redis-session共享配置 -->\n    <Valve className=\"com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\" />\n    <Manager className=\"com.orangefunction.tomcat.redissessions.RedisSessionManager\"\n    sentinels=\"a.redis.dns.cn:58783,b.redis.dns.cn:58783,c.redis.dns.cn:58783\"\n    sentinelMaster=\"master\"\n    timeout=\"3000\"\n    maxInactiveInterval=\"60\" />\n\n3、在tomcat 的lib下添加以下包\n\n    tomcat-redis-cache-manager.jar\n    注意:tomcat8,与tomcat7包有所不同,请按版本添加，详细查看官网。\n\n\n##### 1.2、CAS的ST、TGT的共享\n\n1、ST根据TGT生成，然后保存\n\n    public ServiceTicket grantServiceTicket(\n            final String ticketGrantingTicketId,\n            final Service service, final Credential... credentials)\n            throws AuthenticationException, TicketException {\n\n        final TicketGrantingTicket ticketGrantingTicket = getTicket(ticketGrantingTicketId, TicketGrantingTicket.class);\n        final RegisteredService registeredService = this.servicesManager.findServiceBy(service);\n\n        ............省略代码\n\n        final String ticketPrefix = authentications.size() == 1 ? ServiceTicket.PREFIX : ServiceTicket.PROXY_TICKET_PREFIX;\n        final String ticketId = serviceTicketUniqueTicketIdGenerator.getNewTicketId(ticketPrefix);\n        final ServiceTicket serviceTicket = ticketGrantingTicket.grantServiceTicket(\n                ticketId,\n                service,\n                this.serviceTicketExpirationPolicy,\n                currentAuthentication != null);\n\n        this.ticketRegistry.addTicket(serviceTicket);//查看2中的DbTicketRegistry\n\n        logger.info(\"Granted ticket [{}] for service [{}] for user [{}]\",\n                serviceTicket.getId(), service.getId(), principal.getId());\n\n        return serviceTicket;\n    }\n\n2、实现自定义的TicketRegistry，以下为简略代码。\n\n    public final class DbTicketRegistry extends AbstractDistributedTicketRegistry implements DisposableBean {\n        private int tgtTimeout;\n        private int stTimeout;\n        @Override\n        public void addTicket(final Ticket ticket) {\n            logger.debug(\"Adding ticket {}\", ticket);\n            try {\n                this.saveTicket(ticket);\n            } catch (final Exception e) {\n                logger.error(\"Failed adding {} ，error:{} 。\", ticket,e);\n            }\n        }\n        \n        private void saveTicket(final Ticket ticket) throws Exception{\n             try {\n                ITicketGrantingTicketService ticketGrantingTicketService =  UumUtil.getApplicationContext().getBean(ITicketGrantingTicketService.class); \n                if(ticket instanceof ServiceTicketImpl){\n                    //st采用了Redis存储\n                    RedisCacheClientUtil.syncAdd(ticket.getId(), ticket, 1000, RedisCacheClientUtil.DEFAULT_TIMEOUT);\n                 }\n                if(ticket instanceof TicketGrantingTicketImpl){\n                    //TGT采用了DB存储\n                    TicketGrantingTicketDTO ticketGrantingTicketDTO = getDbTicket((TicketGrantingTicketImpl)ticket,ticketGrantingTicketService);\n                    ticketGrantingTicketService.save(ticketGrantingTicketDTO);\n                 }\n             } catch (final Exception e) {\n                 logger.error(\"Failed save {} ，error:{} 。\", ticket,e);\n             }\n        }\n    }\n\n\n3、cas-client-core共享ST和session的对应关系，退出票据删除\n\ncas-client-core利用HashMapBackedSessionMappingStorage实现了ST和session的内存存储\n    \n    //添加\n    @Override\n    public void addSessionById(String mappingId, HttpSession session) {\n        String STKey = getKey(mappingId);\n        StandardSessionFacade standardSessionFacade = (StandardSessionFacade) session;\n        RedisSession redisSession = null;\n        try {\n            redisSession = (RedisSession) getValue(standardSessionFacade, \"session\");\n        } catch (IllegalAccessException e) {\n            e.printStackTrace();\n        } catch (NoSuchFieldException e) {\n            e.printStackTrace();\n        }\n        if (null == redisSession) {\n            log.error(\"get redisSession fail\");\n            return;\n        }\n \n        sessionRedisTemplate.opsForValue().set(STKey, jdkSerializer.serialize(redisSession));\n        String sessionKey = getKey(session.getId());\n        stringRedisTemplate.opsForValue().set(sessionKey, STKey);\n        log.debug(\"cas-client add session, mappingId:\" + mappingId + \" sessionId:\" + session.getId());\n    }\n    \n    //删除\n    private void destroySession(final HttpServletRequest request) {\n        final String logoutMessage;\n        final String token = XmlUtils.getTextForElement(logoutMessage, \"SessionIndex\");\n        if (CommonUtils.isNotBlank(token)) {\n            final HttpSession session = this.sessionMappingStorage.removeSessionByMappingId(token);\n            if (session != null) {\n                final String sessionID = session.getId();\n                logger.debug(\"Invalidating session [{}] for token [{}]\", sessionID, token);\n                try {\n                    session.invalidate();\n                } catch (final IllegalStateException e) {\n                    logger.debug(\"Error invalidating session.\", e);\n                }\n                this.logoutStrategy.logout(request);\n            }\n        }\n    }\n    \n[参考文档](https://blog.csdn.net/dodolzg/article/details/43833545)    \n\n## 二、针对RPC接口\n\n    1、高耦合问题：确定接口的职责，例如只获取用户信息，只返回用户基本信息，但是改造成本高，业务改动大，不建议做。\n    2、数据量大问题：加入分页限制，不全部返回。\n\n\n## 三、成果\n\n    1、分布式改造后，解决了单点节点崩溃服务不可用问题。\n    2、加入分页限制后，解决了RPC调用造成的超时问题。\n    3、即使分布式+分页改造，依然没有解决登录耗时问题，主要是单点登录设计缺陷，需要获取的用户信息过多。\n\n\n\n","slug":"2019-03-15-单点登录优化方案一","published":1,"updated":"2024-10-14T09:38:11.857Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnub0008a13khvtj5g0k","content":"<p>针对现有统一登录系统问题，进行了一些尝试，这篇文章是尝试过程中使用的方案一。</p>\n<h2 id=\"一、针对cas-server单点问题\"><a href=\"#一、针对cas-server单点问题\" class=\"headerlink\" title=\"一、针对cas server单点问题\"></a>一、针对cas server单点问题</h2><p>cas交互流程大致如下：</p>\n<blockquote>\n<ul>\n<li>拦截到web应用的请求，验证登录状态，若未登录则跳转到登录页</li>\n<li>登录成功，web应用的tomcat存储session，cas-server保存TGT信息，cas-client-core保存ST和session的对应关系</li>\n<li>登出时由cas-server返回ST信息，cas-client-core根据ST删除自己存储在内存的ST和session信息。（web应用在接入cas的时候需要继承cas-client-core）</li>\n</ul>\n</blockquote>\n<p>针对现有cas单点部署情况及会遇到的问题，进行了分布式集群部署的尝试。</p>\n<a id=\"more\"></a>\n\n<p>》》解决分布式，主要是解决session共享</p>\n<pre><code>1、Tomcat的session共享。\n2、CAS的ST、TGT的共享。\n3、cas-client-core共享ST和session的对应关系</code></pre><h5 id=\"1-1、tomcat-session-redis-共享\"><a href=\"#1-1、tomcat-session-redis-共享\" class=\"headerlink\" title=\"1.1、tomcat-session-redis 共享\"></a>1.1、tomcat-session-redis 共享</h5><p>1、引入tomcat-redis-session-manager插件。</p>\n<p>2、修改tomcat的 context.xml 配置文件，添加如下配置：</p>\n<pre><code>&lt;!-- tomcat-redis-session共享配置 --&gt;\n&lt;Valve className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve&quot; /&gt;\n&lt;Manager className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionManager&quot;\nsentinels=&quot;a.redis.dns.cn:58783,b.redis.dns.cn:58783,c.redis.dns.cn:58783&quot;\nsentinelMaster=&quot;master&quot;\ntimeout=&quot;3000&quot;\nmaxInactiveInterval=&quot;60&quot; /&gt;</code></pre><p>3、在tomcat 的lib下添加以下包</p>\n<pre><code>tomcat-redis-cache-manager.jar\n注意:tomcat8,与tomcat7包有所不同,请按版本添加，详细查看官网。</code></pre><h5 id=\"1-2、CAS的ST、TGT的共享\"><a href=\"#1-2、CAS的ST、TGT的共享\" class=\"headerlink\" title=\"1.2、CAS的ST、TGT的共享\"></a>1.2、CAS的ST、TGT的共享</h5><p>1、ST根据TGT生成，然后保存</p>\n<pre><code>public ServiceTicket grantServiceTicket(\n        final String ticketGrantingTicketId,\n        final Service service, final Credential... credentials)\n        throws AuthenticationException, TicketException {\n\n    final TicketGrantingTicket ticketGrantingTicket = getTicket(ticketGrantingTicketId, TicketGrantingTicket.class);\n    final RegisteredService registeredService = this.servicesManager.findServiceBy(service);\n\n    ............省略代码\n\n    final String ticketPrefix = authentications.size() == 1 ? ServiceTicket.PREFIX : ServiceTicket.PROXY_TICKET_PREFIX;\n    final String ticketId = serviceTicketUniqueTicketIdGenerator.getNewTicketId(ticketPrefix);\n    final ServiceTicket serviceTicket = ticketGrantingTicket.grantServiceTicket(\n            ticketId,\n            service,\n            this.serviceTicketExpirationPolicy,\n            currentAuthentication != null);\n\n    this.ticketRegistry.addTicket(serviceTicket);//查看2中的DbTicketRegistry\n\n    logger.info(&quot;Granted ticket [{}] for service [{}] for user [{}]&quot;,\n            serviceTicket.getId(), service.getId(), principal.getId());\n\n    return serviceTicket;\n}</code></pre><p>2、实现自定义的TicketRegistry，以下为简略代码。</p>\n<pre><code>public final class DbTicketRegistry extends AbstractDistributedTicketRegistry implements DisposableBean {\n    private int tgtTimeout;\n    private int stTimeout;\n    @Override\n    public void addTicket(final Ticket ticket) {\n        logger.debug(&quot;Adding ticket {}&quot;, ticket);\n        try {\n            this.saveTicket(ticket);\n        } catch (final Exception e) {\n            logger.error(&quot;Failed adding {} ，error:{} 。&quot;, ticket,e);\n        }\n    }\n\n    private void saveTicket(final Ticket ticket) throws Exception{\n         try {\n            ITicketGrantingTicketService ticketGrantingTicketService =  UumUtil.getApplicationContext().getBean(ITicketGrantingTicketService.class); \n            if(ticket instanceof ServiceTicketImpl){\n                //st采用了Redis存储\n                RedisCacheClientUtil.syncAdd(ticket.getId(), ticket, 1000, RedisCacheClientUtil.DEFAULT_TIMEOUT);\n             }\n            if(ticket instanceof TicketGrantingTicketImpl){\n                //TGT采用了DB存储\n                TicketGrantingTicketDTO ticketGrantingTicketDTO = getDbTicket((TicketGrantingTicketImpl)ticket,ticketGrantingTicketService);\n                ticketGrantingTicketService.save(ticketGrantingTicketDTO);\n             }\n         } catch (final Exception e) {\n             logger.error(&quot;Failed save {} ，error:{} 。&quot;, ticket,e);\n         }\n    }\n}</code></pre><p>3、cas-client-core共享ST和session的对应关系，退出票据删除</p>\n<p>cas-client-core利用HashMapBackedSessionMappingStorage实现了ST和session的内存存储</p>\n<pre><code>//添加\n@Override\npublic void addSessionById(String mappingId, HttpSession session) {\n    String STKey = getKey(mappingId);\n    StandardSessionFacade standardSessionFacade = (StandardSessionFacade) session;\n    RedisSession redisSession = null;\n    try {\n        redisSession = (RedisSession) getValue(standardSessionFacade, &quot;session&quot;);\n    } catch (IllegalAccessException e) {\n        e.printStackTrace();\n    } catch (NoSuchFieldException e) {\n        e.printStackTrace();\n    }\n    if (null == redisSession) {\n        log.error(&quot;get redisSession fail&quot;);\n        return;\n    }\n\n    sessionRedisTemplate.opsForValue().set(STKey, jdkSerializer.serialize(redisSession));\n    String sessionKey = getKey(session.getId());\n    stringRedisTemplate.opsForValue().set(sessionKey, STKey);\n    log.debug(&quot;cas-client add session, mappingId:&quot; + mappingId + &quot; sessionId:&quot; + session.getId());\n}\n\n//删除\nprivate void destroySession(final HttpServletRequest request) {\n    final String logoutMessage;\n    final String token = XmlUtils.getTextForElement(logoutMessage, &quot;SessionIndex&quot;);\n    if (CommonUtils.isNotBlank(token)) {\n        final HttpSession session = this.sessionMappingStorage.removeSessionByMappingId(token);\n        if (session != null) {\n            final String sessionID = session.getId();\n            logger.debug(&quot;Invalidating session [{}] for token [{}]&quot;, sessionID, token);\n            try {\n                session.invalidate();\n            } catch (final IllegalStateException e) {\n                logger.debug(&quot;Error invalidating session.&quot;, e);\n            }\n            this.logoutStrategy.logout(request);\n        }\n    }\n}</code></pre><p><a href=\"https://blog.csdn.net/dodolzg/article/details/43833545\" target=\"_blank\" rel=\"noopener\">参考文档</a>    </p>\n<h2 id=\"二、针对RPC接口\"><a href=\"#二、针对RPC接口\" class=\"headerlink\" title=\"二、针对RPC接口\"></a>二、针对RPC接口</h2><pre><code>1、高耦合问题：确定接口的职责，例如只获取用户信息，只返回用户基本信息，但是改造成本高，业务改动大，不建议做。\n2、数据量大问题：加入分页限制，不全部返回。</code></pre><h2 id=\"三、成果\"><a href=\"#三、成果\" class=\"headerlink\" title=\"三、成果\"></a>三、成果</h2><pre><code>1、分布式改造后，解决了单点节点崩溃服务不可用问题。\n2、加入分页限制后，解决了RPC调用造成的超时问题。\n3、即使分布式+分页改造，依然没有解决登录耗时问题，主要是单点登录设计缺陷，需要获取的用户信息过多。</code></pre>","site":{"data":{}},"excerpt":"<p>针对现有统一登录系统问题，进行了一些尝试，这篇文章是尝试过程中使用的方案一。</p>\n<h2 id=\"一、针对cas-server单点问题\"><a href=\"#一、针对cas-server单点问题\" class=\"headerlink\" title=\"一、针对cas server单点问题\"></a>一、针对cas server单点问题</h2><p>cas交互流程大致如下：</p>\n<blockquote>\n<ul>\n<li>拦截到web应用的请求，验证登录状态，若未登录则跳转到登录页</li>\n<li>登录成功，web应用的tomcat存储session，cas-server保存TGT信息，cas-client-core保存ST和session的对应关系</li>\n<li>登出时由cas-server返回ST信息，cas-client-core根据ST删除自己存储在内存的ST和session信息。（web应用在接入cas的时候需要继承cas-client-core）</li>\n</ul>\n</blockquote>\n<p>针对现有cas单点部署情况及会遇到的问题，进行了分布式集群部署的尝试。</p>","more":"<p>》》解决分布式，主要是解决session共享</p>\n<pre><code>1、Tomcat的session共享。\n2、CAS的ST、TGT的共享。\n3、cas-client-core共享ST和session的对应关系</code></pre><h5 id=\"1-1、tomcat-session-redis-共享\"><a href=\"#1-1、tomcat-session-redis-共享\" class=\"headerlink\" title=\"1.1、tomcat-session-redis 共享\"></a>1.1、tomcat-session-redis 共享</h5><p>1、引入tomcat-redis-session-manager插件。</p>\n<p>2、修改tomcat的 context.xml 配置文件，添加如下配置：</p>\n<pre><code>&lt;!-- tomcat-redis-session共享配置 --&gt;\n&lt;Valve className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve&quot; /&gt;\n&lt;Manager className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionManager&quot;\nsentinels=&quot;a.redis.dns.cn:58783,b.redis.dns.cn:58783,c.redis.dns.cn:58783&quot;\nsentinelMaster=&quot;master&quot;\ntimeout=&quot;3000&quot;\nmaxInactiveInterval=&quot;60&quot; /&gt;</code></pre><p>3、在tomcat 的lib下添加以下包</p>\n<pre><code>tomcat-redis-cache-manager.jar\n注意:tomcat8,与tomcat7包有所不同,请按版本添加，详细查看官网。</code></pre><h5 id=\"1-2、CAS的ST、TGT的共享\"><a href=\"#1-2、CAS的ST、TGT的共享\" class=\"headerlink\" title=\"1.2、CAS的ST、TGT的共享\"></a>1.2、CAS的ST、TGT的共享</h5><p>1、ST根据TGT生成，然后保存</p>\n<pre><code>public ServiceTicket grantServiceTicket(\n        final String ticketGrantingTicketId,\n        final Service service, final Credential... credentials)\n        throws AuthenticationException, TicketException {\n\n    final TicketGrantingTicket ticketGrantingTicket = getTicket(ticketGrantingTicketId, TicketGrantingTicket.class);\n    final RegisteredService registeredService = this.servicesManager.findServiceBy(service);\n\n    ............省略代码\n\n    final String ticketPrefix = authentications.size() == 1 ? ServiceTicket.PREFIX : ServiceTicket.PROXY_TICKET_PREFIX;\n    final String ticketId = serviceTicketUniqueTicketIdGenerator.getNewTicketId(ticketPrefix);\n    final ServiceTicket serviceTicket = ticketGrantingTicket.grantServiceTicket(\n            ticketId,\n            service,\n            this.serviceTicketExpirationPolicy,\n            currentAuthentication != null);\n\n    this.ticketRegistry.addTicket(serviceTicket);//查看2中的DbTicketRegistry\n\n    logger.info(&quot;Granted ticket [{}] for service [{}] for user [{}]&quot;,\n            serviceTicket.getId(), service.getId(), principal.getId());\n\n    return serviceTicket;\n}</code></pre><p>2、实现自定义的TicketRegistry，以下为简略代码。</p>\n<pre><code>public final class DbTicketRegistry extends AbstractDistributedTicketRegistry implements DisposableBean {\n    private int tgtTimeout;\n    private int stTimeout;\n    @Override\n    public void addTicket(final Ticket ticket) {\n        logger.debug(&quot;Adding ticket {}&quot;, ticket);\n        try {\n            this.saveTicket(ticket);\n        } catch (final Exception e) {\n            logger.error(&quot;Failed adding {} ，error:{} 。&quot;, ticket,e);\n        }\n    }\n\n    private void saveTicket(final Ticket ticket) throws Exception{\n         try {\n            ITicketGrantingTicketService ticketGrantingTicketService =  UumUtil.getApplicationContext().getBean(ITicketGrantingTicketService.class); \n            if(ticket instanceof ServiceTicketImpl){\n                //st采用了Redis存储\n                RedisCacheClientUtil.syncAdd(ticket.getId(), ticket, 1000, RedisCacheClientUtil.DEFAULT_TIMEOUT);\n             }\n            if(ticket instanceof TicketGrantingTicketImpl){\n                //TGT采用了DB存储\n                TicketGrantingTicketDTO ticketGrantingTicketDTO = getDbTicket((TicketGrantingTicketImpl)ticket,ticketGrantingTicketService);\n                ticketGrantingTicketService.save(ticketGrantingTicketDTO);\n             }\n         } catch (final Exception e) {\n             logger.error(&quot;Failed save {} ，error:{} 。&quot;, ticket,e);\n         }\n    }\n}</code></pre><p>3、cas-client-core共享ST和session的对应关系，退出票据删除</p>\n<p>cas-client-core利用HashMapBackedSessionMappingStorage实现了ST和session的内存存储</p>\n<pre><code>//添加\n@Override\npublic void addSessionById(String mappingId, HttpSession session) {\n    String STKey = getKey(mappingId);\n    StandardSessionFacade standardSessionFacade = (StandardSessionFacade) session;\n    RedisSession redisSession = null;\n    try {\n        redisSession = (RedisSession) getValue(standardSessionFacade, &quot;session&quot;);\n    } catch (IllegalAccessException e) {\n        e.printStackTrace();\n    } catch (NoSuchFieldException e) {\n        e.printStackTrace();\n    }\n    if (null == redisSession) {\n        log.error(&quot;get redisSession fail&quot;);\n        return;\n    }\n\n    sessionRedisTemplate.opsForValue().set(STKey, jdkSerializer.serialize(redisSession));\n    String sessionKey = getKey(session.getId());\n    stringRedisTemplate.opsForValue().set(sessionKey, STKey);\n    log.debug(&quot;cas-client add session, mappingId:&quot; + mappingId + &quot; sessionId:&quot; + session.getId());\n}\n\n//删除\nprivate void destroySession(final HttpServletRequest request) {\n    final String logoutMessage;\n    final String token = XmlUtils.getTextForElement(logoutMessage, &quot;SessionIndex&quot;);\n    if (CommonUtils.isNotBlank(token)) {\n        final HttpSession session = this.sessionMappingStorage.removeSessionByMappingId(token);\n        if (session != null) {\n            final String sessionID = session.getId();\n            logger.debug(&quot;Invalidating session [{}] for token [{}]&quot;, sessionID, token);\n            try {\n                session.invalidate();\n            } catch (final IllegalStateException e) {\n                logger.debug(&quot;Error invalidating session.&quot;, e);\n            }\n            this.logoutStrategy.logout(request);\n        }\n    }\n}</code></pre><p><a href=\"https://blog.csdn.net/dodolzg/article/details/43833545\" target=\"_blank\" rel=\"noopener\">参考文档</a>    </p>\n<h2 id=\"二、针对RPC接口\"><a href=\"#二、针对RPC接口\" class=\"headerlink\" title=\"二、针对RPC接口\"></a>二、针对RPC接口</h2><pre><code>1、高耦合问题：确定接口的职责，例如只获取用户信息，只返回用户基本信息，但是改造成本高，业务改动大，不建议做。\n2、数据量大问题：加入分页限制，不全部返回。</code></pre><h2 id=\"三、成果\"><a href=\"#三、成果\" class=\"headerlink\" title=\"三、成果\"></a>三、成果</h2><pre><code>1、分布式改造后，解决了单点节点崩溃服务不可用问题。\n2、加入分页限制后，解决了RPC调用造成的超时问题。\n3、即使分布式+分页改造，依然没有解决登录耗时问题，主要是单点登录设计缺陷，需要获取的用户信息过多。</code></pre>"},{"title":"单点登录优化方案二","date":"2019-03-22T07:30:33.000Z","_content":"从改造成本、维护性、业务支撑、使用性等多方面进行综合考虑后，决定搭建一套新的单点登录系统。\n\n    1、性能：重新设计登录流程，验证中心只负责记录、验证用户登录信息，用户登录达到毫秒级。\n    2、可接入：现有单点登录业务侧接入复杂，需要简化。\n    3、业务支撑：菜单权限、数据权限分开控制。\n    4、改造成本：原有单点登录已经无法进行改造，所以需要接入业务重新接入。\n\n# 1、架构设计\n\n## 1.1、原有整体架构\n<!--more-->\n\n![uum](2019-03-22-单点登录优化方案二/uum-1.png)\n\n    1、原有权限模型基于RBAC，当接入系统、菜单、角色增多后，不便于管理。\n    2、业务侧高耦合，记录了很多业务侧信息。\n    3、数据存储方面，大数据量的日志记录，导致MySQL性能的降低。\n    \n\n## 1.2、新整体架构\n![urm](2019-03-22-单点登录优化方案二/urm-1.png)\n\n    1、权限模型改造，分成菜单权限+数据权限的隔离控制。\n    2、解耦，不再记录业务侧数据，公用服务进行拆分，拆出了地域基础服务、字典服务和业务日志服务。\n    3、大数据存储，采用HBASE等大数据库。 \n   \n## 1.3、 旧单点登录流程\n![old-sso](2019-03-22-单点登录优化方案二/old-sso-1.png)\n    \n    1、登录验证获取用户权限数据多。\n    2、客户端缓存权限信息，用户权限不同步。\n  \n![old-sso-out](2019-03-22-单点登录优化方案二/old-sso-out.png)\n\n    1、单点退出，通知所有业务方，MQ消息泛滥并且会堆积。\n    2、退出会出现用户登录状态不同步问题。\n\n## 1.4、新单点登录流程\n![new-sso](2019-03-22-单点登录优化方案二/new-sso-1.png)  \n\n    1、提供统一的过滤器提供给业务方，接入简单，没有其他配置。\n    2、登录信息缓存至Redis，统一管理。\n    \n    \n# 2、权限设计\n\n## 2.1、旧权限设计\n![old-permission](2019-03-22-单点登录优化方案二/old-permission.png)  \n\n    1、采用RBAC权限模型，无法很好的管理数据权限、权限设计不易维护。\n    2、无法满足现有的所有业务场景。\n    3、权限申请走线下，采用传统的邮箱方式，耗时高。\n\n\n## 2.3、新权限设计\n![new-permission](2019-03-22-单点登录优化方案二/new-permission.png)  \n    \n    1、权限组成：功能权限+数据权限。\n    2、权限之间低耦合、可扩展。\n    \n# 3、具体实现\n\n## 3.1、权限模块\n\n- 功能权限（也是基于RBAC）\n    - t_system： 系统表\n    - t_menu：菜单表，记录菜单归属系统。\n    - t_role：角色表，记录角色归属系统，包含权限标识字段。\n    - t_role_menu：角色功能表，记录角色拥有的菜单、功能权限。\n    - t_user_role：用户角色表，记录用户拥有的角色。\n\n- 数据权限\n    - t_data_dict：数据权限字典，按系统区分（分成城市、门店、机构、品类、服务项等）\n    - t_access_city：用户城市数据权限\n    - t_access_store：用户门店数据权限\n    - .....\n    \n    \n    \n    \n## 3.2、单点登录模块\n\n    @Path(\"/check\")\n    public ActionResult checkUser(UserCheckDto userCheckDto) {\n        try {\n            CheckUtil.check(userCheckDto.getUsername(), \"用户名\", StrRuler.notEmpty()).check(userCheckDto.getPassword(), \"密码\", StrRuler.notEmpty()).check(userCheckDto.getVerifycode(), \"验证码\", StrRuler.notEmpty());\n        } catch (CheckException e) {\n            return failHandler(userCheckDto, \"用户信息不存在\");\n        }\n        HttpServletRequest request = beat().getRequest();\n        HttpServletResponse response = beat().getResponse();\n        try {\n            LoginEnum checkResult = checkUserLogin(userCheckDto.getUsername());//校验用户信息，账号是否正常等\n            if (checkResult != LoginEnum.ALLOW_LOGIN) {\n                return failHandler(userCheckDto, checkResult.getDesc());\n            }\n            LoginResult result = checkUserInfo(userCheckDto);//校验用户用户名密码是否正常\n            if (result == null || !result.isSuccess()) {\n                return failHandler(userCheckDto, result.getDesc());//登录，用户名密码错误\n            } else {\n                log.info(\"用户使用账号登录成功\");\n                userCheckDto.setLoginType(LoginTypeEnum.ACCOUNT_LOGIN.getKey());\n                //以下为用户登录信息存储至Redis\n                try {\n                    String domain =getDomain(request);\n                    //用户名信息加密，将信息存入cookie内\n                    String context = DESUtil.encryptV3(context,DESUtil.KEY);\n                    Cookie cookie = new Cookie(LoginInfo.COOKIEUSERNAME_V2.getDesc(), string);//（cs_user_login2:CcGG25zcqDsCBL3fj1HLdj001VAYPoXdqCM4dj001yDSYC4aLoLhm6UQf2H0HkuV）\n                    cookie.setDomain(domain);\n                    cookie.setPath(LoginInfo.COOKIEPATH.getDesc());\n                    cookie.setMaxAge(LoginInfo.COOKIEEFFECTIVE.getValue());\n                    response.addCookie(cookie);\n                    if (StringUtils.isNotBlank(context) && StringUtils.isNotBlank(Constant.PC_LOGIN_TIMEOUT) && StringUtils.isNumeric(Constant.PC_LOGIN_TIMEOUT)) {\n                        String userKey = Constant.SSO_USER_LOGIN_INFO + userCheckDto.getUsername();\n                        int time = Integer.parseInt(Constant.PC_LOGIN_TIMEOUT);\n                        //token（用户登录信息）写入Redis中；(张三, CcGG25zcqDsCBL3fj1HLdj001VAYPoXdqCM4dj001yDSYC4aLoLhm6UQf2H0HkuV)\n                        boolean cacheResult = RedisClientUtil.setexString(userKey, time, context);\n                    }\n                } catch (Exception e) {\n                    log.error(\"用户登录信息写入cookies异常\", e);\n                }\n            }\n        } catch (Exception e) {\n            return failHandler(userCheckDto, AlertEnum.ERROR_SERVICE.getDesc());\n        }\n    }\n     \n说明：     \n     \n    1、新认证方式是使用cookies信息做为认证依据的，将用户的信息存放至cookie，再将登录状态存入Redis内。\n    2、浏览器跨域问题，两个子级域名无法共享信息，通过把登录信息存放至顶级域名实现信息共享。\n    3、登录状态信息，通过存放至Redis实现单点登录。\n    \n## 3.3、登录安全\n\n1、采用DES加密算法，对用户信息进行加密后存入cookie内。\n\n    public static String encrypt(byte[] datasource, String password) { \n        try{\n            SecureRandom random = new SecureRandom();\n            DESKeySpec desKey = new DESKeySpec(password.getBytes());\n            //创建一个密匙工厂，然后用它把DESKeySpec转换成\n            SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(\"DES\");\n            SecretKey securekey = keyFactory.generateSecret(desKey);\n            //Cipher对象实际完成加密操作\n            Cipher cipher = Cipher.getInstance(\"DES\");\n            //用密匙初始化Cipher对象\n            cipher.init(Cipher.ENCRYPT_MODE, securekey, random);\n            //现在，获取数据并加密\n            //正式执行加密操作\n            return byteArr2HexStr(cipher.doFinal(datasource));\n        }catch(Throwable e){\n            e.printStackTrace();\n        }\n        return null;\n    }\n\n2、添加黑白IP名单控制。\n\n3、所有系统全部使用HTTPS，        \n   \n[参考文章1](https://segmentfault.com/a/1190000022486395)      \n[美团-将军令](https://tech.meituan.com/2019/02/14/data-security-platform-construction-practice-jiangjunling.html)\n  ","source":"_posts/2019-03-22-单点登录优化方案二.md","raw":"---\ntitle: 单点登录优化方案二\ndate: 2019-03-22 15:30:33\ntags: Redis SSO 权限控制\ncategories: 单点登录\n---\n从改造成本、维护性、业务支撑、使用性等多方面进行综合考虑后，决定搭建一套新的单点登录系统。\n\n    1、性能：重新设计登录流程，验证中心只负责记录、验证用户登录信息，用户登录达到毫秒级。\n    2、可接入：现有单点登录业务侧接入复杂，需要简化。\n    3、业务支撑：菜单权限、数据权限分开控制。\n    4、改造成本：原有单点登录已经无法进行改造，所以需要接入业务重新接入。\n\n# 1、架构设计\n\n## 1.1、原有整体架构\n<!--more-->\n\n![uum](2019-03-22-单点登录优化方案二/uum-1.png)\n\n    1、原有权限模型基于RBAC，当接入系统、菜单、角色增多后，不便于管理。\n    2、业务侧高耦合，记录了很多业务侧信息。\n    3、数据存储方面，大数据量的日志记录，导致MySQL性能的降低。\n    \n\n## 1.2、新整体架构\n![urm](2019-03-22-单点登录优化方案二/urm-1.png)\n\n    1、权限模型改造，分成菜单权限+数据权限的隔离控制。\n    2、解耦，不再记录业务侧数据，公用服务进行拆分，拆出了地域基础服务、字典服务和业务日志服务。\n    3、大数据存储，采用HBASE等大数据库。 \n   \n## 1.3、 旧单点登录流程\n![old-sso](2019-03-22-单点登录优化方案二/old-sso-1.png)\n    \n    1、登录验证获取用户权限数据多。\n    2、客户端缓存权限信息，用户权限不同步。\n  \n![old-sso-out](2019-03-22-单点登录优化方案二/old-sso-out.png)\n\n    1、单点退出，通知所有业务方，MQ消息泛滥并且会堆积。\n    2、退出会出现用户登录状态不同步问题。\n\n## 1.4、新单点登录流程\n![new-sso](2019-03-22-单点登录优化方案二/new-sso-1.png)  \n\n    1、提供统一的过滤器提供给业务方，接入简单，没有其他配置。\n    2、登录信息缓存至Redis，统一管理。\n    \n    \n# 2、权限设计\n\n## 2.1、旧权限设计\n![old-permission](2019-03-22-单点登录优化方案二/old-permission.png)  \n\n    1、采用RBAC权限模型，无法很好的管理数据权限、权限设计不易维护。\n    2、无法满足现有的所有业务场景。\n    3、权限申请走线下，采用传统的邮箱方式，耗时高。\n\n\n## 2.3、新权限设计\n![new-permission](2019-03-22-单点登录优化方案二/new-permission.png)  \n    \n    1、权限组成：功能权限+数据权限。\n    2、权限之间低耦合、可扩展。\n    \n# 3、具体实现\n\n## 3.1、权限模块\n\n- 功能权限（也是基于RBAC）\n    - t_system： 系统表\n    - t_menu：菜单表，记录菜单归属系统。\n    - t_role：角色表，记录角色归属系统，包含权限标识字段。\n    - t_role_menu：角色功能表，记录角色拥有的菜单、功能权限。\n    - t_user_role：用户角色表，记录用户拥有的角色。\n\n- 数据权限\n    - t_data_dict：数据权限字典，按系统区分（分成城市、门店、机构、品类、服务项等）\n    - t_access_city：用户城市数据权限\n    - t_access_store：用户门店数据权限\n    - .....\n    \n    \n    \n    \n## 3.2、单点登录模块\n\n    @Path(\"/check\")\n    public ActionResult checkUser(UserCheckDto userCheckDto) {\n        try {\n            CheckUtil.check(userCheckDto.getUsername(), \"用户名\", StrRuler.notEmpty()).check(userCheckDto.getPassword(), \"密码\", StrRuler.notEmpty()).check(userCheckDto.getVerifycode(), \"验证码\", StrRuler.notEmpty());\n        } catch (CheckException e) {\n            return failHandler(userCheckDto, \"用户信息不存在\");\n        }\n        HttpServletRequest request = beat().getRequest();\n        HttpServletResponse response = beat().getResponse();\n        try {\n            LoginEnum checkResult = checkUserLogin(userCheckDto.getUsername());//校验用户信息，账号是否正常等\n            if (checkResult != LoginEnum.ALLOW_LOGIN) {\n                return failHandler(userCheckDto, checkResult.getDesc());\n            }\n            LoginResult result = checkUserInfo(userCheckDto);//校验用户用户名密码是否正常\n            if (result == null || !result.isSuccess()) {\n                return failHandler(userCheckDto, result.getDesc());//登录，用户名密码错误\n            } else {\n                log.info(\"用户使用账号登录成功\");\n                userCheckDto.setLoginType(LoginTypeEnum.ACCOUNT_LOGIN.getKey());\n                //以下为用户登录信息存储至Redis\n                try {\n                    String domain =getDomain(request);\n                    //用户名信息加密，将信息存入cookie内\n                    String context = DESUtil.encryptV3(context,DESUtil.KEY);\n                    Cookie cookie = new Cookie(LoginInfo.COOKIEUSERNAME_V2.getDesc(), string);//（cs_user_login2:CcGG25zcqDsCBL3fj1HLdj001VAYPoXdqCM4dj001yDSYC4aLoLhm6UQf2H0HkuV）\n                    cookie.setDomain(domain);\n                    cookie.setPath(LoginInfo.COOKIEPATH.getDesc());\n                    cookie.setMaxAge(LoginInfo.COOKIEEFFECTIVE.getValue());\n                    response.addCookie(cookie);\n                    if (StringUtils.isNotBlank(context) && StringUtils.isNotBlank(Constant.PC_LOGIN_TIMEOUT) && StringUtils.isNumeric(Constant.PC_LOGIN_TIMEOUT)) {\n                        String userKey = Constant.SSO_USER_LOGIN_INFO + userCheckDto.getUsername();\n                        int time = Integer.parseInt(Constant.PC_LOGIN_TIMEOUT);\n                        //token（用户登录信息）写入Redis中；(张三, CcGG25zcqDsCBL3fj1HLdj001VAYPoXdqCM4dj001yDSYC4aLoLhm6UQf2H0HkuV)\n                        boolean cacheResult = RedisClientUtil.setexString(userKey, time, context);\n                    }\n                } catch (Exception e) {\n                    log.error(\"用户登录信息写入cookies异常\", e);\n                }\n            }\n        } catch (Exception e) {\n            return failHandler(userCheckDto, AlertEnum.ERROR_SERVICE.getDesc());\n        }\n    }\n     \n说明：     \n     \n    1、新认证方式是使用cookies信息做为认证依据的，将用户的信息存放至cookie，再将登录状态存入Redis内。\n    2、浏览器跨域问题，两个子级域名无法共享信息，通过把登录信息存放至顶级域名实现信息共享。\n    3、登录状态信息，通过存放至Redis实现单点登录。\n    \n## 3.3、登录安全\n\n1、采用DES加密算法，对用户信息进行加密后存入cookie内。\n\n    public static String encrypt(byte[] datasource, String password) { \n        try{\n            SecureRandom random = new SecureRandom();\n            DESKeySpec desKey = new DESKeySpec(password.getBytes());\n            //创建一个密匙工厂，然后用它把DESKeySpec转换成\n            SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(\"DES\");\n            SecretKey securekey = keyFactory.generateSecret(desKey);\n            //Cipher对象实际完成加密操作\n            Cipher cipher = Cipher.getInstance(\"DES\");\n            //用密匙初始化Cipher对象\n            cipher.init(Cipher.ENCRYPT_MODE, securekey, random);\n            //现在，获取数据并加密\n            //正式执行加密操作\n            return byteArr2HexStr(cipher.doFinal(datasource));\n        }catch(Throwable e){\n            e.printStackTrace();\n        }\n        return null;\n    }\n\n2、添加黑白IP名单控制。\n\n3、所有系统全部使用HTTPS，        \n   \n[参考文章1](https://segmentfault.com/a/1190000022486395)      \n[美团-将军令](https://tech.meituan.com/2019/02/14/data-security-platform-construction-practice-jiangjunling.html)\n  ","slug":"2019-03-22-单点登录优化方案二","published":1,"updated":"2024-10-14T09:38:11.858Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnue000ca13kugxq9pjc","content":"<p>从改造成本、维护性、业务支撑、使用性等多方面进行综合考虑后，决定搭建一套新的单点登录系统。</p>\n<pre><code>1、性能：重新设计登录流程，验证中心只负责记录、验证用户登录信息，用户登录达到毫秒级。\n2、可接入：现有单点登录业务侧接入复杂，需要简化。\n3、业务支撑：菜单权限、数据权限分开控制。\n4、改造成本：原有单点登录已经无法进行改造，所以需要接入业务重新接入。</code></pre><h1 id=\"1、架构设计\"><a href=\"#1、架构设计\" class=\"headerlink\" title=\"1、架构设计\"></a>1、架构设计</h1><h2 id=\"1-1、原有整体架构\"><a href=\"#1-1、原有整体架构\" class=\"headerlink\" title=\"1.1、原有整体架构\"></a>1.1、原有整体架构</h2><a id=\"more\"></a>\n\n<p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/uum-1.png\" alt=\"uum\"></p>\n<pre><code>1、原有权限模型基于RBAC，当接入系统、菜单、角色增多后，不便于管理。\n2、业务侧高耦合，记录了很多业务侧信息。\n3、数据存储方面，大数据量的日志记录，导致MySQL性能的降低。</code></pre><h2 id=\"1-2、新整体架构\"><a href=\"#1-2、新整体架构\" class=\"headerlink\" title=\"1.2、新整体架构\"></a>1.2、新整体架构</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/urm-1.png\" alt=\"urm\"></p>\n<pre><code>1、权限模型改造，分成菜单权限+数据权限的隔离控制。\n2、解耦，不再记录业务侧数据，公用服务进行拆分，拆出了地域基础服务、字典服务和业务日志服务。\n3、大数据存储，采用HBASE等大数据库。 </code></pre><h2 id=\"1-3、-旧单点登录流程\"><a href=\"#1-3、-旧单点登录流程\" class=\"headerlink\" title=\"1.3、 旧单点登录流程\"></a>1.3、 旧单点登录流程</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/old-sso-1.png\" alt=\"old-sso\"></p>\n<pre><code>1、登录验证获取用户权限数据多。\n2、客户端缓存权限信息，用户权限不同步。</code></pre><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/old-sso-out.png\" alt=\"old-sso-out\"></p>\n<pre><code>1、单点退出，通知所有业务方，MQ消息泛滥并且会堆积。\n2、退出会出现用户登录状态不同步问题。</code></pre><h2 id=\"1-4、新单点登录流程\"><a href=\"#1-4、新单点登录流程\" class=\"headerlink\" title=\"1.4、新单点登录流程\"></a>1.4、新单点登录流程</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/new-sso-1.png\" alt=\"new-sso\">  </p>\n<pre><code>1、提供统一的过滤器提供给业务方，接入简单，没有其他配置。\n2、登录信息缓存至Redis，统一管理。</code></pre><h1 id=\"2、权限设计\"><a href=\"#2、权限设计\" class=\"headerlink\" title=\"2、权限设计\"></a>2、权限设计</h1><h2 id=\"2-1、旧权限设计\"><a href=\"#2-1、旧权限设计\" class=\"headerlink\" title=\"2.1、旧权限设计\"></a>2.1、旧权限设计</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/old-permission.png\" alt=\"old-permission\">  </p>\n<pre><code>1、采用RBAC权限模型，无法很好的管理数据权限、权限设计不易维护。\n2、无法满足现有的所有业务场景。\n3、权限申请走线下，采用传统的邮箱方式，耗时高。</code></pre><h2 id=\"2-3、新权限设计\"><a href=\"#2-3、新权限设计\" class=\"headerlink\" title=\"2.3、新权限设计\"></a>2.3、新权限设计</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/new-permission.png\" alt=\"new-permission\">  </p>\n<pre><code>1、权限组成：功能权限+数据权限。\n2、权限之间低耦合、可扩展。</code></pre><h1 id=\"3、具体实现\"><a href=\"#3、具体实现\" class=\"headerlink\" title=\"3、具体实现\"></a>3、具体实现</h1><h2 id=\"3-1、权限模块\"><a href=\"#3-1、权限模块\" class=\"headerlink\" title=\"3.1、权限模块\"></a>3.1、权限模块</h2><ul>\n<li><p>功能权限（也是基于RBAC）</p>\n<ul>\n<li>t_system： 系统表</li>\n<li>t_menu：菜单表，记录菜单归属系统。</li>\n<li>t_role：角色表，记录角色归属系统，包含权限标识字段。</li>\n<li>t_role_menu：角色功能表，记录角色拥有的菜单、功能权限。</li>\n<li>t_user_role：用户角色表，记录用户拥有的角色。</li>\n</ul>\n</li>\n<li><p>数据权限</p>\n<ul>\n<li>t_data_dict：数据权限字典，按系统区分（分成城市、门店、机构、品类、服务项等）</li>\n<li>t_access_city：用户城市数据权限</li>\n<li>t_access_store：用户门店数据权限</li>\n<li>…..</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-2、单点登录模块\"><a href=\"#3-2、单点登录模块\" class=\"headerlink\" title=\"3.2、单点登录模块\"></a>3.2、单点登录模块</h2><pre><code>@Path(&quot;/check&quot;)\npublic ActionResult checkUser(UserCheckDto userCheckDto) {\n    try {\n        CheckUtil.check(userCheckDto.getUsername(), &quot;用户名&quot;, StrRuler.notEmpty()).check(userCheckDto.getPassword(), &quot;密码&quot;, StrRuler.notEmpty()).check(userCheckDto.getVerifycode(), &quot;验证码&quot;, StrRuler.notEmpty());\n    } catch (CheckException e) {\n        return failHandler(userCheckDto, &quot;用户信息不存在&quot;);\n    }\n    HttpServletRequest request = beat().getRequest();\n    HttpServletResponse response = beat().getResponse();\n    try {\n        LoginEnum checkResult = checkUserLogin(userCheckDto.getUsername());//校验用户信息，账号是否正常等\n        if (checkResult != LoginEnum.ALLOW_LOGIN) {\n            return failHandler(userCheckDto, checkResult.getDesc());\n        }\n        LoginResult result = checkUserInfo(userCheckDto);//校验用户用户名密码是否正常\n        if (result == null || !result.isSuccess()) {\n            return failHandler(userCheckDto, result.getDesc());//登录，用户名密码错误\n        } else {\n            log.info(&quot;用户使用账号登录成功&quot;);\n            userCheckDto.setLoginType(LoginTypeEnum.ACCOUNT_LOGIN.getKey());\n            //以下为用户登录信息存储至Redis\n            try {\n                String domain =getDomain(request);\n                //用户名信息加密，将信息存入cookie内\n                String context = DESUtil.encryptV3(context,DESUtil.KEY);\n                Cookie cookie = new Cookie(LoginInfo.COOKIEUSERNAME_V2.getDesc(), string);//（cs_user_login2:CcGG25zcqDsCBL3fj1HLdj001VAYPoXdqCM4dj001yDSYC4aLoLhm6UQf2H0HkuV）\n                cookie.setDomain(domain);\n                cookie.setPath(LoginInfo.COOKIEPATH.getDesc());\n                cookie.setMaxAge(LoginInfo.COOKIEEFFECTIVE.getValue());\n                response.addCookie(cookie);\n                if (StringUtils.isNotBlank(context) &amp;&amp; StringUtils.isNotBlank(Constant.PC_LOGIN_TIMEOUT) &amp;&amp; StringUtils.isNumeric(Constant.PC_LOGIN_TIMEOUT)) {\n                    String userKey = Constant.SSO_USER_LOGIN_INFO + userCheckDto.getUsername();\n                    int time = Integer.parseInt(Constant.PC_LOGIN_TIMEOUT);\n                    //token（用户登录信息）写入Redis中；(张三, CcGG25zcqDsCBL3fj1HLdj001VAYPoXdqCM4dj001yDSYC4aLoLhm6UQf2H0HkuV)\n                    boolean cacheResult = RedisClientUtil.setexString(userKey, time, context);\n                }\n            } catch (Exception e) {\n                log.error(&quot;用户登录信息写入cookies异常&quot;, e);\n            }\n        }\n    } catch (Exception e) {\n        return failHandler(userCheckDto, AlertEnum.ERROR_SERVICE.getDesc());\n    }\n}</code></pre><p>说明：     </p>\n<pre><code>1、新认证方式是使用cookies信息做为认证依据的，将用户的信息存放至cookie，再将登录状态存入Redis内。\n2、浏览器跨域问题，两个子级域名无法共享信息，通过把登录信息存放至顶级域名实现信息共享。\n3、登录状态信息，通过存放至Redis实现单点登录。</code></pre><h2 id=\"3-3、登录安全\"><a href=\"#3-3、登录安全\" class=\"headerlink\" title=\"3.3、登录安全\"></a>3.3、登录安全</h2><p>1、采用DES加密算法，对用户信息进行加密后存入cookie内。</p>\n<pre><code>public static String encrypt(byte[] datasource, String password) { \n    try{\n        SecureRandom random = new SecureRandom();\n        DESKeySpec desKey = new DESKeySpec(password.getBytes());\n        //创建一个密匙工厂，然后用它把DESKeySpec转换成\n        SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(&quot;DES&quot;);\n        SecretKey securekey = keyFactory.generateSecret(desKey);\n        //Cipher对象实际完成加密操作\n        Cipher cipher = Cipher.getInstance(&quot;DES&quot;);\n        //用密匙初始化Cipher对象\n        cipher.init(Cipher.ENCRYPT_MODE, securekey, random);\n        //现在，获取数据并加密\n        //正式执行加密操作\n        return byteArr2HexStr(cipher.doFinal(datasource));\n    }catch(Throwable e){\n        e.printStackTrace();\n    }\n    return null;\n}</code></pre><p>2、添加黑白IP名单控制。</p>\n<p>3、所有系统全部使用HTTPS，        </p>\n<p><a href=\"https://segmentfault.com/a/1190000022486395\" target=\"_blank\" rel=\"noopener\">参考文章1</a><br><a href=\"https://tech.meituan.com/2019/02/14/data-security-platform-construction-practice-jiangjunling.html\" target=\"_blank\" rel=\"noopener\">美团-将军令</a></p>\n","site":{"data":{}},"excerpt":"<p>从改造成本、维护性、业务支撑、使用性等多方面进行综合考虑后，决定搭建一套新的单点登录系统。</p>\n<pre><code>1、性能：重新设计登录流程，验证中心只负责记录、验证用户登录信息，用户登录达到毫秒级。\n2、可接入：现有单点登录业务侧接入复杂，需要简化。\n3、业务支撑：菜单权限、数据权限分开控制。\n4、改造成本：原有单点登录已经无法进行改造，所以需要接入业务重新接入。</code></pre><h1 id=\"1、架构设计\"><a href=\"#1、架构设计\" class=\"headerlink\" title=\"1、架构设计\"></a>1、架构设计</h1><h2 id=\"1-1、原有整体架构\"><a href=\"#1-1、原有整体架构\" class=\"headerlink\" title=\"1.1、原有整体架构\"></a>1.1、原有整体架构</h2>","more":"<p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/uum-1.png\" alt=\"uum\"></p>\n<pre><code>1、原有权限模型基于RBAC，当接入系统、菜单、角色增多后，不便于管理。\n2、业务侧高耦合，记录了很多业务侧信息。\n3、数据存储方面，大数据量的日志记录，导致MySQL性能的降低。</code></pre><h2 id=\"1-2、新整体架构\"><a href=\"#1-2、新整体架构\" class=\"headerlink\" title=\"1.2、新整体架构\"></a>1.2、新整体架构</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/urm-1.png\" alt=\"urm\"></p>\n<pre><code>1、权限模型改造，分成菜单权限+数据权限的隔离控制。\n2、解耦，不再记录业务侧数据，公用服务进行拆分，拆出了地域基础服务、字典服务和业务日志服务。\n3、大数据存储，采用HBASE等大数据库。 </code></pre><h2 id=\"1-3、-旧单点登录流程\"><a href=\"#1-3、-旧单点登录流程\" class=\"headerlink\" title=\"1.3、 旧单点登录流程\"></a>1.3、 旧单点登录流程</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/old-sso-1.png\" alt=\"old-sso\"></p>\n<pre><code>1、登录验证获取用户权限数据多。\n2、客户端缓存权限信息，用户权限不同步。</code></pre><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/old-sso-out.png\" alt=\"old-sso-out\"></p>\n<pre><code>1、单点退出，通知所有业务方，MQ消息泛滥并且会堆积。\n2、退出会出现用户登录状态不同步问题。</code></pre><h2 id=\"1-4、新单点登录流程\"><a href=\"#1-4、新单点登录流程\" class=\"headerlink\" title=\"1.4、新单点登录流程\"></a>1.4、新单点登录流程</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/new-sso-1.png\" alt=\"new-sso\">  </p>\n<pre><code>1、提供统一的过滤器提供给业务方，接入简单，没有其他配置。\n2、登录信息缓存至Redis，统一管理。</code></pre><h1 id=\"2、权限设计\"><a href=\"#2、权限设计\" class=\"headerlink\" title=\"2、权限设计\"></a>2、权限设计</h1><h2 id=\"2-1、旧权限设计\"><a href=\"#2-1、旧权限设计\" class=\"headerlink\" title=\"2.1、旧权限设计\"></a>2.1、旧权限设计</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/old-permission.png\" alt=\"old-permission\">  </p>\n<pre><code>1、采用RBAC权限模型，无法很好的管理数据权限、权限设计不易维护。\n2、无法满足现有的所有业务场景。\n3、权限申请走线下，采用传统的邮箱方式，耗时高。</code></pre><h2 id=\"2-3、新权限设计\"><a href=\"#2-3、新权限设计\" class=\"headerlink\" title=\"2.3、新权限设计\"></a>2.3、新权限设计</h2><p><img src=\"/2019/03/22/2019-03-22-单点登录优化方案二/new-permission.png\" alt=\"new-permission\">  </p>\n<pre><code>1、权限组成：功能权限+数据权限。\n2、权限之间低耦合、可扩展。</code></pre><h1 id=\"3、具体实现\"><a href=\"#3、具体实现\" class=\"headerlink\" title=\"3、具体实现\"></a>3、具体实现</h1><h2 id=\"3-1、权限模块\"><a href=\"#3-1、权限模块\" class=\"headerlink\" title=\"3.1、权限模块\"></a>3.1、权限模块</h2><ul>\n<li><p>功能权限（也是基于RBAC）</p>\n<ul>\n<li>t_system： 系统表</li>\n<li>t_menu：菜单表，记录菜单归属系统。</li>\n<li>t_role：角色表，记录角色归属系统，包含权限标识字段。</li>\n<li>t_role_menu：角色功能表，记录角色拥有的菜单、功能权限。</li>\n<li>t_user_role：用户角色表，记录用户拥有的角色。</li>\n</ul>\n</li>\n<li><p>数据权限</p>\n<ul>\n<li>t_data_dict：数据权限字典，按系统区分（分成城市、门店、机构、品类、服务项等）</li>\n<li>t_access_city：用户城市数据权限</li>\n<li>t_access_store：用户门店数据权限</li>\n<li>…..</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-2、单点登录模块\"><a href=\"#3-2、单点登录模块\" class=\"headerlink\" title=\"3.2、单点登录模块\"></a>3.2、单点登录模块</h2><pre><code>@Path(&quot;/check&quot;)\npublic ActionResult checkUser(UserCheckDto userCheckDto) {\n    try {\n        CheckUtil.check(userCheckDto.getUsername(), &quot;用户名&quot;, StrRuler.notEmpty()).check(userCheckDto.getPassword(), &quot;密码&quot;, StrRuler.notEmpty()).check(userCheckDto.getVerifycode(), &quot;验证码&quot;, StrRuler.notEmpty());\n    } catch (CheckException e) {\n        return failHandler(userCheckDto, &quot;用户信息不存在&quot;);\n    }\n    HttpServletRequest request = beat().getRequest();\n    HttpServletResponse response = beat().getResponse();\n    try {\n        LoginEnum checkResult = checkUserLogin(userCheckDto.getUsername());//校验用户信息，账号是否正常等\n        if (checkResult != LoginEnum.ALLOW_LOGIN) {\n            return failHandler(userCheckDto, checkResult.getDesc());\n        }\n        LoginResult result = checkUserInfo(userCheckDto);//校验用户用户名密码是否正常\n        if (result == null || !result.isSuccess()) {\n            return failHandler(userCheckDto, result.getDesc());//登录，用户名密码错误\n        } else {\n            log.info(&quot;用户使用账号登录成功&quot;);\n            userCheckDto.setLoginType(LoginTypeEnum.ACCOUNT_LOGIN.getKey());\n            //以下为用户登录信息存储至Redis\n            try {\n                String domain =getDomain(request);\n                //用户名信息加密，将信息存入cookie内\n                String context = DESUtil.encryptV3(context,DESUtil.KEY);\n                Cookie cookie = new Cookie(LoginInfo.COOKIEUSERNAME_V2.getDesc(), string);//（cs_user_login2:CcGG25zcqDsCBL3fj1HLdj001VAYPoXdqCM4dj001yDSYC4aLoLhm6UQf2H0HkuV）\n                cookie.setDomain(domain);\n                cookie.setPath(LoginInfo.COOKIEPATH.getDesc());\n                cookie.setMaxAge(LoginInfo.COOKIEEFFECTIVE.getValue());\n                response.addCookie(cookie);\n                if (StringUtils.isNotBlank(context) &amp;&amp; StringUtils.isNotBlank(Constant.PC_LOGIN_TIMEOUT) &amp;&amp; StringUtils.isNumeric(Constant.PC_LOGIN_TIMEOUT)) {\n                    String userKey = Constant.SSO_USER_LOGIN_INFO + userCheckDto.getUsername();\n                    int time = Integer.parseInt(Constant.PC_LOGIN_TIMEOUT);\n                    //token（用户登录信息）写入Redis中；(张三, CcGG25zcqDsCBL3fj1HLdj001VAYPoXdqCM4dj001yDSYC4aLoLhm6UQf2H0HkuV)\n                    boolean cacheResult = RedisClientUtil.setexString(userKey, time, context);\n                }\n            } catch (Exception e) {\n                log.error(&quot;用户登录信息写入cookies异常&quot;, e);\n            }\n        }\n    } catch (Exception e) {\n        return failHandler(userCheckDto, AlertEnum.ERROR_SERVICE.getDesc());\n    }\n}</code></pre><p>说明：     </p>\n<pre><code>1、新认证方式是使用cookies信息做为认证依据的，将用户的信息存放至cookie，再将登录状态存入Redis内。\n2、浏览器跨域问题，两个子级域名无法共享信息，通过把登录信息存放至顶级域名实现信息共享。\n3、登录状态信息，通过存放至Redis实现单点登录。</code></pre><h2 id=\"3-3、登录安全\"><a href=\"#3-3、登录安全\" class=\"headerlink\" title=\"3.3、登录安全\"></a>3.3、登录安全</h2><p>1、采用DES加密算法，对用户信息进行加密后存入cookie内。</p>\n<pre><code>public static String encrypt(byte[] datasource, String password) { \n    try{\n        SecureRandom random = new SecureRandom();\n        DESKeySpec desKey = new DESKeySpec(password.getBytes());\n        //创建一个密匙工厂，然后用它把DESKeySpec转换成\n        SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(&quot;DES&quot;);\n        SecretKey securekey = keyFactory.generateSecret(desKey);\n        //Cipher对象实际完成加密操作\n        Cipher cipher = Cipher.getInstance(&quot;DES&quot;);\n        //用密匙初始化Cipher对象\n        cipher.init(Cipher.ENCRYPT_MODE, securekey, random);\n        //现在，获取数据并加密\n        //正式执行加密操作\n        return byteArr2HexStr(cipher.doFinal(datasource));\n    }catch(Throwable e){\n        e.printStackTrace();\n    }\n    return null;\n}</code></pre><p>2、添加黑白IP名单控制。</p>\n<p>3、所有系统全部使用HTTPS，        </p>\n<p><a href=\"https://segmentfault.com/a/1190000022486395\" target=\"_blank\" rel=\"noopener\">参考文章1</a><br><a href=\"https://tech.meituan.com/2019/02/14/data-security-platform-construction-practice-jiangjunling.html\" target=\"_blank\" rel=\"noopener\">美团-将军令</a></p>"},{"title":"MySQL-连接异常问题","date":"2019-04-24T07:03:26.000Z","_content":"\n# 一、问题场景\nmybatis报异常\n![redis-io](2019-04-24-MySQL-连接异常问题/mysql-error.png)\n\n<!--more-->\n\n# 二、排查过程\n如日志所述，无法和MySQL服务端建立通讯。那为什么会断开连接呢？\n\n排查步骤如下：\n* a、上次该连接与mysql的交互是108ms以前，但是现在却出问题了，说明是mysql server主动关闭了连接。（ps：只有服务器主动断开连接时才会出现这种问题）\n* b、检查MySQL参数\n```\ndataSource.url=jdbc:mysql://mysql:3306/uum?useUnicode=true&characterEncoding=utf8&rewriteBatchedStatements=true&zeroDateTimeBehavior=convertToNull\ndataSource.username=aaa\ndataSource.password=111\ndataSource.initialSize=10\ndataSource.maxActive=20\ndataSource.minIdle=10\ndataSource.maxWait=5000\ndataSource.testOnBorrow=false\ndataSource.testOnReturn=false\ndataSource.testWhileIdle=true\ndataSource.timeBetweenEvictionRunsMillis=60000\ndataSource.minEvictableIdleTimeMillis=25200000\ndataSource.removeAbandoned=true\ndataSource.removeAbandonedTimeout=1800\ndataSource.logAbandoned=true\ndataSource.slowSqlMillis=100\n```\n排查是否由wait_timeout设置太小，导致服务器断开了连接，发现并没有设置，默认是8小时，排除wait_timeout参数问题。\n* c、排查是否是连接池连接数过小\n```\ndataSource.maxActive=20，最大活跃数20个，对当前系统访问量，也不少了，排除。\ndataSource.maxWait=5000，是否是最大等待毫秒数, 超过时间，5s，排除。\n```\n* c、查看数据库连接池情况。（连接池数据图标，出现空白问题，跟DBA沟通，认为是mysql server连接池的淘汰策略问题：实际上是正确的）\n* d、DBA排查，和前几天的job有关。（相同SQL CPU飙升，会激活job，进行连接kill；验证了是mysql server主动关闭连接）\n\n\n# 三、总结\n影响MySQL连接的问题原因有很多种。   \n1、和连接mysql时间有关的系统变量\n* wait_timeout：服务器关闭非交互连接之前等待活动的秒数。（即一个连接多久没交互后会被关闭）\n* interactive_timeout：服务器关闭交互式连接前等待活动的秒数。（即一个连接多久没交互后会被关闭）\n\n以上两个参数，会影响MySQL服务端对连接进行关闭，保持默认即可。  \n2、连接非正常关闭，可以查看MySQL服务端是否出现问题，都是服务端关闭连接后，\n而客户端连接池还持有这个连接，用关闭的连接去请求服务器，当然不能响应。\n\n\n","source":"_posts/2019-04-24-MySQL-连接异常问题.md","raw":"---\ntitle: MySQL-连接异常问题\ndate: 2019-04-24 15:03:26\ntags: MySQL\ncategories:\n  - [数据库, mysql, 线上问题]\n---\n\n# 一、问题场景\nmybatis报异常\n![redis-io](2019-04-24-MySQL-连接异常问题/mysql-error.png)\n\n<!--more-->\n\n# 二、排查过程\n如日志所述，无法和MySQL服务端建立通讯。那为什么会断开连接呢？\n\n排查步骤如下：\n* a、上次该连接与mysql的交互是108ms以前，但是现在却出问题了，说明是mysql server主动关闭了连接。（ps：只有服务器主动断开连接时才会出现这种问题）\n* b、检查MySQL参数\n```\ndataSource.url=jdbc:mysql://mysql:3306/uum?useUnicode=true&characterEncoding=utf8&rewriteBatchedStatements=true&zeroDateTimeBehavior=convertToNull\ndataSource.username=aaa\ndataSource.password=111\ndataSource.initialSize=10\ndataSource.maxActive=20\ndataSource.minIdle=10\ndataSource.maxWait=5000\ndataSource.testOnBorrow=false\ndataSource.testOnReturn=false\ndataSource.testWhileIdle=true\ndataSource.timeBetweenEvictionRunsMillis=60000\ndataSource.minEvictableIdleTimeMillis=25200000\ndataSource.removeAbandoned=true\ndataSource.removeAbandonedTimeout=1800\ndataSource.logAbandoned=true\ndataSource.slowSqlMillis=100\n```\n排查是否由wait_timeout设置太小，导致服务器断开了连接，发现并没有设置，默认是8小时，排除wait_timeout参数问题。\n* c、排查是否是连接池连接数过小\n```\ndataSource.maxActive=20，最大活跃数20个，对当前系统访问量，也不少了，排除。\ndataSource.maxWait=5000，是否是最大等待毫秒数, 超过时间，5s，排除。\n```\n* c、查看数据库连接池情况。（连接池数据图标，出现空白问题，跟DBA沟通，认为是mysql server连接池的淘汰策略问题：实际上是正确的）\n* d、DBA排查，和前几天的job有关。（相同SQL CPU飙升，会激活job，进行连接kill；验证了是mysql server主动关闭连接）\n\n\n# 三、总结\n影响MySQL连接的问题原因有很多种。   \n1、和连接mysql时间有关的系统变量\n* wait_timeout：服务器关闭非交互连接之前等待活动的秒数。（即一个连接多久没交互后会被关闭）\n* interactive_timeout：服务器关闭交互式连接前等待活动的秒数。（即一个连接多久没交互后会被关闭）\n\n以上两个参数，会影响MySQL服务端对连接进行关闭，保持默认即可。  \n2、连接非正常关闭，可以查看MySQL服务端是否出现问题，都是服务端关闭连接后，\n而客户端连接池还持有这个连接，用关闭的连接去请求服务器，当然不能响应。\n\n\n","slug":"2019-04-24-MySQL-连接异常问题","published":1,"updated":"2024-12-09T03:26:17.278Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnuh000da13knd69zcpj","content":"<h1 id=\"一、问题场景\"><a href=\"#一、问题场景\" class=\"headerlink\" title=\"一、问题场景\"></a>一、问题场景</h1><p>mybatis报异常<br><img src=\"/2019/04/24/2019-04-24-MySQL-连接异常问题/mysql-error.png\" alt=\"redis-io\"></p>\n<a id=\"more\"></a>\n\n<h1 id=\"二、排查过程\"><a href=\"#二、排查过程\" class=\"headerlink\" title=\"二、排查过程\"></a>二、排查过程</h1><p>如日志所述，无法和MySQL服务端建立通讯。那为什么会断开连接呢？</p>\n<p>排查步骤如下：</p>\n<ul>\n<li>a、上次该连接与mysql的交互是108ms以前，但是现在却出问题了，说明是mysql server主动关闭了连接。（ps：只有服务器主动断开连接时才会出现这种问题）</li>\n<li>b、检查MySQL参数<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataSource.url=jdbc:mysql://mysql:3306/uum?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;zeroDateTimeBehavior=convertToNull</span><br><span class=\"line\">dataSource.username=aaa</span><br><span class=\"line\">dataSource.password=111</span><br><span class=\"line\">dataSource.initialSize=10</span><br><span class=\"line\">dataSource.maxActive=20</span><br><span class=\"line\">dataSource.minIdle=10</span><br><span class=\"line\">dataSource.maxWait=5000</span><br><span class=\"line\">dataSource.testOnBorrow=false</span><br><span class=\"line\">dataSource.testOnReturn=false</span><br><span class=\"line\">dataSource.testWhileIdle=true</span><br><span class=\"line\">dataSource.timeBetweenEvictionRunsMillis=60000</span><br><span class=\"line\">dataSource.minEvictableIdleTimeMillis=25200000</span><br><span class=\"line\">dataSource.removeAbandoned=true</span><br><span class=\"line\">dataSource.removeAbandonedTimeout=1800</span><br><span class=\"line\">dataSource.logAbandoned=true</span><br><span class=\"line\">dataSource.slowSqlMillis=100</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>排查是否由wait_timeout设置太小，导致服务器断开了连接，发现并没有设置，默认是8小时，排除wait_timeout参数问题。</p>\n<ul>\n<li><p>c、排查是否是连接池连接数过小</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataSource.maxActive=20，最大活跃数20个，对当前系统访问量，也不少了，排除。</span><br><span class=\"line\">dataSource.maxWait=5000，是否是最大等待毫秒数, 超过时间，5s，排除。</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>c、查看数据库连接池情况。（连接池数据图标，出现空白问题，跟DBA沟通，认为是mysql server连接池的淘汰策略问题：实际上是正确的）</p>\n</li>\n<li><p>d、DBA排查，和前几天的job有关。（相同SQL CPU飙升，会激活job，进行连接kill；验证了是mysql server主动关闭连接）</p>\n</li>\n</ul>\n<h1 id=\"三、总结\"><a href=\"#三、总结\" class=\"headerlink\" title=\"三、总结\"></a>三、总结</h1><p>影响MySQL连接的问题原因有很多种。<br>1、和连接mysql时间有关的系统变量</p>\n<ul>\n<li>wait_timeout：服务器关闭非交互连接之前等待活动的秒数。（即一个连接多久没交互后会被关闭）</li>\n<li>interactive_timeout：服务器关闭交互式连接前等待活动的秒数。（即一个连接多久没交互后会被关闭）</li>\n</ul>\n<p>以上两个参数，会影响MySQL服务端对连接进行关闭，保持默认即可。<br>2、连接非正常关闭，可以查看MySQL服务端是否出现问题，都是服务端关闭连接后，<br>而客户端连接池还持有这个连接，用关闭的连接去请求服务器，当然不能响应。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、问题场景\"><a href=\"#一、问题场景\" class=\"headerlink\" title=\"一、问题场景\"></a>一、问题场景</h1><p>mybatis报异常<br><img src=\"/2019/04/24/2019-04-24-MySQL-连接异常问题/mysql-error.png\" alt=\"redis-io\"></p>","more":"<h1 id=\"二、排查过程\"><a href=\"#二、排查过程\" class=\"headerlink\" title=\"二、排查过程\"></a>二、排查过程</h1><p>如日志所述，无法和MySQL服务端建立通讯。那为什么会断开连接呢？</p>\n<p>排查步骤如下：</p>\n<ul>\n<li>a、上次该连接与mysql的交互是108ms以前，但是现在却出问题了，说明是mysql server主动关闭了连接。（ps：只有服务器主动断开连接时才会出现这种问题）</li>\n<li>b、检查MySQL参数<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataSource.url=jdbc:mysql://mysql:3306/uum?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;zeroDateTimeBehavior=convertToNull</span><br><span class=\"line\">dataSource.username=aaa</span><br><span class=\"line\">dataSource.password=111</span><br><span class=\"line\">dataSource.initialSize=10</span><br><span class=\"line\">dataSource.maxActive=20</span><br><span class=\"line\">dataSource.minIdle=10</span><br><span class=\"line\">dataSource.maxWait=5000</span><br><span class=\"line\">dataSource.testOnBorrow=false</span><br><span class=\"line\">dataSource.testOnReturn=false</span><br><span class=\"line\">dataSource.testWhileIdle=true</span><br><span class=\"line\">dataSource.timeBetweenEvictionRunsMillis=60000</span><br><span class=\"line\">dataSource.minEvictableIdleTimeMillis=25200000</span><br><span class=\"line\">dataSource.removeAbandoned=true</span><br><span class=\"line\">dataSource.removeAbandonedTimeout=1800</span><br><span class=\"line\">dataSource.logAbandoned=true</span><br><span class=\"line\">dataSource.slowSqlMillis=100</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>排查是否由wait_timeout设置太小，导致服务器断开了连接，发现并没有设置，默认是8小时，排除wait_timeout参数问题。</p>\n<ul>\n<li><p>c、排查是否是连接池连接数过小</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataSource.maxActive=20，最大活跃数20个，对当前系统访问量，也不少了，排除。</span><br><span class=\"line\">dataSource.maxWait=5000，是否是最大等待毫秒数, 超过时间，5s，排除。</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>c、查看数据库连接池情况。（连接池数据图标，出现空白问题，跟DBA沟通，认为是mysql server连接池的淘汰策略问题：实际上是正确的）</p>\n</li>\n<li><p>d、DBA排查，和前几天的job有关。（相同SQL CPU飙升，会激活job，进行连接kill；验证了是mysql server主动关闭连接）</p>\n</li>\n</ul>\n<h1 id=\"三、总结\"><a href=\"#三、总结\" class=\"headerlink\" title=\"三、总结\"></a>三、总结</h1><p>影响MySQL连接的问题原因有很多种。<br>1、和连接mysql时间有关的系统变量</p>\n<ul>\n<li>wait_timeout：服务器关闭非交互连接之前等待活动的秒数。（即一个连接多久没交互后会被关闭）</li>\n<li>interactive_timeout：服务器关闭交互式连接前等待活动的秒数。（即一个连接多久没交互后会被关闭）</li>\n</ul>\n<p>以上两个参数，会影响MySQL服务端对连接进行关闭，保持默认即可。<br>2、连接非正常关闭，可以查看MySQL服务端是否出现问题，都是服务端关闭连接后，<br>而客户端连接池还持有这个连接，用关闭的连接去请求服务器，当然不能响应。</p>"},{"title":"bio","date":"2019-05-18T14:11:10.000Z","_content":"\n# 一、从代码层次了解BIO\n\n    //服务端\n    public class BioServer {\n        public static void main(String[] args) {\n            byte[] bs = new byte[1024];\n            try {\n                //服务端的监听socket，只负责监听连接，监听的端口是：9878\n                ServerSocket serverSocket = new ServerSocket();\n                serverSocket.bind(new InetSocketAddress(9878));\n                while (true) {//可以进行下一次的通信\n                    System.out.println(\"等待连接\");\n                    Socket accept = serverSocket.accept();//服务端进程将阻塞(将释放CPU资源)，直至连接请求过来，然后会生成一个socket\n                    //accept，这个socket是负责和客户端数据交换的\n                    System.out.println(\"连接成功\");\n                    System.out.println(\"等待数据\");\n                    int readCount = accept.getInputStream().read(bs);//read也将阻塞\n                    System.out.println(\"数据获取成功\");\n                    System.out.println(\"读取的数量=\" + readCount);\n                    String content = bs.toString();\n                    System.out.println(\"读取的内容为：\" + content);\n                }\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    //客户端\n    public class BioClient {\n        public static void main(String[] args) {\n            Socket socket = new Socket();\n            socket.connect(new InetSocketAddress(\"127.0.0.1\", 9878));\n        }\n    }\n<!--more-->\n\n# 二、以下是图形解释\n\n![bio](2019-05-18-bio/bio.png)\n\nbio：accept(),read()两个阻塞，如果采用单线程时，无法处理并发。当上一个连接未处理完成，server端则不会处理其他客户端请求。\n\n# 三、bio的优化方式：\n1、多线程方式，主线程负责连接，子线程数据交换\n\n    while (true) {//可以进行下一次的通信\n        System.out.println(\"等待连接\");\n        Socket accept = serverSocket.accept();//服务端进程将阻塞(将释放CPU资源)，直至连接请求过来，然后会生成一个socket\n        //accept，这个socket是负责和客户端数据交换的\n        System.out.println(\"连接成功\");\n\n        Threa thread = new Thread();\n        thread.start();\n        //int readCount = accept.getInputStream().read(bs);//read也将阻塞\n        //System.out.println(\"数据获取成功\");\n        //System.out.println(\"读取的数量=\" + readCount);\n        //String content = bs.toString();\n        //System.out.println(\"读取的内容为：\" + content);\n    }\n缺点：线程利用率太低，大部分线程都是无效线程（不会进行数据传输）\n使用多线程方式，需要考虑线程利用率，线程都是用来数据传输。\n\n2、操作系统也再优化演进，多路复用器selector应运而生，java nio基于操作系统的多路复用器。 \n    ","source":"_posts/2019-05-18-bio.md","raw":"---\ntitle: bio\ndate: 2019-05-18 22:11:10\ntags: bio\ncategories: io\n---\n\n# 一、从代码层次了解BIO\n\n    //服务端\n    public class BioServer {\n        public static void main(String[] args) {\n            byte[] bs = new byte[1024];\n            try {\n                //服务端的监听socket，只负责监听连接，监听的端口是：9878\n                ServerSocket serverSocket = new ServerSocket();\n                serverSocket.bind(new InetSocketAddress(9878));\n                while (true) {//可以进行下一次的通信\n                    System.out.println(\"等待连接\");\n                    Socket accept = serverSocket.accept();//服务端进程将阻塞(将释放CPU资源)，直至连接请求过来，然后会生成一个socket\n                    //accept，这个socket是负责和客户端数据交换的\n                    System.out.println(\"连接成功\");\n                    System.out.println(\"等待数据\");\n                    int readCount = accept.getInputStream().read(bs);//read也将阻塞\n                    System.out.println(\"数据获取成功\");\n                    System.out.println(\"读取的数量=\" + readCount);\n                    String content = bs.toString();\n                    System.out.println(\"读取的内容为：\" + content);\n                }\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    //客户端\n    public class BioClient {\n        public static void main(String[] args) {\n            Socket socket = new Socket();\n            socket.connect(new InetSocketAddress(\"127.0.0.1\", 9878));\n        }\n    }\n<!--more-->\n\n# 二、以下是图形解释\n\n![bio](2019-05-18-bio/bio.png)\n\nbio：accept(),read()两个阻塞，如果采用单线程时，无法处理并发。当上一个连接未处理完成，server端则不会处理其他客户端请求。\n\n# 三、bio的优化方式：\n1、多线程方式，主线程负责连接，子线程数据交换\n\n    while (true) {//可以进行下一次的通信\n        System.out.println(\"等待连接\");\n        Socket accept = serverSocket.accept();//服务端进程将阻塞(将释放CPU资源)，直至连接请求过来，然后会生成一个socket\n        //accept，这个socket是负责和客户端数据交换的\n        System.out.println(\"连接成功\");\n\n        Threa thread = new Thread();\n        thread.start();\n        //int readCount = accept.getInputStream().read(bs);//read也将阻塞\n        //System.out.println(\"数据获取成功\");\n        //System.out.println(\"读取的数量=\" + readCount);\n        //String content = bs.toString();\n        //System.out.println(\"读取的内容为：\" + content);\n    }\n缺点：线程利用率太低，大部分线程都是无效线程（不会进行数据传输）\n使用多线程方式，需要考虑线程利用率，线程都是用来数据传输。\n\n2、操作系统也再优化演进，多路复用器selector应运而生，java nio基于操作系统的多路复用器。 \n    ","slug":"2019-05-18-bio","published":1,"updated":"2024-10-14T09:38:11.898Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnuk000ga13k21m2lmbq","content":"<h1 id=\"一、从代码层次了解BIO\"><a href=\"#一、从代码层次了解BIO\" class=\"headerlink\" title=\"一、从代码层次了解BIO\"></a>一、从代码层次了解BIO</h1><pre><code>//服务端\npublic class BioServer {\n    public static void main(String[] args) {\n        byte[] bs = new byte[1024];\n        try {\n            //服务端的监听socket，只负责监听连接，监听的端口是：9878\n            ServerSocket serverSocket = new ServerSocket();\n            serverSocket.bind(new InetSocketAddress(9878));\n            while (true) {//可以进行下一次的通信\n                System.out.println(&quot;等待连接&quot;);\n                Socket accept = serverSocket.accept();//服务端进程将阻塞(将释放CPU资源)，直至连接请求过来，然后会生成一个socket\n                //accept，这个socket是负责和客户端数据交换的\n                System.out.println(&quot;连接成功&quot;);\n                System.out.println(&quot;等待数据&quot;);\n                int readCount = accept.getInputStream().read(bs);//read也将阻塞\n                System.out.println(&quot;数据获取成功&quot;);\n                System.out.println(&quot;读取的数量=&quot; + readCount);\n                String content = bs.toString();\n                System.out.println(&quot;读取的内容为：&quot; + content);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n//客户端\npublic class BioClient {\n    public static void main(String[] args) {\n        Socket socket = new Socket();\n        socket.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 9878));\n    }\n}</code></pre><a id=\"more\"></a>\n\n<h1 id=\"二、以下是图形解释\"><a href=\"#二、以下是图形解释\" class=\"headerlink\" title=\"二、以下是图形解释\"></a>二、以下是图形解释</h1><p><img src=\"/2019/05/18/2019-05-18-bio/bio.png\" alt=\"bio\"></p>\n<p>bio：accept(),read()两个阻塞，如果采用单线程时，无法处理并发。当上一个连接未处理完成，server端则不会处理其他客户端请求。</p>\n<h1 id=\"三、bio的优化方式：\"><a href=\"#三、bio的优化方式：\" class=\"headerlink\" title=\"三、bio的优化方式：\"></a>三、bio的优化方式：</h1><p>1、多线程方式，主线程负责连接，子线程数据交换</p>\n<pre><code>while (true) {//可以进行下一次的通信\n    System.out.println(&quot;等待连接&quot;);\n    Socket accept = serverSocket.accept();//服务端进程将阻塞(将释放CPU资源)，直至连接请求过来，然后会生成一个socket\n    //accept，这个socket是负责和客户端数据交换的\n    System.out.println(&quot;连接成功&quot;);\n\n    Threa thread = new Thread();\n    thread.start();\n    //int readCount = accept.getInputStream().read(bs);//read也将阻塞\n    //System.out.println(&quot;数据获取成功&quot;);\n    //System.out.println(&quot;读取的数量=&quot; + readCount);\n    //String content = bs.toString();\n    //System.out.println(&quot;读取的内容为：&quot; + content);\n}</code></pre><p>缺点：线程利用率太低，大部分线程都是无效线程（不会进行数据传输）<br>使用多线程方式，需要考虑线程利用率，线程都是用来数据传输。</p>\n<p>2、操作系统也再优化演进，多路复用器selector应运而生，java nio基于操作系统的多路复用器。 </p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、从代码层次了解BIO\"><a href=\"#一、从代码层次了解BIO\" class=\"headerlink\" title=\"一、从代码层次了解BIO\"></a>一、从代码层次了解BIO</h1><pre><code>//服务端\npublic class BioServer {\n    public static void main(String[] args) {\n        byte[] bs = new byte[1024];\n        try {\n            //服务端的监听socket，只负责监听连接，监听的端口是：9878\n            ServerSocket serverSocket = new ServerSocket();\n            serverSocket.bind(new InetSocketAddress(9878));\n            while (true) {//可以进行下一次的通信\n                System.out.println(&quot;等待连接&quot;);\n                Socket accept = serverSocket.accept();//服务端进程将阻塞(将释放CPU资源)，直至连接请求过来，然后会生成一个socket\n                //accept，这个socket是负责和客户端数据交换的\n                System.out.println(&quot;连接成功&quot;);\n                System.out.println(&quot;等待数据&quot;);\n                int readCount = accept.getInputStream().read(bs);//read也将阻塞\n                System.out.println(&quot;数据获取成功&quot;);\n                System.out.println(&quot;读取的数量=&quot; + readCount);\n                String content = bs.toString();\n                System.out.println(&quot;读取的内容为：&quot; + content);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n//客户端\npublic class BioClient {\n    public static void main(String[] args) {\n        Socket socket = new Socket();\n        socket.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 9878));\n    }\n}</code></pre>","more":"<h1 id=\"二、以下是图形解释\"><a href=\"#二、以下是图形解释\" class=\"headerlink\" title=\"二、以下是图形解释\"></a>二、以下是图形解释</h1><p><img src=\"/2019/05/18/2019-05-18-bio/bio.png\" alt=\"bio\"></p>\n<p>bio：accept(),read()两个阻塞，如果采用单线程时，无法处理并发。当上一个连接未处理完成，server端则不会处理其他客户端请求。</p>\n<h1 id=\"三、bio的优化方式：\"><a href=\"#三、bio的优化方式：\" class=\"headerlink\" title=\"三、bio的优化方式：\"></a>三、bio的优化方式：</h1><p>1、多线程方式，主线程负责连接，子线程数据交换</p>\n<pre><code>while (true) {//可以进行下一次的通信\n    System.out.println(&quot;等待连接&quot;);\n    Socket accept = serverSocket.accept();//服务端进程将阻塞(将释放CPU资源)，直至连接请求过来，然后会生成一个socket\n    //accept，这个socket是负责和客户端数据交换的\n    System.out.println(&quot;连接成功&quot;);\n\n    Threa thread = new Thread();\n    thread.start();\n    //int readCount = accept.getInputStream().read(bs);//read也将阻塞\n    //System.out.println(&quot;数据获取成功&quot;);\n    //System.out.println(&quot;读取的数量=&quot; + readCount);\n    //String content = bs.toString();\n    //System.out.println(&quot;读取的内容为：&quot; + content);\n}</code></pre><p>缺点：线程利用率太低，大部分线程都是无效线程（不会进行数据传输）<br>使用多线程方式，需要考虑线程利用率，线程都是用来数据传输。</p>\n<p>2、操作系统也再优化演进，多路复用器selector应运而生，java nio基于操作系统的多路复用器。 </p>"},{"title":"nio","date":"2019-06-14T15:00:42.000Z","_content":"从上篇bio文章，我们了解了传统socket连接为阻塞IO，然后了解了bio的多线程优化方式及其缺点。多路复用则是另外一种优化方式。\n\n# 一、nio的设计思想\n\n<!--more-->  \n\n![nio-1](2019-06-14-nio/nio-common.png)\n\n\n以下是代码设计思想\n```\n//服务端\npublic class BioServer {\n    public static void main(String[] args) {\n        List<Socket> socketList = Lists.newArrayList();\n        byte[] bs = new byte[1024];\n        try {\n            //服务端的监听socket，只负责监听连接，监听的端口是：9878\n            ServerSocket serverSocket = new ServerSocket();\n            serverSocket.bind(new InetSocketAddress(9878));\n            serverSocket.setBlock(false);//伪代码，表示设置serverSocket为非阻塞\n            while (true) {//可以进行下一次的通信\n                Socket accept = serverSocket.accept();\n                if (accept == null) {\n                    //表示该次while中，无新连接\n                    socketList.forEach(socket -> {\n                        //遍历socket，看是否有数据发过来\n                        int readCount = socket.getInputStream().read(bs);\n                        if(readCount > 0) {\n                            //输出\n                        }\n                    });\n                } else {\n                    accept.setBlock(false);//伪代码，表示socket.read为非阻塞\n                    socketList.add(accept);                            \n                    socketList.forEach(socket -> {\n                        int readCount = socket.getInputStream().read(bs);\n                        if(readCount > 0) {\n                            //输出\n                        }\n                    });\n                }\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n    \n//服务端\nServerSocketChannel serverChannel = ServerSocketChannel.open();\nserverChannel.configureBlocking(false);\nserverChannel.socket().bind(new InetSocketAddress(port));\nSelector selector = Selector.open();\nserverChannel.register(selector, SelectionKey.OP_ACCEPT);\nwhile(true){\n    int n = selector.select();\n    if (n == 0) continue;\n    Iterator ite = this.selector.selectedKeys().iterator();\n    while(ite.hasNext()){\n        SelectionKey key = (SelectionKey)ite.next();\n        if (key.isAcceptable()){\n            SocketChannel clntChan = ((ServerSocketChannel) key.channel()).accept();\n            clntChan.configureBlocking(false);\n            //将选择器注册到连接到的客户端信道，\n            //并指定该信道key值的属性为OP_READ，\n            //同时为该信道指定关联的附件\n            clntChan.register(key.selector(), SelectionKey.OP_READ, ByteBuffer.allocate(bufSize));\n        }\n        if (key.isReadable()){\n            handleRead(key);\n        }\n        if (key.isWritable() && key.isValid()){\n            handleWrite(key);\n        }\n        if (key.isConnectable()){\n            System.out.println(\"isConnectable = true\");\n        }\n      ite.remove();\n    }\n}\n```      \nMore info:[参考文章](https://www.bilibili.com/video/av54147951/)\n\n# 二、多路复用具体实现\n\n### 2.1、ServerSocketChannel\n\n>追踪系统调用：sudo dtruss -f -p 12345 2> /tmp/trace.txt\n\n    ServerSocketChannel ss = ServerSocketChannel.open();\n    ss.bind(new InetSocketAddress(9090));\n    ss.configureBlocking(false); //重点  OS  NONBLOCKING!!!\n    \n    \n    对应的系统调用\n    socket(PF_INET, SOCK_STREAM, IPPROTO_IP)  = 4    ---->获取文件描述符=4\n    fcntl(4, SETEL, O_RDWR|O_NONBLOCK) = 0           ---->修改文件描述符为非阻塞\n    bind(4, {sa_family=AF_INET, sin_port=htons(9090)})--->绑定端口\n    listen(4, 50);                         \n    \n>多路复用是nio模型的一个升级，将由应用程序循环遍历的socket列表交给了内核，由内核去通知应用程序socket是否OK。\n \n \n### 2.2、socket非阻塞\n创建socket的时候，指定socket是异步的，在type的参数中设置SOCK_NONBLOCK标志即可。\n\n    int socket(int domain, int type, int protocol);\n    int s = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, IPPROTO_TCP);\n\n### 2.3、普通文件非阻塞\n对于文件的阻塞模式还是非阻塞模式::\n        \n    方法1、open时，使用O_NONBLOCK；\n    方法2、fcntl设置，使用F_SETFL，flags|O_NONBLOCK；\n\n\n### 2.4、传统阻塞模式\n\n    ServerSocket server = new ServerSocket(9090,20);\n    Socket client = server.accept();  //阻塞1 \n\n\n# 三、演进\n传统阻塞模式  ->  非阻塞模式  ->   多路复用\n\n阻塞模式的问题：server阻塞，无法处理更多的客户端连接。  \n优化：采用多线程+线程池方式  \n非阻塞的问题：连接和读取不阻塞，但是当服务端越多时，主线程去遍历的时候耗时越多，而且无效的遍历可能无效，此时每次遍历都会产生系统调用。  \n\n# 四、多路复用\n将文件描述符交给内核，一次系统调用，内核返回满足条件的文件描述符，再由用户程序去对文件描述符操作。\n    \n#### 4.1、select、poll\n    select：只能支持1024个fd\n    poll：不限制fd个数\n    select\\poll问题：\n        1、每次都要更新，重复传递fds（解决方法：创建内核空间存放fds）\n        2、每次内核被调用后，内核需要遍历一遍所有的fds耗时耗资源（）\n\n#### 4.2、epoll：\n解决前两个的问题\n\n    1、创建内核空间存放fds，每次内核调用后，将满足条件的fd存入链表，epoll_wait时再将链表返回。\n    为什么不需要遍历所有fds???\n    a. 网卡中段时，将数据存入至fd的buffer缓冲区内，再由”延伸“将对应的fd由内核空间的fd红黑树对应的fd拷贝至链表内。      \n    \n\n#### 4.3、代码\n\n    public static void main(String[] args) {\n        try (ServerSocketChannel serverSocketChannel = ServerSocketChannel.open()) {\n            //创建serverSocket\n            serverSocketChannel.bind(new InetSocketAddress(9090));\n            //创建多路复用器\n            Selector selector = Selector.open();\n            //将服务端注册进多路复用器内\n            SelectionKey selectionKey = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n            //返回多路复用器的keys\n            Set<SelectionKey> selectionKeySet = selector.keys();\n            //准备好了io的key数量\n            int readyIOKeyCount = selector.select(500);\n            if (readyIOKeyCount > 0) {\n                //代表有准备好的fd，此时需要获取出key并进行数据的读取\n                Set<SelectionKey> readyKeySet = selector.selectedKeys();\n                //遍历，进行数据的处理\n                Iterator<SelectionKey> iterator = readyKeySet.iterator();\n                while (iterator.hasNext()) {\n                    SelectionKey key = iterator.next();\n                    iterator.remove();\n                    if (key.isAcceptable()) {\n                        //代表是客户端连接类型的fd\n                        ServerSocketChannel ssc = (ServerSocketChannel)key.channel();\n                        SocketChannel client = ssc.accept();\n                        //客户端设置为非阻塞\n                        client.configureBlocking(false);\n                        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n                        //将客户端注册进多路复用器内\n                        client.register(selector, SelectionKey.OP_ACCEPT);\n                    } else if (key.isReadable()) {\n                        //代表是可以数据读取的类型\n                        SocketChannel client = (SocketChannel)key.channel();\n                        ByteBuffer byteBuffer = (ByteBuffer)key.attachment();\n                        byteBuffer.clear();\n                        while (true) {\n                            client.read(byteBuffer);\n                        }\n                    }\n                }\n            }\n        } catch (Exception e) {\n        }\n    }\n\nChannel，对应操作系统是一个fd（支持双向读写），然后将该fd注册进Selector内。Selector 会不断地轮询注册在其上的 Channel，如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I/O 操作\n\n***java代码：selector.select***\n\n    epoll在register时就调用了epoll_ctl注册进内核空间了，所以selector.select时是不用Java再传\n    poll在register时只是将fd注册进JVM内，selector.select时会将JVM中记录的fd数组传给内核\n\n# 五、文件IO\n***标准IO：***\n\n    File file = new File(path);\n    FileOutputStream out = new FileOutputStream(file);\n    while(true){\n        Thread.sleep(10);\n        out.write(data);\n    }\n>注：每次write，会进行系统调用，此时写入的数据为data\n\n***字符IO***\n\n    File file = new File(path);\n    BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(file));\n    while(true){\n        Thread.sleep(10);\n        out.write(data);\n    }\n\n>注：此时有字符缓冲区，当缓冲区满时，才会系统调用，因为系统调用减少了，进程空间的切换减少了，所以速度得到了提升。\n其他：数据写入，也只是将数据写入到了内核的pagecache内，pagecache写入磁盘的方式（主动、定时写入）    \n    \n***NIO方式***\n\n    RandomAccessFile raf = new RandomAccessFile(path, \"rw\");\n    raf.write(\"hello mashibing\\n\".getBytes());\n    raf.write(\"hello seanzhou\\n\".getBytes());\n    raf.seek(4);\n    raf.write(\"ooxx\".getBytes());\n    FileChannel rafchannel = raf.getChannel();\n    //mmap  堆外  和文件映射的   byte  not  objtect\n    MappedByteBuffer map = rafchannel.map(FileChannel.MapMode.READ_WRITE, 0, 4096);\n\n    对应的系统调用\n    open(\"/Users/chw/xxoo.txt\\0\", 0x202, 0x1B6)：打开文件\n    socketpair(0x1, 0x1, 0x0)：创建一对无名的、相互连接的套接子\n\n    buffer\n    capacity：缓存容量大小\n    position：当前位置。\n    limit：\n    mark：\n    channel\n    fileChannel.seek：支持多个进程对一个文件描述符进行操作，通过seek进行段位控制\n    MappedByteBuffer mapBuffer = filechannel.map： 只有文件channel才有map，建立内存映射，实际系统调用为mmap，建立一个堆外内存。此时若向mapBuffer.put()数据，数据会放入到内核的pagecache内（put操作不会产生系统调用）    \n    \nMore info:[I/O 多路复用入门](https://jeff.wtf/2017/02/IO-multiplexing/)\n[一步步构建I/O多路复用的请求模型](https://juejin.im/entry/599f971af265da247d728531)\n[Java NIO浅析](https://tech.meituan.com/2016/11/04/nio.html)            ","source":"_posts/2019-06-14-nio.md","raw":"---\ntitle: nio\ndate: 2019-06-14 23:00:42\ntags: nio\ncategories: io\n---\n从上篇bio文章，我们了解了传统socket连接为阻塞IO，然后了解了bio的多线程优化方式及其缺点。多路复用则是另外一种优化方式。\n\n# 一、nio的设计思想\n\n<!--more-->  \n\n![nio-1](2019-06-14-nio/nio-common.png)\n\n\n以下是代码设计思想\n```\n//服务端\npublic class BioServer {\n    public static void main(String[] args) {\n        List<Socket> socketList = Lists.newArrayList();\n        byte[] bs = new byte[1024];\n        try {\n            //服务端的监听socket，只负责监听连接，监听的端口是：9878\n            ServerSocket serverSocket = new ServerSocket();\n            serverSocket.bind(new InetSocketAddress(9878));\n            serverSocket.setBlock(false);//伪代码，表示设置serverSocket为非阻塞\n            while (true) {//可以进行下一次的通信\n                Socket accept = serverSocket.accept();\n                if (accept == null) {\n                    //表示该次while中，无新连接\n                    socketList.forEach(socket -> {\n                        //遍历socket，看是否有数据发过来\n                        int readCount = socket.getInputStream().read(bs);\n                        if(readCount > 0) {\n                            //输出\n                        }\n                    });\n                } else {\n                    accept.setBlock(false);//伪代码，表示socket.read为非阻塞\n                    socketList.add(accept);                            \n                    socketList.forEach(socket -> {\n                        int readCount = socket.getInputStream().read(bs);\n                        if(readCount > 0) {\n                            //输出\n                        }\n                    });\n                }\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n    \n//服务端\nServerSocketChannel serverChannel = ServerSocketChannel.open();\nserverChannel.configureBlocking(false);\nserverChannel.socket().bind(new InetSocketAddress(port));\nSelector selector = Selector.open();\nserverChannel.register(selector, SelectionKey.OP_ACCEPT);\nwhile(true){\n    int n = selector.select();\n    if (n == 0) continue;\n    Iterator ite = this.selector.selectedKeys().iterator();\n    while(ite.hasNext()){\n        SelectionKey key = (SelectionKey)ite.next();\n        if (key.isAcceptable()){\n            SocketChannel clntChan = ((ServerSocketChannel) key.channel()).accept();\n            clntChan.configureBlocking(false);\n            //将选择器注册到连接到的客户端信道，\n            //并指定该信道key值的属性为OP_READ，\n            //同时为该信道指定关联的附件\n            clntChan.register(key.selector(), SelectionKey.OP_READ, ByteBuffer.allocate(bufSize));\n        }\n        if (key.isReadable()){\n            handleRead(key);\n        }\n        if (key.isWritable() && key.isValid()){\n            handleWrite(key);\n        }\n        if (key.isConnectable()){\n            System.out.println(\"isConnectable = true\");\n        }\n      ite.remove();\n    }\n}\n```      \nMore info:[参考文章](https://www.bilibili.com/video/av54147951/)\n\n# 二、多路复用具体实现\n\n### 2.1、ServerSocketChannel\n\n>追踪系统调用：sudo dtruss -f -p 12345 2> /tmp/trace.txt\n\n    ServerSocketChannel ss = ServerSocketChannel.open();\n    ss.bind(new InetSocketAddress(9090));\n    ss.configureBlocking(false); //重点  OS  NONBLOCKING!!!\n    \n    \n    对应的系统调用\n    socket(PF_INET, SOCK_STREAM, IPPROTO_IP)  = 4    ---->获取文件描述符=4\n    fcntl(4, SETEL, O_RDWR|O_NONBLOCK) = 0           ---->修改文件描述符为非阻塞\n    bind(4, {sa_family=AF_INET, sin_port=htons(9090)})--->绑定端口\n    listen(4, 50);                         \n    \n>多路复用是nio模型的一个升级，将由应用程序循环遍历的socket列表交给了内核，由内核去通知应用程序socket是否OK。\n \n \n### 2.2、socket非阻塞\n创建socket的时候，指定socket是异步的，在type的参数中设置SOCK_NONBLOCK标志即可。\n\n    int socket(int domain, int type, int protocol);\n    int s = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, IPPROTO_TCP);\n\n### 2.3、普通文件非阻塞\n对于文件的阻塞模式还是非阻塞模式::\n        \n    方法1、open时，使用O_NONBLOCK；\n    方法2、fcntl设置，使用F_SETFL，flags|O_NONBLOCK；\n\n\n### 2.4、传统阻塞模式\n\n    ServerSocket server = new ServerSocket(9090,20);\n    Socket client = server.accept();  //阻塞1 \n\n\n# 三、演进\n传统阻塞模式  ->  非阻塞模式  ->   多路复用\n\n阻塞模式的问题：server阻塞，无法处理更多的客户端连接。  \n优化：采用多线程+线程池方式  \n非阻塞的问题：连接和读取不阻塞，但是当服务端越多时，主线程去遍历的时候耗时越多，而且无效的遍历可能无效，此时每次遍历都会产生系统调用。  \n\n# 四、多路复用\n将文件描述符交给内核，一次系统调用，内核返回满足条件的文件描述符，再由用户程序去对文件描述符操作。\n    \n#### 4.1、select、poll\n    select：只能支持1024个fd\n    poll：不限制fd个数\n    select\\poll问题：\n        1、每次都要更新，重复传递fds（解决方法：创建内核空间存放fds）\n        2、每次内核被调用后，内核需要遍历一遍所有的fds耗时耗资源（）\n\n#### 4.2、epoll：\n解决前两个的问题\n\n    1、创建内核空间存放fds，每次内核调用后，将满足条件的fd存入链表，epoll_wait时再将链表返回。\n    为什么不需要遍历所有fds???\n    a. 网卡中段时，将数据存入至fd的buffer缓冲区内，再由”延伸“将对应的fd由内核空间的fd红黑树对应的fd拷贝至链表内。      \n    \n\n#### 4.3、代码\n\n    public static void main(String[] args) {\n        try (ServerSocketChannel serverSocketChannel = ServerSocketChannel.open()) {\n            //创建serverSocket\n            serverSocketChannel.bind(new InetSocketAddress(9090));\n            //创建多路复用器\n            Selector selector = Selector.open();\n            //将服务端注册进多路复用器内\n            SelectionKey selectionKey = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n            //返回多路复用器的keys\n            Set<SelectionKey> selectionKeySet = selector.keys();\n            //准备好了io的key数量\n            int readyIOKeyCount = selector.select(500);\n            if (readyIOKeyCount > 0) {\n                //代表有准备好的fd，此时需要获取出key并进行数据的读取\n                Set<SelectionKey> readyKeySet = selector.selectedKeys();\n                //遍历，进行数据的处理\n                Iterator<SelectionKey> iterator = readyKeySet.iterator();\n                while (iterator.hasNext()) {\n                    SelectionKey key = iterator.next();\n                    iterator.remove();\n                    if (key.isAcceptable()) {\n                        //代表是客户端连接类型的fd\n                        ServerSocketChannel ssc = (ServerSocketChannel)key.channel();\n                        SocketChannel client = ssc.accept();\n                        //客户端设置为非阻塞\n                        client.configureBlocking(false);\n                        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n                        //将客户端注册进多路复用器内\n                        client.register(selector, SelectionKey.OP_ACCEPT);\n                    } else if (key.isReadable()) {\n                        //代表是可以数据读取的类型\n                        SocketChannel client = (SocketChannel)key.channel();\n                        ByteBuffer byteBuffer = (ByteBuffer)key.attachment();\n                        byteBuffer.clear();\n                        while (true) {\n                            client.read(byteBuffer);\n                        }\n                    }\n                }\n            }\n        } catch (Exception e) {\n        }\n    }\n\nChannel，对应操作系统是一个fd（支持双向读写），然后将该fd注册进Selector内。Selector 会不断地轮询注册在其上的 Channel，如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I/O 操作\n\n***java代码：selector.select***\n\n    epoll在register时就调用了epoll_ctl注册进内核空间了，所以selector.select时是不用Java再传\n    poll在register时只是将fd注册进JVM内，selector.select时会将JVM中记录的fd数组传给内核\n\n# 五、文件IO\n***标准IO：***\n\n    File file = new File(path);\n    FileOutputStream out = new FileOutputStream(file);\n    while(true){\n        Thread.sleep(10);\n        out.write(data);\n    }\n>注：每次write，会进行系统调用，此时写入的数据为data\n\n***字符IO***\n\n    File file = new File(path);\n    BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(file));\n    while(true){\n        Thread.sleep(10);\n        out.write(data);\n    }\n\n>注：此时有字符缓冲区，当缓冲区满时，才会系统调用，因为系统调用减少了，进程空间的切换减少了，所以速度得到了提升。\n其他：数据写入，也只是将数据写入到了内核的pagecache内，pagecache写入磁盘的方式（主动、定时写入）    \n    \n***NIO方式***\n\n    RandomAccessFile raf = new RandomAccessFile(path, \"rw\");\n    raf.write(\"hello mashibing\\n\".getBytes());\n    raf.write(\"hello seanzhou\\n\".getBytes());\n    raf.seek(4);\n    raf.write(\"ooxx\".getBytes());\n    FileChannel rafchannel = raf.getChannel();\n    //mmap  堆外  和文件映射的   byte  not  objtect\n    MappedByteBuffer map = rafchannel.map(FileChannel.MapMode.READ_WRITE, 0, 4096);\n\n    对应的系统调用\n    open(\"/Users/chw/xxoo.txt\\0\", 0x202, 0x1B6)：打开文件\n    socketpair(0x1, 0x1, 0x0)：创建一对无名的、相互连接的套接子\n\n    buffer\n    capacity：缓存容量大小\n    position：当前位置。\n    limit：\n    mark：\n    channel\n    fileChannel.seek：支持多个进程对一个文件描述符进行操作，通过seek进行段位控制\n    MappedByteBuffer mapBuffer = filechannel.map： 只有文件channel才有map，建立内存映射，实际系统调用为mmap，建立一个堆外内存。此时若向mapBuffer.put()数据，数据会放入到内核的pagecache内（put操作不会产生系统调用）    \n    \nMore info:[I/O 多路复用入门](https://jeff.wtf/2017/02/IO-multiplexing/)\n[一步步构建I/O多路复用的请求模型](https://juejin.im/entry/599f971af265da247d728531)\n[Java NIO浅析](https://tech.meituan.com/2016/11/04/nio.html)            ","slug":"2019-06-14-nio","published":1,"updated":"2024-10-14T09:38:11.900Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnun000ia13ktfx71f01","content":"<p>从上篇bio文章，我们了解了传统socket连接为阻塞IO，然后了解了bio的多线程优化方式及其缺点。多路复用则是另外一种优化方式。</p>\n<h1 id=\"一、nio的设计思想\"><a href=\"#一、nio的设计思想\" class=\"headerlink\" title=\"一、nio的设计思想\"></a>一、nio的设计思想</h1><a id=\"more\"></a>  \n\n<p><img src=\"/2019/06/14/2019-06-14-nio/nio-common.png\" alt=\"nio-1\"></p>\n<p>以下是代码设计思想</p>\n<pre><code>//服务端\npublic class BioServer {\n    public static void main(String[] args) {\n        List&lt;Socket&gt; socketList = Lists.newArrayList();\n        byte[] bs = new byte[1024];\n        try {\n            //服务端的监听socket，只负责监听连接，监听的端口是：9878\n            ServerSocket serverSocket = new ServerSocket();\n            serverSocket.bind(new InetSocketAddress(9878));\n            serverSocket.setBlock(false);//伪代码，表示设置serverSocket为非阻塞\n            while (true) {//可以进行下一次的通信\n                Socket accept = serverSocket.accept();\n                if (accept == null) {\n                    //表示该次while中，无新连接\n                    socketList.forEach(socket -&gt; {\n                        //遍历socket，看是否有数据发过来\n                        int readCount = socket.getInputStream().read(bs);\n                        if(readCount &gt; 0) {\n                            //输出\n                        }\n                    });\n                } else {\n                    accept.setBlock(false);//伪代码，表示socket.read为非阻塞\n                    socketList.add(accept);                            \n                    socketList.forEach(socket -&gt; {\n                        int readCount = socket.getInputStream().read(bs);\n                        if(readCount &gt; 0) {\n                            //输出\n                        }\n                    });\n                }\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n//服务端\nServerSocketChannel serverChannel = ServerSocketChannel.open();\nserverChannel.configureBlocking(false);\nserverChannel.socket().bind(new InetSocketAddress(port));\nSelector selector = Selector.open();\nserverChannel.register(selector, SelectionKey.OP_ACCEPT);\nwhile(true){\n    int n = selector.select();\n    if (n == 0) continue;\n    Iterator ite = this.selector.selectedKeys().iterator();\n    while(ite.hasNext()){\n        SelectionKey key = (SelectionKey)ite.next();\n        if (key.isAcceptable()){\n            SocketChannel clntChan = ((ServerSocketChannel) key.channel()).accept();\n            clntChan.configureBlocking(false);\n            //将选择器注册到连接到的客户端信道，\n            //并指定该信道key值的属性为OP_READ，\n            //同时为该信道指定关联的附件\n            clntChan.register(key.selector(), SelectionKey.OP_READ, ByteBuffer.allocate(bufSize));\n        }\n        if (key.isReadable()){\n            handleRead(key);\n        }\n        if (key.isWritable() &amp;&amp; key.isValid()){\n            handleWrite(key);\n        }\n        if (key.isConnectable()){\n            System.out.println(&quot;isConnectable = true&quot;);\n        }\n      ite.remove();\n    }\n}</code></pre><p>More info:<a href=\"https://www.bilibili.com/video/av54147951/\" target=\"_blank\" rel=\"noopener\">参考文章</a></p>\n<h1 id=\"二、多路复用具体实现\"><a href=\"#二、多路复用具体实现\" class=\"headerlink\" title=\"二、多路复用具体实现\"></a>二、多路复用具体实现</h1><h3 id=\"2-1、ServerSocketChannel\"><a href=\"#2-1、ServerSocketChannel\" class=\"headerlink\" title=\"2.1、ServerSocketChannel\"></a>2.1、ServerSocketChannel</h3><blockquote>\n<p>追踪系统调用：sudo dtruss -f -p 12345 2&gt; /tmp/trace.txt</p>\n</blockquote>\n<pre><code>ServerSocketChannel ss = ServerSocketChannel.open();\nss.bind(new InetSocketAddress(9090));\nss.configureBlocking(false); //重点  OS  NONBLOCKING!!!\n\n\n对应的系统调用\nsocket(PF_INET, SOCK_STREAM, IPPROTO_IP)  = 4    ----&gt;获取文件描述符=4\nfcntl(4, SETEL, O_RDWR|O_NONBLOCK) = 0           ----&gt;修改文件描述符为非阻塞\nbind(4, {sa_family=AF_INET, sin_port=htons(9090)})---&gt;绑定端口\nlisten(4, 50);                         </code></pre><blockquote>\n<p>多路复用是nio模型的一个升级，将由应用程序循环遍历的socket列表交给了内核，由内核去通知应用程序socket是否OK。</p>\n</blockquote>\n<h3 id=\"2-2、socket非阻塞\"><a href=\"#2-2、socket非阻塞\" class=\"headerlink\" title=\"2.2、socket非阻塞\"></a>2.2、socket非阻塞</h3><p>创建socket的时候，指定socket是异步的，在type的参数中设置SOCK_NONBLOCK标志即可。</p>\n<pre><code>int socket(int domain, int type, int protocol);\nint s = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, IPPROTO_TCP);</code></pre><h3 id=\"2-3、普通文件非阻塞\"><a href=\"#2-3、普通文件非阻塞\" class=\"headerlink\" title=\"2.3、普通文件非阻塞\"></a>2.3、普通文件非阻塞</h3><p>对于文件的阻塞模式还是非阻塞模式::</p>\n<pre><code>方法1、open时，使用O_NONBLOCK；\n方法2、fcntl设置，使用F_SETFL，flags|O_NONBLOCK；</code></pre><h3 id=\"2-4、传统阻塞模式\"><a href=\"#2-4、传统阻塞模式\" class=\"headerlink\" title=\"2.4、传统阻塞模式\"></a>2.4、传统阻塞模式</h3><pre><code>ServerSocket server = new ServerSocket(9090,20);\nSocket client = server.accept();  //阻塞1 </code></pre><h1 id=\"三、演进\"><a href=\"#三、演进\" class=\"headerlink\" title=\"三、演进\"></a>三、演进</h1><p>传统阻塞模式  -&gt;  非阻塞模式  -&gt;   多路复用</p>\n<p>阻塞模式的问题：server阻塞，无法处理更多的客户端连接。<br>优化：采用多线程+线程池方式<br>非阻塞的问题：连接和读取不阻塞，但是当服务端越多时，主线程去遍历的时候耗时越多，而且无效的遍历可能无效，此时每次遍历都会产生系统调用。  </p>\n<h1 id=\"四、多路复用\"><a href=\"#四、多路复用\" class=\"headerlink\" title=\"四、多路复用\"></a>四、多路复用</h1><p>将文件描述符交给内核，一次系统调用，内核返回满足条件的文件描述符，再由用户程序去对文件描述符操作。</p>\n<h4 id=\"4-1、select、poll\"><a href=\"#4-1、select、poll\" class=\"headerlink\" title=\"4.1、select、poll\"></a>4.1、select、poll</h4><pre><code>select：只能支持1024个fd\npoll：不限制fd个数\nselect\\poll问题：\n    1、每次都要更新，重复传递fds（解决方法：创建内核空间存放fds）\n    2、每次内核被调用后，内核需要遍历一遍所有的fds耗时耗资源（）</code></pre><h4 id=\"4-2、epoll：\"><a href=\"#4-2、epoll：\" class=\"headerlink\" title=\"4.2、epoll：\"></a>4.2、epoll：</h4><p>解决前两个的问题</p>\n<pre><code>1、创建内核空间存放fds，每次内核调用后，将满足条件的fd存入链表，epoll_wait时再将链表返回。\n为什么不需要遍历所有fds???\na. 网卡中段时，将数据存入至fd的buffer缓冲区内，再由”延伸“将对应的fd由内核空间的fd红黑树对应的fd拷贝至链表内。      </code></pre><h4 id=\"4-3、代码\"><a href=\"#4-3、代码\" class=\"headerlink\" title=\"4.3、代码\"></a>4.3、代码</h4><pre><code>public static void main(String[] args) {\n    try (ServerSocketChannel serverSocketChannel = ServerSocketChannel.open()) {\n        //创建serverSocket\n        serverSocketChannel.bind(new InetSocketAddress(9090));\n        //创建多路复用器\n        Selector selector = Selector.open();\n        //将服务端注册进多路复用器内\n        SelectionKey selectionKey = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n        //返回多路复用器的keys\n        Set&lt;SelectionKey&gt; selectionKeySet = selector.keys();\n        //准备好了io的key数量\n        int readyIOKeyCount = selector.select(500);\n        if (readyIOKeyCount &gt; 0) {\n            //代表有准备好的fd，此时需要获取出key并进行数据的读取\n            Set&lt;SelectionKey&gt; readyKeySet = selector.selectedKeys();\n            //遍历，进行数据的处理\n            Iterator&lt;SelectionKey&gt; iterator = readyKeySet.iterator();\n            while (iterator.hasNext()) {\n                SelectionKey key = iterator.next();\n                iterator.remove();\n                if (key.isAcceptable()) {\n                    //代表是客户端连接类型的fd\n                    ServerSocketChannel ssc = (ServerSocketChannel)key.channel();\n                    SocketChannel client = ssc.accept();\n                    //客户端设置为非阻塞\n                    client.configureBlocking(false);\n                    ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n                    //将客户端注册进多路复用器内\n                    client.register(selector, SelectionKey.OP_ACCEPT);\n                } else if (key.isReadable()) {\n                    //代表是可以数据读取的类型\n                    SocketChannel client = (SocketChannel)key.channel();\n                    ByteBuffer byteBuffer = (ByteBuffer)key.attachment();\n                    byteBuffer.clear();\n                    while (true) {\n                        client.read(byteBuffer);\n                    }\n                }\n            }\n        }\n    } catch (Exception e) {\n    }\n}</code></pre><p>Channel，对应操作系统是一个fd（支持双向读写），然后将该fd注册进Selector内。Selector 会不断地轮询注册在其上的 Channel，如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I/O 操作</p>\n<p><strong><em>java代码：selector.select</em></strong></p>\n<pre><code>epoll在register时就调用了epoll_ctl注册进内核空间了，所以selector.select时是不用Java再传\npoll在register时只是将fd注册进JVM内，selector.select时会将JVM中记录的fd数组传给内核</code></pre><h1 id=\"五、文件IO\"><a href=\"#五、文件IO\" class=\"headerlink\" title=\"五、文件IO\"></a>五、文件IO</h1><p><strong><em>标准IO：</em></strong></p>\n<pre><code>File file = new File(path);\nFileOutputStream out = new FileOutputStream(file);\nwhile(true){\n    Thread.sleep(10);\n    out.write(data);\n}</code></pre><blockquote>\n<p>注：每次write，会进行系统调用，此时写入的数据为data</p>\n</blockquote>\n<p><strong><em>字符IO</em></strong></p>\n<pre><code>File file = new File(path);\nBufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(file));\nwhile(true){\n    Thread.sleep(10);\n    out.write(data);\n}</code></pre><blockquote>\n<p>注：此时有字符缓冲区，当缓冲区满时，才会系统调用，因为系统调用减少了，进程空间的切换减少了，所以速度得到了提升。<br>其他：数据写入，也只是将数据写入到了内核的pagecache内，pagecache写入磁盘的方式（主动、定时写入）    </p>\n</blockquote>\n<p><strong><em>NIO方式</em></strong></p>\n<pre><code>RandomAccessFile raf = new RandomAccessFile(path, &quot;rw&quot;);\nraf.write(&quot;hello mashibing\\n&quot;.getBytes());\nraf.write(&quot;hello seanzhou\\n&quot;.getBytes());\nraf.seek(4);\nraf.write(&quot;ooxx&quot;.getBytes());\nFileChannel rafchannel = raf.getChannel();\n//mmap  堆外  和文件映射的   byte  not  objtect\nMappedByteBuffer map = rafchannel.map(FileChannel.MapMode.READ_WRITE, 0, 4096);\n\n对应的系统调用\nopen(&quot;/Users/chw/xxoo.txt\\0&quot;, 0x202, 0x1B6)：打开文件\nsocketpair(0x1, 0x1, 0x0)：创建一对无名的、相互连接的套接子\n\nbuffer\ncapacity：缓存容量大小\nposition：当前位置。\nlimit：\nmark：\nchannel\nfileChannel.seek：支持多个进程对一个文件描述符进行操作，通过seek进行段位控制\nMappedByteBuffer mapBuffer = filechannel.map： 只有文件channel才有map，建立内存映射，实际系统调用为mmap，建立一个堆外内存。此时若向mapBuffer.put()数据，数据会放入到内核的pagecache内（put操作不会产生系统调用）    </code></pre><p>More info:<a href=\"https://jeff.wtf/2017/02/IO-multiplexing/\" target=\"_blank\" rel=\"noopener\">I/O 多路复用入门</a><br><a href=\"https://juejin.im/entry/599f971af265da247d728531\" target=\"_blank\" rel=\"noopener\">一步步构建I/O多路复用的请求模型</a><br><a href=\"https://tech.meituan.com/2016/11/04/nio.html\" target=\"_blank\" rel=\"noopener\">Java NIO浅析</a>            </p>\n","site":{"data":{}},"excerpt":"<p>从上篇bio文章，我们了解了传统socket连接为阻塞IO，然后了解了bio的多线程优化方式及其缺点。多路复用则是另外一种优化方式。</p>\n<h1 id=\"一、nio的设计思想\"><a href=\"#一、nio的设计思想\" class=\"headerlink\" title=\"一、nio的设计思想\"></a>一、nio的设计思想</h1>","more":"<p><img src=\"/2019/06/14/2019-06-14-nio/nio-common.png\" alt=\"nio-1\"></p>\n<p>以下是代码设计思想</p>\n<pre><code>//服务端\npublic class BioServer {\n    public static void main(String[] args) {\n        List&lt;Socket&gt; socketList = Lists.newArrayList();\n        byte[] bs = new byte[1024];\n        try {\n            //服务端的监听socket，只负责监听连接，监听的端口是：9878\n            ServerSocket serverSocket = new ServerSocket();\n            serverSocket.bind(new InetSocketAddress(9878));\n            serverSocket.setBlock(false);//伪代码，表示设置serverSocket为非阻塞\n            while (true) {//可以进行下一次的通信\n                Socket accept = serverSocket.accept();\n                if (accept == null) {\n                    //表示该次while中，无新连接\n                    socketList.forEach(socket -&gt; {\n                        //遍历socket，看是否有数据发过来\n                        int readCount = socket.getInputStream().read(bs);\n                        if(readCount &gt; 0) {\n                            //输出\n                        }\n                    });\n                } else {\n                    accept.setBlock(false);//伪代码，表示socket.read为非阻塞\n                    socketList.add(accept);                            \n                    socketList.forEach(socket -&gt; {\n                        int readCount = socket.getInputStream().read(bs);\n                        if(readCount &gt; 0) {\n                            //输出\n                        }\n                    });\n                }\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n//服务端\nServerSocketChannel serverChannel = ServerSocketChannel.open();\nserverChannel.configureBlocking(false);\nserverChannel.socket().bind(new InetSocketAddress(port));\nSelector selector = Selector.open();\nserverChannel.register(selector, SelectionKey.OP_ACCEPT);\nwhile(true){\n    int n = selector.select();\n    if (n == 0) continue;\n    Iterator ite = this.selector.selectedKeys().iterator();\n    while(ite.hasNext()){\n        SelectionKey key = (SelectionKey)ite.next();\n        if (key.isAcceptable()){\n            SocketChannel clntChan = ((ServerSocketChannel) key.channel()).accept();\n            clntChan.configureBlocking(false);\n            //将选择器注册到连接到的客户端信道，\n            //并指定该信道key值的属性为OP_READ，\n            //同时为该信道指定关联的附件\n            clntChan.register(key.selector(), SelectionKey.OP_READ, ByteBuffer.allocate(bufSize));\n        }\n        if (key.isReadable()){\n            handleRead(key);\n        }\n        if (key.isWritable() &amp;&amp; key.isValid()){\n            handleWrite(key);\n        }\n        if (key.isConnectable()){\n            System.out.println(&quot;isConnectable = true&quot;);\n        }\n      ite.remove();\n    }\n}</code></pre><p>More info:<a href=\"https://www.bilibili.com/video/av54147951/\" target=\"_blank\" rel=\"noopener\">参考文章</a></p>\n<h1 id=\"二、多路复用具体实现\"><a href=\"#二、多路复用具体实现\" class=\"headerlink\" title=\"二、多路复用具体实现\"></a>二、多路复用具体实现</h1><h3 id=\"2-1、ServerSocketChannel\"><a href=\"#2-1、ServerSocketChannel\" class=\"headerlink\" title=\"2.1、ServerSocketChannel\"></a>2.1、ServerSocketChannel</h3><blockquote>\n<p>追踪系统调用：sudo dtruss -f -p 12345 2&gt; /tmp/trace.txt</p>\n</blockquote>\n<pre><code>ServerSocketChannel ss = ServerSocketChannel.open();\nss.bind(new InetSocketAddress(9090));\nss.configureBlocking(false); //重点  OS  NONBLOCKING!!!\n\n\n对应的系统调用\nsocket(PF_INET, SOCK_STREAM, IPPROTO_IP)  = 4    ----&gt;获取文件描述符=4\nfcntl(4, SETEL, O_RDWR|O_NONBLOCK) = 0           ----&gt;修改文件描述符为非阻塞\nbind(4, {sa_family=AF_INET, sin_port=htons(9090)})---&gt;绑定端口\nlisten(4, 50);                         </code></pre><blockquote>\n<p>多路复用是nio模型的一个升级，将由应用程序循环遍历的socket列表交给了内核，由内核去通知应用程序socket是否OK。</p>\n</blockquote>\n<h3 id=\"2-2、socket非阻塞\"><a href=\"#2-2、socket非阻塞\" class=\"headerlink\" title=\"2.2、socket非阻塞\"></a>2.2、socket非阻塞</h3><p>创建socket的时候，指定socket是异步的，在type的参数中设置SOCK_NONBLOCK标志即可。</p>\n<pre><code>int socket(int domain, int type, int protocol);\nint s = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, IPPROTO_TCP);</code></pre><h3 id=\"2-3、普通文件非阻塞\"><a href=\"#2-3、普通文件非阻塞\" class=\"headerlink\" title=\"2.3、普通文件非阻塞\"></a>2.3、普通文件非阻塞</h3><p>对于文件的阻塞模式还是非阻塞模式::</p>\n<pre><code>方法1、open时，使用O_NONBLOCK；\n方法2、fcntl设置，使用F_SETFL，flags|O_NONBLOCK；</code></pre><h3 id=\"2-4、传统阻塞模式\"><a href=\"#2-4、传统阻塞模式\" class=\"headerlink\" title=\"2.4、传统阻塞模式\"></a>2.4、传统阻塞模式</h3><pre><code>ServerSocket server = new ServerSocket(9090,20);\nSocket client = server.accept();  //阻塞1 </code></pre><h1 id=\"三、演进\"><a href=\"#三、演进\" class=\"headerlink\" title=\"三、演进\"></a>三、演进</h1><p>传统阻塞模式  -&gt;  非阻塞模式  -&gt;   多路复用</p>\n<p>阻塞模式的问题：server阻塞，无法处理更多的客户端连接。<br>优化：采用多线程+线程池方式<br>非阻塞的问题：连接和读取不阻塞，但是当服务端越多时，主线程去遍历的时候耗时越多，而且无效的遍历可能无效，此时每次遍历都会产生系统调用。  </p>\n<h1 id=\"四、多路复用\"><a href=\"#四、多路复用\" class=\"headerlink\" title=\"四、多路复用\"></a>四、多路复用</h1><p>将文件描述符交给内核，一次系统调用，内核返回满足条件的文件描述符，再由用户程序去对文件描述符操作。</p>\n<h4 id=\"4-1、select、poll\"><a href=\"#4-1、select、poll\" class=\"headerlink\" title=\"4.1、select、poll\"></a>4.1、select、poll</h4><pre><code>select：只能支持1024个fd\npoll：不限制fd个数\nselect\\poll问题：\n    1、每次都要更新，重复传递fds（解决方法：创建内核空间存放fds）\n    2、每次内核被调用后，内核需要遍历一遍所有的fds耗时耗资源（）</code></pre><h4 id=\"4-2、epoll：\"><a href=\"#4-2、epoll：\" class=\"headerlink\" title=\"4.2、epoll：\"></a>4.2、epoll：</h4><p>解决前两个的问题</p>\n<pre><code>1、创建内核空间存放fds，每次内核调用后，将满足条件的fd存入链表，epoll_wait时再将链表返回。\n为什么不需要遍历所有fds???\na. 网卡中段时，将数据存入至fd的buffer缓冲区内，再由”延伸“将对应的fd由内核空间的fd红黑树对应的fd拷贝至链表内。      </code></pre><h4 id=\"4-3、代码\"><a href=\"#4-3、代码\" class=\"headerlink\" title=\"4.3、代码\"></a>4.3、代码</h4><pre><code>public static void main(String[] args) {\n    try (ServerSocketChannel serverSocketChannel = ServerSocketChannel.open()) {\n        //创建serverSocket\n        serverSocketChannel.bind(new InetSocketAddress(9090));\n        //创建多路复用器\n        Selector selector = Selector.open();\n        //将服务端注册进多路复用器内\n        SelectionKey selectionKey = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n        //返回多路复用器的keys\n        Set&lt;SelectionKey&gt; selectionKeySet = selector.keys();\n        //准备好了io的key数量\n        int readyIOKeyCount = selector.select(500);\n        if (readyIOKeyCount &gt; 0) {\n            //代表有准备好的fd，此时需要获取出key并进行数据的读取\n            Set&lt;SelectionKey&gt; readyKeySet = selector.selectedKeys();\n            //遍历，进行数据的处理\n            Iterator&lt;SelectionKey&gt; iterator = readyKeySet.iterator();\n            while (iterator.hasNext()) {\n                SelectionKey key = iterator.next();\n                iterator.remove();\n                if (key.isAcceptable()) {\n                    //代表是客户端连接类型的fd\n                    ServerSocketChannel ssc = (ServerSocketChannel)key.channel();\n                    SocketChannel client = ssc.accept();\n                    //客户端设置为非阻塞\n                    client.configureBlocking(false);\n                    ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n                    //将客户端注册进多路复用器内\n                    client.register(selector, SelectionKey.OP_ACCEPT);\n                } else if (key.isReadable()) {\n                    //代表是可以数据读取的类型\n                    SocketChannel client = (SocketChannel)key.channel();\n                    ByteBuffer byteBuffer = (ByteBuffer)key.attachment();\n                    byteBuffer.clear();\n                    while (true) {\n                        client.read(byteBuffer);\n                    }\n                }\n            }\n        }\n    } catch (Exception e) {\n    }\n}</code></pre><p>Channel，对应操作系统是一个fd（支持双向读写），然后将该fd注册进Selector内。Selector 会不断地轮询注册在其上的 Channel，如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I/O 操作</p>\n<p><strong><em>java代码：selector.select</em></strong></p>\n<pre><code>epoll在register时就调用了epoll_ctl注册进内核空间了，所以selector.select时是不用Java再传\npoll在register时只是将fd注册进JVM内，selector.select时会将JVM中记录的fd数组传给内核</code></pre><h1 id=\"五、文件IO\"><a href=\"#五、文件IO\" class=\"headerlink\" title=\"五、文件IO\"></a>五、文件IO</h1><p><strong><em>标准IO：</em></strong></p>\n<pre><code>File file = new File(path);\nFileOutputStream out = new FileOutputStream(file);\nwhile(true){\n    Thread.sleep(10);\n    out.write(data);\n}</code></pre><blockquote>\n<p>注：每次write，会进行系统调用，此时写入的数据为data</p>\n</blockquote>\n<p><strong><em>字符IO</em></strong></p>\n<pre><code>File file = new File(path);\nBufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(file));\nwhile(true){\n    Thread.sleep(10);\n    out.write(data);\n}</code></pre><blockquote>\n<p>注：此时有字符缓冲区，当缓冲区满时，才会系统调用，因为系统调用减少了，进程空间的切换减少了，所以速度得到了提升。<br>其他：数据写入，也只是将数据写入到了内核的pagecache内，pagecache写入磁盘的方式（主动、定时写入）    </p>\n</blockquote>\n<p><strong><em>NIO方式</em></strong></p>\n<pre><code>RandomAccessFile raf = new RandomAccessFile(path, &quot;rw&quot;);\nraf.write(&quot;hello mashibing\\n&quot;.getBytes());\nraf.write(&quot;hello seanzhou\\n&quot;.getBytes());\nraf.seek(4);\nraf.write(&quot;ooxx&quot;.getBytes());\nFileChannel rafchannel = raf.getChannel();\n//mmap  堆外  和文件映射的   byte  not  objtect\nMappedByteBuffer map = rafchannel.map(FileChannel.MapMode.READ_WRITE, 0, 4096);\n\n对应的系统调用\nopen(&quot;/Users/chw/xxoo.txt\\0&quot;, 0x202, 0x1B6)：打开文件\nsocketpair(0x1, 0x1, 0x0)：创建一对无名的、相互连接的套接子\n\nbuffer\ncapacity：缓存容量大小\nposition：当前位置。\nlimit：\nmark：\nchannel\nfileChannel.seek：支持多个进程对一个文件描述符进行操作，通过seek进行段位控制\nMappedByteBuffer mapBuffer = filechannel.map： 只有文件channel才有map，建立内存映射，实际系统调用为mmap，建立一个堆外内存。此时若向mapBuffer.put()数据，数据会放入到内核的pagecache内（put操作不会产生系统调用）    </code></pre><p>More info:<a href=\"https://jeff.wtf/2017/02/IO-multiplexing/\" target=\"_blank\" rel=\"noopener\">I/O 多路复用入门</a><br><a href=\"https://juejin.im/entry/599f971af265da247d728531\" target=\"_blank\" rel=\"noopener\">一步步构建I/O多路复用的请求模型</a><br><a href=\"https://tech.meituan.com/2016/11/04/nio.html\" target=\"_blank\" rel=\"noopener\">Java NIO浅析</a>            </p>"},{"title":"socket创建过程","date":"2019-06-16T13:38:37.000Z","_content":"\n# 一、socket创建过程\n## 1、建立socket, sock的关系\n创建完sock变量之后，便是初始化sock结构体，并建立sock与socket之间的引用关系；调\n用链如下：\n    \n    net/Socket.c:sys_socket()\n        ->sock_create()\n        ->__sock_create()\n        ->net /ipv4/Af_inet.c:inet_create()\n        ->net/core/Sock.c:sock_init_data()：\n该函数主要工作是：\n\n    a. 初始化sock结构的缓冲区、队列等；\n    b. 初始化sock结构的状态为TCP_CLOSE；\n    c. 建立socket与sock结构的相互引用关系；\n    \n<!--more-->        \n\n## 2、使用tcp协议初始化sock：\ninet_create()函数最后，通过相应的协议来初始化sock结构：这里调用的是tcp_prot的init钩子函数net/ipv4/Tcp_ipv4.c:tcp_v4_init_sock()，它主要是对tcp_sock和inet_connection_sock进行一些初始化；\n\n## 3、socket与文件系统关联：\n创建好与socket相关的结构后，需要与文件系统关联，详见sock_map_fd()函数：\n    \n    1) 申请文件描述符，并分配file结构和目录项结构；\n    2) 关联socket相关的文件操作函数表和目录项操作函数表；\n    3) 将file->private_date指向socket；\n> fd代表这文件系统\n\nsocket与文件系统关联后，以后便可以通过文件系统read/write对socket进行操作了；\n\n## 4、服务端socket启动过程：90端口\n\n    a. 内核创建socket（socket有接收队列+发送队列）\n    b. 然后会申请创建一个对应的TCP类型的fd，此fd处于监听状态\n    c. 最后建立socket与文件系统的关联\n    -------------------------------------------------\n    1、netstat -natp\n        此时会创建90端口TCP进程，处于listen状态，内核分配资源：fd+接收队列+发送队列。\n    2、lsof -p pid\n        该进程对应的fd，也处于listen状态\n    3、其他\n        该listen进程会一直存在，用于接受其他连接\n\n\n## 5、客户端连接\n\n    客户端创建socket，与服务端创建过程一致。（创建socket和fd）\n    1、此时服务端未accept()\n        a. 三次握手后，服务端会创建一个新的socket（socket有缓存队列用于接收消息）\n        b. 未accept()，此时不会创建fd与该socket建立关联。\n        c. 若要读取缓存队列中的消息，需要创建新进程(fd)，与该socket建立映射\n    \n        1、netstat -natp\n            经过三次握手后，服务端会新创建一个socket，但是未分配给进程使用；\n        2、客户端发送消息\n            此时服务端的socket对应的rec-q接收队列会受到客户端发送的内容。\n        ----此时服务端创建的socket未指定到具体的fd.\n    2、服务端accept\n        创建fd，此时socket会指定到这个fd\n    \n    每个进程的进程控制块task_struct中都有一个files_struct结构体，它保存了进程所有打开的文件，以文件描述符fd为索引即可找到对应的file对象，file对象中也包含了文件当前位置的信息\n\n> serverSocket会创建一个监听的socket，监听客户端的连接。会为每一个client再创建一个socket，该socket用于和客户端进行数据通信。（如果不做处理，这些socket对应的fd会放入同一个selector）\n基于一个selector，如果一个线程去遍历该selector会遇到性能问题，所以netty的主从多线程模式，会将为client创建的socket添加到另外一个新的selector，再起新线程去处理改selector，\n从而解决netty单reactor中遇到洪峰连接的性能问题。（即selector内的socket不仅仅有连接请求，还有数据读写等请求）\n\n\n# 二、其他\n\n    socket都需要fd去接收\n    socket：是一个四元组（客户端IP   客户端port     服务端IP     服务端port），内核级，\n    四元组唯一确定一个连接\n\n\n# 三、SocketChannel创建过程\n## 3.1、SocketChannel和Socket的区别\nSocketChannel是对传统Java Socket API的改进，主要是支持了非阻塞的读写。同时改进了传统的单向流API, Channel同时支持读写(其实就是加了个中间层Buffer)。\n\n### 1、socketChannel原理\n```\n// sun.nio.ch.SelectorProvider\npublic SocketChannel openSocketChannel() throws IOException {\n    // 调用SocketChannelImpl的构造器\n    return new SocketChannelImpl(this);\n}\n// sun.nio.ch.SocketChannelImpl\nSocketChannelImpl(SelectorProvider sp) throws IOException {\n    super(sp);\n    // 创建socket fd\n    this.fd = Net.socket(true);\n    // 获取socket fd的值\n    this.fdVal = IOUtil.fdVal(fd);\n    // 初始化SocketChannel状态, 状态不多，总共就6个\n    // 未初始化，未连接，正在连接，已连接，断开连接中，已断开\n    this.state = ST_UNCONNECTED;\n}\n// sun.nio.ch.Net\nstatic FileDescriptor socket(ProtocolFamily family, boolean stream)\n    throws IOException {\n    boolean preferIPv6 = isIPv6Available() &&\n        (family != StandardProtocolFamily.INET);\n    // 最后调用的是socket0\n    return IOUtil.newFD(socket0(preferIPv6, stream, false));\n}\n// Due to oddities SO_REUSEADDR on windows reuse is ignored\nprivate static native int socket0(boolean preferIPv6, boolean stream, boolean reuse);\n```\n\n底层还是socket函数\n\n### 2、如何支持非阻塞\n正常在c里我们实现非阻塞是靠fcntl这个函数，这个函数全称就是file control   \n通过它可以管理fd的各种属性，比如设置fd的阻塞与否。\n\n**fcntl的函数签名为:**\n```\n#include <fcntl.h>\nint fcntl(int fildes, int cmd, ...);\n\n```\n\n第一个参数是传入的fd, 第二个参数是操作类型，后面是flag\n要设置非阻塞，操作类型是F_SETFL和F_GETFL,flag是O_NONBLOCK\n\n那么JVM是怎么做的呢，在SocketChannel上有一个configureBlocking函数，这个函数是设置当前SocketChannel是否是阻塞的，和selector一起用的时候一定要设置成非阻塞才有意义, 阻塞的话就不需要IO多路复用的事件通知了。\n\n\n\n","source":"_posts/2019-06-16-socket创建过程.md","raw":"---\ntitle: socket创建过程\ndate: 2019-06-16 21:38:37\ntags: tcp socket\n---\n\n# 一、socket创建过程\n## 1、建立socket, sock的关系\n创建完sock变量之后，便是初始化sock结构体，并建立sock与socket之间的引用关系；调\n用链如下：\n    \n    net/Socket.c:sys_socket()\n        ->sock_create()\n        ->__sock_create()\n        ->net /ipv4/Af_inet.c:inet_create()\n        ->net/core/Sock.c:sock_init_data()：\n该函数主要工作是：\n\n    a. 初始化sock结构的缓冲区、队列等；\n    b. 初始化sock结构的状态为TCP_CLOSE；\n    c. 建立socket与sock结构的相互引用关系；\n    \n<!--more-->        \n\n## 2、使用tcp协议初始化sock：\ninet_create()函数最后，通过相应的协议来初始化sock结构：这里调用的是tcp_prot的init钩子函数net/ipv4/Tcp_ipv4.c:tcp_v4_init_sock()，它主要是对tcp_sock和inet_connection_sock进行一些初始化；\n\n## 3、socket与文件系统关联：\n创建好与socket相关的结构后，需要与文件系统关联，详见sock_map_fd()函数：\n    \n    1) 申请文件描述符，并分配file结构和目录项结构；\n    2) 关联socket相关的文件操作函数表和目录项操作函数表；\n    3) 将file->private_date指向socket；\n> fd代表这文件系统\n\nsocket与文件系统关联后，以后便可以通过文件系统read/write对socket进行操作了；\n\n## 4、服务端socket启动过程：90端口\n\n    a. 内核创建socket（socket有接收队列+发送队列）\n    b. 然后会申请创建一个对应的TCP类型的fd，此fd处于监听状态\n    c. 最后建立socket与文件系统的关联\n    -------------------------------------------------\n    1、netstat -natp\n        此时会创建90端口TCP进程，处于listen状态，内核分配资源：fd+接收队列+发送队列。\n    2、lsof -p pid\n        该进程对应的fd，也处于listen状态\n    3、其他\n        该listen进程会一直存在，用于接受其他连接\n\n\n## 5、客户端连接\n\n    客户端创建socket，与服务端创建过程一致。（创建socket和fd）\n    1、此时服务端未accept()\n        a. 三次握手后，服务端会创建一个新的socket（socket有缓存队列用于接收消息）\n        b. 未accept()，此时不会创建fd与该socket建立关联。\n        c. 若要读取缓存队列中的消息，需要创建新进程(fd)，与该socket建立映射\n    \n        1、netstat -natp\n            经过三次握手后，服务端会新创建一个socket，但是未分配给进程使用；\n        2、客户端发送消息\n            此时服务端的socket对应的rec-q接收队列会受到客户端发送的内容。\n        ----此时服务端创建的socket未指定到具体的fd.\n    2、服务端accept\n        创建fd，此时socket会指定到这个fd\n    \n    每个进程的进程控制块task_struct中都有一个files_struct结构体，它保存了进程所有打开的文件，以文件描述符fd为索引即可找到对应的file对象，file对象中也包含了文件当前位置的信息\n\n> serverSocket会创建一个监听的socket，监听客户端的连接。会为每一个client再创建一个socket，该socket用于和客户端进行数据通信。（如果不做处理，这些socket对应的fd会放入同一个selector）\n基于一个selector，如果一个线程去遍历该selector会遇到性能问题，所以netty的主从多线程模式，会将为client创建的socket添加到另外一个新的selector，再起新线程去处理改selector，\n从而解决netty单reactor中遇到洪峰连接的性能问题。（即selector内的socket不仅仅有连接请求，还有数据读写等请求）\n\n\n# 二、其他\n\n    socket都需要fd去接收\n    socket：是一个四元组（客户端IP   客户端port     服务端IP     服务端port），内核级，\n    四元组唯一确定一个连接\n\n\n# 三、SocketChannel创建过程\n## 3.1、SocketChannel和Socket的区别\nSocketChannel是对传统Java Socket API的改进，主要是支持了非阻塞的读写。同时改进了传统的单向流API, Channel同时支持读写(其实就是加了个中间层Buffer)。\n\n### 1、socketChannel原理\n```\n// sun.nio.ch.SelectorProvider\npublic SocketChannel openSocketChannel() throws IOException {\n    // 调用SocketChannelImpl的构造器\n    return new SocketChannelImpl(this);\n}\n// sun.nio.ch.SocketChannelImpl\nSocketChannelImpl(SelectorProvider sp) throws IOException {\n    super(sp);\n    // 创建socket fd\n    this.fd = Net.socket(true);\n    // 获取socket fd的值\n    this.fdVal = IOUtil.fdVal(fd);\n    // 初始化SocketChannel状态, 状态不多，总共就6个\n    // 未初始化，未连接，正在连接，已连接，断开连接中，已断开\n    this.state = ST_UNCONNECTED;\n}\n// sun.nio.ch.Net\nstatic FileDescriptor socket(ProtocolFamily family, boolean stream)\n    throws IOException {\n    boolean preferIPv6 = isIPv6Available() &&\n        (family != StandardProtocolFamily.INET);\n    // 最后调用的是socket0\n    return IOUtil.newFD(socket0(preferIPv6, stream, false));\n}\n// Due to oddities SO_REUSEADDR on windows reuse is ignored\nprivate static native int socket0(boolean preferIPv6, boolean stream, boolean reuse);\n```\n\n底层还是socket函数\n\n### 2、如何支持非阻塞\n正常在c里我们实现非阻塞是靠fcntl这个函数，这个函数全称就是file control   \n通过它可以管理fd的各种属性，比如设置fd的阻塞与否。\n\n**fcntl的函数签名为:**\n```\n#include <fcntl.h>\nint fcntl(int fildes, int cmd, ...);\n\n```\n\n第一个参数是传入的fd, 第二个参数是操作类型，后面是flag\n要设置非阻塞，操作类型是F_SETFL和F_GETFL,flag是O_NONBLOCK\n\n那么JVM是怎么做的呢，在SocketChannel上有一个configureBlocking函数，这个函数是设置当前SocketChannel是否是阻塞的，和selector一起用的时候一定要设置成非阻塞才有意义, 阻塞的话就不需要IO多路复用的事件通知了。\n\n\n\n","slug":"2019-06-16-socket创建过程","published":1,"updated":"2024-10-14T09:38:11.901Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnuo000ma13khtg8z0e1","content":"<h1 id=\"一、socket创建过程\"><a href=\"#一、socket创建过程\" class=\"headerlink\" title=\"一、socket创建过程\"></a>一、socket创建过程</h1><h2 id=\"1、建立socket-sock的关系\"><a href=\"#1、建立socket-sock的关系\" class=\"headerlink\" title=\"1、建立socket, sock的关系\"></a>1、建立socket, sock的关系</h2><p>创建完sock变量之后，便是初始化sock结构体，并建立sock与socket之间的引用关系；调<br>用链如下：</p>\n<pre><code>net/Socket.c:sys_socket()\n    -&gt;sock_create()\n    -&gt;__sock_create()\n    -&gt;net /ipv4/Af_inet.c:inet_create()\n    -&gt;net/core/Sock.c:sock_init_data()：</code></pre><p>该函数主要工作是：</p>\n<pre><code>a. 初始化sock结构的缓冲区、队列等；\nb. 初始化sock结构的状态为TCP_CLOSE；\nc. 建立socket与sock结构的相互引用关系；</code></pre><a id=\"more\"></a>        \n\n<h2 id=\"2、使用tcp协议初始化sock：\"><a href=\"#2、使用tcp协议初始化sock：\" class=\"headerlink\" title=\"2、使用tcp协议初始化sock：\"></a>2、使用tcp协议初始化sock：</h2><p>inet_create()函数最后，通过相应的协议来初始化sock结构：这里调用的是tcp_prot的init钩子函数net/ipv4/Tcp_ipv4.c:tcp_v4_init_sock()，它主要是对tcp_sock和inet_connection_sock进行一些初始化；</p>\n<h2 id=\"3、socket与文件系统关联：\"><a href=\"#3、socket与文件系统关联：\" class=\"headerlink\" title=\"3、socket与文件系统关联：\"></a>3、socket与文件系统关联：</h2><p>创建好与socket相关的结构后，需要与文件系统关联，详见sock_map_fd()函数：</p>\n<pre><code>1) 申请文件描述符，并分配file结构和目录项结构；\n2) 关联socket相关的文件操作函数表和目录项操作函数表；\n3) 将file-&gt;private_date指向socket；</code></pre><blockquote>\n<p>fd代表这文件系统</p>\n</blockquote>\n<p>socket与文件系统关联后，以后便可以通过文件系统read/write对socket进行操作了；</p>\n<h2 id=\"4、服务端socket启动过程：90端口\"><a href=\"#4、服务端socket启动过程：90端口\" class=\"headerlink\" title=\"4、服务端socket启动过程：90端口\"></a>4、服务端socket启动过程：90端口</h2><pre><code>a. 内核创建socket（socket有接收队列+发送队列）\nb. 然后会申请创建一个对应的TCP类型的fd，此fd处于监听状态\nc. 最后建立socket与文件系统的关联\n-------------------------------------------------\n1、netstat -natp\n    此时会创建90端口TCP进程，处于listen状态，内核分配资源：fd+接收队列+发送队列。\n2、lsof -p pid\n    该进程对应的fd，也处于listen状态\n3、其他\n    该listen进程会一直存在，用于接受其他连接</code></pre><h2 id=\"5、客户端连接\"><a href=\"#5、客户端连接\" class=\"headerlink\" title=\"5、客户端连接\"></a>5、客户端连接</h2><pre><code>客户端创建socket，与服务端创建过程一致。（创建socket和fd）\n1、此时服务端未accept()\n    a. 三次握手后，服务端会创建一个新的socket（socket有缓存队列用于接收消息）\n    b. 未accept()，此时不会创建fd与该socket建立关联。\n    c. 若要读取缓存队列中的消息，需要创建新进程(fd)，与该socket建立映射\n\n    1、netstat -natp\n        经过三次握手后，服务端会新创建一个socket，但是未分配给进程使用；\n    2、客户端发送消息\n        此时服务端的socket对应的rec-q接收队列会受到客户端发送的内容。\n    ----此时服务端创建的socket未指定到具体的fd.\n2、服务端accept\n    创建fd，此时socket会指定到这个fd\n\n每个进程的进程控制块task_struct中都有一个files_struct结构体，它保存了进程所有打开的文件，以文件描述符fd为索引即可找到对应的file对象，file对象中也包含了文件当前位置的信息</code></pre><blockquote>\n<p>serverSocket会创建一个监听的socket，监听客户端的连接。会为每一个client再创建一个socket，该socket用于和客户端进行数据通信。（如果不做处理，这些socket对应的fd会放入同一个selector）<br>基于一个selector，如果一个线程去遍历该selector会遇到性能问题，所以netty的主从多线程模式，会将为client创建的socket添加到另外一个新的selector，再起新线程去处理改selector，<br>从而解决netty单reactor中遇到洪峰连接的性能问题。（即selector内的socket不仅仅有连接请求，还有数据读写等请求）</p>\n</blockquote>\n<h1 id=\"二、其他\"><a href=\"#二、其他\" class=\"headerlink\" title=\"二、其他\"></a>二、其他</h1><pre><code>socket都需要fd去接收\nsocket：是一个四元组（客户端IP   客户端port     服务端IP     服务端port），内核级，\n四元组唯一确定一个连接</code></pre><h1 id=\"三、SocketChannel创建过程\"><a href=\"#三、SocketChannel创建过程\" class=\"headerlink\" title=\"三、SocketChannel创建过程\"></a>三、SocketChannel创建过程</h1><h2 id=\"3-1、SocketChannel和Socket的区别\"><a href=\"#3-1、SocketChannel和Socket的区别\" class=\"headerlink\" title=\"3.1、SocketChannel和Socket的区别\"></a>3.1、SocketChannel和Socket的区别</h2><p>SocketChannel是对传统Java Socket API的改进，主要是支持了非阻塞的读写。同时改进了传统的单向流API, Channel同时支持读写(其实就是加了个中间层Buffer)。</p>\n<h3 id=\"1、socketChannel原理\"><a href=\"#1、socketChannel原理\" class=\"headerlink\" title=\"1、socketChannel原理\"></a>1、socketChannel原理</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// sun.nio.ch.SelectorProvider</span><br><span class=\"line\">public SocketChannel openSocketChannel() throws IOException &#123;</span><br><span class=\"line\">    // 调用SocketChannelImpl的构造器</span><br><span class=\"line\">    return new SocketChannelImpl(this);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// sun.nio.ch.SocketChannelImpl</span><br><span class=\"line\">SocketChannelImpl(SelectorProvider sp) throws IOException &#123;</span><br><span class=\"line\">    super(sp);</span><br><span class=\"line\">    // 创建socket fd</span><br><span class=\"line\">    this.fd = Net.socket(true);</span><br><span class=\"line\">    // 获取socket fd的值</span><br><span class=\"line\">    this.fdVal = IOUtil.fdVal(fd);</span><br><span class=\"line\">    // 初始化SocketChannel状态, 状态不多，总共就6个</span><br><span class=\"line\">    // 未初始化，未连接，正在连接，已连接，断开连接中，已断开</span><br><span class=\"line\">    this.state = ST_UNCONNECTED;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// sun.nio.ch.Net</span><br><span class=\"line\">static FileDescriptor socket(ProtocolFamily family, boolean stream)</span><br><span class=\"line\">    throws IOException &#123;</span><br><span class=\"line\">    boolean preferIPv6 = isIPv6Available() &amp;&amp;</span><br><span class=\"line\">        (family != StandardProtocolFamily.INET);</span><br><span class=\"line\">    // 最后调用的是socket0</span><br><span class=\"line\">    return IOUtil.newFD(socket0(preferIPv6, stream, false));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// Due to oddities SO_REUSEADDR on windows reuse is ignored</span><br><span class=\"line\">private static native int socket0(boolean preferIPv6, boolean stream, boolean reuse);</span><br></pre></td></tr></table></figure>\n\n<p>底层还是socket函数</p>\n<h3 id=\"2、如何支持非阻塞\"><a href=\"#2、如何支持非阻塞\" class=\"headerlink\" title=\"2、如何支持非阻塞\"></a>2、如何支持非阻塞</h3><p>正常在c里我们实现非阻塞是靠fcntl这个函数，这个函数全称就是file control<br>通过它可以管理fd的各种属性，比如设置fd的阻塞与否。</p>\n<p><strong>fcntl的函数签名为:</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;fcntl.h&gt;</span><br><span class=\"line\">int fcntl(int fildes, int cmd, ...);</span><br></pre></td></tr></table></figure>\n\n<p>第一个参数是传入的fd, 第二个参数是操作类型，后面是flag<br>要设置非阻塞，操作类型是F_SETFL和F_GETFL,flag是O_NONBLOCK</p>\n<p>那么JVM是怎么做的呢，在SocketChannel上有一个configureBlocking函数，这个函数是设置当前SocketChannel是否是阻塞的，和selector一起用的时候一定要设置成非阻塞才有意义, 阻塞的话就不需要IO多路复用的事件通知了。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、socket创建过程\"><a href=\"#一、socket创建过程\" class=\"headerlink\" title=\"一、socket创建过程\"></a>一、socket创建过程</h1><h2 id=\"1、建立socket-sock的关系\"><a href=\"#1、建立socket-sock的关系\" class=\"headerlink\" title=\"1、建立socket, sock的关系\"></a>1、建立socket, sock的关系</h2><p>创建完sock变量之后，便是初始化sock结构体，并建立sock与socket之间的引用关系；调<br>用链如下：</p>\n<pre><code>net/Socket.c:sys_socket()\n    -&gt;sock_create()\n    -&gt;__sock_create()\n    -&gt;net /ipv4/Af_inet.c:inet_create()\n    -&gt;net/core/Sock.c:sock_init_data()：</code></pre><p>该函数主要工作是：</p>\n<pre><code>a. 初始化sock结构的缓冲区、队列等；\nb. 初始化sock结构的状态为TCP_CLOSE；\nc. 建立socket与sock结构的相互引用关系；</code></pre>","more":"<h2 id=\"2、使用tcp协议初始化sock：\"><a href=\"#2、使用tcp协议初始化sock：\" class=\"headerlink\" title=\"2、使用tcp协议初始化sock：\"></a>2、使用tcp协议初始化sock：</h2><p>inet_create()函数最后，通过相应的协议来初始化sock结构：这里调用的是tcp_prot的init钩子函数net/ipv4/Tcp_ipv4.c:tcp_v4_init_sock()，它主要是对tcp_sock和inet_connection_sock进行一些初始化；</p>\n<h2 id=\"3、socket与文件系统关联：\"><a href=\"#3、socket与文件系统关联：\" class=\"headerlink\" title=\"3、socket与文件系统关联：\"></a>3、socket与文件系统关联：</h2><p>创建好与socket相关的结构后，需要与文件系统关联，详见sock_map_fd()函数：</p>\n<pre><code>1) 申请文件描述符，并分配file结构和目录项结构；\n2) 关联socket相关的文件操作函数表和目录项操作函数表；\n3) 将file-&gt;private_date指向socket；</code></pre><blockquote>\n<p>fd代表这文件系统</p>\n</blockquote>\n<p>socket与文件系统关联后，以后便可以通过文件系统read/write对socket进行操作了；</p>\n<h2 id=\"4、服务端socket启动过程：90端口\"><a href=\"#4、服务端socket启动过程：90端口\" class=\"headerlink\" title=\"4、服务端socket启动过程：90端口\"></a>4、服务端socket启动过程：90端口</h2><pre><code>a. 内核创建socket（socket有接收队列+发送队列）\nb. 然后会申请创建一个对应的TCP类型的fd，此fd处于监听状态\nc. 最后建立socket与文件系统的关联\n-------------------------------------------------\n1、netstat -natp\n    此时会创建90端口TCP进程，处于listen状态，内核分配资源：fd+接收队列+发送队列。\n2、lsof -p pid\n    该进程对应的fd，也处于listen状态\n3、其他\n    该listen进程会一直存在，用于接受其他连接</code></pre><h2 id=\"5、客户端连接\"><a href=\"#5、客户端连接\" class=\"headerlink\" title=\"5、客户端连接\"></a>5、客户端连接</h2><pre><code>客户端创建socket，与服务端创建过程一致。（创建socket和fd）\n1、此时服务端未accept()\n    a. 三次握手后，服务端会创建一个新的socket（socket有缓存队列用于接收消息）\n    b. 未accept()，此时不会创建fd与该socket建立关联。\n    c. 若要读取缓存队列中的消息，需要创建新进程(fd)，与该socket建立映射\n\n    1、netstat -natp\n        经过三次握手后，服务端会新创建一个socket，但是未分配给进程使用；\n    2、客户端发送消息\n        此时服务端的socket对应的rec-q接收队列会受到客户端发送的内容。\n    ----此时服务端创建的socket未指定到具体的fd.\n2、服务端accept\n    创建fd，此时socket会指定到这个fd\n\n每个进程的进程控制块task_struct中都有一个files_struct结构体，它保存了进程所有打开的文件，以文件描述符fd为索引即可找到对应的file对象，file对象中也包含了文件当前位置的信息</code></pre><blockquote>\n<p>serverSocket会创建一个监听的socket，监听客户端的连接。会为每一个client再创建一个socket，该socket用于和客户端进行数据通信。（如果不做处理，这些socket对应的fd会放入同一个selector）<br>基于一个selector，如果一个线程去遍历该selector会遇到性能问题，所以netty的主从多线程模式，会将为client创建的socket添加到另外一个新的selector，再起新线程去处理改selector，<br>从而解决netty单reactor中遇到洪峰连接的性能问题。（即selector内的socket不仅仅有连接请求，还有数据读写等请求）</p>\n</blockquote>\n<h1 id=\"二、其他\"><a href=\"#二、其他\" class=\"headerlink\" title=\"二、其他\"></a>二、其他</h1><pre><code>socket都需要fd去接收\nsocket：是一个四元组（客户端IP   客户端port     服务端IP     服务端port），内核级，\n四元组唯一确定一个连接</code></pre><h1 id=\"三、SocketChannel创建过程\"><a href=\"#三、SocketChannel创建过程\" class=\"headerlink\" title=\"三、SocketChannel创建过程\"></a>三、SocketChannel创建过程</h1><h2 id=\"3-1、SocketChannel和Socket的区别\"><a href=\"#3-1、SocketChannel和Socket的区别\" class=\"headerlink\" title=\"3.1、SocketChannel和Socket的区别\"></a>3.1、SocketChannel和Socket的区别</h2><p>SocketChannel是对传统Java Socket API的改进，主要是支持了非阻塞的读写。同时改进了传统的单向流API, Channel同时支持读写(其实就是加了个中间层Buffer)。</p>\n<h3 id=\"1、socketChannel原理\"><a href=\"#1、socketChannel原理\" class=\"headerlink\" title=\"1、socketChannel原理\"></a>1、socketChannel原理</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// sun.nio.ch.SelectorProvider</span><br><span class=\"line\">public SocketChannel openSocketChannel() throws IOException &#123;</span><br><span class=\"line\">    // 调用SocketChannelImpl的构造器</span><br><span class=\"line\">    return new SocketChannelImpl(this);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// sun.nio.ch.SocketChannelImpl</span><br><span class=\"line\">SocketChannelImpl(SelectorProvider sp) throws IOException &#123;</span><br><span class=\"line\">    super(sp);</span><br><span class=\"line\">    // 创建socket fd</span><br><span class=\"line\">    this.fd = Net.socket(true);</span><br><span class=\"line\">    // 获取socket fd的值</span><br><span class=\"line\">    this.fdVal = IOUtil.fdVal(fd);</span><br><span class=\"line\">    // 初始化SocketChannel状态, 状态不多，总共就6个</span><br><span class=\"line\">    // 未初始化，未连接，正在连接，已连接，断开连接中，已断开</span><br><span class=\"line\">    this.state = ST_UNCONNECTED;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// sun.nio.ch.Net</span><br><span class=\"line\">static FileDescriptor socket(ProtocolFamily family, boolean stream)</span><br><span class=\"line\">    throws IOException &#123;</span><br><span class=\"line\">    boolean preferIPv6 = isIPv6Available() &amp;&amp;</span><br><span class=\"line\">        (family != StandardProtocolFamily.INET);</span><br><span class=\"line\">    // 最后调用的是socket0</span><br><span class=\"line\">    return IOUtil.newFD(socket0(preferIPv6, stream, false));</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// Due to oddities SO_REUSEADDR on windows reuse is ignored</span><br><span class=\"line\">private static native int socket0(boolean preferIPv6, boolean stream, boolean reuse);</span><br></pre></td></tr></table></figure>\n\n<p>底层还是socket函数</p>\n<h3 id=\"2、如何支持非阻塞\"><a href=\"#2、如何支持非阻塞\" class=\"headerlink\" title=\"2、如何支持非阻塞\"></a>2、如何支持非阻塞</h3><p>正常在c里我们实现非阻塞是靠fcntl这个函数，这个函数全称就是file control<br>通过它可以管理fd的各种属性，比如设置fd的阻塞与否。</p>\n<p><strong>fcntl的函数签名为:</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;fcntl.h&gt;</span><br><span class=\"line\">int fcntl(int fildes, int cmd, ...);</span><br></pre></td></tr></table></figure>\n\n<p>第一个参数是传入的fd, 第二个参数是操作类型，后面是flag<br>要设置非阻塞，操作类型是F_SETFL和F_GETFL,flag是O_NONBLOCK</p>\n<p>那么JVM是怎么做的呢，在SocketChannel上有一个configureBlocking函数，这个函数是设置当前SocketChannel是否是阻塞的，和selector一起用的时候一定要设置成非阻塞才有意义, 阻塞的话就不需要IO多路复用的事件通知了。</p>"},{"title":"netty","date":"2019-06-18T13:43:40.000Z","_content":"\n\n# 一、Reactor反应堆模式\n一个进程轮询接受客户端请求，再将客户端连接分发给另外一个进程，再通过这个反应堆分发给线程池去处理\n\n\n# 二、netty三种模式\n***单reactor单线程：*** 一个线程，需要处理连接、读写，有性能瓶颈  \n***单reactor多线程：*** 一个线程处理连接，将读写分发给其他线程，容易出现一个线程无法处理过多连接的问题。  \n***主从reactor多线程：*** 为了解决一个线程无法处理过多连接的问题，引入了多线程解决该问题。  \n\n> serverSocket会创建一个监听的socket，监听客户端的连接。会为每一个client再创建一个socket，该socket用于和客户端进行数据通信。（如果不做处理，这些socket对应的fd会放入同一个selector）\n基于一个selector，如果一个线程去遍历该selector会遇到性能问题，所以netty的主从多线程模式，会将为client创建的socket添加到另外一个新的selector，再起新线程去处理该selector，\n从而解决netty单reactor中遇到洪峰连接的性能问题。（即selector内的socket不仅仅有连接请求，还有数据读写等请求）\n\n<!--more-->    \n\n# 三、代码解析\n## 3.1、服务端代码\n```\npublic static void main(String[] args){\n    try {\n        //主线程池，用于接收客户端连接\n        NioEventLoopGroup mainGroup = new NioEventLoopGroup(1);\n        //工作线程池，用于分发读写操作\n        NioEventLoopGroup workGroup = new NioEventLoopGroup(5);\n\n        ServerBootstrap serverBootstrap = new ServerBootstrap();\n        //此处只是设置了一系列的启动器参数\n        serverBootstrap\n            //将两个线程池设置到启动器内\n            .group(mainGroup, workGroup)\n            //设置channel类型\n            .channel(NioServerSocketChannel.class)\n            //设置channel，只监听TCPNODELAY事件\n            .option(ChannelOption.TCP_NODELAY, false)\n            //设置处理器（若处理器写多个，实际只有一个有效，以最后一个为准）\n            .handler(new LoggingHandler())\n            //设置子处理器（若处理器写多个，实际只有一个有效，以最后一个为准）\n            .childHandler(new ChannelInitializer<NioSocketChannel>() {\n                @Override\n                protected void initChannel(NioSocketChannel socketChannel) throws Exception {\n                    logger.info(\"新客户端连接进来了-----{}\", socketChannel.remoteAddress().toString());\n                    ChannelPipeline pipeline = socketChannel.pipeline();\n                    pipeline.addLast(new MyHandler());\n                    pipeline.addLast(new LoggingHandler());\n                }\n            });\n        //bind操作，此处才实际绑定端口并创建channel\n        ChannelFuture future = serverBootstrap.bind(1234);\n        future.channel().closeFuture().sync();\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    }\n}\n```\n代码解析：  \n1. new NioEventLoopGroup()：\n```\n    public NioEventLoopGroup(int nThreads, Executor executor) {\n        this(nThreads, executor, SelectorProvider.provider());\n    }\n    1、此构造方法，SelectorProvider.provider()会去创建Selector多路复用器；\n    2、跟踪至父类构造函数MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args)\n        protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) {\n            children = new EventExecutor[nThreads];\n            for (int i = 0; i < nThreads; i ++) {\n                boolean success = false;\n                try {\n                    children[i] = newChild(executor, args);\n                }\n            }\n        }            \n        创建线程池：children = new EventExecutor[nThreads];\n        实例化数组元素：实际作用是创建了Selector池\n            //实际创建NioEventLoop，NioEventLoop内有Selector\n            children[i] = newChild(executor, args);\n    3、newChild(executor, args)方法解析\n        protected EventLoop newChild(Executor executor, Object... args) throws Exception {\n            return new NioEventLoop(this, executor, (SelectorProvider) args[0],\n                ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]);\n        }\n        3.1、实际进入NioEventLoop 的构造函数，然后继续进入SingleThreadEventLoop构造函数\n        3.2、SingleThreadEventLoop 的父类 SingleThreadEventExecutor 的构造函数，这是一个只有一个线程的线程池\n            state：线程池当前的状态；\n            taskQueue：存放任务的队列；\n            thread：线程池维护的唯一线程；\n            scheduledTaskQueue：定义在其父类AbstractScheduledEventExecutor中，用以保存延迟执行的任务。\n```     \n\n2. bind()操作：\n```\n    1. AbstractBootstrap.initAndRegister()，内部会使用channelFactory.newChannel()去创建channel\n    2. \n```\n\n3. NioEventLoop\n```\nNioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider,\n                 SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) {\n    super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler);\n    if (selectorProvider == null) {\n        throw new NullPointerException(\"selectorProvider\");\n    }\n    if (strategy == null) {\n        throw new NullPointerException(\"selectStrategy\");\n    }\n    provider = selectorProvider;\n    //SelectorProvider.provider()会去创建Selector多路复用器；\n    final SelectorTuple selectorTuple = openSelector();//\n    selector = selectorTuple.selector;\n    unwrappedSelector = selectorTuple.unwrappedSelector;\n    selectStrategy = strategy;\n}\n```\n\n一个NioEventLoopGroup，对应对个NioEventLoop（对应一个selector），从而可以将很多的socket设置到不同的selector，分配多个线程对selector进行分别的遍历。\n\n## 3.2、客户端代码\n```\npublic static void main(String[] args) {\n    try {\n        NioEventLoopGroup eventLoopGroup = new NioEventLoopGroup(10);\n        Bootstrap bootstrap = new Bootstrap();\n        bootstrap.group(eventLoopGroup)\n            .channel(NioSocketChannel.class)\n            .option(ChannelOption.TCP_NODELAY, false)\n            .handler(new ChannelInitializer<NioSocketChannel>() {\n                @Override\n                protected void initChannel(NioSocketChannel socketChannel) throws Exception {\n                    ChannelPipeline pipeline = socketChannel.pipeline();\n                    System.out.println(\"aaaa\");\n                    pipeline.addLast(new LoggingHandler());\n                }\n            });\n        ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 1234).sync();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n```\n代码解析：\n```\n1、new NioEventLoopGroup()，同服务端。\n2、bootstrap.connect连接操作\n    -> Bootstrap.initAndRegister()\n        -> //使用工厂类ChannelFactory的newChannel通过反射创建Channel实例\n        -> 2.1、channel = channelFactory.newChannel();\n            -> 3、channelFactory.newChannel()\n            ->  工厂类创建NioSocketChannel\n            ->  构造函数：public NioSocketChannel(SelectorProvider provider) {    \n            ->      //newSocket(provider) 方法会创建 JDK 的 SocketChannel，\n            ->      this(newSocket(provider));// 实现---> provider.openSocketChannel();\n            ->  }\n        -> //进行channel初始化，给channel设置handler、option\n        -> 2.2、init(channel);\n        -> //channel的注册\n        -> 2.3、ChannelFuture regFuture = config().group().register(channel);\n            -> config().group().register(channel)\n                -> AbstractChannel.AbstractUnsafe.register()方法\n                判断 NioEventLoop 的线程是否已经启动，如果已经启动，调用 register0方法；否则调用 eventLoop.execute 方法启动线程\n                    -> //调用JDK去注册Selector\n                    -> doRegister();\n                    -> neverRegistered = false;\n                    -> registered = true;\n                    -> //设置注册成功通知监听器\n                    -> safeSetSuccess(promise);\n                    -> //触发注册成功事件\n                    -> pipeline.fireChannelRegistered();\n\n```       \n\n\n\n","source":"_posts/2019-06-18-netty.md","raw":"---\ntitle: netty\ndate: 2019-06-18  21:43:40\ntags:\n---\n\n\n# 一、Reactor反应堆模式\n一个进程轮询接受客户端请求，再将客户端连接分发给另外一个进程，再通过这个反应堆分发给线程池去处理\n\n\n# 二、netty三种模式\n***单reactor单线程：*** 一个线程，需要处理连接、读写，有性能瓶颈  \n***单reactor多线程：*** 一个线程处理连接，将读写分发给其他线程，容易出现一个线程无法处理过多连接的问题。  \n***主从reactor多线程：*** 为了解决一个线程无法处理过多连接的问题，引入了多线程解决该问题。  \n\n> serverSocket会创建一个监听的socket，监听客户端的连接。会为每一个client再创建一个socket，该socket用于和客户端进行数据通信。（如果不做处理，这些socket对应的fd会放入同一个selector）\n基于一个selector，如果一个线程去遍历该selector会遇到性能问题，所以netty的主从多线程模式，会将为client创建的socket添加到另外一个新的selector，再起新线程去处理该selector，\n从而解决netty单reactor中遇到洪峰连接的性能问题。（即selector内的socket不仅仅有连接请求，还有数据读写等请求）\n\n<!--more-->    \n\n# 三、代码解析\n## 3.1、服务端代码\n```\npublic static void main(String[] args){\n    try {\n        //主线程池，用于接收客户端连接\n        NioEventLoopGroup mainGroup = new NioEventLoopGroup(1);\n        //工作线程池，用于分发读写操作\n        NioEventLoopGroup workGroup = new NioEventLoopGroup(5);\n\n        ServerBootstrap serverBootstrap = new ServerBootstrap();\n        //此处只是设置了一系列的启动器参数\n        serverBootstrap\n            //将两个线程池设置到启动器内\n            .group(mainGroup, workGroup)\n            //设置channel类型\n            .channel(NioServerSocketChannel.class)\n            //设置channel，只监听TCPNODELAY事件\n            .option(ChannelOption.TCP_NODELAY, false)\n            //设置处理器（若处理器写多个，实际只有一个有效，以最后一个为准）\n            .handler(new LoggingHandler())\n            //设置子处理器（若处理器写多个，实际只有一个有效，以最后一个为准）\n            .childHandler(new ChannelInitializer<NioSocketChannel>() {\n                @Override\n                protected void initChannel(NioSocketChannel socketChannel) throws Exception {\n                    logger.info(\"新客户端连接进来了-----{}\", socketChannel.remoteAddress().toString());\n                    ChannelPipeline pipeline = socketChannel.pipeline();\n                    pipeline.addLast(new MyHandler());\n                    pipeline.addLast(new LoggingHandler());\n                }\n            });\n        //bind操作，此处才实际绑定端口并创建channel\n        ChannelFuture future = serverBootstrap.bind(1234);\n        future.channel().closeFuture().sync();\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    }\n}\n```\n代码解析：  \n1. new NioEventLoopGroup()：\n```\n    public NioEventLoopGroup(int nThreads, Executor executor) {\n        this(nThreads, executor, SelectorProvider.provider());\n    }\n    1、此构造方法，SelectorProvider.provider()会去创建Selector多路复用器；\n    2、跟踪至父类构造函数MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args)\n        protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) {\n            children = new EventExecutor[nThreads];\n            for (int i = 0; i < nThreads; i ++) {\n                boolean success = false;\n                try {\n                    children[i] = newChild(executor, args);\n                }\n            }\n        }            \n        创建线程池：children = new EventExecutor[nThreads];\n        实例化数组元素：实际作用是创建了Selector池\n            //实际创建NioEventLoop，NioEventLoop内有Selector\n            children[i] = newChild(executor, args);\n    3、newChild(executor, args)方法解析\n        protected EventLoop newChild(Executor executor, Object... args) throws Exception {\n            return new NioEventLoop(this, executor, (SelectorProvider) args[0],\n                ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]);\n        }\n        3.1、实际进入NioEventLoop 的构造函数，然后继续进入SingleThreadEventLoop构造函数\n        3.2、SingleThreadEventLoop 的父类 SingleThreadEventExecutor 的构造函数，这是一个只有一个线程的线程池\n            state：线程池当前的状态；\n            taskQueue：存放任务的队列；\n            thread：线程池维护的唯一线程；\n            scheduledTaskQueue：定义在其父类AbstractScheduledEventExecutor中，用以保存延迟执行的任务。\n```     \n\n2. bind()操作：\n```\n    1. AbstractBootstrap.initAndRegister()，内部会使用channelFactory.newChannel()去创建channel\n    2. \n```\n\n3. NioEventLoop\n```\nNioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider,\n                 SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) {\n    super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler);\n    if (selectorProvider == null) {\n        throw new NullPointerException(\"selectorProvider\");\n    }\n    if (strategy == null) {\n        throw new NullPointerException(\"selectStrategy\");\n    }\n    provider = selectorProvider;\n    //SelectorProvider.provider()会去创建Selector多路复用器；\n    final SelectorTuple selectorTuple = openSelector();//\n    selector = selectorTuple.selector;\n    unwrappedSelector = selectorTuple.unwrappedSelector;\n    selectStrategy = strategy;\n}\n```\n\n一个NioEventLoopGroup，对应对个NioEventLoop（对应一个selector），从而可以将很多的socket设置到不同的selector，分配多个线程对selector进行分别的遍历。\n\n## 3.2、客户端代码\n```\npublic static void main(String[] args) {\n    try {\n        NioEventLoopGroup eventLoopGroup = new NioEventLoopGroup(10);\n        Bootstrap bootstrap = new Bootstrap();\n        bootstrap.group(eventLoopGroup)\n            .channel(NioSocketChannel.class)\n            .option(ChannelOption.TCP_NODELAY, false)\n            .handler(new ChannelInitializer<NioSocketChannel>() {\n                @Override\n                protected void initChannel(NioSocketChannel socketChannel) throws Exception {\n                    ChannelPipeline pipeline = socketChannel.pipeline();\n                    System.out.println(\"aaaa\");\n                    pipeline.addLast(new LoggingHandler());\n                }\n            });\n        ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 1234).sync();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n```\n代码解析：\n```\n1、new NioEventLoopGroup()，同服务端。\n2、bootstrap.connect连接操作\n    -> Bootstrap.initAndRegister()\n        -> //使用工厂类ChannelFactory的newChannel通过反射创建Channel实例\n        -> 2.1、channel = channelFactory.newChannel();\n            -> 3、channelFactory.newChannel()\n            ->  工厂类创建NioSocketChannel\n            ->  构造函数：public NioSocketChannel(SelectorProvider provider) {    \n            ->      //newSocket(provider) 方法会创建 JDK 的 SocketChannel，\n            ->      this(newSocket(provider));// 实现---> provider.openSocketChannel();\n            ->  }\n        -> //进行channel初始化，给channel设置handler、option\n        -> 2.2、init(channel);\n        -> //channel的注册\n        -> 2.3、ChannelFuture regFuture = config().group().register(channel);\n            -> config().group().register(channel)\n                -> AbstractChannel.AbstractUnsafe.register()方法\n                判断 NioEventLoop 的线程是否已经启动，如果已经启动，调用 register0方法；否则调用 eventLoop.execute 方法启动线程\n                    -> //调用JDK去注册Selector\n                    -> doRegister();\n                    -> neverRegistered = false;\n                    -> registered = true;\n                    -> //设置注册成功通知监听器\n                    -> safeSetSuccess(promise);\n                    -> //触发注册成功事件\n                    -> pipeline.fireChannelRegistered();\n\n```       \n\n\n\n","slug":"2019-06-18-netty","published":1,"updated":"2024-10-14T09:38:11.902Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnuq000pa13kmk1pn87a","content":"<h1 id=\"一、Reactor反应堆模式\"><a href=\"#一、Reactor反应堆模式\" class=\"headerlink\" title=\"一、Reactor反应堆模式\"></a>一、Reactor反应堆模式</h1><p>一个进程轮询接受客户端请求，再将客户端连接分发给另外一个进程，再通过这个反应堆分发给线程池去处理</p>\n<h1 id=\"二、netty三种模式\"><a href=\"#二、netty三种模式\" class=\"headerlink\" title=\"二、netty三种模式\"></a>二、netty三种模式</h1><p><strong><em>单reactor单线程：</em></strong> 一个线程，需要处理连接、读写，有性能瓶颈<br><strong><em>单reactor多线程：</em></strong> 一个线程处理连接，将读写分发给其他线程，容易出现一个线程无法处理过多连接的问题。<br><strong><em>主从reactor多线程：</em></strong> 为了解决一个线程无法处理过多连接的问题，引入了多线程解决该问题。  </p>\n<blockquote>\n<p>serverSocket会创建一个监听的socket，监听客户端的连接。会为每一个client再创建一个socket，该socket用于和客户端进行数据通信。（如果不做处理，这些socket对应的fd会放入同一个selector）<br>基于一个selector，如果一个线程去遍历该selector会遇到性能问题，所以netty的主从多线程模式，会将为client创建的socket添加到另外一个新的selector，再起新线程去处理该selector，<br>从而解决netty单reactor中遇到洪峰连接的性能问题。（即selector内的socket不仅仅有连接请求，还有数据读写等请求）</p>\n</blockquote>\n<a id=\"more\"></a>    \n\n<h1 id=\"三、代码解析\"><a href=\"#三、代码解析\" class=\"headerlink\" title=\"三、代码解析\"></a>三、代码解析</h1><h2 id=\"3-1、服务端代码\"><a href=\"#3-1、服务端代码\" class=\"headerlink\" title=\"3.1、服务端代码\"></a>3.1、服务端代码</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String[] args)&#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        //主线程池，用于接收客户端连接</span><br><span class=\"line\">        NioEventLoopGroup mainGroup = new NioEventLoopGroup(1);</span><br><span class=\"line\">        //工作线程池，用于分发读写操作</span><br><span class=\"line\">        NioEventLoopGroup workGroup = new NioEventLoopGroup(5);</span><br><span class=\"line\"></span><br><span class=\"line\">        ServerBootstrap serverBootstrap = new ServerBootstrap();</span><br><span class=\"line\">        //此处只是设置了一系列的启动器参数</span><br><span class=\"line\">        serverBootstrap</span><br><span class=\"line\">            //将两个线程池设置到启动器内</span><br><span class=\"line\">            .group(mainGroup, workGroup)</span><br><span class=\"line\">            //设置channel类型</span><br><span class=\"line\">            .channel(NioServerSocketChannel.class)</span><br><span class=\"line\">            //设置channel，只监听TCPNODELAY事件</span><br><span class=\"line\">            .option(ChannelOption.TCP_NODELAY, false)</span><br><span class=\"line\">            //设置处理器（若处理器写多个，实际只有一个有效，以最后一个为准）</span><br><span class=\"line\">            .handler(new LoggingHandler())</span><br><span class=\"line\">            //设置子处理器（若处理器写多个，实际只有一个有效，以最后一个为准）</span><br><span class=\"line\">            .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class=\"line\">                @Override</span><br><span class=\"line\">                protected void initChannel(NioSocketChannel socketChannel) throws Exception &#123;</span><br><span class=\"line\">                    logger.info(&quot;新客户端连接进来了-----&#123;&#125;&quot;, socketChannel.remoteAddress().toString());</span><br><span class=\"line\">                    ChannelPipeline pipeline = socketChannel.pipeline();</span><br><span class=\"line\">                    pipeline.addLast(new MyHandler());</span><br><span class=\"line\">                    pipeline.addLast(new LoggingHandler());</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        //bind操作，此处才实际绑定端口并创建channel</span><br><span class=\"line\">        ChannelFuture future = serverBootstrap.bind(1234);</span><br><span class=\"line\">        future.channel().closeFuture().sync();</span><br><span class=\"line\">    &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>代码解析：  </p>\n<ol>\n<li><p>new NioEventLoopGroup()：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    public NioEventLoopGroup(int nThreads, Executor executor) &#123;</span><br><span class=\"line\">        this(nThreads, executor, SelectorProvider.provider());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    1、此构造方法，SelectorProvider.provider()会去创建Selector多路复用器；</span><br><span class=\"line\">    2、跟踪至父类构造函数MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args)</span><br><span class=\"line\">        protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123;</span><br><span class=\"line\">            children = new EventExecutor[nThreads];</span><br><span class=\"line\">            for (int i = 0; i &lt; nThreads; i ++) &#123;</span><br><span class=\"line\">                boolean success = false;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    children[i] = newChild(executor, args);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;            </span><br><span class=\"line\">        创建线程池：children = new EventExecutor[nThreads];</span><br><span class=\"line\">        实例化数组元素：实际作用是创建了Selector池</span><br><span class=\"line\">            //实际创建NioEventLoop，NioEventLoop内有Selector</span><br><span class=\"line\">            children[i] = newChild(executor, args);</span><br><span class=\"line\">    3、newChild(executor, args)方法解析</span><br><span class=\"line\">        protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123;</span><br><span class=\"line\">            return new NioEventLoop(this, executor, (SelectorProvider) args[0],</span><br><span class=\"line\">                ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        3.1、实际进入NioEventLoop 的构造函数，然后继续进入SingleThreadEventLoop构造函数</span><br><span class=\"line\">        3.2、SingleThreadEventLoop 的父类 SingleThreadEventExecutor 的构造函数，这是一个只有一个线程的线程池</span><br><span class=\"line\">            state：线程池当前的状态；</span><br><span class=\"line\">            taskQueue：存放任务的队列；</span><br><span class=\"line\">            thread：线程池维护的唯一线程；</span><br><span class=\"line\">            scheduledTaskQueue：定义在其父类AbstractScheduledEventExecutor中，用以保存延迟执行的任务。</span><br><span class=\"line\">```     </span><br><span class=\"line\"></span><br><span class=\"line\">2. bind()操作：</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>AbstractBootstrap.initAndRegister()，内部会使用channelFactory.newChannel()去创建channel</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">3. NioEventLoop</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n</li>\n</ol>\n<p>NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider,<br>                 SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) {<br>    super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler);<br>    if (selectorProvider == null) {<br>        throw new NullPointerException(“selectorProvider”);<br>    }<br>    if (strategy == null) {<br>        throw new NullPointerException(“selectStrategy”);<br>    }<br>    provider = selectorProvider;<br>    //SelectorProvider.provider()会去创建Selector多路复用器；<br>    final SelectorTuple selectorTuple = openSelector();//<br>    selector = selectorTuple.selector;<br>    unwrappedSelector = selectorTuple.unwrappedSelector;<br>    selectStrategy = strategy;<br>}</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">一个NioEventLoopGroup，对应对个NioEventLoop（对应一个selector），从而可以将很多的socket设置到不同的selector，分配多个线程对selector进行分别的遍历。</span><br><span class=\"line\"></span><br><span class=\"line\">## 3.2、客户端代码</span><br></pre></td></tr></table></figure>\n\n<p>public static void main(String[] args) {<br>    try {<br>        NioEventLoopGroup eventLoopGroup = new NioEventLoopGroup(10);<br>        Bootstrap bootstrap = new Bootstrap();<br>        bootstrap.group(eventLoopGroup)<br>            .channel(NioSocketChannel.class)<br>            .option(ChannelOption.TCP_NODELAY, false)<br>            .handler(new ChannelInitializer<niosocketchannel>() {<br>                @Override<br>                protected void initChannel(NioSocketChannel socketChannel) throws Exception {<br>                    ChannelPipeline pipeline = socketChannel.pipeline();<br>                    System.out.println(“aaaa”);<br>                    pipeline.addLast(new LoggingHandler());<br>                }<br>            });<br>        ChannelFuture channelFuture = bootstrap.connect(“127.0.0.1”, 1234).sync();<br>    } catch (Exception e) {<br>        e.printStackTrace();<br>    }<br>}</niosocketchannel></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">代码解析：</span><br></pre></td></tr></table></figure>\n\n<p>1、new NioEventLoopGroup()，同服务端。<br>2、bootstrap.connect连接操作<br>    -&gt; Bootstrap.initAndRegister()<br>        -&gt; //使用工厂类ChannelFactory的newChannel通过反射创建Channel实例<br>        -&gt; 2.1、channel = channelFactory.newChannel();<br>            -&gt; 3、channelFactory.newChannel()<br>            -&gt;  工厂类创建NioSocketChannel<br>            -&gt;  构造函数：public NioSocketChannel(SelectorProvider provider) {<br>            -&gt;      //newSocket(provider) 方法会创建 JDK 的 SocketChannel，<br>            -&gt;      this(newSocket(provider));// 实现—&gt; provider.openSocketChannel();<br>            -&gt;  }<br>        -&gt; //进行channel初始化，给channel设置handler、option<br>        -&gt; 2.2、init(channel);<br>        -&gt; //channel的注册<br>        -&gt; 2.3、ChannelFuture regFuture = config().group().register(channel);<br>            -&gt; config().group().register(channel)<br>                -&gt; AbstractChannel.AbstractUnsafe.register()方法<br>                判断 NioEventLoop 的线程是否已经启动，如果已经启动，调用 register0方法；否则调用 eventLoop.execute 方法启动线程<br>                    -&gt; //调用JDK去注册Selector<br>                    -&gt; doRegister();<br>                    -&gt; neverRegistered = false;<br>                    -&gt; registered = true;<br>                    -&gt; //设置注册成功通知监听器<br>                    -&gt; safeSetSuccess(promise);<br>                    -&gt; //触发注册成功事件<br>                    -&gt; pipeline.fireChannelRegistered();</p>\n<pre><code>\n\n</code></pre>","site":{"data":{}},"excerpt":"<h1 id=\"一、Reactor反应堆模式\"><a href=\"#一、Reactor反应堆模式\" class=\"headerlink\" title=\"一、Reactor反应堆模式\"></a>一、Reactor反应堆模式</h1><p>一个进程轮询接受客户端请求，再将客户端连接分发给另外一个进程，再通过这个反应堆分发给线程池去处理</p>\n<h1 id=\"二、netty三种模式\"><a href=\"#二、netty三种模式\" class=\"headerlink\" title=\"二、netty三种模式\"></a>二、netty三种模式</h1><p><strong><em>单reactor单线程：</em></strong> 一个线程，需要处理连接、读写，有性能瓶颈<br><strong><em>单reactor多线程：</em></strong> 一个线程处理连接，将读写分发给其他线程，容易出现一个线程无法处理过多连接的问题。<br><strong><em>主从reactor多线程：</em></strong> 为了解决一个线程无法处理过多连接的问题，引入了多线程解决该问题。  </p>\n<blockquote>\n<p>serverSocket会创建一个监听的socket，监听客户端的连接。会为每一个client再创建一个socket，该socket用于和客户端进行数据通信。（如果不做处理，这些socket对应的fd会放入同一个selector）<br>基于一个selector，如果一个线程去遍历该selector会遇到性能问题，所以netty的主从多线程模式，会将为client创建的socket添加到另外一个新的selector，再起新线程去处理该selector，<br>从而解决netty单reactor中遇到洪峰连接的性能问题。（即selector内的socket不仅仅有连接请求，还有数据读写等请求）</p>\n</blockquote>","more":"<h1 id=\"三、代码解析\"><a href=\"#三、代码解析\" class=\"headerlink\" title=\"三、代码解析\"></a>三、代码解析</h1><h2 id=\"3-1、服务端代码\"><a href=\"#3-1、服务端代码\" class=\"headerlink\" title=\"3.1、服务端代码\"></a>3.1、服务端代码</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String[] args)&#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        //主线程池，用于接收客户端连接</span><br><span class=\"line\">        NioEventLoopGroup mainGroup = new NioEventLoopGroup(1);</span><br><span class=\"line\">        //工作线程池，用于分发读写操作</span><br><span class=\"line\">        NioEventLoopGroup workGroup = new NioEventLoopGroup(5);</span><br><span class=\"line\"></span><br><span class=\"line\">        ServerBootstrap serverBootstrap = new ServerBootstrap();</span><br><span class=\"line\">        //此处只是设置了一系列的启动器参数</span><br><span class=\"line\">        serverBootstrap</span><br><span class=\"line\">            //将两个线程池设置到启动器内</span><br><span class=\"line\">            .group(mainGroup, workGroup)</span><br><span class=\"line\">            //设置channel类型</span><br><span class=\"line\">            .channel(NioServerSocketChannel.class)</span><br><span class=\"line\">            //设置channel，只监听TCPNODELAY事件</span><br><span class=\"line\">            .option(ChannelOption.TCP_NODELAY, false)</span><br><span class=\"line\">            //设置处理器（若处理器写多个，实际只有一个有效，以最后一个为准）</span><br><span class=\"line\">            .handler(new LoggingHandler())</span><br><span class=\"line\">            //设置子处理器（若处理器写多个，实际只有一个有效，以最后一个为准）</span><br><span class=\"line\">            .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class=\"line\">                @Override</span><br><span class=\"line\">                protected void initChannel(NioSocketChannel socketChannel) throws Exception &#123;</span><br><span class=\"line\">                    logger.info(&quot;新客户端连接进来了-----&#123;&#125;&quot;, socketChannel.remoteAddress().toString());</span><br><span class=\"line\">                    ChannelPipeline pipeline = socketChannel.pipeline();</span><br><span class=\"line\">                    pipeline.addLast(new MyHandler());</span><br><span class=\"line\">                    pipeline.addLast(new LoggingHandler());</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        //bind操作，此处才实际绑定端口并创建channel</span><br><span class=\"line\">        ChannelFuture future = serverBootstrap.bind(1234);</span><br><span class=\"line\">        future.channel().closeFuture().sync();</span><br><span class=\"line\">    &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>代码解析：  </p>\n<ol>\n<li><p>new NioEventLoopGroup()：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    public NioEventLoopGroup(int nThreads, Executor executor) &#123;</span><br><span class=\"line\">        this(nThreads, executor, SelectorProvider.provider());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    1、此构造方法，SelectorProvider.provider()会去创建Selector多路复用器；</span><br><span class=\"line\">    2、跟踪至父类构造函数MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args)</span><br><span class=\"line\">        protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123;</span><br><span class=\"line\">            children = new EventExecutor[nThreads];</span><br><span class=\"line\">            for (int i = 0; i &lt; nThreads; i ++) &#123;</span><br><span class=\"line\">                boolean success = false;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    children[i] = newChild(executor, args);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;            </span><br><span class=\"line\">        创建线程池：children = new EventExecutor[nThreads];</span><br><span class=\"line\">        实例化数组元素：实际作用是创建了Selector池</span><br><span class=\"line\">            //实际创建NioEventLoop，NioEventLoop内有Selector</span><br><span class=\"line\">            children[i] = newChild(executor, args);</span><br><span class=\"line\">    3、newChild(executor, args)方法解析</span><br><span class=\"line\">        protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123;</span><br><span class=\"line\">            return new NioEventLoop(this, executor, (SelectorProvider) args[0],</span><br><span class=\"line\">                ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        3.1、实际进入NioEventLoop 的构造函数，然后继续进入SingleThreadEventLoop构造函数</span><br><span class=\"line\">        3.2、SingleThreadEventLoop 的父类 SingleThreadEventExecutor 的构造函数，这是一个只有一个线程的线程池</span><br><span class=\"line\">            state：线程池当前的状态；</span><br><span class=\"line\">            taskQueue：存放任务的队列；</span><br><span class=\"line\">            thread：线程池维护的唯一线程；</span><br><span class=\"line\">            scheduledTaskQueue：定义在其父类AbstractScheduledEventExecutor中，用以保存延迟执行的任务。</span><br><span class=\"line\">```     </span><br><span class=\"line\"></span><br><span class=\"line\">2. bind()操作：</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>AbstractBootstrap.initAndRegister()，内部会使用channelFactory.newChannel()去创建channel</li>\n<li><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">3. NioEventLoop</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n</li>\n</ol>\n<p>NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider,<br>                 SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) {<br>    super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler);<br>    if (selectorProvider == null) {<br>        throw new NullPointerException(“selectorProvider”);<br>    }<br>    if (strategy == null) {<br>        throw new NullPointerException(“selectStrategy”);<br>    }<br>    provider = selectorProvider;<br>    //SelectorProvider.provider()会去创建Selector多路复用器；<br>    final SelectorTuple selectorTuple = openSelector();//<br>    selector = selectorTuple.selector;<br>    unwrappedSelector = selectorTuple.unwrappedSelector;<br>    selectStrategy = strategy;<br>}</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">一个NioEventLoopGroup，对应对个NioEventLoop（对应一个selector），从而可以将很多的socket设置到不同的selector，分配多个线程对selector进行分别的遍历。</span><br><span class=\"line\"></span><br><span class=\"line\">## 3.2、客户端代码</span><br></pre></td></tr></table></figure>\n\n<p>public static void main(String[] args) {<br>    try {<br>        NioEventLoopGroup eventLoopGroup = new NioEventLoopGroup(10);<br>        Bootstrap bootstrap = new Bootstrap();<br>        bootstrap.group(eventLoopGroup)<br>            .channel(NioSocketChannel.class)<br>            .option(ChannelOption.TCP_NODELAY, false)<br>            .handler(new ChannelInitializer<niosocketchannel>() {<br>                @Override<br>                protected void initChannel(NioSocketChannel socketChannel) throws Exception {<br>                    ChannelPipeline pipeline = socketChannel.pipeline();<br>                    System.out.println(“aaaa”);<br>                    pipeline.addLast(new LoggingHandler());<br>                }<br>            });<br>        ChannelFuture channelFuture = bootstrap.connect(“127.0.0.1”, 1234).sync();<br>    } catch (Exception e) {<br>        e.printStackTrace();<br>    }<br>}</niosocketchannel></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">代码解析：</span><br></pre></td></tr></table></figure>\n\n<p>1、new NioEventLoopGroup()，同服务端。<br>2、bootstrap.connect连接操作<br>    -&gt; Bootstrap.initAndRegister()<br>        -&gt; //使用工厂类ChannelFactory的newChannel通过反射创建Channel实例<br>        -&gt; 2.1、channel = channelFactory.newChannel();<br>            -&gt; 3、channelFactory.newChannel()<br>            -&gt;  工厂类创建NioSocketChannel<br>            -&gt;  构造函数：public NioSocketChannel(SelectorProvider provider) {<br>            -&gt;      //newSocket(provider) 方法会创建 JDK 的 SocketChannel，<br>            -&gt;      this(newSocket(provider));// 实现—&gt; provider.openSocketChannel();<br>            -&gt;  }<br>        -&gt; //进行channel初始化，给channel设置handler、option<br>        -&gt; 2.2、init(channel);<br>        -&gt; //channel的注册<br>        -&gt; 2.3、ChannelFuture regFuture = config().group().register(channel);<br>            -&gt; config().group().register(channel)<br>                -&gt; AbstractChannel.AbstractUnsafe.register()方法<br>                判断 NioEventLoop 的线程是否已经启动，如果已经启动，调用 register0方法；否则调用 eventLoop.execute 方法启动线程<br>                    -&gt; //调用JDK去注册Selector<br>                    -&gt; doRegister();<br>                    -&gt; neverRegistered = false;<br>                    -&gt; registered = true;<br>                    -&gt; //设置注册成功通知监听器<br>                    -&gt; safeSetSuccess(promise);<br>                    -&gt; //触发注册成功事件<br>                    -&gt; pipeline.fireChannelRegistered();</p>\n<pre><code>\n\n</code></pre>"},{"title":"hbase","date":"2019-07-03T13:58:49.000Z","_content":"# HBASE\n1、面向列存储的分布式存储系统。   \n2、概念有row key和cloumn family。   \n3、仅能通过行键(row key)和行键序列来检索数据，仅支持单行事务。  \n\n<!--more-->  \n\n> 下图为hbase的整体架构图  \n\n![hbase工作原理](2019-07-03-hbase/HBASE工作原理.png)   \n> zk存储了所有Region server节点的信息 \n\nHBase中的每一张表就是所谓的BigTable。BigTable会存储一系列的行记录，行记录有三个基本类型的定义：\n\n1.RowKey\n\n是行在BigTable中的唯一标识。\n\n2.TimeStamp：\n\n是每一次数据操作对应关联的时间戳，可以看作SVN的版本。\n\n3.Column：\n\n定义为<family>:<label>，通过这两部分可以指定唯一的数据的存储列，family的定义和修改需要对HBase进行类似于DB的DDL操作，\n\n而label，不需要定义直接可以使用，这也为动态定制列提供了一种手段。family另一个作用体现在物理存储优化读写操作上，同family\n\n的数据物理上保存的会比较接近，因此在业务设计的过程中可以利用这个特性。\n\n**逻辑存储**\n![hbase工作原理](2019-07-03-hbase/HBASE存储.png) \n\n## 一、hbase master \n1、协调各个regsion server的负载均衡。  \n2、负责给region分配region server。  \n3、通过zk可以实现master的集群部署，但是同时只有一个master提供服务。  \n\n```\n**************************\n**** HBase Meta Table ****\n**************************\nMeta table存储所有region的列表\nMeta table的结构如下:\n- Key: region的开始row key, region id\n- Values: Region server\n```\n\n## 二、Regsion Server\n1、client直接与Regsion server进行连接。   \n\n![hbase工作原理](2019-07-03-hbase/hregion.png)  \n\n* 1、Region  \n```\n1、根据Row Key的区域分成多个Region（按照rowkey分成region，若一个region存储不下则开辟新的region）\n2、每个HRegion对应Table中一个Region，HRegion由多个HStore组成；\n3、每个HStore对应Table中一个Column Family的存储；\n4、flush的最小单位是region。\n5、每个region最大1GB(默认)。\n```    \n* 2、MemStore\n```\n1、每一个cloumn family对应一个memstore，\n2、采用LSM数据结构存储，并在内存中排序，提高写入速度。\n3、若rowkey的cf过多，则会导致memstore过多，导致region的flush。\n```\n\n* 3、Store File\n```\nHFile的轻量封装。\n```\n\n* 4、HFile\n```\n1、HFile中存储有序的Key-Value对. 当Memstore满了之后, Memstore中的所有数据写入HDFS中,形成一个新的HFile\n2、HFile文件主要分为4个部分：Scanned block部分、Non-scanned block部分、Load-on-open部分和Trailer。\n```\n\n* 5、HLog\n```\n一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况\n```\n\n参考  \n[深度分析HBASE架构](https://zhuanlan.zhihu.com/p/30414252)    \n[hbase存储结构介绍及hbase各种概念](https://www.cnblogs.com/yangjiming/p/9429169.html)  \n    \n    \n# HBASE应用\n## 一、现状\n* 统一登录系统容量为26G左右  \n![uum总容量](2019-07-03-hbase/uumsize.jpg)   \n \n* 业务日志容量为200G左右  \n![业务日志容量](2019-07-03-hbase/businesslog.png)  \n\n```\n1、业务日志容量占总数据库的80%，每日新增数量多。\n2、日志存储及重新，消耗机器过多的CPU和IO，会影响整个服务的性能。\n```\n\n## 二、优化\n\n### 1、现有使用方式调研\n```\n1、业务ID+_+系统模块ID 两条件查询业务操作日志。  \n2、各业务系统可以查看各自处理的历史数据。  \n```\n\n### 2、技术选型\n\n1、存储问题\n> MySQL 与 HBase 是我们日常应用中常用的两个数据库，分别解决应用的在线事务问题和大数据场景的海量存储问题，HBASE侧重写，存储无碎片，数据导入能力强;\n\n2、数据分析处理\n> MySQL 与 HBase 在大数据量下分析处理，显而易见，HBASE优势优于MYSQL ,完全分布式，易扩展, 底层使用HDFS, 存储与计算分离 ;\n\n3、结合业务场景\n> 业务操作日志，数据量大，业务单一，且历史数据在MQSQL中已达200G,没有过多复杂的查询;\n\n4、性能\n> HBase  在合理的设计存储 结构 合理的设计ROWKEY,查询效率很高，毫秒级\n\n### 3、功能设计\n* 1.可以使用rowkey精确查找.  \n* 2.可根据查询条件查询，可以查询分页查询的方工有：  \n    * 1.业务ID;  \n    * 2.业务ID，系统ID;  \n\n### 4、row key设计\n业务ID+_+系统ID+_+业务系统操作ID+_+生成的唯一ID(时间毫秒数+4位计数（0000-9999）);  rowkey最大长度为 17*4+3\n","source":"_posts/2019-07-03-hbase.md","raw":"---\ntitle: hbase\ndate: 2019-07-03 21:58:49\ntags:\n---\n# HBASE\n1、面向列存储的分布式存储系统。   \n2、概念有row key和cloumn family。   \n3、仅能通过行键(row key)和行键序列来检索数据，仅支持单行事务。  \n\n<!--more-->  \n\n> 下图为hbase的整体架构图  \n\n![hbase工作原理](2019-07-03-hbase/HBASE工作原理.png)   \n> zk存储了所有Region server节点的信息 \n\nHBase中的每一张表就是所谓的BigTable。BigTable会存储一系列的行记录，行记录有三个基本类型的定义：\n\n1.RowKey\n\n是行在BigTable中的唯一标识。\n\n2.TimeStamp：\n\n是每一次数据操作对应关联的时间戳，可以看作SVN的版本。\n\n3.Column：\n\n定义为<family>:<label>，通过这两部分可以指定唯一的数据的存储列，family的定义和修改需要对HBase进行类似于DB的DDL操作，\n\n而label，不需要定义直接可以使用，这也为动态定制列提供了一种手段。family另一个作用体现在物理存储优化读写操作上，同family\n\n的数据物理上保存的会比较接近，因此在业务设计的过程中可以利用这个特性。\n\n**逻辑存储**\n![hbase工作原理](2019-07-03-hbase/HBASE存储.png) \n\n## 一、hbase master \n1、协调各个regsion server的负载均衡。  \n2、负责给region分配region server。  \n3、通过zk可以实现master的集群部署，但是同时只有一个master提供服务。  \n\n```\n**************************\n**** HBase Meta Table ****\n**************************\nMeta table存储所有region的列表\nMeta table的结构如下:\n- Key: region的开始row key, region id\n- Values: Region server\n```\n\n## 二、Regsion Server\n1、client直接与Regsion server进行连接。   \n\n![hbase工作原理](2019-07-03-hbase/hregion.png)  \n\n* 1、Region  \n```\n1、根据Row Key的区域分成多个Region（按照rowkey分成region，若一个region存储不下则开辟新的region）\n2、每个HRegion对应Table中一个Region，HRegion由多个HStore组成；\n3、每个HStore对应Table中一个Column Family的存储；\n4、flush的最小单位是region。\n5、每个region最大1GB(默认)。\n```    \n* 2、MemStore\n```\n1、每一个cloumn family对应一个memstore，\n2、采用LSM数据结构存储，并在内存中排序，提高写入速度。\n3、若rowkey的cf过多，则会导致memstore过多，导致region的flush。\n```\n\n* 3、Store File\n```\nHFile的轻量封装。\n```\n\n* 4、HFile\n```\n1、HFile中存储有序的Key-Value对. 当Memstore满了之后, Memstore中的所有数据写入HDFS中,形成一个新的HFile\n2、HFile文件主要分为4个部分：Scanned block部分、Non-scanned block部分、Load-on-open部分和Trailer。\n```\n\n* 5、HLog\n```\n一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况\n```\n\n参考  \n[深度分析HBASE架构](https://zhuanlan.zhihu.com/p/30414252)    \n[hbase存储结构介绍及hbase各种概念](https://www.cnblogs.com/yangjiming/p/9429169.html)  \n    \n    \n# HBASE应用\n## 一、现状\n* 统一登录系统容量为26G左右  \n![uum总容量](2019-07-03-hbase/uumsize.jpg)   \n \n* 业务日志容量为200G左右  \n![业务日志容量](2019-07-03-hbase/businesslog.png)  \n\n```\n1、业务日志容量占总数据库的80%，每日新增数量多。\n2、日志存储及重新，消耗机器过多的CPU和IO，会影响整个服务的性能。\n```\n\n## 二、优化\n\n### 1、现有使用方式调研\n```\n1、业务ID+_+系统模块ID 两条件查询业务操作日志。  \n2、各业务系统可以查看各自处理的历史数据。  \n```\n\n### 2、技术选型\n\n1、存储问题\n> MySQL 与 HBase 是我们日常应用中常用的两个数据库，分别解决应用的在线事务问题和大数据场景的海量存储问题，HBASE侧重写，存储无碎片，数据导入能力强;\n\n2、数据分析处理\n> MySQL 与 HBase 在大数据量下分析处理，显而易见，HBASE优势优于MYSQL ,完全分布式，易扩展, 底层使用HDFS, 存储与计算分离 ;\n\n3、结合业务场景\n> 业务操作日志，数据量大，业务单一，且历史数据在MQSQL中已达200G,没有过多复杂的查询;\n\n4、性能\n> HBase  在合理的设计存储 结构 合理的设计ROWKEY,查询效率很高，毫秒级\n\n### 3、功能设计\n* 1.可以使用rowkey精确查找.  \n* 2.可根据查询条件查询，可以查询分页查询的方工有：  \n    * 1.业务ID;  \n    * 2.业务ID，系统ID;  \n\n### 4、row key设计\n业务ID+_+系统ID+_+业务系统操作ID+_+生成的唯一ID(时间毫秒数+4位计数（0000-9999）);  rowkey最大长度为 17*4+3\n","slug":"2019-07-03-hbase","published":1,"updated":"2024-10-14T09:38:11.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnut000ra13k74i47kzl","content":"<h1 id=\"HBASE\"><a href=\"#HBASE\" class=\"headerlink\" title=\"HBASE\"></a>HBASE</h1><p>1、面向列存储的分布式存储系统。<br>2、概念有row key和cloumn family。<br>3、仅能通过行键(row key)和行键序列来检索数据，仅支持单行事务。  </p>\n<a id=\"more\"></a>  \n\n<blockquote>\n<p>下图为hbase的整体架构图  </p>\n</blockquote>\n<p><img src=\"/2019/07/03/2019-07-03-hbase/HBASE%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png\" alt=\"hbase工作原理\">   </p>\n<blockquote>\n<p>zk存储了所有Region server节点的信息 </p>\n</blockquote>\n<p>HBase中的每一张表就是所谓的BigTable。BigTable会存储一系列的行记录，行记录有三个基本类型的定义：</p>\n<p>1.RowKey</p>\n<p>是行在BigTable中的唯一标识。</p>\n<p>2.TimeStamp：</p>\n<p>是每一次数据操作对应关联的时间戳，可以看作SVN的版本。</p>\n<p>3.Column：</p>\n<p>定义为<family>:<label>，通过这两部分可以指定唯一的数据的存储列，family的定义和修改需要对HBase进行类似于DB的DDL操作，</label></family></p>\n<p>而label，不需要定义直接可以使用，这也为动态定制列提供了一种手段。family另一个作用体现在物理存储优化读写操作上，同family</p>\n<p>的数据物理上保存的会比较接近，因此在业务设计的过程中可以利用这个特性。</p>\n<p><strong>逻辑存储</strong><br><img src=\"/2019/07/03/2019-07-03-hbase/HBASE%E5%AD%98%E5%82%A8.png\" alt=\"hbase工作原理\"> </p>\n<h2 id=\"一、hbase-master\"><a href=\"#一、hbase-master\" class=\"headerlink\" title=\"一、hbase master\"></a>一、hbase master</h2><p>1、协调各个regsion server的负载均衡。<br>2、负责给region分配region server。<br>3、通过zk可以实现master的集群部署，但是同时只有一个master提供服务。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">**************************</span><br><span class=\"line\">**** HBase Meta Table ****</span><br><span class=\"line\">**************************</span><br><span class=\"line\">Meta table存储所有region的列表</span><br><span class=\"line\">Meta table的结构如下:</span><br><span class=\"line\">- Key: region的开始row key, region id</span><br><span class=\"line\">- Values: Region server</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"二、Regsion-Server\"><a href=\"#二、Regsion-Server\" class=\"headerlink\" title=\"二、Regsion Server\"></a>二、Regsion Server</h2><p>1、client直接与Regsion server进行连接。   </p>\n<p><img src=\"/2019/07/03/2019-07-03-hbase/hregion.png\" alt=\"hbase工作原理\">  </p>\n<ul>\n<li>1、Region  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、根据Row Key的区域分成多个Region（按照rowkey分成region，若一个region存储不下则开辟新的region）</span><br><span class=\"line\">2、每个HRegion对应Table中一个Region，HRegion由多个HStore组成；</span><br><span class=\"line\">3、每个HStore对应Table中一个Column Family的存储；</span><br><span class=\"line\">4、flush的最小单位是region。</span><br><span class=\"line\">5、每个region最大1GB(默认)。</span><br><span class=\"line\">```    </span><br><span class=\"line\">* 2、MemStore</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>1、每一个cloumn family对应一个memstore，<br>2、采用LSM数据结构存储，并在内存中排序，提高写入速度。<br>3、若rowkey的cf过多，则会导致memstore过多，导致region的flush。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">* 3、Store File</span><br></pre></td></tr></table></figure>\n\n<p>HFile的轻量封装。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">* 4、HFile</span><br></pre></td></tr></table></figure>\n\n<p>1、HFile中存储有序的Key-Value对. 当Memstore满了之后, Memstore中的所有数据写入HDFS中,形成一个新的HFile<br>2、HFile文件主要分为4个部分：Scanned block部分、Non-scanned block部分、Load-on-open部分和Trailer。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">* 5、HLog</span><br></pre></td></tr></table></figure>\n\n<p>一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">参考  </span><br><span class=\"line\">[深度分析HBASE架构](https://zhuanlan.zhihu.com/p/30414252)    </span><br><span class=\"line\">[hbase存储结构介绍及hbase各种概念](https://www.cnblogs.com/yangjiming/p/9429169.html)  </span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\"># HBASE应用</span><br><span class=\"line\">## 一、现状</span><br><span class=\"line\">* 统一登录系统容量为26G左右  </span><br><span class=\"line\">![uum总容量](2019-07-03-hbase/uumsize.jpg)   </span><br><span class=\"line\"> </span><br><span class=\"line\">* 业务日志容量为200G左右  </span><br><span class=\"line\">![业务日志容量](2019-07-03-hbase/businesslog.png)</span><br></pre></td></tr></table></figure>\n\n<p>1、业务日志容量占总数据库的80%，每日新增数量多。<br>2、日志存储及重新，消耗机器过多的CPU和IO，会影响整个服务的性能。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">## 二、优化</span><br><span class=\"line\"></span><br><span class=\"line\">### 1、现有使用方式调研</span><br></pre></td></tr></table></figure>\n\n<p>1、业务ID+_+系统模块ID 两条件查询业务操作日志。<br>2、各业务系统可以查看各自处理的历史数据。  </p>\n<pre><code>\n### 2、技术选型\n\n1、存储问题\n&gt; MySQL 与 HBase 是我们日常应用中常用的两个数据库，分别解决应用的在线事务问题和大数据场景的海量存储问题，HBASE侧重写，存储无碎片，数据导入能力强;\n\n2、数据分析处理\n&gt; MySQL 与 HBase 在大数据量下分析处理，显而易见，HBASE优势优于MYSQL ,完全分布式，易扩展, 底层使用HDFS, 存储与计算分离 ;\n\n3、结合业务场景\n&gt; 业务操作日志，数据量大，业务单一，且历史数据在MQSQL中已达200G,没有过多复杂的查询;\n\n4、性能\n&gt; HBase  在合理的设计存储 结构 合理的设计ROWKEY,查询效率很高，毫秒级\n\n### 3、功能设计\n* 1.可以使用rowkey精确查找.  \n* 2.可根据查询条件查询，可以查询分页查询的方工有：  \n    * 1.业务ID;  \n    * 2.业务ID，系统ID;  \n\n### 4、row key设计\n业务ID+_+系统ID+_+业务系统操作ID+_+生成的唯一ID(时间毫秒数+4位计数（0000-9999）);  rowkey最大长度为 17*4+3</code></pre>","site":{"data":{}},"excerpt":"<h1 id=\"HBASE\"><a href=\"#HBASE\" class=\"headerlink\" title=\"HBASE\"></a>HBASE</h1><p>1、面向列存储的分布式存储系统。<br>2、概念有row key和cloumn family。<br>3、仅能通过行键(row key)和行键序列来检索数据，仅支持单行事务。  </p>","more":"<blockquote>\n<p>下图为hbase的整体架构图  </p>\n</blockquote>\n<p><img src=\"/2019/07/03/2019-07-03-hbase/HBASE%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png\" alt=\"hbase工作原理\">   </p>\n<blockquote>\n<p>zk存储了所有Region server节点的信息 </p>\n</blockquote>\n<p>HBase中的每一张表就是所谓的BigTable。BigTable会存储一系列的行记录，行记录有三个基本类型的定义：</p>\n<p>1.RowKey</p>\n<p>是行在BigTable中的唯一标识。</p>\n<p>2.TimeStamp：</p>\n<p>是每一次数据操作对应关联的时间戳，可以看作SVN的版本。</p>\n<p>3.Column：</p>\n<p>定义为<family>:<label>，通过这两部分可以指定唯一的数据的存储列，family的定义和修改需要对HBase进行类似于DB的DDL操作，</label></family></p>\n<p>而label，不需要定义直接可以使用，这也为动态定制列提供了一种手段。family另一个作用体现在物理存储优化读写操作上，同family</p>\n<p>的数据物理上保存的会比较接近，因此在业务设计的过程中可以利用这个特性。</p>\n<p><strong>逻辑存储</strong><br><img src=\"/2019/07/03/2019-07-03-hbase/HBASE%E5%AD%98%E5%82%A8.png\" alt=\"hbase工作原理\"> </p>\n<h2 id=\"一、hbase-master\"><a href=\"#一、hbase-master\" class=\"headerlink\" title=\"一、hbase master\"></a>一、hbase master</h2><p>1、协调各个regsion server的负载均衡。<br>2、负责给region分配region server。<br>3、通过zk可以实现master的集群部署，但是同时只有一个master提供服务。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">**************************</span><br><span class=\"line\">**** HBase Meta Table ****</span><br><span class=\"line\">**************************</span><br><span class=\"line\">Meta table存储所有region的列表</span><br><span class=\"line\">Meta table的结构如下:</span><br><span class=\"line\">- Key: region的开始row key, region id</span><br><span class=\"line\">- Values: Region server</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"二、Regsion-Server\"><a href=\"#二、Regsion-Server\" class=\"headerlink\" title=\"二、Regsion Server\"></a>二、Regsion Server</h2><p>1、client直接与Regsion server进行连接。   </p>\n<p><img src=\"/2019/07/03/2019-07-03-hbase/hregion.png\" alt=\"hbase工作原理\">  </p>\n<ul>\n<li>1、Region  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、根据Row Key的区域分成多个Region（按照rowkey分成region，若一个region存储不下则开辟新的region）</span><br><span class=\"line\">2、每个HRegion对应Table中一个Region，HRegion由多个HStore组成；</span><br><span class=\"line\">3、每个HStore对应Table中一个Column Family的存储；</span><br><span class=\"line\">4、flush的最小单位是region。</span><br><span class=\"line\">5、每个region最大1GB(默认)。</span><br><span class=\"line\">```    </span><br><span class=\"line\">* 2、MemStore</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>1、每一个cloumn family对应一个memstore，<br>2、采用LSM数据结构存储，并在内存中排序，提高写入速度。<br>3、若rowkey的cf过多，则会导致memstore过多，导致region的flush。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">* 3、Store File</span><br></pre></td></tr></table></figure>\n\n<p>HFile的轻量封装。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">* 4、HFile</span><br></pre></td></tr></table></figure>\n\n<p>1、HFile中存储有序的Key-Value对. 当Memstore满了之后, Memstore中的所有数据写入HDFS中,形成一个新的HFile<br>2、HFile文件主要分为4个部分：Scanned block部分、Non-scanned block部分、Load-on-open部分和Trailer。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">* 5、HLog</span><br></pre></td></tr></table></figure>\n\n<p>一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">参考  </span><br><span class=\"line\">[深度分析HBASE架构](https://zhuanlan.zhihu.com/p/30414252)    </span><br><span class=\"line\">[hbase存储结构介绍及hbase各种概念](https://www.cnblogs.com/yangjiming/p/9429169.html)  </span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\"># HBASE应用</span><br><span class=\"line\">## 一、现状</span><br><span class=\"line\">* 统一登录系统容量为26G左右  </span><br><span class=\"line\">![uum总容量](2019-07-03-hbase/uumsize.jpg)   </span><br><span class=\"line\"> </span><br><span class=\"line\">* 业务日志容量为200G左右  </span><br><span class=\"line\">![业务日志容量](2019-07-03-hbase/businesslog.png)</span><br></pre></td></tr></table></figure>\n\n<p>1、业务日志容量占总数据库的80%，每日新增数量多。<br>2、日志存储及重新，消耗机器过多的CPU和IO，会影响整个服务的性能。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">## 二、优化</span><br><span class=\"line\"></span><br><span class=\"line\">### 1、现有使用方式调研</span><br></pre></td></tr></table></figure>\n\n<p>1、业务ID+_+系统模块ID 两条件查询业务操作日志。<br>2、各业务系统可以查看各自处理的历史数据。  </p>\n<pre><code>\n### 2、技术选型\n\n1、存储问题\n&gt; MySQL 与 HBase 是我们日常应用中常用的两个数据库，分别解决应用的在线事务问题和大数据场景的海量存储问题，HBASE侧重写，存储无碎片，数据导入能力强;\n\n2、数据分析处理\n&gt; MySQL 与 HBase 在大数据量下分析处理，显而易见，HBASE优势优于MYSQL ,完全分布式，易扩展, 底层使用HDFS, 存储与计算分离 ;\n\n3、结合业务场景\n&gt; 业务操作日志，数据量大，业务单一，且历史数据在MQSQL中已达200G,没有过多复杂的查询;\n\n4、性能\n&gt; HBase  在合理的设计存储 结构 合理的设计ROWKEY,查询效率很高，毫秒级\n\n### 3、功能设计\n* 1.可以使用rowkey精确查找.  \n* 2.可根据查询条件查询，可以查询分页查询的方工有：  \n    * 1.业务ID;  \n    * 2.业务ID，系统ID;  \n\n### 4、row key设计\n业务ID+_+系统ID+_+业务系统操作ID+_+生成的唯一ID(时间毫秒数+4位计数（0000-9999）);  rowkey最大长度为 17*4+3</code></pre>"},{"title":"HIVE","date":"2019-07-20T06:45:42.000Z","_content":"# 一、HIVE架构\n![HIVE架构](2019-07-20-HIVE/HIVE架构.png)\n\n## 1. 连接方式\n* CLI：command line interface\n* JDBC/ODBC\n* WEBUI\n\n## 2. 驱动器：Driver\n* Parser：SQL解析器，将HQL转换成抽象语法树，AST tree\n    * 对AST tree进行解析：例如表是否存在、字段是否存在、SQL语义是否有误。\n* Planner：编译器， 对HQL语句进行词法、语法、语义的编译(需要跟元数据关联)，编译完成后会生成一个执行计划。 hive上就是编译成mapreduce的job。\n* Optimizer：优化器， 将执行计划进行优化，减少不必要的列、使用分区、使用索引等。优化job。\n* Execution：将优化后的执行计划提交给hadoop的yarn上执行。提交job。\n\n## 3. 元数据：meta store\n* 元数据包括：\n    * 表名\n    * 表所属的数据库\n    * 表的拥有者\n    * 列/分区字段\n    * 表的类型\n    * 表的数据所在目录\n\n* 表类型\n    * 内部表：create table xxx (xx xxx)\n        * 默认创建的是默认表\n        * 删除表的时候，数据和元数据都会被删除\n        * \n    * 外边表：create external table xxx (xxx)\n        * 删除外部表时原数据不会被删除\n        * 外部表指向的数据发生变化的时候会自动更新，不用特殊处理\n        * 外部表文件可以在外部系统上，只要有访问权限就可以\n        * 外部表导入文件时不移动文件，仅仅是添加一个metadata\n\n* 分区和桶\n    * 分区：\n        * 例如按天分区，只存储一个的数据\n        * 一个Hive表在HDFS上是有一个对应的目录来存储数据，普通表的数据直接存储在这个目录下，而分区表数据存储时，是再划分子目录来存储的\n    * 桶：分桶将整个数据内容安装某列属性值得hash值进行区分，按照取模结果对数据分桶            \n    \n    \n## 4. 工作流程\n\n1. 用户提交查询等任务给Driver。\n2. 驱动程序将Hql发送编译器，检查语法和生成查询计划。\n3. 编译器Compiler根据用户任务去MetaStore中获取需要的Hive的元数据信息。\n4. 编译器Compiler得到元数据信息，对任务进行编译，先将HiveQL转换为抽象语法树，然后将抽象语法树 转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划 （MapReduce）, 最后选择最佳的策略。\n5. 将最终的计划提交给Driver。到此为止，查询解析和编译完成。\n6. Driver将计划Plan转交给ExecutionEngine去执行。\n7. 在内部，执行作业的过程是一个MapReduce工作。执行引擎发送作业给JobTracker，在名称节点并把它 分配作业到TaskTracker，这是在数据节点。在这里，查询执行MapReduce工作。\n    7.1. 与此同时,在执行时,执行引擎可以通过Metastore执行元数据操作。\n8. 执行引擎接收来自数据节点的结果。\n9. 执行引擎发送这些结果值给驱动程序。\n10. 驱动程序将结果发送给Hive接口。    \n\n    ","source":"_posts/2019-07-20-HIVE.md","raw":"---\ntitle: HIVE\ndate: 2019-07-20 14:45:42\ntags: HIVE HDFS\n---\n# 一、HIVE架构\n![HIVE架构](2019-07-20-HIVE/HIVE架构.png)\n\n## 1. 连接方式\n* CLI：command line interface\n* JDBC/ODBC\n* WEBUI\n\n## 2. 驱动器：Driver\n* Parser：SQL解析器，将HQL转换成抽象语法树，AST tree\n    * 对AST tree进行解析：例如表是否存在、字段是否存在、SQL语义是否有误。\n* Planner：编译器， 对HQL语句进行词法、语法、语义的编译(需要跟元数据关联)，编译完成后会生成一个执行计划。 hive上就是编译成mapreduce的job。\n* Optimizer：优化器， 将执行计划进行优化，减少不必要的列、使用分区、使用索引等。优化job。\n* Execution：将优化后的执行计划提交给hadoop的yarn上执行。提交job。\n\n## 3. 元数据：meta store\n* 元数据包括：\n    * 表名\n    * 表所属的数据库\n    * 表的拥有者\n    * 列/分区字段\n    * 表的类型\n    * 表的数据所在目录\n\n* 表类型\n    * 内部表：create table xxx (xx xxx)\n        * 默认创建的是默认表\n        * 删除表的时候，数据和元数据都会被删除\n        * \n    * 外边表：create external table xxx (xxx)\n        * 删除外部表时原数据不会被删除\n        * 外部表指向的数据发生变化的时候会自动更新，不用特殊处理\n        * 外部表文件可以在外部系统上，只要有访问权限就可以\n        * 外部表导入文件时不移动文件，仅仅是添加一个metadata\n\n* 分区和桶\n    * 分区：\n        * 例如按天分区，只存储一个的数据\n        * 一个Hive表在HDFS上是有一个对应的目录来存储数据，普通表的数据直接存储在这个目录下，而分区表数据存储时，是再划分子目录来存储的\n    * 桶：分桶将整个数据内容安装某列属性值得hash值进行区分，按照取模结果对数据分桶            \n    \n    \n## 4. 工作流程\n\n1. 用户提交查询等任务给Driver。\n2. 驱动程序将Hql发送编译器，检查语法和生成查询计划。\n3. 编译器Compiler根据用户任务去MetaStore中获取需要的Hive的元数据信息。\n4. 编译器Compiler得到元数据信息，对任务进行编译，先将HiveQL转换为抽象语法树，然后将抽象语法树 转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划 （MapReduce）, 最后选择最佳的策略。\n5. 将最终的计划提交给Driver。到此为止，查询解析和编译完成。\n6. Driver将计划Plan转交给ExecutionEngine去执行。\n7. 在内部，执行作业的过程是一个MapReduce工作。执行引擎发送作业给JobTracker，在名称节点并把它 分配作业到TaskTracker，这是在数据节点。在这里，查询执行MapReduce工作。\n    7.1. 与此同时,在执行时,执行引擎可以通过Metastore执行元数据操作。\n8. 执行引擎接收来自数据节点的结果。\n9. 执行引擎发送这些结果值给驱动程序。\n10. 驱动程序将结果发送给Hive接口。    \n\n    ","slug":"2019-07-20-HIVE","published":1,"updated":"2024-10-14T09:38:11.982Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnuv000ua13k5fti9j56","content":"<h1 id=\"一、HIVE架构\"><a href=\"#一、HIVE架构\" class=\"headerlink\" title=\"一、HIVE架构\"></a>一、HIVE架构</h1><p><img src=\"/2019/07/20/2019-07-20-HIVE/HIVE%E6%9E%B6%E6%9E%84.png\" alt=\"HIVE架构\"></p>\n<h2 id=\"1-连接方式\"><a href=\"#1-连接方式\" class=\"headerlink\" title=\"1. 连接方式\"></a>1. 连接方式</h2><ul>\n<li>CLI：command line interface</li>\n<li>JDBC/ODBC</li>\n<li>WEBUI</li>\n</ul>\n<h2 id=\"2-驱动器：Driver\"><a href=\"#2-驱动器：Driver\" class=\"headerlink\" title=\"2. 驱动器：Driver\"></a>2. 驱动器：Driver</h2><ul>\n<li>Parser：SQL解析器，将HQL转换成抽象语法树，AST tree<ul>\n<li>对AST tree进行解析：例如表是否存在、字段是否存在、SQL语义是否有误。</li>\n</ul>\n</li>\n<li>Planner：编译器， 对HQL语句进行词法、语法、语义的编译(需要跟元数据关联)，编译完成后会生成一个执行计划。 hive上就是编译成mapreduce的job。</li>\n<li>Optimizer：优化器， 将执行计划进行优化，减少不必要的列、使用分区、使用索引等。优化job。</li>\n<li>Execution：将优化后的执行计划提交给hadoop的yarn上执行。提交job。</li>\n</ul>\n<h2 id=\"3-元数据：meta-store\"><a href=\"#3-元数据：meta-store\" class=\"headerlink\" title=\"3. 元数据：meta store\"></a>3. 元数据：meta store</h2><ul>\n<li><p>元数据包括：</p>\n<ul>\n<li>表名</li>\n<li>表所属的数据库</li>\n<li>表的拥有者</li>\n<li>列/分区字段</li>\n<li>表的类型</li>\n<li>表的数据所在目录</li>\n</ul>\n</li>\n<li><p>表类型</p>\n<ul>\n<li>内部表：create table xxx (xx xxx)<ul>\n<li>默认创建的是默认表</li>\n<li>删除表的时候，数据和元数据都会被删除</li>\n<li></li>\n</ul>\n</li>\n<li>外边表：create external table xxx (xxx)<ul>\n<li>删除外部表时原数据不会被删除</li>\n<li>外部表指向的数据发生变化的时候会自动更新，不用特殊处理</li>\n<li>外部表文件可以在外部系统上，只要有访问权限就可以</li>\n<li>外部表导入文件时不移动文件，仅仅是添加一个metadata</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>分区和桶</p>\n<ul>\n<li>分区：<ul>\n<li>例如按天分区，只存储一个的数据</li>\n<li>一个Hive表在HDFS上是有一个对应的目录来存储数据，普通表的数据直接存储在这个目录下，而分区表数据存储时，是再划分子目录来存储的</li>\n</ul>\n</li>\n<li>桶：分桶将整个数据内容安装某列属性值得hash值进行区分，按照取模结果对数据分桶            </li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-工作流程\"><a href=\"#4-工作流程\" class=\"headerlink\" title=\"4. 工作流程\"></a>4. 工作流程</h2><ol>\n<li>用户提交查询等任务给Driver。</li>\n<li>驱动程序将Hql发送编译器，检查语法和生成查询计划。</li>\n<li>编译器Compiler根据用户任务去MetaStore中获取需要的Hive的元数据信息。</li>\n<li>编译器Compiler得到元数据信息，对任务进行编译，先将HiveQL转换为抽象语法树，然后将抽象语法树 转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划 （MapReduce）, 最后选择最佳的策略。</li>\n<li>将最终的计划提交给Driver。到此为止，查询解析和编译完成。</li>\n<li>Driver将计划Plan转交给ExecutionEngine去执行。</li>\n<li>在内部，执行作业的过程是一个MapReduce工作。执行引擎发送作业给JobTracker，在名称节点并把它 分配作业到TaskTracker，这是在数据节点。在这里，查询执行MapReduce工作。<br> 7.1. 与此同时,在执行时,执行引擎可以通过Metastore执行元数据操作。</li>\n<li>执行引擎接收来自数据节点的结果。</li>\n<li>执行引擎发送这些结果值给驱动程序。</li>\n<li>驱动程序将结果发送给Hive接口。    </li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、HIVE架构\"><a href=\"#一、HIVE架构\" class=\"headerlink\" title=\"一、HIVE架构\"></a>一、HIVE架构</h1><p><img src=\"/2019/07/20/2019-07-20-HIVE/HIVE%E6%9E%B6%E6%9E%84.png\" alt=\"HIVE架构\"></p>\n<h2 id=\"1-连接方式\"><a href=\"#1-连接方式\" class=\"headerlink\" title=\"1. 连接方式\"></a>1. 连接方式</h2><ul>\n<li>CLI：command line interface</li>\n<li>JDBC/ODBC</li>\n<li>WEBUI</li>\n</ul>\n<h2 id=\"2-驱动器：Driver\"><a href=\"#2-驱动器：Driver\" class=\"headerlink\" title=\"2. 驱动器：Driver\"></a>2. 驱动器：Driver</h2><ul>\n<li>Parser：SQL解析器，将HQL转换成抽象语法树，AST tree<ul>\n<li>对AST tree进行解析：例如表是否存在、字段是否存在、SQL语义是否有误。</li>\n</ul>\n</li>\n<li>Planner：编译器， 对HQL语句进行词法、语法、语义的编译(需要跟元数据关联)，编译完成后会生成一个执行计划。 hive上就是编译成mapreduce的job。</li>\n<li>Optimizer：优化器， 将执行计划进行优化，减少不必要的列、使用分区、使用索引等。优化job。</li>\n<li>Execution：将优化后的执行计划提交给hadoop的yarn上执行。提交job。</li>\n</ul>\n<h2 id=\"3-元数据：meta-store\"><a href=\"#3-元数据：meta-store\" class=\"headerlink\" title=\"3. 元数据：meta store\"></a>3. 元数据：meta store</h2><ul>\n<li><p>元数据包括：</p>\n<ul>\n<li>表名</li>\n<li>表所属的数据库</li>\n<li>表的拥有者</li>\n<li>列/分区字段</li>\n<li>表的类型</li>\n<li>表的数据所在目录</li>\n</ul>\n</li>\n<li><p>表类型</p>\n<ul>\n<li>内部表：create table xxx (xx xxx)<ul>\n<li>默认创建的是默认表</li>\n<li>删除表的时候，数据和元数据都会被删除</li>\n<li></li>\n</ul>\n</li>\n<li>外边表：create external table xxx (xxx)<ul>\n<li>删除外部表时原数据不会被删除</li>\n<li>外部表指向的数据发生变化的时候会自动更新，不用特殊处理</li>\n<li>外部表文件可以在外部系统上，只要有访问权限就可以</li>\n<li>外部表导入文件时不移动文件，仅仅是添加一个metadata</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>分区和桶</p>\n<ul>\n<li>分区：<ul>\n<li>例如按天分区，只存储一个的数据</li>\n<li>一个Hive表在HDFS上是有一个对应的目录来存储数据，普通表的数据直接存储在这个目录下，而分区表数据存储时，是再划分子目录来存储的</li>\n</ul>\n</li>\n<li>桶：分桶将整个数据内容安装某列属性值得hash值进行区分，按照取模结果对数据分桶            </li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-工作流程\"><a href=\"#4-工作流程\" class=\"headerlink\" title=\"4. 工作流程\"></a>4. 工作流程</h2><ol>\n<li>用户提交查询等任务给Driver。</li>\n<li>驱动程序将Hql发送编译器，检查语法和生成查询计划。</li>\n<li>编译器Compiler根据用户任务去MetaStore中获取需要的Hive的元数据信息。</li>\n<li>编译器Compiler得到元数据信息，对任务进行编译，先将HiveQL转换为抽象语法树，然后将抽象语法树 转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划 （MapReduce）, 最后选择最佳的策略。</li>\n<li>将最终的计划提交给Driver。到此为止，查询解析和编译完成。</li>\n<li>Driver将计划Plan转交给ExecutionEngine去执行。</li>\n<li>在内部，执行作业的过程是一个MapReduce工作。执行引擎发送作业给JobTracker，在名称节点并把它 分配作业到TaskTracker，这是在数据节点。在这里，查询执行MapReduce工作。<br> 7.1. 与此同时,在执行时,执行引擎可以通过Metastore执行元数据操作。</li>\n<li>执行引擎接收来自数据节点的结果。</li>\n<li>执行引擎发送这些结果值给驱动程序。</li>\n<li>驱动程序将结果发送给Hive接口。    </li>\n</ol>\n"},{"title":"hadoop","date":"2019-06-28T13:44:04.000Z","_content":"\n# hadoop\n分布式文件存储系统\n\n## 1、hadoop架构图\n![hadoop](2019-06-28-hadoop/hadoop-架构.png)\n* MapReduce：分布式计算模型\n* YARN：任务管理与资源管理调度\n* HDFS：Hadoop Distributed File system，分布式文件存储系统\n\n<!--more-->    \n\n## 2、HDFS\nHadoop Distributed File System\n### 2.1、HDFS架构图\n![hadoop](2019-06-28-hadoop/hdfs-架构.png)\n* NameNode（NN）是主节点，存储文件的元数据如文件名，文件目录结构，文件属性（生成时间,副本数,文件权限），以及每个文件的块列表和块所在DataNode等。 响应Hadoop客户端请求\n* DataNode（DN）在本地文件系统存储文件块数据，以及块数据的校验和。 \n* Secondary NameNode（SNN） 用来监控HDFS状态的辅助后台程序，每隔一段时间获 取HDFS元数据的快照。\n\n\n#### 1、NameNode\nnamespace：维护整个文件系统的目录树结构及目录树上的状态变化。  \nblockmanager：维护数据块相关信息及数据块的状态变化，\n\n##### A、namespace [命名空间]\n![hadoop](2019-06-28-hadoop/namespace1.jpg)  \n1、目录树常驻内存，会定期生成fsImage文件（快照），方便当NameNode重启后数据恢复。  \n2、目录树文件节点由NodeFile定义，每个NodeFile分割成多个block（BlockInfo的数组），BlockInfo维护的是block的元数据，例如在哪个DataNode等等。  \n\n##### B、BlockManager 【块管理器】\n![hadoop](2019-06-28-hadoop/BlockManager.jpg)    \n1、为了根据blockId快速定位block，使用了BlocksMap来保存。   \n2、blockInfo指向NodeFile中的BlockInfo。   \n3、根据blockId进行hash计算，获取blockInfo在blocksMap中的位置，获取位置后再进行block的获取。  \n\n#### 2、DataNode\n1、存储block信息。  \n2、周期性（1小时）向NN上传所有block信息。   \n3、DN与NN之间有3s每次的心跳信息，若超过10分钟未收到心跳，NN认为该DN无效。   \n\n\n#### 3、Secondary NameNode\n1、通知NN，checkpoint。   \n2、读取NN的fsimage和editlog。  \n3、将两个合并。  \n4、然后将合并结果回传给NN。   \n\n\n\n### 2.2、数据写过程\n![hadoop](2019-06-28-hadoop/文件写入.jpg)    \n\n1、client请求NN获取文件的存储位置。   \n2、client根据client的位置直接与DN连接进行数据传输，数据备份由DN之间通过pipeline进行。   \n\n\n\n### 2.3、数据读过程\n![hadoop](2019-06-28-hadoop/文件读取.jpg)    \n\n\n\n## 3、MapReduce\n\n\n\n\n## 4、YARN\n\n\n## 5、NameNode单点故障问题\n采用HA方案，Namenode可以部署两个：Active NN和Standly NN。在同一时间永远都是只有一个NN对外提供服务的，即Active NN。Active NN并不永远都是一个固定的状态，当Active NN出现故障后，Standly NN就会切换成Active NN提供服务，而之前的Active NN就会变成Standly NN停止位集群服务。\n\n其实就是NameNode和Secondary NameNode\n### 5.1、脑裂问题\n两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信。当active状态的NameNode的命名空间有任何修改时，会告知大部分的JournalNodes进程。\n\n只有standby状态的NameNode才可以对JNS的日志进行操作\n\n\n参考\n[HDFS NameNode内存全景](https://tech.meituan.com/2016/08/26/namenode.html)  \n[原理漫画](https://chu888chu888.gitbooks.io/hadoopstudy/content/Content/3/chapter0302.html)        ","source":"_posts/2019-06-28-hadoop.md","raw":"---\ntitle: hadoop\ndate: 2019-06-28 21:44:04\ntags:\n---\n\n# hadoop\n分布式文件存储系统\n\n## 1、hadoop架构图\n![hadoop](2019-06-28-hadoop/hadoop-架构.png)\n* MapReduce：分布式计算模型\n* YARN：任务管理与资源管理调度\n* HDFS：Hadoop Distributed File system，分布式文件存储系统\n\n<!--more-->    \n\n## 2、HDFS\nHadoop Distributed File System\n### 2.1、HDFS架构图\n![hadoop](2019-06-28-hadoop/hdfs-架构.png)\n* NameNode（NN）是主节点，存储文件的元数据如文件名，文件目录结构，文件属性（生成时间,副本数,文件权限），以及每个文件的块列表和块所在DataNode等。 响应Hadoop客户端请求\n* DataNode（DN）在本地文件系统存储文件块数据，以及块数据的校验和。 \n* Secondary NameNode（SNN） 用来监控HDFS状态的辅助后台程序，每隔一段时间获 取HDFS元数据的快照。\n\n\n#### 1、NameNode\nnamespace：维护整个文件系统的目录树结构及目录树上的状态变化。  \nblockmanager：维护数据块相关信息及数据块的状态变化，\n\n##### A、namespace [命名空间]\n![hadoop](2019-06-28-hadoop/namespace1.jpg)  \n1、目录树常驻内存，会定期生成fsImage文件（快照），方便当NameNode重启后数据恢复。  \n2、目录树文件节点由NodeFile定义，每个NodeFile分割成多个block（BlockInfo的数组），BlockInfo维护的是block的元数据，例如在哪个DataNode等等。  \n\n##### B、BlockManager 【块管理器】\n![hadoop](2019-06-28-hadoop/BlockManager.jpg)    \n1、为了根据blockId快速定位block，使用了BlocksMap来保存。   \n2、blockInfo指向NodeFile中的BlockInfo。   \n3、根据blockId进行hash计算，获取blockInfo在blocksMap中的位置，获取位置后再进行block的获取。  \n\n#### 2、DataNode\n1、存储block信息。  \n2、周期性（1小时）向NN上传所有block信息。   \n3、DN与NN之间有3s每次的心跳信息，若超过10分钟未收到心跳，NN认为该DN无效。   \n\n\n#### 3、Secondary NameNode\n1、通知NN，checkpoint。   \n2、读取NN的fsimage和editlog。  \n3、将两个合并。  \n4、然后将合并结果回传给NN。   \n\n\n\n### 2.2、数据写过程\n![hadoop](2019-06-28-hadoop/文件写入.jpg)    \n\n1、client请求NN获取文件的存储位置。   \n2、client根据client的位置直接与DN连接进行数据传输，数据备份由DN之间通过pipeline进行。   \n\n\n\n### 2.3、数据读过程\n![hadoop](2019-06-28-hadoop/文件读取.jpg)    \n\n\n\n## 3、MapReduce\n\n\n\n\n## 4、YARN\n\n\n## 5、NameNode单点故障问题\n采用HA方案，Namenode可以部署两个：Active NN和Standly NN。在同一时间永远都是只有一个NN对外提供服务的，即Active NN。Active NN并不永远都是一个固定的状态，当Active NN出现故障后，Standly NN就会切换成Active NN提供服务，而之前的Active NN就会变成Standly NN停止位集群服务。\n\n其实就是NameNode和Secondary NameNode\n### 5.1、脑裂问题\n两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信。当active状态的NameNode的命名空间有任何修改时，会告知大部分的JournalNodes进程。\n\n只有standby状态的NameNode才可以对JNS的日志进行操作\n\n\n参考\n[HDFS NameNode内存全景](https://tech.meituan.com/2016/08/26/namenode.html)  \n[原理漫画](https://chu888chu888.gitbooks.io/hadoopstudy/content/Content/3/chapter0302.html)        ","slug":"2019-06-28-hadoop","published":1,"updated":"2024-10-14T09:38:11.902Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnuy000va13kssfnsm5e","content":"<h1 id=\"hadoop\"><a href=\"#hadoop\" class=\"headerlink\" title=\"hadoop\"></a>hadoop</h1><p>分布式文件存储系统</p>\n<h2 id=\"1、hadoop架构图\"><a href=\"#1、hadoop架构图\" class=\"headerlink\" title=\"1、hadoop架构图\"></a>1、hadoop架构图</h2><p><img src=\"/2019/06/28/2019-06-28-hadoop/hadoop-%E6%9E%B6%E6%9E%84.png\" alt=\"hadoop\"></p>\n<ul>\n<li>MapReduce：分布式计算模型</li>\n<li>YARN：任务管理与资源管理调度</li>\n<li>HDFS：Hadoop Distributed File system，分布式文件存储系统</li>\n</ul>\n<a id=\"more\"></a>    \n\n<h2 id=\"2、HDFS\"><a href=\"#2、HDFS\" class=\"headerlink\" title=\"2、HDFS\"></a>2、HDFS</h2><p>Hadoop Distributed File System</p>\n<h3 id=\"2-1、HDFS架构图\"><a href=\"#2-1、HDFS架构图\" class=\"headerlink\" title=\"2.1、HDFS架构图\"></a>2.1、HDFS架构图</h3><p><img src=\"/2019/06/28/2019-06-28-hadoop/hdfs-%E6%9E%B6%E6%9E%84.png\" alt=\"hadoop\"></p>\n<ul>\n<li>NameNode（NN）是主节点，存储文件的元数据如文件名，文件目录结构，文件属性（生成时间,副本数,文件权限），以及每个文件的块列表和块所在DataNode等。 响应Hadoop客户端请求</li>\n<li>DataNode（DN）在本地文件系统存储文件块数据，以及块数据的校验和。 </li>\n<li>Secondary NameNode（SNN） 用来监控HDFS状态的辅助后台程序，每隔一段时间获 取HDFS元数据的快照。</li>\n</ul>\n<h4 id=\"1、NameNode\"><a href=\"#1、NameNode\" class=\"headerlink\" title=\"1、NameNode\"></a>1、NameNode</h4><p>namespace：维护整个文件系统的目录树结构及目录树上的状态变化。<br>blockmanager：维护数据块相关信息及数据块的状态变化，</p>\n<h5 id=\"A、namespace-命名空间\"><a href=\"#A、namespace-命名空间\" class=\"headerlink\" title=\"A、namespace [命名空间]\"></a>A、namespace [命名空间]</h5><p><img src=\"/2019/06/28/2019-06-28-hadoop/namespace1.jpg\" alt=\"hadoop\"><br>1、目录树常驻内存，会定期生成fsImage文件（快照），方便当NameNode重启后数据恢复。<br>2、目录树文件节点由NodeFile定义，每个NodeFile分割成多个block（BlockInfo的数组），BlockInfo维护的是block的元数据，例如在哪个DataNode等等。  </p>\n<h5 id=\"B、BlockManager-【块管理器】\"><a href=\"#B、BlockManager-【块管理器】\" class=\"headerlink\" title=\"B、BlockManager 【块管理器】\"></a>B、BlockManager 【块管理器】</h5><p><img src=\"/2019/06/28/2019-06-28-hadoop/BlockManager.jpg\" alt=\"hadoop\"><br>1、为了根据blockId快速定位block，使用了BlocksMap来保存。<br>2、blockInfo指向NodeFile中的BlockInfo。<br>3、根据blockId进行hash计算，获取blockInfo在blocksMap中的位置，获取位置后再进行block的获取。  </p>\n<h4 id=\"2、DataNode\"><a href=\"#2、DataNode\" class=\"headerlink\" title=\"2、DataNode\"></a>2、DataNode</h4><p>1、存储block信息。<br>2、周期性（1小时）向NN上传所有block信息。<br>3、DN与NN之间有3s每次的心跳信息，若超过10分钟未收到心跳，NN认为该DN无效。   </p>\n<h4 id=\"3、Secondary-NameNode\"><a href=\"#3、Secondary-NameNode\" class=\"headerlink\" title=\"3、Secondary NameNode\"></a>3、Secondary NameNode</h4><p>1、通知NN，checkpoint。<br>2、读取NN的fsimage和editlog。<br>3、将两个合并。<br>4、然后将合并结果回传给NN。   </p>\n<h3 id=\"2-2、数据写过程\"><a href=\"#2-2、数据写过程\" class=\"headerlink\" title=\"2.2、数据写过程\"></a>2.2、数据写过程</h3><p><img src=\"/2019/06/28/2019-06-28-hadoop/%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5.jpg\" alt=\"hadoop\">    </p>\n<p>1、client请求NN获取文件的存储位置。<br>2、client根据client的位置直接与DN连接进行数据传输，数据备份由DN之间通过pipeline进行。   </p>\n<h3 id=\"2-3、数据读过程\"><a href=\"#2-3、数据读过程\" class=\"headerlink\" title=\"2.3、数据读过程\"></a>2.3、数据读过程</h3><p><img src=\"/2019/06/28/2019-06-28-hadoop/%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96.jpg\" alt=\"hadoop\">    </p>\n<h2 id=\"3、MapReduce\"><a href=\"#3、MapReduce\" class=\"headerlink\" title=\"3、MapReduce\"></a>3、MapReduce</h2><h2 id=\"4、YARN\"><a href=\"#4、YARN\" class=\"headerlink\" title=\"4、YARN\"></a>4、YARN</h2><h2 id=\"5、NameNode单点故障问题\"><a href=\"#5、NameNode单点故障问题\" class=\"headerlink\" title=\"5、NameNode单点故障问题\"></a>5、NameNode单点故障问题</h2><p>采用HA方案，Namenode可以部署两个：Active NN和Standly NN。在同一时间永远都是只有一个NN对外提供服务的，即Active NN。Active NN并不永远都是一个固定的状态，当Active NN出现故障后，Standly NN就会切换成Active NN提供服务，而之前的Active NN就会变成Standly NN停止位集群服务。</p>\n<p>其实就是NameNode和Secondary NameNode</p>\n<h3 id=\"5-1、脑裂问题\"><a href=\"#5-1、脑裂问题\" class=\"headerlink\" title=\"5.1、脑裂问题\"></a>5.1、脑裂问题</h3><p>两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信。当active状态的NameNode的命名空间有任何修改时，会告知大部分的JournalNodes进程。</p>\n<p>只有standby状态的NameNode才可以对JNS的日志进行操作</p>\n<p>参考<br><a href=\"https://tech.meituan.com/2016/08/26/namenode.html\" target=\"_blank\" rel=\"noopener\">HDFS NameNode内存全景</a><br><a href=\"https://chu888chu888.gitbooks.io/hadoopstudy/content/Content/3/chapter0302.html\" target=\"_blank\" rel=\"noopener\">原理漫画</a>        </p>\n","site":{"data":{}},"excerpt":"<h1 id=\"hadoop\"><a href=\"#hadoop\" class=\"headerlink\" title=\"hadoop\"></a>hadoop</h1><p>分布式文件存储系统</p>\n<h2 id=\"1、hadoop架构图\"><a href=\"#1、hadoop架构图\" class=\"headerlink\" title=\"1、hadoop架构图\"></a>1、hadoop架构图</h2><p><img src=\"/2019/06/28/2019-06-28-hadoop/hadoop-%E6%9E%B6%E6%9E%84.png\" alt=\"hadoop\"></p>\n<ul>\n<li>MapReduce：分布式计算模型</li>\n<li>YARN：任务管理与资源管理调度</li>\n<li>HDFS：Hadoop Distributed File system，分布式文件存储系统</li>\n</ul>","more":"<h2 id=\"2、HDFS\"><a href=\"#2、HDFS\" class=\"headerlink\" title=\"2、HDFS\"></a>2、HDFS</h2><p>Hadoop Distributed File System</p>\n<h3 id=\"2-1、HDFS架构图\"><a href=\"#2-1、HDFS架构图\" class=\"headerlink\" title=\"2.1、HDFS架构图\"></a>2.1、HDFS架构图</h3><p><img src=\"/2019/06/28/2019-06-28-hadoop/hdfs-%E6%9E%B6%E6%9E%84.png\" alt=\"hadoop\"></p>\n<ul>\n<li>NameNode（NN）是主节点，存储文件的元数据如文件名，文件目录结构，文件属性（生成时间,副本数,文件权限），以及每个文件的块列表和块所在DataNode等。 响应Hadoop客户端请求</li>\n<li>DataNode（DN）在本地文件系统存储文件块数据，以及块数据的校验和。 </li>\n<li>Secondary NameNode（SNN） 用来监控HDFS状态的辅助后台程序，每隔一段时间获 取HDFS元数据的快照。</li>\n</ul>\n<h4 id=\"1、NameNode\"><a href=\"#1、NameNode\" class=\"headerlink\" title=\"1、NameNode\"></a>1、NameNode</h4><p>namespace：维护整个文件系统的目录树结构及目录树上的状态变化。<br>blockmanager：维护数据块相关信息及数据块的状态变化，</p>\n<h5 id=\"A、namespace-命名空间\"><a href=\"#A、namespace-命名空间\" class=\"headerlink\" title=\"A、namespace [命名空间]\"></a>A、namespace [命名空间]</h5><p><img src=\"/2019/06/28/2019-06-28-hadoop/namespace1.jpg\" alt=\"hadoop\"><br>1、目录树常驻内存，会定期生成fsImage文件（快照），方便当NameNode重启后数据恢复。<br>2、目录树文件节点由NodeFile定义，每个NodeFile分割成多个block（BlockInfo的数组），BlockInfo维护的是block的元数据，例如在哪个DataNode等等。  </p>\n<h5 id=\"B、BlockManager-【块管理器】\"><a href=\"#B、BlockManager-【块管理器】\" class=\"headerlink\" title=\"B、BlockManager 【块管理器】\"></a>B、BlockManager 【块管理器】</h5><p><img src=\"/2019/06/28/2019-06-28-hadoop/BlockManager.jpg\" alt=\"hadoop\"><br>1、为了根据blockId快速定位block，使用了BlocksMap来保存。<br>2、blockInfo指向NodeFile中的BlockInfo。<br>3、根据blockId进行hash计算，获取blockInfo在blocksMap中的位置，获取位置后再进行block的获取。  </p>\n<h4 id=\"2、DataNode\"><a href=\"#2、DataNode\" class=\"headerlink\" title=\"2、DataNode\"></a>2、DataNode</h4><p>1、存储block信息。<br>2、周期性（1小时）向NN上传所有block信息。<br>3、DN与NN之间有3s每次的心跳信息，若超过10分钟未收到心跳，NN认为该DN无效。   </p>\n<h4 id=\"3、Secondary-NameNode\"><a href=\"#3、Secondary-NameNode\" class=\"headerlink\" title=\"3、Secondary NameNode\"></a>3、Secondary NameNode</h4><p>1、通知NN，checkpoint。<br>2、读取NN的fsimage和editlog。<br>3、将两个合并。<br>4、然后将合并结果回传给NN。   </p>\n<h3 id=\"2-2、数据写过程\"><a href=\"#2-2、数据写过程\" class=\"headerlink\" title=\"2.2、数据写过程\"></a>2.2、数据写过程</h3><p><img src=\"/2019/06/28/2019-06-28-hadoop/%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5.jpg\" alt=\"hadoop\">    </p>\n<p>1、client请求NN获取文件的存储位置。<br>2、client根据client的位置直接与DN连接进行数据传输，数据备份由DN之间通过pipeline进行。   </p>\n<h3 id=\"2-3、数据读过程\"><a href=\"#2-3、数据读过程\" class=\"headerlink\" title=\"2.3、数据读过程\"></a>2.3、数据读过程</h3><p><img src=\"/2019/06/28/2019-06-28-hadoop/%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96.jpg\" alt=\"hadoop\">    </p>\n<h2 id=\"3、MapReduce\"><a href=\"#3、MapReduce\" class=\"headerlink\" title=\"3、MapReduce\"></a>3、MapReduce</h2><h2 id=\"4、YARN\"><a href=\"#4、YARN\" class=\"headerlink\" title=\"4、YARN\"></a>4、YARN</h2><h2 id=\"5、NameNode单点故障问题\"><a href=\"#5、NameNode单点故障问题\" class=\"headerlink\" title=\"5、NameNode单点故障问题\"></a>5、NameNode单点故障问题</h2><p>采用HA方案，Namenode可以部署两个：Active NN和Standly NN。在同一时间永远都是只有一个NN对外提供服务的，即Active NN。Active NN并不永远都是一个固定的状态，当Active NN出现故障后，Standly NN就会切换成Active NN提供服务，而之前的Active NN就会变成Standly NN停止位集群服务。</p>\n<p>其实就是NameNode和Secondary NameNode</p>\n<h3 id=\"5-1、脑裂问题\"><a href=\"#5-1、脑裂问题\" class=\"headerlink\" title=\"5.1、脑裂问题\"></a>5.1、脑裂问题</h3><p>两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信。当active状态的NameNode的命名空间有任何修改时，会告知大部分的JournalNodes进程。</p>\n<p>只有standby状态的NameNode才可以对JNS的日志进行操作</p>\n<p>参考<br><a href=\"https://tech.meituan.com/2016/08/26/namenode.html\" target=\"_blank\" rel=\"noopener\">HDFS NameNode内存全景</a><br><a href=\"https://chu888chu888.gitbooks.io/hadoopstudy/content/Content/3/chapter0302.html\" target=\"_blank\" rel=\"noopener\">原理漫画</a>        </p>"},{"title":"zookeeper","date":"2019-07-13T12:46:40.000Z","_content":"\n# 一、什么是zk\n分布式服务的协调服务：  \n1、配置管理。  \n2、分布式锁。  \n3、集群选举。  \n4、消息订阅。  \n\n<!--more-->  \n\n# 二、基本架构\n![zk](2019-07-13-zookeeper/zk.png)\n- 一主多从，主服务支持读写，从服务只支持读，客户端写都需要经过主服务。\n\n\n# 三、数据结构\n- 整体结构  \n![zk](2019-07-13-zookeeper/datastruct.png)\n\n> 结构类似于树，每个节点对应的数据结构是znode，每个node的数据最大不能超过1M\n\n- znode  \n![zk](2019-07-13-zookeeper/zknode.png)\n\n> data：存储的是数据信息  \n> ACL：记录了znode的访问权限  \n> stat：znode的元数据，例如事务ID、版本号、时间戳、大小等  \n> child：子节点引用，可以有多个子节点 \n> 节点：节点的数据大小不超过1M，适用于读多写少的情况\n\n- 示例\n![zk](2019-07-13-zookeeper/zknode-example.png)\n\n- znode类型：  \n    - PERSISTENT：持久化节点  \n    - PERSISTENT_SEQUENTIAL：持久化排序节点  \n    - EPHEMERAL：临时节点（一种特殊的znode，只要创建znode的会话处于活跃状态，就会存在；当session结束时，就会删除。在实现分布式锁时非常有用）\n    - EPHEMERAL_SEQUENTIAL：临时排序节点 \n\n- 节点基本操作\n    - create\n    - delete\n    - setData\n    - exists：读操作\n    - getData：读操作\n    - getChildren：读操作\n    - 读操作，可以选择设置watch\n    - 写操作，会触发相应节点注册的watch\n    \n- 应用\n    - 分组管理：path结构\n    - 统一命名：sequential\n    - 同步：临时节点\n\n\n# 四、数据一致性和高可用\n采用了ZAB协议（zookeeper atomic broadcast：原子广播协议），这种协议非常类似于一致性协议paxos和raft。  \n首先了解三种状态：\n- 1、looking：选举状态\n- 2、following：follwer（从节点）的状态\n- 3、leading：leader（主节点）的状态  \n\n最大ZXID的概念：就是当前节点的最新事务编号  \n- 1、ZXID=epoch+计数，由这两部分组成.高32位是epoch，低32位是epoch内的自增id\n- 2、epoch：纪元的意思，选举阶段会发送自己的epoch并与接收的epoch对比，若自身的小则重新发送并携带已知最大的epoch。\n\n\n## 4.1、集群故障恢复：\n***两种情况：***  \n1、Leader节点运行后会周期性地向Follower发送心跳信息（称之为ping），如果一个Follower未收到Leader节点的心跳信息，Follower节点的状态会从FOLLOWING转变为LOOKING，此时该follower会发起重新选主。  \n2、leader会检测follower返回的节点状态，若多数节点状态未响应，此时需要重新发起选主。\n### 一、选举阶段\n**步骤一：**  \n![zk](2019-07-13-zookeeper/选举1.png)\n> 1、每个server发出一个投票，格式：（myid, zxid）= （机器编号，ZXID）  \n> 2、节点1比对节点2和节点3的投票都小于自身，此时不做处理。  \n> 3、节点2判断发现节点1比自己大、节点3比自己小，将重新投票  \n> 4、节点3判断发现节点1比自己大、节点2比自己大，将重新投票，给最大的投票 \n \n**步骤二：**  \n![zk](2019-07-13-zookeeper/选举2.png)\n> 1、节点2、节点3重新投票，投票给1  \n> 2、开始统计投票，节点1收到半数的投票，此时为leader，其他的变更为follower  \n\n\n### 二、发现阶段\n发现阶段，用于在从节点中发现最新的ZXID和事务日志。或许有人会问：既然Leader被选为主节点，已经是集群里数据最新的了，为什么还要从节点中寻找最新事务呢？\n这是为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。\n\n所以这一阶段，Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。\n\n各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。\n\n### 三、同步阶段\n同步阶段，把Leader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。\n\n***自此，故障恢复正式完成。***\n\n## 4.2、数据一致性\n当更新节点，zk是如果保证所有节点的数据一致？\n\n> 写入数据，就涉及到了ZAB协议的Broadcast广播阶段。\n\nBroadcast过程如下：\n  \n    1、客户端发出写入数据请求给任意Follower。\n    2、Follower把写入数据请求转发给Leader。\n    3、Leader采用二阶段提交方式，先发送Propose广播给Follower。\n    4、Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader。\n    5、Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower。\n\n# 五、watch机制\n![zk](2019-07-13-zookeeper/watch.png)\n\n***watch类型：***  \nzk状态的watch 事件:\n```\nKeeperState:\n    Unknown (-1),\n    Disconnected (0),\n    SyncConnected (3),\n    AuthFailed (4),\n    ConnectedReadOnly (5),\n    SaslAuthenticated(6),\n    Expired (-112);\n```\nzk节点的watch 事件：\n```\nEventType\n    None (-1),\n    NodeCreated (1),\n    NodeDeleted (2),\n    NodeDataChanged (3),\n    NodeChildrenChanged (4);\n```\n\n***整体流程：***  \n客户端将watch注册到服务器，并将该watch保存至当前客户端的watchManager中。当服务器发现数据节点发生变更，则通知客户端，此时客户端接收消息后会调用watchManager中的相应watch进行相应逻辑处理。\n\n> 客户端watch管理器（ZKWatchManager），数据结构：\n```\n//ZKWatchManager维护了三个map，key代表数据节点的绝对路径，value代表注册在当前节点上的watcher集合\n//代表节点上内容数据、状态信息变更相关监听\nprivate final Map<String, Set<Watcher>> dataWatches =\n    new HashMap<String, Set<Watcher>>();\n//代表节点变更相关监听\nprivate final Map<String, Set<Watcher>> existWatches =\n    new HashMap<String, Set<Watcher>>();\n//代表节点子列表变更相关监听\nprivate final Map<String, Set<Watcher>> childWatches =\n    new HashMap<String, Set<Watcher>>();\n```\n> 服务端watch管理器（WatchManager），数据结构：\n```\n//WatchManager维护了两个map\n//说明：WatchManager中的Watcher对象不是客户端用户定义的Watcher，\n//     而是服务端中实现了Watcher接口的ServerCnxn抽象类，\n//     该抽象类代表了一个客户端与服务端的连接\n\n//key代表数据节点路径，value代表客户端连接的集合，该map作用为：\n//通过一个指定znode路径可找到其映射的所有客户端，当znode发生变更时\n//可快速通知所有注册了当前Watcher的客户端\nprivate final HashMap<String, HashSet<Watcher>> watchTable =\n    new HashMap<String, HashSet<Watcher>>();\n\n//key代表一个客户端与服务端的连接，value代表当前客户端监听的所有数据节点路径\n//该map作用为：当一个连接彻底断开时，可快速找到当前连接对应的所有\n//注册了监听的节点，以便移除当前客户端对节点的Watcher\nprivate final HashMap<Watcher, HashSet<String>> watch2Paths =\n    new HashMap<Watcher, HashSet<String>>();\n```\n> 注册过程\n\n![zk](2019-07-13-zookeeper/注册过程.png)\n\n# 六、分布式锁\n\n## 6.1 使用\"临时\"实现\n利用同级节点唯一性，多个进程去zk创建相同名称的节点，只有一个能够成功，创建失败的通过zk的watch机制监听节点的状态，一但监听到节点删除事件，会再次触发所有进程的写锁，这里会有惊群效应，会影响到性能。\n\n\n## 6.2 使用\"临时有序节点\"实现\n***思想图：***  \n![zk](2019-07-13-zookeeper/分布式锁.png)\n\n    总体思想：\n    1、每个客户端都去创建临时节点，等待创建callBack\n    2、创建成功callBack，此时去获取锁目录下的节点数量，等待获取数据的callBack\n    3、数据返回callBack，对数据进行排序，判断当前节点大小\n    4、若当前节点是第一个，则代表获得了锁；否则，监听前一个节点，添加watch（解决惊群问题）\n    5、监听到watch事件，则继续循环获取节点列表。\n\n***实现图：***\n![zk](2019-07-13-zookeeper/实现分布式锁流程.png)\n\n    1、zk.create，等待callBack ---> \n    2、然后获得所有节点，等待callBack; callBack返回后，去节点排序--->\n    3、然后判断当前节点的大小，若是第一个，则获取到了锁，执行业务代码；否则监听前一个节点 --->\n    4、然后循环去判断当前节点所处的位置。\n\n***代码实现：***\n```\n//Children2Callback\n@Override\npublic void processResult(int rc, String path, Object ctx, List<String> children, Stat stat) {\n    //获得所目录的所有有序节点，然后排序，然后取自己在有序list中的index\n    if (children == null) {\n        System.out.println(ctx.toString() + \"list null\");\n    } else {\n        try {\n            Collections.sort(children);\n            int i = children.indexOf(lockName);\n            if (i < 1) {\n                System.out.println(threadName + \" i am first...\");\n                zk.setData(\"/\", threadName.getBytes(), -1);\n                cc.countDown();\n            } else {\n                System.out.println(threadName + \" watch \" + children.get(i - 1));\n                //监听前一个节点，关注前一个的删除事件\n                zk.exists(\"/\" + children.get(i - 1), this);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n","source":"_posts/2019-07-13-zookeeper.md","raw":"---\ntitle: zookeeper\ndate: 2019-07-13 20:46:40\ntags:\n---\n\n# 一、什么是zk\n分布式服务的协调服务：  \n1、配置管理。  \n2、分布式锁。  \n3、集群选举。  \n4、消息订阅。  \n\n<!--more-->  \n\n# 二、基本架构\n![zk](2019-07-13-zookeeper/zk.png)\n- 一主多从，主服务支持读写，从服务只支持读，客户端写都需要经过主服务。\n\n\n# 三、数据结构\n- 整体结构  \n![zk](2019-07-13-zookeeper/datastruct.png)\n\n> 结构类似于树，每个节点对应的数据结构是znode，每个node的数据最大不能超过1M\n\n- znode  \n![zk](2019-07-13-zookeeper/zknode.png)\n\n> data：存储的是数据信息  \n> ACL：记录了znode的访问权限  \n> stat：znode的元数据，例如事务ID、版本号、时间戳、大小等  \n> child：子节点引用，可以有多个子节点 \n> 节点：节点的数据大小不超过1M，适用于读多写少的情况\n\n- 示例\n![zk](2019-07-13-zookeeper/zknode-example.png)\n\n- znode类型：  \n    - PERSISTENT：持久化节点  \n    - PERSISTENT_SEQUENTIAL：持久化排序节点  \n    - EPHEMERAL：临时节点（一种特殊的znode，只要创建znode的会话处于活跃状态，就会存在；当session结束时，就会删除。在实现分布式锁时非常有用）\n    - EPHEMERAL_SEQUENTIAL：临时排序节点 \n\n- 节点基本操作\n    - create\n    - delete\n    - setData\n    - exists：读操作\n    - getData：读操作\n    - getChildren：读操作\n    - 读操作，可以选择设置watch\n    - 写操作，会触发相应节点注册的watch\n    \n- 应用\n    - 分组管理：path结构\n    - 统一命名：sequential\n    - 同步：临时节点\n\n\n# 四、数据一致性和高可用\n采用了ZAB协议（zookeeper atomic broadcast：原子广播协议），这种协议非常类似于一致性协议paxos和raft。  \n首先了解三种状态：\n- 1、looking：选举状态\n- 2、following：follwer（从节点）的状态\n- 3、leading：leader（主节点）的状态  \n\n最大ZXID的概念：就是当前节点的最新事务编号  \n- 1、ZXID=epoch+计数，由这两部分组成.高32位是epoch，低32位是epoch内的自增id\n- 2、epoch：纪元的意思，选举阶段会发送自己的epoch并与接收的epoch对比，若自身的小则重新发送并携带已知最大的epoch。\n\n\n## 4.1、集群故障恢复：\n***两种情况：***  \n1、Leader节点运行后会周期性地向Follower发送心跳信息（称之为ping），如果一个Follower未收到Leader节点的心跳信息，Follower节点的状态会从FOLLOWING转变为LOOKING，此时该follower会发起重新选主。  \n2、leader会检测follower返回的节点状态，若多数节点状态未响应，此时需要重新发起选主。\n### 一、选举阶段\n**步骤一：**  \n![zk](2019-07-13-zookeeper/选举1.png)\n> 1、每个server发出一个投票，格式：（myid, zxid）= （机器编号，ZXID）  \n> 2、节点1比对节点2和节点3的投票都小于自身，此时不做处理。  \n> 3、节点2判断发现节点1比自己大、节点3比自己小，将重新投票  \n> 4、节点3判断发现节点1比自己大、节点2比自己大，将重新投票，给最大的投票 \n \n**步骤二：**  \n![zk](2019-07-13-zookeeper/选举2.png)\n> 1、节点2、节点3重新投票，投票给1  \n> 2、开始统计投票，节点1收到半数的投票，此时为leader，其他的变更为follower  \n\n\n### 二、发现阶段\n发现阶段，用于在从节点中发现最新的ZXID和事务日志。或许有人会问：既然Leader被选为主节点，已经是集群里数据最新的了，为什么还要从节点中寻找最新事务呢？\n这是为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。\n\n所以这一阶段，Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。\n\n各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。\n\n### 三、同步阶段\n同步阶段，把Leader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。\n\n***自此，故障恢复正式完成。***\n\n## 4.2、数据一致性\n当更新节点，zk是如果保证所有节点的数据一致？\n\n> 写入数据，就涉及到了ZAB协议的Broadcast广播阶段。\n\nBroadcast过程如下：\n  \n    1、客户端发出写入数据请求给任意Follower。\n    2、Follower把写入数据请求转发给Leader。\n    3、Leader采用二阶段提交方式，先发送Propose广播给Follower。\n    4、Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader。\n    5、Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower。\n\n# 五、watch机制\n![zk](2019-07-13-zookeeper/watch.png)\n\n***watch类型：***  \nzk状态的watch 事件:\n```\nKeeperState:\n    Unknown (-1),\n    Disconnected (0),\n    SyncConnected (3),\n    AuthFailed (4),\n    ConnectedReadOnly (5),\n    SaslAuthenticated(6),\n    Expired (-112);\n```\nzk节点的watch 事件：\n```\nEventType\n    None (-1),\n    NodeCreated (1),\n    NodeDeleted (2),\n    NodeDataChanged (3),\n    NodeChildrenChanged (4);\n```\n\n***整体流程：***  \n客户端将watch注册到服务器，并将该watch保存至当前客户端的watchManager中。当服务器发现数据节点发生变更，则通知客户端，此时客户端接收消息后会调用watchManager中的相应watch进行相应逻辑处理。\n\n> 客户端watch管理器（ZKWatchManager），数据结构：\n```\n//ZKWatchManager维护了三个map，key代表数据节点的绝对路径，value代表注册在当前节点上的watcher集合\n//代表节点上内容数据、状态信息变更相关监听\nprivate final Map<String, Set<Watcher>> dataWatches =\n    new HashMap<String, Set<Watcher>>();\n//代表节点变更相关监听\nprivate final Map<String, Set<Watcher>> existWatches =\n    new HashMap<String, Set<Watcher>>();\n//代表节点子列表变更相关监听\nprivate final Map<String, Set<Watcher>> childWatches =\n    new HashMap<String, Set<Watcher>>();\n```\n> 服务端watch管理器（WatchManager），数据结构：\n```\n//WatchManager维护了两个map\n//说明：WatchManager中的Watcher对象不是客户端用户定义的Watcher，\n//     而是服务端中实现了Watcher接口的ServerCnxn抽象类，\n//     该抽象类代表了一个客户端与服务端的连接\n\n//key代表数据节点路径，value代表客户端连接的集合，该map作用为：\n//通过一个指定znode路径可找到其映射的所有客户端，当znode发生变更时\n//可快速通知所有注册了当前Watcher的客户端\nprivate final HashMap<String, HashSet<Watcher>> watchTable =\n    new HashMap<String, HashSet<Watcher>>();\n\n//key代表一个客户端与服务端的连接，value代表当前客户端监听的所有数据节点路径\n//该map作用为：当一个连接彻底断开时，可快速找到当前连接对应的所有\n//注册了监听的节点，以便移除当前客户端对节点的Watcher\nprivate final HashMap<Watcher, HashSet<String>> watch2Paths =\n    new HashMap<Watcher, HashSet<String>>();\n```\n> 注册过程\n\n![zk](2019-07-13-zookeeper/注册过程.png)\n\n# 六、分布式锁\n\n## 6.1 使用\"临时\"实现\n利用同级节点唯一性，多个进程去zk创建相同名称的节点，只有一个能够成功，创建失败的通过zk的watch机制监听节点的状态，一但监听到节点删除事件，会再次触发所有进程的写锁，这里会有惊群效应，会影响到性能。\n\n\n## 6.2 使用\"临时有序节点\"实现\n***思想图：***  \n![zk](2019-07-13-zookeeper/分布式锁.png)\n\n    总体思想：\n    1、每个客户端都去创建临时节点，等待创建callBack\n    2、创建成功callBack，此时去获取锁目录下的节点数量，等待获取数据的callBack\n    3、数据返回callBack，对数据进行排序，判断当前节点大小\n    4、若当前节点是第一个，则代表获得了锁；否则，监听前一个节点，添加watch（解决惊群问题）\n    5、监听到watch事件，则继续循环获取节点列表。\n\n***实现图：***\n![zk](2019-07-13-zookeeper/实现分布式锁流程.png)\n\n    1、zk.create，等待callBack ---> \n    2、然后获得所有节点，等待callBack; callBack返回后，去节点排序--->\n    3、然后判断当前节点的大小，若是第一个，则获取到了锁，执行业务代码；否则监听前一个节点 --->\n    4、然后循环去判断当前节点所处的位置。\n\n***代码实现：***\n```\n//Children2Callback\n@Override\npublic void processResult(int rc, String path, Object ctx, List<String> children, Stat stat) {\n    //获得所目录的所有有序节点，然后排序，然后取自己在有序list中的index\n    if (children == null) {\n        System.out.println(ctx.toString() + \"list null\");\n    } else {\n        try {\n            Collections.sort(children);\n            int i = children.indexOf(lockName);\n            if (i < 1) {\n                System.out.println(threadName + \" i am first...\");\n                zk.setData(\"/\", threadName.getBytes(), -1);\n                cc.countDown();\n            } else {\n                System.out.println(threadName + \" watch \" + children.get(i - 1));\n                //监听前一个节点，关注前一个的删除事件\n                zk.exists(\"/\" + children.get(i - 1), this);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n","slug":"2019-07-13-zookeeper","published":1,"updated":"2024-10-14T09:38:11.945Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnv5000za13kuwd0pacs","content":"<h1 id=\"一、什么是zk\"><a href=\"#一、什么是zk\" class=\"headerlink\" title=\"一、什么是zk\"></a>一、什么是zk</h1><p>分布式服务的协调服务：<br>1、配置管理。<br>2、分布式锁。<br>3、集群选举。<br>4、消息订阅。  </p>\n<a id=\"more\"></a>  \n\n<h1 id=\"二、基本架构\"><a href=\"#二、基本架构\" class=\"headerlink\" title=\"二、基本架构\"></a>二、基本架构</h1><p><img src=\"/2019/07/13/2019-07-13-zookeeper/zk.png\" alt=\"zk\"></p>\n<ul>\n<li>一主多从，主服务支持读写，从服务只支持读，客户端写都需要经过主服务。</li>\n</ul>\n<h1 id=\"三、数据结构\"><a href=\"#三、数据结构\" class=\"headerlink\" title=\"三、数据结构\"></a>三、数据结构</h1><ul>\n<li>整体结构<br><img src=\"/2019/07/13/2019-07-13-zookeeper/datastruct.png\" alt=\"zk\"></li>\n</ul>\n<blockquote>\n<p>结构类似于树，每个节点对应的数据结构是znode，每个node的数据最大不能超过1M</p>\n</blockquote>\n<ul>\n<li>znode<br><img src=\"/2019/07/13/2019-07-13-zookeeper/zknode.png\" alt=\"zk\"></li>\n</ul>\n<blockquote>\n<p>data：存储的是数据信息<br>ACL：记录了znode的访问权限<br>stat：znode的元数据，例如事务ID、版本号、时间戳、大小等<br>child：子节点引用，可以有多个子节点<br>节点：节点的数据大小不超过1M，适用于读多写少的情况</p>\n</blockquote>\n<ul>\n<li><p>示例<br><img src=\"/2019/07/13/2019-07-13-zookeeper/zknode-example.png\" alt=\"zk\"></p>\n</li>\n<li><p>znode类型：  </p>\n<ul>\n<li>PERSISTENT：持久化节点  </li>\n<li>PERSISTENT_SEQUENTIAL：持久化排序节点  </li>\n<li>EPHEMERAL：临时节点（一种特殊的znode，只要创建znode的会话处于活跃状态，就会存在；当session结束时，就会删除。在实现分布式锁时非常有用）</li>\n<li>EPHEMERAL_SEQUENTIAL：临时排序节点 </li>\n</ul>\n</li>\n<li><p>节点基本操作</p>\n<ul>\n<li>create</li>\n<li>delete</li>\n<li>setData</li>\n<li>exists：读操作</li>\n<li>getData：读操作</li>\n<li>getChildren：读操作</li>\n<li>读操作，可以选择设置watch</li>\n<li>写操作，会触发相应节点注册的watch</li>\n</ul>\n</li>\n<li><p>应用</p>\n<ul>\n<li>分组管理：path结构</li>\n<li>统一命名：sequential</li>\n<li>同步：临时节点</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"四、数据一致性和高可用\"><a href=\"#四、数据一致性和高可用\" class=\"headerlink\" title=\"四、数据一致性和高可用\"></a>四、数据一致性和高可用</h1><p>采用了ZAB协议（zookeeper atomic broadcast：原子广播协议），这种协议非常类似于一致性协议paxos和raft。<br>首先了解三种状态：</p>\n<ul>\n<li>1、looking：选举状态</li>\n<li>2、following：follwer（从节点）的状态</li>\n<li>3、leading：leader（主节点）的状态  </li>\n</ul>\n<p>最大ZXID的概念：就是当前节点的最新事务编号  </p>\n<ul>\n<li>1、ZXID=epoch+计数，由这两部分组成.高32位是epoch，低32位是epoch内的自增id</li>\n<li>2、epoch：纪元的意思，选举阶段会发送自己的epoch并与接收的epoch对比，若自身的小则重新发送并携带已知最大的epoch。</li>\n</ul>\n<h2 id=\"4-1、集群故障恢复：\"><a href=\"#4-1、集群故障恢复：\" class=\"headerlink\" title=\"4.1、集群故障恢复：\"></a>4.1、集群故障恢复：</h2><p><strong><em>两种情况：</em></strong><br>1、Leader节点运行后会周期性地向Follower发送心跳信息（称之为ping），如果一个Follower未收到Leader节点的心跳信息，Follower节点的状态会从FOLLOWING转变为LOOKING，此时该follower会发起重新选主。<br>2、leader会检测follower返回的节点状态，若多数节点状态未响应，此时需要重新发起选主。</p>\n<h3 id=\"一、选举阶段\"><a href=\"#一、选举阶段\" class=\"headerlink\" title=\"一、选举阶段\"></a>一、选举阶段</h3><p><strong>步骤一：</strong><br><img src=\"/2019/07/13/2019-07-13-zookeeper/%E9%80%89%E4%B8%BE1.png\" alt=\"zk\"></p>\n<blockquote>\n<p>1、每个server发出一个投票，格式：（myid, zxid）= （机器编号，ZXID）<br>2、节点1比对节点2和节点3的投票都小于自身，此时不做处理。<br>3、节点2判断发现节点1比自己大、节点3比自己小，将重新投票<br>4、节点3判断发现节点1比自己大、节点2比自己大，将重新投票，给最大的投票 </p>\n</blockquote>\n<p><strong>步骤二：</strong><br><img src=\"/2019/07/13/2019-07-13-zookeeper/%E9%80%89%E4%B8%BE2.png\" alt=\"zk\"></p>\n<blockquote>\n<p>1、节点2、节点3重新投票，投票给1<br>2、开始统计投票，节点1收到半数的投票，此时为leader，其他的变更为follower  </p>\n</blockquote>\n<h3 id=\"二、发现阶段\"><a href=\"#二、发现阶段\" class=\"headerlink\" title=\"二、发现阶段\"></a>二、发现阶段</h3><p>发现阶段，用于在从节点中发现最新的ZXID和事务日志。或许有人会问：既然Leader被选为主节点，已经是集群里数据最新的了，为什么还要从节点中寻找最新事务呢？<br>这是为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。</p>\n<p>所以这一阶段，Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。</p>\n<p>各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。</p>\n<h3 id=\"三、同步阶段\"><a href=\"#三、同步阶段\" class=\"headerlink\" title=\"三、同步阶段\"></a>三、同步阶段</h3><p>同步阶段，把Leader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。</p>\n<p><strong><em>自此，故障恢复正式完成。</em></strong></p>\n<h2 id=\"4-2、数据一致性\"><a href=\"#4-2、数据一致性\" class=\"headerlink\" title=\"4.2、数据一致性\"></a>4.2、数据一致性</h2><p>当更新节点，zk是如果保证所有节点的数据一致？</p>\n<blockquote>\n<p>写入数据，就涉及到了ZAB协议的Broadcast广播阶段。</p>\n</blockquote>\n<p>Broadcast过程如下：</p>\n<pre><code>1、客户端发出写入数据请求给任意Follower。\n2、Follower把写入数据请求转发给Leader。\n3、Leader采用二阶段提交方式，先发送Propose广播给Follower。\n4、Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader。\n5、Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower。</code></pre><h1 id=\"五、watch机制\"><a href=\"#五、watch机制\" class=\"headerlink\" title=\"五、watch机制\"></a>五、watch机制</h1><p><img src=\"/2019/07/13/2019-07-13-zookeeper/watch.png\" alt=\"zk\"></p>\n<p><strong><em>watch类型：</em></strong><br>zk状态的watch 事件:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">KeeperState:</span><br><span class=\"line\">    Unknown (-1),</span><br><span class=\"line\">    Disconnected (0),</span><br><span class=\"line\">    SyncConnected (3),</span><br><span class=\"line\">    AuthFailed (4),</span><br><span class=\"line\">    ConnectedReadOnly (5),</span><br><span class=\"line\">    SaslAuthenticated(6),</span><br><span class=\"line\">    Expired (-112);</span><br></pre></td></tr></table></figure>\n\n<p>zk节点的watch 事件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EventType</span><br><span class=\"line\">    None (-1),</span><br><span class=\"line\">    NodeCreated (1),</span><br><span class=\"line\">    NodeDeleted (2),</span><br><span class=\"line\">    NodeDataChanged (3),</span><br><span class=\"line\">    NodeChildrenChanged (4);</span><br></pre></td></tr></table></figure>\n\n<p><strong><em>整体流程：</em></strong><br>客户端将watch注册到服务器，并将该watch保存至当前客户端的watchManager中。当服务器发现数据节点发生变更，则通知客户端，此时客户端接收消息后会调用watchManager中的相应watch进行相应逻辑处理。</p>\n<blockquote>\n<p>客户端watch管理器（ZKWatchManager），数据结构：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//ZKWatchManager维护了三个map，key代表数据节点的绝对路径，value代表注册在当前节点上的watcher集合</span><br><span class=\"line\">//代表节点上内容数据、状态信息变更相关监听</span><br><span class=\"line\">private final Map&lt;String, Set&lt;Watcher&gt;&gt; dataWatches =</span><br><span class=\"line\">    new HashMap&lt;String, Set&lt;Watcher&gt;&gt;();</span><br><span class=\"line\">//代表节点变更相关监听</span><br><span class=\"line\">private final Map&lt;String, Set&lt;Watcher&gt;&gt; existWatches =</span><br><span class=\"line\">    new HashMap&lt;String, Set&lt;Watcher&gt;&gt;();</span><br><span class=\"line\">//代表节点子列表变更相关监听</span><br><span class=\"line\">private final Map&lt;String, Set&lt;Watcher&gt;&gt; childWatches =</span><br><span class=\"line\">    new HashMap&lt;String, Set&lt;Watcher&gt;&gt;();</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>服务端watch管理器（WatchManager），数据结构：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//WatchManager维护了两个map</span><br><span class=\"line\">//说明：WatchManager中的Watcher对象不是客户端用户定义的Watcher，</span><br><span class=\"line\">//     而是服务端中实现了Watcher接口的ServerCnxn抽象类，</span><br><span class=\"line\">//     该抽象类代表了一个客户端与服务端的连接</span><br><span class=\"line\"></span><br><span class=\"line\">//key代表数据节点路径，value代表客户端连接的集合，该map作用为：</span><br><span class=\"line\">//通过一个指定znode路径可找到其映射的所有客户端，当znode发生变更时</span><br><span class=\"line\">//可快速通知所有注册了当前Watcher的客户端</span><br><span class=\"line\">private final HashMap&lt;String, HashSet&lt;Watcher&gt;&gt; watchTable =</span><br><span class=\"line\">    new HashMap&lt;String, HashSet&lt;Watcher&gt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">//key代表一个客户端与服务端的连接，value代表当前客户端监听的所有数据节点路径</span><br><span class=\"line\">//该map作用为：当一个连接彻底断开时，可快速找到当前连接对应的所有</span><br><span class=\"line\">//注册了监听的节点，以便移除当前客户端对节点的Watcher</span><br><span class=\"line\">private final HashMap&lt;Watcher, HashSet&lt;String&gt;&gt; watch2Paths =</span><br><span class=\"line\">    new HashMap&lt;Watcher, HashSet&lt;String&gt;&gt;();</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>注册过程</p>\n</blockquote>\n<p><img src=\"/2019/07/13/2019-07-13-zookeeper/%E6%B3%A8%E5%86%8C%E8%BF%87%E7%A8%8B.png\" alt=\"zk\"></p>\n<h1 id=\"六、分布式锁\"><a href=\"#六、分布式锁\" class=\"headerlink\" title=\"六、分布式锁\"></a>六、分布式锁</h1><h2 id=\"6-1-使用”临时”实现\"><a href=\"#6-1-使用”临时”实现\" class=\"headerlink\" title=\"6.1 使用”临时”实现\"></a>6.1 使用”临时”实现</h2><p>利用同级节点唯一性，多个进程去zk创建相同名称的节点，只有一个能够成功，创建失败的通过zk的watch机制监听节点的状态，一但监听到节点删除事件，会再次触发所有进程的写锁，这里会有惊群效应，会影响到性能。</p>\n<h2 id=\"6-2-使用”临时有序节点”实现\"><a href=\"#6-2-使用”临时有序节点”实现\" class=\"headerlink\" title=\"6.2 使用”临时有序节点”实现\"></a>6.2 使用”临时有序节点”实现</h2><p><strong><em>思想图：</em></strong><br><img src=\"/2019/07/13/2019-07-13-zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.png\" alt=\"zk\"></p>\n<pre><code>总体思想：\n1、每个客户端都去创建临时节点，等待创建callBack\n2、创建成功callBack，此时去获取锁目录下的节点数量，等待获取数据的callBack\n3、数据返回callBack，对数据进行排序，判断当前节点大小\n4、若当前节点是第一个，则代表获得了锁；否则，监听前一个节点，添加watch（解决惊群问题）\n5、监听到watch事件，则继续循环获取节点列表。</code></pre><p><strong><em>实现图：</em></strong><br><img src=\"/2019/07/13/2019-07-13-zookeeper/%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%B5%81%E7%A8%8B.png\" alt=\"zk\"></p>\n<pre><code>1、zk.create，等待callBack ---&gt; \n2、然后获得所有节点，等待callBack; callBack返回后，去节点排序---&gt;\n3、然后判断当前节点的大小，若是第一个，则获取到了锁，执行业务代码；否则监听前一个节点 ---&gt;\n4、然后循环去判断当前节点所处的位置。</code></pre><p><strong><em>代码实现：</em></strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//Children2Callback</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public void processResult(int rc, String path, Object ctx, List&lt;String&gt; children, Stat stat) &#123;</span><br><span class=\"line\">    //获得所目录的所有有序节点，然后排序，然后取自己在有序list中的index</span><br><span class=\"line\">    if (children == null) &#123;</span><br><span class=\"line\">        System.out.println(ctx.toString() + &quot;list null&quot;);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            Collections.sort(children);</span><br><span class=\"line\">            int i = children.indexOf(lockName);</span><br><span class=\"line\">            if (i &lt; 1) &#123;</span><br><span class=\"line\">                System.out.println(threadName + &quot; i am first...&quot;);</span><br><span class=\"line\">                zk.setData(&quot;/&quot;, threadName.getBytes(), -1);</span><br><span class=\"line\">                cc.countDown();</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                System.out.println(threadName + &quot; watch &quot; + children.get(i - 1));</span><br><span class=\"line\">                //监听前一个节点，关注前一个的删除事件</span><br><span class=\"line\">                zk.exists(&quot;/&quot; + children.get(i - 1), this);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; catch (Exception e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<h1 id=\"一、什么是zk\"><a href=\"#一、什么是zk\" class=\"headerlink\" title=\"一、什么是zk\"></a>一、什么是zk</h1><p>分布式服务的协调服务：<br>1、配置管理。<br>2、分布式锁。<br>3、集群选举。<br>4、消息订阅。  </p>","more":"<h1 id=\"二、基本架构\"><a href=\"#二、基本架构\" class=\"headerlink\" title=\"二、基本架构\"></a>二、基本架构</h1><p><img src=\"/2019/07/13/2019-07-13-zookeeper/zk.png\" alt=\"zk\"></p>\n<ul>\n<li>一主多从，主服务支持读写，从服务只支持读，客户端写都需要经过主服务。</li>\n</ul>\n<h1 id=\"三、数据结构\"><a href=\"#三、数据结构\" class=\"headerlink\" title=\"三、数据结构\"></a>三、数据结构</h1><ul>\n<li>整体结构<br><img src=\"/2019/07/13/2019-07-13-zookeeper/datastruct.png\" alt=\"zk\"></li>\n</ul>\n<blockquote>\n<p>结构类似于树，每个节点对应的数据结构是znode，每个node的数据最大不能超过1M</p>\n</blockquote>\n<ul>\n<li>znode<br><img src=\"/2019/07/13/2019-07-13-zookeeper/zknode.png\" alt=\"zk\"></li>\n</ul>\n<blockquote>\n<p>data：存储的是数据信息<br>ACL：记录了znode的访问权限<br>stat：znode的元数据，例如事务ID、版本号、时间戳、大小等<br>child：子节点引用，可以有多个子节点<br>节点：节点的数据大小不超过1M，适用于读多写少的情况</p>\n</blockquote>\n<ul>\n<li><p>示例<br><img src=\"/2019/07/13/2019-07-13-zookeeper/zknode-example.png\" alt=\"zk\"></p>\n</li>\n<li><p>znode类型：  </p>\n<ul>\n<li>PERSISTENT：持久化节点  </li>\n<li>PERSISTENT_SEQUENTIAL：持久化排序节点  </li>\n<li>EPHEMERAL：临时节点（一种特殊的znode，只要创建znode的会话处于活跃状态，就会存在；当session结束时，就会删除。在实现分布式锁时非常有用）</li>\n<li>EPHEMERAL_SEQUENTIAL：临时排序节点 </li>\n</ul>\n</li>\n<li><p>节点基本操作</p>\n<ul>\n<li>create</li>\n<li>delete</li>\n<li>setData</li>\n<li>exists：读操作</li>\n<li>getData：读操作</li>\n<li>getChildren：读操作</li>\n<li>读操作，可以选择设置watch</li>\n<li>写操作，会触发相应节点注册的watch</li>\n</ul>\n</li>\n<li><p>应用</p>\n<ul>\n<li>分组管理：path结构</li>\n<li>统一命名：sequential</li>\n<li>同步：临时节点</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"四、数据一致性和高可用\"><a href=\"#四、数据一致性和高可用\" class=\"headerlink\" title=\"四、数据一致性和高可用\"></a>四、数据一致性和高可用</h1><p>采用了ZAB协议（zookeeper atomic broadcast：原子广播协议），这种协议非常类似于一致性协议paxos和raft。<br>首先了解三种状态：</p>\n<ul>\n<li>1、looking：选举状态</li>\n<li>2、following：follwer（从节点）的状态</li>\n<li>3、leading：leader（主节点）的状态  </li>\n</ul>\n<p>最大ZXID的概念：就是当前节点的最新事务编号  </p>\n<ul>\n<li>1、ZXID=epoch+计数，由这两部分组成.高32位是epoch，低32位是epoch内的自增id</li>\n<li>2、epoch：纪元的意思，选举阶段会发送自己的epoch并与接收的epoch对比，若自身的小则重新发送并携带已知最大的epoch。</li>\n</ul>\n<h2 id=\"4-1、集群故障恢复：\"><a href=\"#4-1、集群故障恢复：\" class=\"headerlink\" title=\"4.1、集群故障恢复：\"></a>4.1、集群故障恢复：</h2><p><strong><em>两种情况：</em></strong><br>1、Leader节点运行后会周期性地向Follower发送心跳信息（称之为ping），如果一个Follower未收到Leader节点的心跳信息，Follower节点的状态会从FOLLOWING转变为LOOKING，此时该follower会发起重新选主。<br>2、leader会检测follower返回的节点状态，若多数节点状态未响应，此时需要重新发起选主。</p>\n<h3 id=\"一、选举阶段\"><a href=\"#一、选举阶段\" class=\"headerlink\" title=\"一、选举阶段\"></a>一、选举阶段</h3><p><strong>步骤一：</strong><br><img src=\"/2019/07/13/2019-07-13-zookeeper/%E9%80%89%E4%B8%BE1.png\" alt=\"zk\"></p>\n<blockquote>\n<p>1、每个server发出一个投票，格式：（myid, zxid）= （机器编号，ZXID）<br>2、节点1比对节点2和节点3的投票都小于自身，此时不做处理。<br>3、节点2判断发现节点1比自己大、节点3比自己小，将重新投票<br>4、节点3判断发现节点1比自己大、节点2比自己大，将重新投票，给最大的投票 </p>\n</blockquote>\n<p><strong>步骤二：</strong><br><img src=\"/2019/07/13/2019-07-13-zookeeper/%E9%80%89%E4%B8%BE2.png\" alt=\"zk\"></p>\n<blockquote>\n<p>1、节点2、节点3重新投票，投票给1<br>2、开始统计投票，节点1收到半数的投票，此时为leader，其他的变更为follower  </p>\n</blockquote>\n<h3 id=\"二、发现阶段\"><a href=\"#二、发现阶段\" class=\"headerlink\" title=\"二、发现阶段\"></a>二、发现阶段</h3><p>发现阶段，用于在从节点中发现最新的ZXID和事务日志。或许有人会问：既然Leader被选为主节点，已经是集群里数据最新的了，为什么还要从节点中寻找最新事务呢？<br>这是为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。</p>\n<p>所以这一阶段，Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。</p>\n<p>各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。</p>\n<h3 id=\"三、同步阶段\"><a href=\"#三、同步阶段\" class=\"headerlink\" title=\"三、同步阶段\"></a>三、同步阶段</h3><p>同步阶段，把Leader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。</p>\n<p><strong><em>自此，故障恢复正式完成。</em></strong></p>\n<h2 id=\"4-2、数据一致性\"><a href=\"#4-2、数据一致性\" class=\"headerlink\" title=\"4.2、数据一致性\"></a>4.2、数据一致性</h2><p>当更新节点，zk是如果保证所有节点的数据一致？</p>\n<blockquote>\n<p>写入数据，就涉及到了ZAB协议的Broadcast广播阶段。</p>\n</blockquote>\n<p>Broadcast过程如下：</p>\n<pre><code>1、客户端发出写入数据请求给任意Follower。\n2、Follower把写入数据请求转发给Leader。\n3、Leader采用二阶段提交方式，先发送Propose广播给Follower。\n4、Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader。\n5、Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower。</code></pre><h1 id=\"五、watch机制\"><a href=\"#五、watch机制\" class=\"headerlink\" title=\"五、watch机制\"></a>五、watch机制</h1><p><img src=\"/2019/07/13/2019-07-13-zookeeper/watch.png\" alt=\"zk\"></p>\n<p><strong><em>watch类型：</em></strong><br>zk状态的watch 事件:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">KeeperState:</span><br><span class=\"line\">    Unknown (-1),</span><br><span class=\"line\">    Disconnected (0),</span><br><span class=\"line\">    SyncConnected (3),</span><br><span class=\"line\">    AuthFailed (4),</span><br><span class=\"line\">    ConnectedReadOnly (5),</span><br><span class=\"line\">    SaslAuthenticated(6),</span><br><span class=\"line\">    Expired (-112);</span><br></pre></td></tr></table></figure>\n\n<p>zk节点的watch 事件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EventType</span><br><span class=\"line\">    None (-1),</span><br><span class=\"line\">    NodeCreated (1),</span><br><span class=\"line\">    NodeDeleted (2),</span><br><span class=\"line\">    NodeDataChanged (3),</span><br><span class=\"line\">    NodeChildrenChanged (4);</span><br></pre></td></tr></table></figure>\n\n<p><strong><em>整体流程：</em></strong><br>客户端将watch注册到服务器，并将该watch保存至当前客户端的watchManager中。当服务器发现数据节点发生变更，则通知客户端，此时客户端接收消息后会调用watchManager中的相应watch进行相应逻辑处理。</p>\n<blockquote>\n<p>客户端watch管理器（ZKWatchManager），数据结构：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//ZKWatchManager维护了三个map，key代表数据节点的绝对路径，value代表注册在当前节点上的watcher集合</span><br><span class=\"line\">//代表节点上内容数据、状态信息变更相关监听</span><br><span class=\"line\">private final Map&lt;String, Set&lt;Watcher&gt;&gt; dataWatches =</span><br><span class=\"line\">    new HashMap&lt;String, Set&lt;Watcher&gt;&gt;();</span><br><span class=\"line\">//代表节点变更相关监听</span><br><span class=\"line\">private final Map&lt;String, Set&lt;Watcher&gt;&gt; existWatches =</span><br><span class=\"line\">    new HashMap&lt;String, Set&lt;Watcher&gt;&gt;();</span><br><span class=\"line\">//代表节点子列表变更相关监听</span><br><span class=\"line\">private final Map&lt;String, Set&lt;Watcher&gt;&gt; childWatches =</span><br><span class=\"line\">    new HashMap&lt;String, Set&lt;Watcher&gt;&gt;();</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>服务端watch管理器（WatchManager），数据结构：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//WatchManager维护了两个map</span><br><span class=\"line\">//说明：WatchManager中的Watcher对象不是客户端用户定义的Watcher，</span><br><span class=\"line\">//     而是服务端中实现了Watcher接口的ServerCnxn抽象类，</span><br><span class=\"line\">//     该抽象类代表了一个客户端与服务端的连接</span><br><span class=\"line\"></span><br><span class=\"line\">//key代表数据节点路径，value代表客户端连接的集合，该map作用为：</span><br><span class=\"line\">//通过一个指定znode路径可找到其映射的所有客户端，当znode发生变更时</span><br><span class=\"line\">//可快速通知所有注册了当前Watcher的客户端</span><br><span class=\"line\">private final HashMap&lt;String, HashSet&lt;Watcher&gt;&gt; watchTable =</span><br><span class=\"line\">    new HashMap&lt;String, HashSet&lt;Watcher&gt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">//key代表一个客户端与服务端的连接，value代表当前客户端监听的所有数据节点路径</span><br><span class=\"line\">//该map作用为：当一个连接彻底断开时，可快速找到当前连接对应的所有</span><br><span class=\"line\">//注册了监听的节点，以便移除当前客户端对节点的Watcher</span><br><span class=\"line\">private final HashMap&lt;Watcher, HashSet&lt;String&gt;&gt; watch2Paths =</span><br><span class=\"line\">    new HashMap&lt;Watcher, HashSet&lt;String&gt;&gt;();</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>注册过程</p>\n</blockquote>\n<p><img src=\"/2019/07/13/2019-07-13-zookeeper/%E6%B3%A8%E5%86%8C%E8%BF%87%E7%A8%8B.png\" alt=\"zk\"></p>\n<h1 id=\"六、分布式锁\"><a href=\"#六、分布式锁\" class=\"headerlink\" title=\"六、分布式锁\"></a>六、分布式锁</h1><h2 id=\"6-1-使用”临时”实现\"><a href=\"#6-1-使用”临时”实现\" class=\"headerlink\" title=\"6.1 使用”临时”实现\"></a>6.1 使用”临时”实现</h2><p>利用同级节点唯一性，多个进程去zk创建相同名称的节点，只有一个能够成功，创建失败的通过zk的watch机制监听节点的状态，一但监听到节点删除事件，会再次触发所有进程的写锁，这里会有惊群效应，会影响到性能。</p>\n<h2 id=\"6-2-使用”临时有序节点”实现\"><a href=\"#6-2-使用”临时有序节点”实现\" class=\"headerlink\" title=\"6.2 使用”临时有序节点”实现\"></a>6.2 使用”临时有序节点”实现</h2><p><strong><em>思想图：</em></strong><br><img src=\"/2019/07/13/2019-07-13-zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.png\" alt=\"zk\"></p>\n<pre><code>总体思想：\n1、每个客户端都去创建临时节点，等待创建callBack\n2、创建成功callBack，此时去获取锁目录下的节点数量，等待获取数据的callBack\n3、数据返回callBack，对数据进行排序，判断当前节点大小\n4、若当前节点是第一个，则代表获得了锁；否则，监听前一个节点，添加watch（解决惊群问题）\n5、监听到watch事件，则继续循环获取节点列表。</code></pre><p><strong><em>实现图：</em></strong><br><img src=\"/2019/07/13/2019-07-13-zookeeper/%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%B5%81%E7%A8%8B.png\" alt=\"zk\"></p>\n<pre><code>1、zk.create，等待callBack ---&gt; \n2、然后获得所有节点，等待callBack; callBack返回后，去节点排序---&gt;\n3、然后判断当前节点的大小，若是第一个，则获取到了锁，执行业务代码；否则监听前一个节点 ---&gt;\n4、然后循环去判断当前节点所处的位置。</code></pre><p><strong><em>代码实现：</em></strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//Children2Callback</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public void processResult(int rc, String path, Object ctx, List&lt;String&gt; children, Stat stat) &#123;</span><br><span class=\"line\">    //获得所目录的所有有序节点，然后排序，然后取自己在有序list中的index</span><br><span class=\"line\">    if (children == null) &#123;</span><br><span class=\"line\">        System.out.println(ctx.toString() + &quot;list null&quot;);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            Collections.sort(children);</span><br><span class=\"line\">            int i = children.indexOf(lockName);</span><br><span class=\"line\">            if (i &lt; 1) &#123;</span><br><span class=\"line\">                System.out.println(threadName + &quot; i am first...&quot;);</span><br><span class=\"line\">                zk.setData(&quot;/&quot;, threadName.getBytes(), -1);</span><br><span class=\"line\">                cc.countDown();</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                System.out.println(threadName + &quot; watch &quot; + children.get(i - 1));</span><br><span class=\"line\">                //监听前一个节点，关注前一个的删除事件</span><br><span class=\"line\">                zk.exists(&quot;/&quot; + children.get(i - 1), this);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; catch (Exception e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"MQ对比","date":"2019-08-01T13:18:53.000Z","_content":"# 一、注册中心对比\n| MQ      | 实现方式   | 部署方式|\n|---      | ---       |  ---   |\n|RocketMQ | NameServer| 集群部署，各节点不会进行数据交换|\n|kafka    | zookeeper |一主多从，主服务器将数据同步至从服务器 |\n| DMQ     | zookeeper |一主多从，主服务器将数据同步至从服务器 |\n\n<!--more-->  \n\n## 1、RocketMQ\n> NameServer：\n1. topicQueueTable：topic消息队列路由信息，消息发送时根据路由表进行负载均衡\n2. brokerAddrTable：broker基础信息，包含brokerName，所属集群名称，主备broker地址；\n一个broker和所有的NameServer连接\n3. clusterAddrTable：Broker集群信息，存储集群中所有Broker名称\n4. brokerLiveTable：broker状态信息。NameServer每次收到心跳包会暂时替换该信息。\n5. filterServerTable：broker上的过滤服务列表\n\n## 2、kafka\n> Zookeeper\n\n1. **broker注册：** /brokers/ids，保存Broker服务列表，如/brokers/ids/[0...N]，并保存broker的IP地址和端口\n2. **topic注册：** 每个topic都会以/brokers/topics/[topic_name]的形式记录在Zookeeper\n3. **consumer注册：** 消费者组也会向Zookeeper进行注册，Zookeeper会为其分配节点来保存相关数据，节点路径为/consumers/{group_id}，\nZookeeper可以记录分区跟消费者的关系，以及分区的offset。\n![kafka](2019-08-01-MQ对比/kafka-consumer注册.jpeg)\n\n## 3、DMQ\n> Zookeeper\n\n![dmq](2019-08-01-MQ对比/mq-center.png)\n1. **topic注册：** /topic/topic1...topicN：主题号节点，注册所有的主题号及其订阅者\n2. **server注册：**/node/node1...nodeN：服务节点，注册所有的server节点        \n    \n\n# 二、服务端对比\n主要功能：消息存储、高可用、请求分发、\n\n## 2.1、架构对比\n### RocketMQ架构\nrocketmq的服务端是broker，主要负责消息的存储、投递和查询以及服务高可用保证\n![rocketmq](2019-08-01-MQ对比/rocketmq_architecture_3.png)\n1. 单台Master部署；\n1. 多台Master部署；\n1. 多Master多Slave部署。\n\nBroker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，**BrokerId为0表示Master，非0表示Slave**\n\n### kafka架构\nkafka集群节点也称做broker，接收生产者的消息，为消息设置偏移量，并提交消息保存到磁盘内。\n![rocketmq](2019-08-01-MQ对比/kafka-broker.png)\n\n* **controller broker**: \n    * broker的协调者，追踪集群中的其他Broker，并在合适的时候处理新加入的和失败的Broker节点、Rebalance分区、分配新的leader分区等\n    * Kafka集群中始终只有一个Controller Broker\n    * Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。\n    其他节点会监听该临时节点（watch机制）\n\nbroker在controller重新选举上，会导致集群不可用。\nZK性能问题，惊群效应\n\n### DMQ架构\nDMQ集群节点称为server，负责数据的存储、发送等功能。\n\n\n\n## 2.2、消息存储对比\n### RocketMQ\n* 消息的基本概念：\n    * topic：表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。\n        * MessageQueue：在创建Topic的时候会让我们指定MessageQueue的数量，简单来说就是指定Topic中的队列数量。本质上是一个数据分片机制。\n        * topic可以存放在多个broker内，每个broker内可以有多个messageQueue.\n    * message：消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。\n    * tag：标签\n\n**关联关系：**\n![rocketmq](2019-08-01-MQ对比/rocketmq-messagequeue.jpeg)\n生产者先获取topic下的messageQueue，Broker在收到一条消息的时候，写入Commit Log的同时，还会将当前这条消息在commit log中的offset、消息的size和对应的Tag的Hash写入到consumer queue文件中去。\n一个broker有多个commitlog文件。\n\n\n使用文件存储，三个跟消息存储相关的文件：CommitLog、ConsumeQueue、IndexFile\n1. **CommitLog**：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件；\n1. **ConsumeQueue**：消息消费队列，引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件，故consumequeue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；\n1. **IndexFile**：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：$HOME \\store\\index${fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。\n\n![rocketmq](2019-08-01-MQ对比/rocketmq_design_1.png)\n\n**broker文件存储结构如下：**\n![rocketmq](2019-08-01-MQ对比/rocketmq-broker.png)\n\n### kafka\nKafka部分名词解释如下：\n1. Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。\n1. Topic：一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。\n1. Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。\n1. Segment：partition物理上由多个segment组成，下面2.2和2.3有详细说明。\n1. offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.\n\n\n\n### DMQ\n1. 采用数据库存储，一条数据对应一个clientID，即一条相同的信息会存储多遍。\n2. 性能不如文件存储，数据库是瓶颈。    \n    \n\n\n\n\n    ","source":"_posts/2019-08-01-MQ对比.md","raw":"---\ntitle: MQ对比\ndate: 2019-08-01 21:18:53\ntags: MQ\n---\n# 一、注册中心对比\n| MQ      | 实现方式   | 部署方式|\n|---      | ---       |  ---   |\n|RocketMQ | NameServer| 集群部署，各节点不会进行数据交换|\n|kafka    | zookeeper |一主多从，主服务器将数据同步至从服务器 |\n| DMQ     | zookeeper |一主多从，主服务器将数据同步至从服务器 |\n\n<!--more-->  \n\n## 1、RocketMQ\n> NameServer：\n1. topicQueueTable：topic消息队列路由信息，消息发送时根据路由表进行负载均衡\n2. brokerAddrTable：broker基础信息，包含brokerName，所属集群名称，主备broker地址；\n一个broker和所有的NameServer连接\n3. clusterAddrTable：Broker集群信息，存储集群中所有Broker名称\n4. brokerLiveTable：broker状态信息。NameServer每次收到心跳包会暂时替换该信息。\n5. filterServerTable：broker上的过滤服务列表\n\n## 2、kafka\n> Zookeeper\n\n1. **broker注册：** /brokers/ids，保存Broker服务列表，如/brokers/ids/[0...N]，并保存broker的IP地址和端口\n2. **topic注册：** 每个topic都会以/brokers/topics/[topic_name]的形式记录在Zookeeper\n3. **consumer注册：** 消费者组也会向Zookeeper进行注册，Zookeeper会为其分配节点来保存相关数据，节点路径为/consumers/{group_id}，\nZookeeper可以记录分区跟消费者的关系，以及分区的offset。\n![kafka](2019-08-01-MQ对比/kafka-consumer注册.jpeg)\n\n## 3、DMQ\n> Zookeeper\n\n![dmq](2019-08-01-MQ对比/mq-center.png)\n1. **topic注册：** /topic/topic1...topicN：主题号节点，注册所有的主题号及其订阅者\n2. **server注册：**/node/node1...nodeN：服务节点，注册所有的server节点        \n    \n\n# 二、服务端对比\n主要功能：消息存储、高可用、请求分发、\n\n## 2.1、架构对比\n### RocketMQ架构\nrocketmq的服务端是broker，主要负责消息的存储、投递和查询以及服务高可用保证\n![rocketmq](2019-08-01-MQ对比/rocketmq_architecture_3.png)\n1. 单台Master部署；\n1. 多台Master部署；\n1. 多Master多Slave部署。\n\nBroker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，**BrokerId为0表示Master，非0表示Slave**\n\n### kafka架构\nkafka集群节点也称做broker，接收生产者的消息，为消息设置偏移量，并提交消息保存到磁盘内。\n![rocketmq](2019-08-01-MQ对比/kafka-broker.png)\n\n* **controller broker**: \n    * broker的协调者，追踪集群中的其他Broker，并在合适的时候处理新加入的和失败的Broker节点、Rebalance分区、分配新的leader分区等\n    * Kafka集群中始终只有一个Controller Broker\n    * Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。\n    其他节点会监听该临时节点（watch机制）\n\nbroker在controller重新选举上，会导致集群不可用。\nZK性能问题，惊群效应\n\n### DMQ架构\nDMQ集群节点称为server，负责数据的存储、发送等功能。\n\n\n\n## 2.2、消息存储对比\n### RocketMQ\n* 消息的基本概念：\n    * topic：表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。\n        * MessageQueue：在创建Topic的时候会让我们指定MessageQueue的数量，简单来说就是指定Topic中的队列数量。本质上是一个数据分片机制。\n        * topic可以存放在多个broker内，每个broker内可以有多个messageQueue.\n    * message：消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。\n    * tag：标签\n\n**关联关系：**\n![rocketmq](2019-08-01-MQ对比/rocketmq-messagequeue.jpeg)\n生产者先获取topic下的messageQueue，Broker在收到一条消息的时候，写入Commit Log的同时，还会将当前这条消息在commit log中的offset、消息的size和对应的Tag的Hash写入到consumer queue文件中去。\n一个broker有多个commitlog文件。\n\n\n使用文件存储，三个跟消息存储相关的文件：CommitLog、ConsumeQueue、IndexFile\n1. **CommitLog**：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件；\n1. **ConsumeQueue**：消息消费队列，引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件，故consumequeue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；\n1. **IndexFile**：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：$HOME \\store\\index${fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。\n\n![rocketmq](2019-08-01-MQ对比/rocketmq_design_1.png)\n\n**broker文件存储结构如下：**\n![rocketmq](2019-08-01-MQ对比/rocketmq-broker.png)\n\n### kafka\nKafka部分名词解释如下：\n1. Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。\n1. Topic：一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。\n1. Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。\n1. Segment：partition物理上由多个segment组成，下面2.2和2.3有详细说明。\n1. offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.\n\n\n\n### DMQ\n1. 采用数据库存储，一条数据对应一个clientID，即一条相同的信息会存储多遍。\n2. 性能不如文件存储，数据库是瓶颈。    \n    \n\n\n\n\n    ","slug":"2019-08-01-MQ对比","published":1,"updated":"2024-10-14T09:38:11.997Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnv90010a13kmo05w9ni","content":"<h1 id=\"一、注册中心对比\"><a href=\"#一、注册中心对比\" class=\"headerlink\" title=\"一、注册中心对比\"></a>一、注册中心对比</h1><table>\n<thead>\n<tr>\n<th>MQ</th>\n<th>实现方式</th>\n<th>部署方式</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RocketMQ</td>\n<td>NameServer</td>\n<td>集群部署，各节点不会进行数据交换</td>\n</tr>\n<tr>\n<td>kafka</td>\n<td>zookeeper</td>\n<td>一主多从，主服务器将数据同步至从服务器</td>\n</tr>\n<tr>\n<td>DMQ</td>\n<td>zookeeper</td>\n<td>一主多从，主服务器将数据同步至从服务器</td>\n</tr>\n</tbody></table>\n<a id=\"more\"></a>  \n\n<h2 id=\"1、RocketMQ\"><a href=\"#1、RocketMQ\" class=\"headerlink\" title=\"1、RocketMQ\"></a>1、RocketMQ</h2><blockquote>\n<p>NameServer：</p>\n<ol>\n<li>topicQueueTable：topic消息队列路由信息，消息发送时根据路由表进行负载均衡</li>\n<li>brokerAddrTable：broker基础信息，包含brokerName，所属集群名称，主备broker地址；<br>一个broker和所有的NameServer连接</li>\n<li>clusterAddrTable：Broker集群信息，存储集群中所有Broker名称</li>\n<li>brokerLiveTable：broker状态信息。NameServer每次收到心跳包会暂时替换该信息。</li>\n<li>filterServerTable：broker上的过滤服务列表</li>\n</ol>\n</blockquote>\n<h2 id=\"2、kafka\"><a href=\"#2、kafka\" class=\"headerlink\" title=\"2、kafka\"></a>2、kafka</h2><blockquote>\n<p>Zookeeper</p>\n</blockquote>\n<ol>\n<li><strong>broker注册：</strong> /brokers/ids，保存Broker服务列表，如/brokers/ids/[0…N]，并保存broker的IP地址和端口</li>\n<li><strong>topic注册：</strong> 每个topic都会以/brokers/topics/[topic_name]的形式记录在Zookeeper</li>\n<li><strong>consumer注册：</strong> 消费者组也会向Zookeeper进行注册，Zookeeper会为其分配节点来保存相关数据，节点路径为/consumers/{group_id}，<br>Zookeeper可以记录分区跟消费者的关系，以及分区的offset。<br><img src=\"/2019/08/01/2019-08-01-MQ对比/kafka-consumer%E6%B3%A8%E5%86%8C.jpeg\" alt=\"kafka\"></li>\n</ol>\n<h2 id=\"3、DMQ\"><a href=\"#3、DMQ\" class=\"headerlink\" title=\"3、DMQ\"></a>3、DMQ</h2><blockquote>\n<p>Zookeeper</p>\n</blockquote>\n<p><img src=\"/2019/08/01/2019-08-01-MQ对比/mq-center.png\" alt=\"dmq\"></p>\n<ol>\n<li><strong>topic注册：</strong> /topic/topic1…topicN：主题号节点，注册所有的主题号及其订阅者</li>\n<li><strong>server注册：</strong>/node/node1…nodeN：服务节点，注册所有的server节点        </li>\n</ol>\n<h1 id=\"二、服务端对比\"><a href=\"#二、服务端对比\" class=\"headerlink\" title=\"二、服务端对比\"></a>二、服务端对比</h1><p>主要功能：消息存储、高可用、请求分发、</p>\n<h2 id=\"2-1、架构对比\"><a href=\"#2-1、架构对比\" class=\"headerlink\" title=\"2.1、架构对比\"></a>2.1、架构对比</h2><h3 id=\"RocketMQ架构\"><a href=\"#RocketMQ架构\" class=\"headerlink\" title=\"RocketMQ架构\"></a>RocketMQ架构</h3><p>rocketmq的服务端是broker，主要负责消息的存储、投递和查询以及服务高可用保证<br><img src=\"/2019/08/01/2019-08-01-MQ对比/rocketmq_architecture_3.png\" alt=\"rocketmq\"></p>\n<ol>\n<li>单台Master部署；</li>\n<li>多台Master部署；</li>\n<li>多Master多Slave部署。</li>\n</ol>\n<p>Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，<strong>BrokerId为0表示Master，非0表示Slave</strong></p>\n<h3 id=\"kafka架构\"><a href=\"#kafka架构\" class=\"headerlink\" title=\"kafka架构\"></a>kafka架构</h3><p>kafka集群节点也称做broker，接收生产者的消息，为消息设置偏移量，并提交消息保存到磁盘内。<br><img src=\"/2019/08/01/2019-08-01-MQ对比/kafka-broker.png\" alt=\"rocketmq\"></p>\n<ul>\n<li><strong>controller broker</strong>: <ul>\n<li>broker的协调者，追踪集群中的其他Broker，并在合适的时候处理新加入的和失败的Broker节点、Rebalance分区、分配新的leader分区等</li>\n<li>Kafka集群中始终只有一个Controller Broker</li>\n<li>Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。<br>其他节点会监听该临时节点（watch机制）</li>\n</ul>\n</li>\n</ul>\n<p>broker在controller重新选举上，会导致集群不可用。<br>ZK性能问题，惊群效应</p>\n<h3 id=\"DMQ架构\"><a href=\"#DMQ架构\" class=\"headerlink\" title=\"DMQ架构\"></a>DMQ架构</h3><p>DMQ集群节点称为server，负责数据的存储、发送等功能。</p>\n<h2 id=\"2-2、消息存储对比\"><a href=\"#2-2、消息存储对比\" class=\"headerlink\" title=\"2.2、消息存储对比\"></a>2.2、消息存储对比</h2><h3 id=\"RocketMQ\"><a href=\"#RocketMQ\" class=\"headerlink\" title=\"RocketMQ\"></a>RocketMQ</h3><ul>\n<li>消息的基本概念：<ul>\n<li>topic：表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。<ul>\n<li>MessageQueue：在创建Topic的时候会让我们指定MessageQueue的数量，简单来说就是指定Topic中的队列数量。本质上是一个数据分片机制。</li>\n<li>topic可以存放在多个broker内，每个broker内可以有多个messageQueue.</li>\n</ul>\n</li>\n<li>message：消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。</li>\n<li>tag：标签</li>\n</ul>\n</li>\n</ul>\n<p><strong>关联关系：</strong><br><img src=\"/2019/08/01/2019-08-01-MQ对比/rocketmq-messagequeue.jpeg\" alt=\"rocketmq\"><br>生产者先获取topic下的messageQueue，Broker在收到一条消息的时候，写入Commit Log的同时，还会将当前这条消息在commit log中的offset、消息的size和对应的Tag的Hash写入到consumer queue文件中去。<br>一个broker有多个commitlog文件。</p>\n<p>使用文件存储，三个跟消息存储相关的文件：CommitLog、ConsumeQueue、IndexFile</p>\n<ol>\n<li><strong>CommitLog</strong>：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件；</li>\n<li><strong>ConsumeQueue</strong>：消息消费队列，引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件，故consumequeue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；</li>\n<li><strong>IndexFile</strong>：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：$HOME \\store\\index${fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。</li>\n</ol>\n<p><img src=\"/2019/08/01/2019-08-01-MQ对比/rocketmq_design_1.png\" alt=\"rocketmq\"></p>\n<p><strong>broker文件存储结构如下：</strong><br><img src=\"/2019/08/01/2019-08-01-MQ对比/rocketmq-broker.png\" alt=\"rocketmq\"></p>\n<h3 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h3><p>Kafka部分名词解释如下：</p>\n<ol>\n<li>Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</li>\n<li>Topic：一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。</li>\n<li>Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。</li>\n<li>Segment：partition物理上由多个segment组成，下面2.2和2.3有详细说明。</li>\n<li>offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.</li>\n</ol>\n<h3 id=\"DMQ\"><a href=\"#DMQ\" class=\"headerlink\" title=\"DMQ\"></a>DMQ</h3><ol>\n<li>采用数据库存储，一条数据对应一个clientID，即一条相同的信息会存储多遍。</li>\n<li>性能不如文件存储，数据库是瓶颈。    </li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、注册中心对比\"><a href=\"#一、注册中心对比\" class=\"headerlink\" title=\"一、注册中心对比\"></a>一、注册中心对比</h1><table>\n<thead>\n<tr>\n<th>MQ</th>\n<th>实现方式</th>\n<th>部署方式</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RocketMQ</td>\n<td>NameServer</td>\n<td>集群部署，各节点不会进行数据交换</td>\n</tr>\n<tr>\n<td>kafka</td>\n<td>zookeeper</td>\n<td>一主多从，主服务器将数据同步至从服务器</td>\n</tr>\n<tr>\n<td>DMQ</td>\n<td>zookeeper</td>\n<td>一主多从，主服务器将数据同步至从服务器</td>\n</tr>\n</tbody></table>","more":"<h2 id=\"1、RocketMQ\"><a href=\"#1、RocketMQ\" class=\"headerlink\" title=\"1、RocketMQ\"></a>1、RocketMQ</h2><blockquote>\n<p>NameServer：</p>\n<ol>\n<li>topicQueueTable：topic消息队列路由信息，消息发送时根据路由表进行负载均衡</li>\n<li>brokerAddrTable：broker基础信息，包含brokerName，所属集群名称，主备broker地址；<br>一个broker和所有的NameServer连接</li>\n<li>clusterAddrTable：Broker集群信息，存储集群中所有Broker名称</li>\n<li>brokerLiveTable：broker状态信息。NameServer每次收到心跳包会暂时替换该信息。</li>\n<li>filterServerTable：broker上的过滤服务列表</li>\n</ol>\n</blockquote>\n<h2 id=\"2、kafka\"><a href=\"#2、kafka\" class=\"headerlink\" title=\"2、kafka\"></a>2、kafka</h2><blockquote>\n<p>Zookeeper</p>\n</blockquote>\n<ol>\n<li><strong>broker注册：</strong> /brokers/ids，保存Broker服务列表，如/brokers/ids/[0…N]，并保存broker的IP地址和端口</li>\n<li><strong>topic注册：</strong> 每个topic都会以/brokers/topics/[topic_name]的形式记录在Zookeeper</li>\n<li><strong>consumer注册：</strong> 消费者组也会向Zookeeper进行注册，Zookeeper会为其分配节点来保存相关数据，节点路径为/consumers/{group_id}，<br>Zookeeper可以记录分区跟消费者的关系，以及分区的offset。<br><img src=\"/2019/08/01/2019-08-01-MQ对比/kafka-consumer%E6%B3%A8%E5%86%8C.jpeg\" alt=\"kafka\"></li>\n</ol>\n<h2 id=\"3、DMQ\"><a href=\"#3、DMQ\" class=\"headerlink\" title=\"3、DMQ\"></a>3、DMQ</h2><blockquote>\n<p>Zookeeper</p>\n</blockquote>\n<p><img src=\"/2019/08/01/2019-08-01-MQ对比/mq-center.png\" alt=\"dmq\"></p>\n<ol>\n<li><strong>topic注册：</strong> /topic/topic1…topicN：主题号节点，注册所有的主题号及其订阅者</li>\n<li><strong>server注册：</strong>/node/node1…nodeN：服务节点，注册所有的server节点        </li>\n</ol>\n<h1 id=\"二、服务端对比\"><a href=\"#二、服务端对比\" class=\"headerlink\" title=\"二、服务端对比\"></a>二、服务端对比</h1><p>主要功能：消息存储、高可用、请求分发、</p>\n<h2 id=\"2-1、架构对比\"><a href=\"#2-1、架构对比\" class=\"headerlink\" title=\"2.1、架构对比\"></a>2.1、架构对比</h2><h3 id=\"RocketMQ架构\"><a href=\"#RocketMQ架构\" class=\"headerlink\" title=\"RocketMQ架构\"></a>RocketMQ架构</h3><p>rocketmq的服务端是broker，主要负责消息的存储、投递和查询以及服务高可用保证<br><img src=\"/2019/08/01/2019-08-01-MQ对比/rocketmq_architecture_3.png\" alt=\"rocketmq\"></p>\n<ol>\n<li>单台Master部署；</li>\n<li>多台Master部署；</li>\n<li>多Master多Slave部署。</li>\n</ol>\n<p>Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，<strong>BrokerId为0表示Master，非0表示Slave</strong></p>\n<h3 id=\"kafka架构\"><a href=\"#kafka架构\" class=\"headerlink\" title=\"kafka架构\"></a>kafka架构</h3><p>kafka集群节点也称做broker，接收生产者的消息，为消息设置偏移量，并提交消息保存到磁盘内。<br><img src=\"/2019/08/01/2019-08-01-MQ对比/kafka-broker.png\" alt=\"rocketmq\"></p>\n<ul>\n<li><strong>controller broker</strong>: <ul>\n<li>broker的协调者，追踪集群中的其他Broker，并在合适的时候处理新加入的和失败的Broker节点、Rebalance分区、分配新的leader分区等</li>\n<li>Kafka集群中始终只有一个Controller Broker</li>\n<li>Broker 在启动时，会尝试去 ZooKeeper 中创建 /controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建 /controller 节点的 Broker 会被指定为控制器。<br>其他节点会监听该临时节点（watch机制）</li>\n</ul>\n</li>\n</ul>\n<p>broker在controller重新选举上，会导致集群不可用。<br>ZK性能问题，惊群效应</p>\n<h3 id=\"DMQ架构\"><a href=\"#DMQ架构\" class=\"headerlink\" title=\"DMQ架构\"></a>DMQ架构</h3><p>DMQ集群节点称为server，负责数据的存储、发送等功能。</p>\n<h2 id=\"2-2、消息存储对比\"><a href=\"#2-2、消息存储对比\" class=\"headerlink\" title=\"2.2、消息存储对比\"></a>2.2、消息存储对比</h2><h3 id=\"RocketMQ\"><a href=\"#RocketMQ\" class=\"headerlink\" title=\"RocketMQ\"></a>RocketMQ</h3><ul>\n<li>消息的基本概念：<ul>\n<li>topic：表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。<ul>\n<li>MessageQueue：在创建Topic的时候会让我们指定MessageQueue的数量，简单来说就是指定Topic中的队列数量。本质上是一个数据分片机制。</li>\n<li>topic可以存放在多个broker内，每个broker内可以有多个messageQueue.</li>\n</ul>\n</li>\n<li>message：消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。</li>\n<li>tag：标签</li>\n</ul>\n</li>\n</ul>\n<p><strong>关联关系：</strong><br><img src=\"/2019/08/01/2019-08-01-MQ对比/rocketmq-messagequeue.jpeg\" alt=\"rocketmq\"><br>生产者先获取topic下的messageQueue，Broker在收到一条消息的时候，写入Commit Log的同时，还会将当前这条消息在commit log中的offset、消息的size和对应的Tag的Hash写入到consumer queue文件中去。<br>一个broker有多个commitlog文件。</p>\n<p>使用文件存储，三个跟消息存储相关的文件：CommitLog、ConsumeQueue、IndexFile</p>\n<ol>\n<li><strong>CommitLog</strong>：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件；</li>\n<li><strong>ConsumeQueue</strong>：消息消费队列，引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件，故consumequeue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；</li>\n<li><strong>IndexFile</strong>：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：$HOME \\store\\index${fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。</li>\n</ol>\n<p><img src=\"/2019/08/01/2019-08-01-MQ对比/rocketmq_design_1.png\" alt=\"rocketmq\"></p>\n<p><strong>broker文件存储结构如下：</strong><br><img src=\"/2019/08/01/2019-08-01-MQ对比/rocketmq-broker.png\" alt=\"rocketmq\"></p>\n<h3 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h3><p>Kafka部分名词解释如下：</p>\n<ol>\n<li>Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</li>\n<li>Topic：一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。</li>\n<li>Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。</li>\n<li>Segment：partition物理上由多个segment组成，下面2.2和2.3有详细说明。</li>\n<li>offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.</li>\n</ol>\n<h3 id=\"DMQ\"><a href=\"#DMQ\" class=\"headerlink\" title=\"DMQ\"></a>DMQ</h3><ol>\n<li>采用数据库存储，一条数据对应一个clientID，即一条相同的信息会存储多遍。</li>\n<li>性能不如文件存储，数据库是瓶颈。    </li>\n</ol>"},{"title":"RPC","date":"2019-08-19T13:38:38.000Z","_content":"\n# 一、RPC需要解决的问题\n1、服务发现（寻址）  \n2、数据传输（序列化）  \n3、底层通讯（TCP）  \n\n## 1.1、服务发现&注册（寻址）\n### A、整体流程\n***涉及两个动作：服务端的服务注册、客户端的服务发现。***  \n![RPC](2019-08-19-RPC/RPC.png)\n\n### B、实现\n**1**、客户端与注册中心：客户端启动主动拉一次配置（获得服务的节点、端口信息）、拉收集项；启动完成后，收集项由注册中心每隔一个小时推送一次，另外在客户端有一个10分钟一次的定时任务会拉取最新的配置信息  \n**2**、服务端与注册中心：服务端会启动一个定时任务，定时发送心跳（上报节点信息）、拉收集项、发送白名单（注册中心接收到白名单消息，并没有做任何处理，暂时无用）；注册中心每隔一小时推送一次最新的收集项，另外推送黑名单给服务端（黑名单用于拦截请求，保护服务）\n\n<!--more-->  \n\n## 1.2、序列化\n![RPC](2019-08-19-RPC/序列化.png)\n* 四元组(TT[L]V)\n\n\n    Tag + Type + Length + Value\n    属性标签、属性类型、属性值字节长度、属性值\n    \n\n\n## 1.3、数据传输\n字段       | 协议头   | 版本号  | 总长度      | SessionId  | 服务编号 | 协议类型 | 压缩类型      | 序列化类型    | 平台     | 调用链数据长度 | 调用链数据 | 服务治理key长度 | 服务治理key | 业务数据 | 协议尾  \n--------- | -------  | ------ | ----------  | ---------- | ------- | ------  | ------------ | ----------- | ------- | ----------- | -------- | ------------- | ---------- | ------ | -----  \n长度(byte) | 5       | 1      | 4          | 4           | 1       | 1      | 1            | 1           | 1        | 2           | xxoo     | 2              | xxoo      | xxoo    | 5  \n含义       | 验证使用 | 扩展使用 | 不包含头和位 | 异步机制使用 | 暂无实现 | 啊     | 暂未实现      | asf、asf_ext | java     | 调用链使用   | 调用链使用  | 服务治理使用     |  服务治理使用 | 自定义java对象序列化后的byte数组 | 断包使用  \n\n- 支持多种序列化方式：Hessian、SCF、json\n- 解析字节流，截取到业务数据\n- 根据序列化方式，对字节数组解析反序列化。\n\n## 1.4、底层通讯（TCP）\n\n底层通讯，使用了netty框架。\n\n# 二、客户端\n## 2.1、架构\n![RPC](2019-08-19-RPC/客户端架构.png)\n\n- 接口代理层：采用Java的动态代理，创建接口代理并缓存，代理类中实现具体的序列化、节点路由、网络连接及数据传输等。\n- 服务代理层：缓存服务，访问控制（同步、异步、服务故障（重启、宕机、超时）等转移）。\n- 节点路由层：服务节点路由及服务负载均衡。\n- 连接管理层：缓存客户端与服务端的TCP连接，并提供连接池功能。\n- 数据传输层：数据的发送与接收。\n\n\n## 2.2、一次方法调用过程\n![RPC](2019-08-19-RPC/方法调用过程.png)\n\n    1.每个Service在客户端，都对应一个ProxyStandard，它代理执行该Service的执行，初始化一次进行缓存  \n    2.MethodCaller中是服务执行方法的地方，会调用ServiceProxy获取Server节点，获取方式是通过负载均衡策略  \n    3.ServiceProxy持有自己的所有对象的Map,根据serviceName可以找到一个服务的节点池  \n    4.Dispatcher是个负载均衡器，他负责选择服务的节点，并且持有一个服务的所有节点  \n    5.一个节点对应一个Server对象，Server是一个服务提供者，它会和服务提供者直接会建立连接池queue  \n\n## 2.3、重试机制\nserver将请求发送至queue中后，会同步等待返回结果，当接收信息时超时抛出异常，异常被serviceProxy捕获，进行超时的重试。\n- 重试次数：默认3次\n- 超时时间：默认3s\n\n## 2.4、负载均衡\n权重随机策略，默认采用轮询\n\n## 2.5、服务降级唤醒\n定时任务，获取断开连接的服务进行连接。\n\n## 2.6、客户端容错汇总\n1、超时连接：服务节点变为Dead，死亡节点异步线程进行探测激活\n\n## 2.7、心跳机制\n1、每个Socket创建连接之后，都会启动一个定期执行的心跳线程发送心跳。  \n2、服务节点状态变为Deaed，异步探测线程5秒执行一次，会进行心跳探测，探测成功更新节点死亡时间，成功恢复节点\n\n# 三、服务端\n## 3.1、线程模型\n![RPC](2019-08-19-RPC/server线程模型.png)\n1、socketHandler接到请求，根据负载均衡，将完整包放入异步处理队列。  \n2、异步处理线程模型，可以有多个线程组，一个线程组默认8个线程，这个8个线程一起维护一个队列。\n\n## 3.2、一次方法的调用过程\n![RPC](2019-08-19-RPC/server方法过程.png)\n\n    1.请求数据首先通过固定结尾DelimiterBasedFrameDecoder解码\n    2.SocketHandler判断数据类型，心跳直接返回\n    3.前置业务过滤器ProtocolParseFilter反序列化请求\n    4.根据请求lookup从服务代理工厂获取代理服务\n    5.返回结果码流\n\n\n## 3.3、启动过程\n\n    2、生成服务代理\n      1.1 加载所有的jar 容器lib+服务目录\n      1.2 加载系统目录下所有class\n      1.3 class中扫描ServiceContract注解的接口，扫描OperationContract注解的方法，去重\n      1.4 class中扫描ServiceBehavior注解的实现，只扫描protected和public的方法，去重，相同的lookup报错\n      1.5 扫描的jar中加载class，扫描jar中的ServiceContract和ServiceBehavior注解类\n      1.6 接口和实现类对应关系绑定\n      1.7 为csf服务实现类，利用java-assist生成代理类，有Spring增加上下文获取Bean逻辑\n      1.8 生成代理对象工厂类\n      1.9 初始化代理对象\n      1.10 初始化代理工厂对象，将代理对象传入工厂\n        \n    3.加载并调用init接口的实现类\n    4.加载Filter\n    5.注册新号\n    6.添加Hooks\n    7.启动server\n    8.注册Server的ShutDownHook \n\n\n\n# 4、异步调用\n## 1、ConcurrentHashMap<Integer, WindowData> WaitWindows\n<key, value> = <sessionId, WinData>，\n\n* sendInvoke(wd); //发送线程职责：将请求流发送给服务端\n* timeOutInvoke(wd); //接收线程职责：超时判断 + 回调函数调用\n\n按sessionId，进行解析\n\n\n","source":"_posts/2019-08-19-RPC.md","raw":"---\ntitle: RPC\ndate: 2019-08-19 21:38:38\ntags: rpc\ncategories: RPC\n---\n\n# 一、RPC需要解决的问题\n1、服务发现（寻址）  \n2、数据传输（序列化）  \n3、底层通讯（TCP）  \n\n## 1.1、服务发现&注册（寻址）\n### A、整体流程\n***涉及两个动作：服务端的服务注册、客户端的服务发现。***  \n![RPC](2019-08-19-RPC/RPC.png)\n\n### B、实现\n**1**、客户端与注册中心：客户端启动主动拉一次配置（获得服务的节点、端口信息）、拉收集项；启动完成后，收集项由注册中心每隔一个小时推送一次，另外在客户端有一个10分钟一次的定时任务会拉取最新的配置信息  \n**2**、服务端与注册中心：服务端会启动一个定时任务，定时发送心跳（上报节点信息）、拉收集项、发送白名单（注册中心接收到白名单消息，并没有做任何处理，暂时无用）；注册中心每隔一小时推送一次最新的收集项，另外推送黑名单给服务端（黑名单用于拦截请求，保护服务）\n\n<!--more-->  \n\n## 1.2、序列化\n![RPC](2019-08-19-RPC/序列化.png)\n* 四元组(TT[L]V)\n\n\n    Tag + Type + Length + Value\n    属性标签、属性类型、属性值字节长度、属性值\n    \n\n\n## 1.3、数据传输\n字段       | 协议头   | 版本号  | 总长度      | SessionId  | 服务编号 | 协议类型 | 压缩类型      | 序列化类型    | 平台     | 调用链数据长度 | 调用链数据 | 服务治理key长度 | 服务治理key | 业务数据 | 协议尾  \n--------- | -------  | ------ | ----------  | ---------- | ------- | ------  | ------------ | ----------- | ------- | ----------- | -------- | ------------- | ---------- | ------ | -----  \n长度(byte) | 5       | 1      | 4          | 4           | 1       | 1      | 1            | 1           | 1        | 2           | xxoo     | 2              | xxoo      | xxoo    | 5  \n含义       | 验证使用 | 扩展使用 | 不包含头和位 | 异步机制使用 | 暂无实现 | 啊     | 暂未实现      | asf、asf_ext | java     | 调用链使用   | 调用链使用  | 服务治理使用     |  服务治理使用 | 自定义java对象序列化后的byte数组 | 断包使用  \n\n- 支持多种序列化方式：Hessian、SCF、json\n- 解析字节流，截取到业务数据\n- 根据序列化方式，对字节数组解析反序列化。\n\n## 1.4、底层通讯（TCP）\n\n底层通讯，使用了netty框架。\n\n# 二、客户端\n## 2.1、架构\n![RPC](2019-08-19-RPC/客户端架构.png)\n\n- 接口代理层：采用Java的动态代理，创建接口代理并缓存，代理类中实现具体的序列化、节点路由、网络连接及数据传输等。\n- 服务代理层：缓存服务，访问控制（同步、异步、服务故障（重启、宕机、超时）等转移）。\n- 节点路由层：服务节点路由及服务负载均衡。\n- 连接管理层：缓存客户端与服务端的TCP连接，并提供连接池功能。\n- 数据传输层：数据的发送与接收。\n\n\n## 2.2、一次方法调用过程\n![RPC](2019-08-19-RPC/方法调用过程.png)\n\n    1.每个Service在客户端，都对应一个ProxyStandard，它代理执行该Service的执行，初始化一次进行缓存  \n    2.MethodCaller中是服务执行方法的地方，会调用ServiceProxy获取Server节点，获取方式是通过负载均衡策略  \n    3.ServiceProxy持有自己的所有对象的Map,根据serviceName可以找到一个服务的节点池  \n    4.Dispatcher是个负载均衡器，他负责选择服务的节点，并且持有一个服务的所有节点  \n    5.一个节点对应一个Server对象，Server是一个服务提供者，它会和服务提供者直接会建立连接池queue  \n\n## 2.3、重试机制\nserver将请求发送至queue中后，会同步等待返回结果，当接收信息时超时抛出异常，异常被serviceProxy捕获，进行超时的重试。\n- 重试次数：默认3次\n- 超时时间：默认3s\n\n## 2.4、负载均衡\n权重随机策略，默认采用轮询\n\n## 2.5、服务降级唤醒\n定时任务，获取断开连接的服务进行连接。\n\n## 2.6、客户端容错汇总\n1、超时连接：服务节点变为Dead，死亡节点异步线程进行探测激活\n\n## 2.7、心跳机制\n1、每个Socket创建连接之后，都会启动一个定期执行的心跳线程发送心跳。  \n2、服务节点状态变为Deaed，异步探测线程5秒执行一次，会进行心跳探测，探测成功更新节点死亡时间，成功恢复节点\n\n# 三、服务端\n## 3.1、线程模型\n![RPC](2019-08-19-RPC/server线程模型.png)\n1、socketHandler接到请求，根据负载均衡，将完整包放入异步处理队列。  \n2、异步处理线程模型，可以有多个线程组，一个线程组默认8个线程，这个8个线程一起维护一个队列。\n\n## 3.2、一次方法的调用过程\n![RPC](2019-08-19-RPC/server方法过程.png)\n\n    1.请求数据首先通过固定结尾DelimiterBasedFrameDecoder解码\n    2.SocketHandler判断数据类型，心跳直接返回\n    3.前置业务过滤器ProtocolParseFilter反序列化请求\n    4.根据请求lookup从服务代理工厂获取代理服务\n    5.返回结果码流\n\n\n## 3.3、启动过程\n\n    2、生成服务代理\n      1.1 加载所有的jar 容器lib+服务目录\n      1.2 加载系统目录下所有class\n      1.3 class中扫描ServiceContract注解的接口，扫描OperationContract注解的方法，去重\n      1.4 class中扫描ServiceBehavior注解的实现，只扫描protected和public的方法，去重，相同的lookup报错\n      1.5 扫描的jar中加载class，扫描jar中的ServiceContract和ServiceBehavior注解类\n      1.6 接口和实现类对应关系绑定\n      1.7 为csf服务实现类，利用java-assist生成代理类，有Spring增加上下文获取Bean逻辑\n      1.8 生成代理对象工厂类\n      1.9 初始化代理对象\n      1.10 初始化代理工厂对象，将代理对象传入工厂\n        \n    3.加载并调用init接口的实现类\n    4.加载Filter\n    5.注册新号\n    6.添加Hooks\n    7.启动server\n    8.注册Server的ShutDownHook \n\n\n\n# 4、异步调用\n## 1、ConcurrentHashMap<Integer, WindowData> WaitWindows\n<key, value> = <sessionId, WinData>，\n\n* sendInvoke(wd); //发送线程职责：将请求流发送给服务端\n* timeOutInvoke(wd); //接收线程职责：超时判断 + 回调函数调用\n\n按sessionId，进行解析\n\n\n","slug":"2019-08-19-RPC","published":1,"updated":"2024-10-14T09:38:12.006Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnve0013a13k3bk80slx","content":"<h1 id=\"一、RPC需要解决的问题\"><a href=\"#一、RPC需要解决的问题\" class=\"headerlink\" title=\"一、RPC需要解决的问题\"></a>一、RPC需要解决的问题</h1><p>1、服务发现（寻址）<br>2、数据传输（序列化）<br>3、底层通讯（TCP）  </p>\n<h2 id=\"1-1、服务发现-amp-注册（寻址）\"><a href=\"#1-1、服务发现-amp-注册（寻址）\" class=\"headerlink\" title=\"1.1、服务发现&amp;注册（寻址）\"></a>1.1、服务发现&amp;注册（寻址）</h2><h3 id=\"A、整体流程\"><a href=\"#A、整体流程\" class=\"headerlink\" title=\"A、整体流程\"></a>A、整体流程</h3><p><strong><em>涉及两个动作：服务端的服务注册、客户端的服务发现。</em></strong><br><img src=\"/2019/08/19/2019-08-19-RPC/RPC.png\" alt=\"RPC\"></p>\n<h3 id=\"B、实现\"><a href=\"#B、实现\" class=\"headerlink\" title=\"B、实现\"></a>B、实现</h3><p><strong>1</strong>、客户端与注册中心：客户端启动主动拉一次配置（获得服务的节点、端口信息）、拉收集项；启动完成后，收集项由注册中心每隔一个小时推送一次，另外在客户端有一个10分钟一次的定时任务会拉取最新的配置信息<br><strong>2</strong>、服务端与注册中心：服务端会启动一个定时任务，定时发送心跳（上报节点信息）、拉收集项、发送白名单（注册中心接收到白名单消息，并没有做任何处理，暂时无用）；注册中心每隔一小时推送一次最新的收集项，另外推送黑名单给服务端（黑名单用于拦截请求，保护服务）</p>\n<a id=\"more\"></a>  \n\n<h2 id=\"1-2、序列化\"><a href=\"#1-2、序列化\" class=\"headerlink\" title=\"1.2、序列化\"></a>1.2、序列化</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/%E5%BA%8F%E5%88%97%E5%8C%96.png\" alt=\"RPC\"></p>\n<ul>\n<li>四元组(TT[L]V)</li>\n</ul>\n<pre><code>Tag + Type + Length + Value\n属性标签、属性类型、属性值字节长度、属性值</code></pre><h2 id=\"1-3、数据传输\"><a href=\"#1-3、数据传输\" class=\"headerlink\" title=\"1.3、数据传输\"></a>1.3、数据传输</h2><table>\n<thead>\n<tr>\n<th>字段</th>\n<th>协议头</th>\n<th>版本号</th>\n<th>总长度</th>\n<th>SessionId</th>\n<th>服务编号</th>\n<th>协议类型</th>\n<th>压缩类型</th>\n<th>序列化类型</th>\n<th>平台</th>\n<th>调用链数据长度</th>\n<th>调用链数据</th>\n<th>服务治理key长度</th>\n<th>服务治理key</th>\n<th>业务数据</th>\n<th>协议尾</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>长度(byte)</td>\n<td>5</td>\n<td>1</td>\n<td>4</td>\n<td>4</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>2</td>\n<td>xxoo</td>\n<td>2</td>\n<td>xxoo</td>\n<td>xxoo</td>\n<td>5</td>\n</tr>\n<tr>\n<td>含义</td>\n<td>验证使用</td>\n<td>扩展使用</td>\n<td>不包含头和位</td>\n<td>异步机制使用</td>\n<td>暂无实现</td>\n<td>啊</td>\n<td>暂未实现</td>\n<td>asf、asf_ext</td>\n<td>java</td>\n<td>调用链使用</td>\n<td>调用链使用</td>\n<td>服务治理使用</td>\n<td>服务治理使用</td>\n<td>自定义java对象序列化后的byte数组</td>\n<td>断包使用</td>\n</tr>\n</tbody></table>\n<ul>\n<li>支持多种序列化方式：Hessian、SCF、json</li>\n<li>解析字节流，截取到业务数据</li>\n<li>根据序列化方式，对字节数组解析反序列化。</li>\n</ul>\n<h2 id=\"1-4、底层通讯（TCP）\"><a href=\"#1-4、底层通讯（TCP）\" class=\"headerlink\" title=\"1.4、底层通讯（TCP）\"></a>1.4、底层通讯（TCP）</h2><p>底层通讯，使用了netty框架。</p>\n<h1 id=\"二、客户端\"><a href=\"#二、客户端\" class=\"headerlink\" title=\"二、客户端\"></a>二、客户端</h1><h2 id=\"2-1、架构\"><a href=\"#2-1、架构\" class=\"headerlink\" title=\"2.1、架构\"></a>2.1、架构</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9E%B6%E6%9E%84.png\" alt=\"RPC\"></p>\n<ul>\n<li>接口代理层：采用Java的动态代理，创建接口代理并缓存，代理类中实现具体的序列化、节点路由、网络连接及数据传输等。</li>\n<li>服务代理层：缓存服务，访问控制（同步、异步、服务故障（重启、宕机、超时）等转移）。</li>\n<li>节点路由层：服务节点路由及服务负载均衡。</li>\n<li>连接管理层：缓存客户端与服务端的TCP连接，并提供连接池功能。</li>\n<li>数据传输层：数据的发送与接收。</li>\n</ul>\n<h2 id=\"2-2、一次方法调用过程\"><a href=\"#2-2、一次方法调用过程\" class=\"headerlink\" title=\"2.2、一次方法调用过程\"></a>2.2、一次方法调用过程</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B.png\" alt=\"RPC\"></p>\n<pre><code>1.每个Service在客户端，都对应一个ProxyStandard，它代理执行该Service的执行，初始化一次进行缓存  \n2.MethodCaller中是服务执行方法的地方，会调用ServiceProxy获取Server节点，获取方式是通过负载均衡策略  \n3.ServiceProxy持有自己的所有对象的Map,根据serviceName可以找到一个服务的节点池  \n4.Dispatcher是个负载均衡器，他负责选择服务的节点，并且持有一个服务的所有节点  \n5.一个节点对应一个Server对象，Server是一个服务提供者，它会和服务提供者直接会建立连接池queue  </code></pre><h2 id=\"2-3、重试机制\"><a href=\"#2-3、重试机制\" class=\"headerlink\" title=\"2.3、重试机制\"></a>2.3、重试机制</h2><p>server将请求发送至queue中后，会同步等待返回结果，当接收信息时超时抛出异常，异常被serviceProxy捕获，进行超时的重试。</p>\n<ul>\n<li>重试次数：默认3次</li>\n<li>超时时间：默认3s</li>\n</ul>\n<h2 id=\"2-4、负载均衡\"><a href=\"#2-4、负载均衡\" class=\"headerlink\" title=\"2.4、负载均衡\"></a>2.4、负载均衡</h2><p>权重随机策略，默认采用轮询</p>\n<h2 id=\"2-5、服务降级唤醒\"><a href=\"#2-5、服务降级唤醒\" class=\"headerlink\" title=\"2.5、服务降级唤醒\"></a>2.5、服务降级唤醒</h2><p>定时任务，获取断开连接的服务进行连接。</p>\n<h2 id=\"2-6、客户端容错汇总\"><a href=\"#2-6、客户端容错汇总\" class=\"headerlink\" title=\"2.6、客户端容错汇总\"></a>2.6、客户端容错汇总</h2><p>1、超时连接：服务节点变为Dead，死亡节点异步线程进行探测激活</p>\n<h2 id=\"2-7、心跳机制\"><a href=\"#2-7、心跳机制\" class=\"headerlink\" title=\"2.7、心跳机制\"></a>2.7、心跳机制</h2><p>1、每个Socket创建连接之后，都会启动一个定期执行的心跳线程发送心跳。<br>2、服务节点状态变为Deaed，异步探测线程5秒执行一次，会进行心跳探测，探测成功更新节点死亡时间，成功恢复节点</p>\n<h1 id=\"三、服务端\"><a href=\"#三、服务端\" class=\"headerlink\" title=\"三、服务端\"></a>三、服务端</h1><h2 id=\"3-1、线程模型\"><a href=\"#3-1、线程模型\" class=\"headerlink\" title=\"3.1、线程模型\"></a>3.1、线程模型</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/server%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png\" alt=\"RPC\"><br>1、socketHandler接到请求，根据负载均衡，将完整包放入异步处理队列。<br>2、异步处理线程模型，可以有多个线程组，一个线程组默认8个线程，这个8个线程一起维护一个队列。</p>\n<h2 id=\"3-2、一次方法的调用过程\"><a href=\"#3-2、一次方法的调用过程\" class=\"headerlink\" title=\"3.2、一次方法的调用过程\"></a>3.2、一次方法的调用过程</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/server%E6%96%B9%E6%B3%95%E8%BF%87%E7%A8%8B.png\" alt=\"RPC\"></p>\n<pre><code>1.请求数据首先通过固定结尾DelimiterBasedFrameDecoder解码\n2.SocketHandler判断数据类型，心跳直接返回\n3.前置业务过滤器ProtocolParseFilter反序列化请求\n4.根据请求lookup从服务代理工厂获取代理服务\n5.返回结果码流</code></pre><h2 id=\"3-3、启动过程\"><a href=\"#3-3、启动过程\" class=\"headerlink\" title=\"3.3、启动过程\"></a>3.3、启动过程</h2><pre><code>2、生成服务代理\n  1.1 加载所有的jar 容器lib+服务目录\n  1.2 加载系统目录下所有class\n  1.3 class中扫描ServiceContract注解的接口，扫描OperationContract注解的方法，去重\n  1.4 class中扫描ServiceBehavior注解的实现，只扫描protected和public的方法，去重，相同的lookup报错\n  1.5 扫描的jar中加载class，扫描jar中的ServiceContract和ServiceBehavior注解类\n  1.6 接口和实现类对应关系绑定\n  1.7 为csf服务实现类，利用java-assist生成代理类，有Spring增加上下文获取Bean逻辑\n  1.8 生成代理对象工厂类\n  1.9 初始化代理对象\n  1.10 初始化代理工厂对象，将代理对象传入工厂\n\n3.加载并调用init接口的实现类\n4.加载Filter\n5.注册新号\n6.添加Hooks\n7.启动server\n8.注册Server的ShutDownHook </code></pre><h1 id=\"4、异步调用\"><a href=\"#4、异步调用\" class=\"headerlink\" title=\"4、异步调用\"></a>4、异步调用</h1><h2 id=\"1、ConcurrentHashMap-lt-Integer-WindowData-gt-WaitWindows\"><a href=\"#1、ConcurrentHashMap-lt-Integer-WindowData-gt-WaitWindows\" class=\"headerlink\" title=\"1、ConcurrentHashMap&lt;Integer, WindowData&gt; WaitWindows\"></a>1、ConcurrentHashMap&lt;Integer, WindowData&gt; WaitWindows</h2><p>&lt;key, value&gt; = &lt;sessionId, WinData&gt;，</p>\n<ul>\n<li>sendInvoke(wd); //发送线程职责：将请求流发送给服务端</li>\n<li>timeOutInvoke(wd); //接收线程职责：超时判断 + 回调函数调用</li>\n</ul>\n<p>按sessionId，进行解析</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、RPC需要解决的问题\"><a href=\"#一、RPC需要解决的问题\" class=\"headerlink\" title=\"一、RPC需要解决的问题\"></a>一、RPC需要解决的问题</h1><p>1、服务发现（寻址）<br>2、数据传输（序列化）<br>3、底层通讯（TCP）  </p>\n<h2 id=\"1-1、服务发现-amp-注册（寻址）\"><a href=\"#1-1、服务发现-amp-注册（寻址）\" class=\"headerlink\" title=\"1.1、服务发现&amp;注册（寻址）\"></a>1.1、服务发现&amp;注册（寻址）</h2><h3 id=\"A、整体流程\"><a href=\"#A、整体流程\" class=\"headerlink\" title=\"A、整体流程\"></a>A、整体流程</h3><p><strong><em>涉及两个动作：服务端的服务注册、客户端的服务发现。</em></strong><br><img src=\"/2019/08/19/2019-08-19-RPC/RPC.png\" alt=\"RPC\"></p>\n<h3 id=\"B、实现\"><a href=\"#B、实现\" class=\"headerlink\" title=\"B、实现\"></a>B、实现</h3><p><strong>1</strong>、客户端与注册中心：客户端启动主动拉一次配置（获得服务的节点、端口信息）、拉收集项；启动完成后，收集项由注册中心每隔一个小时推送一次，另外在客户端有一个10分钟一次的定时任务会拉取最新的配置信息<br><strong>2</strong>、服务端与注册中心：服务端会启动一个定时任务，定时发送心跳（上报节点信息）、拉收集项、发送白名单（注册中心接收到白名单消息，并没有做任何处理，暂时无用）；注册中心每隔一小时推送一次最新的收集项，另外推送黑名单给服务端（黑名单用于拦截请求，保护服务）</p>","more":"<h2 id=\"1-2、序列化\"><a href=\"#1-2、序列化\" class=\"headerlink\" title=\"1.2、序列化\"></a>1.2、序列化</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/%E5%BA%8F%E5%88%97%E5%8C%96.png\" alt=\"RPC\"></p>\n<ul>\n<li>四元组(TT[L]V)</li>\n</ul>\n<pre><code>Tag + Type + Length + Value\n属性标签、属性类型、属性值字节长度、属性值</code></pre><h2 id=\"1-3、数据传输\"><a href=\"#1-3、数据传输\" class=\"headerlink\" title=\"1.3、数据传输\"></a>1.3、数据传输</h2><table>\n<thead>\n<tr>\n<th>字段</th>\n<th>协议头</th>\n<th>版本号</th>\n<th>总长度</th>\n<th>SessionId</th>\n<th>服务编号</th>\n<th>协议类型</th>\n<th>压缩类型</th>\n<th>序列化类型</th>\n<th>平台</th>\n<th>调用链数据长度</th>\n<th>调用链数据</th>\n<th>服务治理key长度</th>\n<th>服务治理key</th>\n<th>业务数据</th>\n<th>协议尾</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>长度(byte)</td>\n<td>5</td>\n<td>1</td>\n<td>4</td>\n<td>4</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>2</td>\n<td>xxoo</td>\n<td>2</td>\n<td>xxoo</td>\n<td>xxoo</td>\n<td>5</td>\n</tr>\n<tr>\n<td>含义</td>\n<td>验证使用</td>\n<td>扩展使用</td>\n<td>不包含头和位</td>\n<td>异步机制使用</td>\n<td>暂无实现</td>\n<td>啊</td>\n<td>暂未实现</td>\n<td>asf、asf_ext</td>\n<td>java</td>\n<td>调用链使用</td>\n<td>调用链使用</td>\n<td>服务治理使用</td>\n<td>服务治理使用</td>\n<td>自定义java对象序列化后的byte数组</td>\n<td>断包使用</td>\n</tr>\n</tbody></table>\n<ul>\n<li>支持多种序列化方式：Hessian、SCF、json</li>\n<li>解析字节流，截取到业务数据</li>\n<li>根据序列化方式，对字节数组解析反序列化。</li>\n</ul>\n<h2 id=\"1-4、底层通讯（TCP）\"><a href=\"#1-4、底层通讯（TCP）\" class=\"headerlink\" title=\"1.4、底层通讯（TCP）\"></a>1.4、底层通讯（TCP）</h2><p>底层通讯，使用了netty框架。</p>\n<h1 id=\"二、客户端\"><a href=\"#二、客户端\" class=\"headerlink\" title=\"二、客户端\"></a>二、客户端</h1><h2 id=\"2-1、架构\"><a href=\"#2-1、架构\" class=\"headerlink\" title=\"2.1、架构\"></a>2.1、架构</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9E%B6%E6%9E%84.png\" alt=\"RPC\"></p>\n<ul>\n<li>接口代理层：采用Java的动态代理，创建接口代理并缓存，代理类中实现具体的序列化、节点路由、网络连接及数据传输等。</li>\n<li>服务代理层：缓存服务，访问控制（同步、异步、服务故障（重启、宕机、超时）等转移）。</li>\n<li>节点路由层：服务节点路由及服务负载均衡。</li>\n<li>连接管理层：缓存客户端与服务端的TCP连接，并提供连接池功能。</li>\n<li>数据传输层：数据的发送与接收。</li>\n</ul>\n<h2 id=\"2-2、一次方法调用过程\"><a href=\"#2-2、一次方法调用过程\" class=\"headerlink\" title=\"2.2、一次方法调用过程\"></a>2.2、一次方法调用过程</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B.png\" alt=\"RPC\"></p>\n<pre><code>1.每个Service在客户端，都对应一个ProxyStandard，它代理执行该Service的执行，初始化一次进行缓存  \n2.MethodCaller中是服务执行方法的地方，会调用ServiceProxy获取Server节点，获取方式是通过负载均衡策略  \n3.ServiceProxy持有自己的所有对象的Map,根据serviceName可以找到一个服务的节点池  \n4.Dispatcher是个负载均衡器，他负责选择服务的节点，并且持有一个服务的所有节点  \n5.一个节点对应一个Server对象，Server是一个服务提供者，它会和服务提供者直接会建立连接池queue  </code></pre><h2 id=\"2-3、重试机制\"><a href=\"#2-3、重试机制\" class=\"headerlink\" title=\"2.3、重试机制\"></a>2.3、重试机制</h2><p>server将请求发送至queue中后，会同步等待返回结果，当接收信息时超时抛出异常，异常被serviceProxy捕获，进行超时的重试。</p>\n<ul>\n<li>重试次数：默认3次</li>\n<li>超时时间：默认3s</li>\n</ul>\n<h2 id=\"2-4、负载均衡\"><a href=\"#2-4、负载均衡\" class=\"headerlink\" title=\"2.4、负载均衡\"></a>2.4、负载均衡</h2><p>权重随机策略，默认采用轮询</p>\n<h2 id=\"2-5、服务降级唤醒\"><a href=\"#2-5、服务降级唤醒\" class=\"headerlink\" title=\"2.5、服务降级唤醒\"></a>2.5、服务降级唤醒</h2><p>定时任务，获取断开连接的服务进行连接。</p>\n<h2 id=\"2-6、客户端容错汇总\"><a href=\"#2-6、客户端容错汇总\" class=\"headerlink\" title=\"2.6、客户端容错汇总\"></a>2.6、客户端容错汇总</h2><p>1、超时连接：服务节点变为Dead，死亡节点异步线程进行探测激活</p>\n<h2 id=\"2-7、心跳机制\"><a href=\"#2-7、心跳机制\" class=\"headerlink\" title=\"2.7、心跳机制\"></a>2.7、心跳机制</h2><p>1、每个Socket创建连接之后，都会启动一个定期执行的心跳线程发送心跳。<br>2、服务节点状态变为Deaed，异步探测线程5秒执行一次，会进行心跳探测，探测成功更新节点死亡时间，成功恢复节点</p>\n<h1 id=\"三、服务端\"><a href=\"#三、服务端\" class=\"headerlink\" title=\"三、服务端\"></a>三、服务端</h1><h2 id=\"3-1、线程模型\"><a href=\"#3-1、线程模型\" class=\"headerlink\" title=\"3.1、线程模型\"></a>3.1、线程模型</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/server%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png\" alt=\"RPC\"><br>1、socketHandler接到请求，根据负载均衡，将完整包放入异步处理队列。<br>2、异步处理线程模型，可以有多个线程组，一个线程组默认8个线程，这个8个线程一起维护一个队列。</p>\n<h2 id=\"3-2、一次方法的调用过程\"><a href=\"#3-2、一次方法的调用过程\" class=\"headerlink\" title=\"3.2、一次方法的调用过程\"></a>3.2、一次方法的调用过程</h2><p><img src=\"/2019/08/19/2019-08-19-RPC/server%E6%96%B9%E6%B3%95%E8%BF%87%E7%A8%8B.png\" alt=\"RPC\"></p>\n<pre><code>1.请求数据首先通过固定结尾DelimiterBasedFrameDecoder解码\n2.SocketHandler判断数据类型，心跳直接返回\n3.前置业务过滤器ProtocolParseFilter反序列化请求\n4.根据请求lookup从服务代理工厂获取代理服务\n5.返回结果码流</code></pre><h2 id=\"3-3、启动过程\"><a href=\"#3-3、启动过程\" class=\"headerlink\" title=\"3.3、启动过程\"></a>3.3、启动过程</h2><pre><code>2、生成服务代理\n  1.1 加载所有的jar 容器lib+服务目录\n  1.2 加载系统目录下所有class\n  1.3 class中扫描ServiceContract注解的接口，扫描OperationContract注解的方法，去重\n  1.4 class中扫描ServiceBehavior注解的实现，只扫描protected和public的方法，去重，相同的lookup报错\n  1.5 扫描的jar中加载class，扫描jar中的ServiceContract和ServiceBehavior注解类\n  1.6 接口和实现类对应关系绑定\n  1.7 为csf服务实现类，利用java-assist生成代理类，有Spring增加上下文获取Bean逻辑\n  1.8 生成代理对象工厂类\n  1.9 初始化代理对象\n  1.10 初始化代理工厂对象，将代理对象传入工厂\n\n3.加载并调用init接口的实现类\n4.加载Filter\n5.注册新号\n6.添加Hooks\n7.启动server\n8.注册Server的ShutDownHook </code></pre><h1 id=\"4、异步调用\"><a href=\"#4、异步调用\" class=\"headerlink\" title=\"4、异步调用\"></a>4、异步调用</h1><h2 id=\"1、ConcurrentHashMap-lt-Integer-WindowData-gt-WaitWindows\"><a href=\"#1、ConcurrentHashMap-lt-Integer-WindowData-gt-WaitWindows\" class=\"headerlink\" title=\"1、ConcurrentHashMap&lt;Integer, WindowData&gt; WaitWindows\"></a>1、ConcurrentHashMap&lt;Integer, WindowData&gt; WaitWindows</h2><p>&lt;key, value&gt; = &lt;sessionId, WinData&gt;，</p>\n<ul>\n<li>sendInvoke(wd); //发送线程职责：将请求流发送给服务端</li>\n<li>timeOutInvoke(wd); //接收线程职责：超时判断 + 回调函数调用</li>\n</ul>\n<p>按sessionId，进行解析</p>"},{"title":"DMQ","date":"2019-07-24T14:29:49.000Z","_content":"\n# 一、注册中心\n注册中心，基于zookeeper来实现。\n- /dmq/topic下为主题号，主题号下为客户端。\n- /dmq/node下为server节点。\n\n<!--more-->  \n\n![dmq](2019-07-24-dmq/mq-center.png)\n``` bash\n1、server心跳节点上报到注册中心，节点变化，由注册中心通知client，client每一小时拉取一次全量的配置信息\n2、client和一台注册中心保持长连接，定时查询server信息，如果该register server挂掉，消费者会自动连接下一个registerserver，直到有可用连接为止，并能自动重连；\n3、心跳保持30s的好处是，可以及时的检测server状态；\n```\n# 二、生产者\n### 2.0 初始化启动过程\n![dmq](2019-07-24-dmq/mq-client-center.png)\n\n>- 1、初始化serverPoll\n>- 2、解析URL服务器地址，生成相应serverConfig，并初始化连接。\n\n### 2.1 生产过程：\n![dmq](2019-07-24-dmq/mq-client-server-3.png)\n- 1、mqClient.send(msg)，客户端API发送消息。\n- 2、内部消息队列控制器（MsgQueueController）将消息存入发送消息队列（sendQueue）\n    - 2.1、sessionid<0或者消息体超过64kb直接放入通知队列\n    - 2.2、队列超长之后进行回调处理\n\n### 2.2 消息处理过程：\n***2.2.1 发送消息队列***\n- 1、sendRunner循环从sendQueue取数据。\n- 2、主题路由获取server，向server发送数据。\n    - 2.1、若发送出现异常，则将消息入接收消息队列（notifyQueue）。\n- 3、判断消息类型（非ack && 非resend）\n    - 3.1、将消息放入消息重发map（resendMap;<Long, value>=<sessionId, WinData）。\n\n```\nwhile (mqController.isOpen()) {\n    MqBody mqBody = null;\n    try {\n        WinData winData = mqController.getSendMsg();\n  \t\tif (winData != null && winData.getMqBody() != null) {\n  \t\t    mqBody = winData.getMqBody();\n  \t\t    try {\n  \t\t\t    if (mqBody.getCommandType() == UP_SUBSCRIBE) {\n  \t\t\t\t    winData.getNioChannel().getServer().send(mqBody);\n  \t\t\t    } else {\n  \t\t\t\t    topicRoute.send(false, winData, mqController);\n  \t\t\t    }\n  \t\t\t} catch (Exception e) {\n  \t\t\t    winData.setStatus(SOCKET_ERROR);\n  \t\t\t    mqController.offerNotifyMsg(winData);\n  \t\t\t    continue;\n  \t\t\t}\n  \t\t\tif (mqBody.getCommandType() != UP_CONSUMER_ACK && mqBody.getCommandType() != UP_PRODUCER_RESEND) {\n  \t\t\t    mqController.offerResendMsg(winData);\n  \t\t\t}\n  \t\t}\n  \t} catch (Exception e) {\n  \t}\n}\n```\n\n\n***2.2.2 消息重发map***\n- 1、resendRunner循环从resendMap取数据。\n- 2、判断消息的重发次数小于3\n    - 2.1、若消息发送时间已经超过30s，则将消息发送至sendQueue\n- 3、发送次数>3\n    - 3.1、将消息从resendMap中删除。\n    - 3.2、将消息发送至notifyQueue中。\n    \n```\nwhile (mqController.isOpen()) {\n    try {\n        for (Map.Entry<Long, WinData> entry : mqController.getResendMap().entrySet()) {\n            WinData winData = entry.getValue();\n            if (winData == null || winData.getMqBody() == null) {\n                continue;\n            }\n            //MqBody clone = winData.getMqBody().clone();\n            //防止订阅者重发时在获得channel时出现空指针，将windowdata直接clone放入重发队列\n            WinData clone = winData.clone();\n            long last = System.currentTimeMillis() - clone.getMqBody().getTimestamp();\n            if(winData.getCount() > 0){\n            \tif(last > MQConst.OUT_TIME * (RESEND_TIME - winData.getCount() + 1)){\n                    if(clone.getMqBody().getCommandType().getCode()!=UP_SUBSCRIBE.getCode()){\n                        clone.getMqBody().setCommandType(UP_PRODUCER_RESEND);\n                    }\n                    winData.setCount(winData.getCount() - 1);\n                    //mqController.offerSendMsg(clone, winData.getCount() - 1, winData.getISendCallback());\n                    //将clone出来的windowdata放入发送队列\n                    mqController.offerSendWin(clone);\n            \t}\n            }else{\n            \tWinData remove = mqController.removeResendMsg(clone.getMqBody().getSessionId());\n                remove.setStatus(SendMsgStatusEnum.OUT_OF_RETRY);\n                mqController.offerNotifyMsg(remove);\n            }\n        }\n        Thread.sleep(1000);\n    } catch (Exception e) {\n    }\n}\n```\n    \n消息最多重发3次，每隔30s进行重发，超过以后不进行重发。  \n\n***2.2.3 接收消息队列***\n- 1、notifyMsgRunner循环从notifyQueue取数据。\n- 2、判断消息类型\n    - 2.1、消费者类型消息，调用相应handler进行相应处理。\n    - 2.2、ack类型消息，调用callback进行相应处理。\n\n\n### 2.3 接收server的ack\n- 1、通过NIOChannel进行通信，将结果回传。\n- 2、根据ack类型，进行相应处理\n    - 2.1、下发成功、主题号异常、服务异常：此时会将消息从重发Map中去除、并将消息放入notifyQueue中。\n    - 2.2、机器重启：将该主题号下的重启服务去除。\n    - 2.3、生产者消息：调用消费者的ReceiveHandler业务处理逻辑，进行相应处理。\n    \n```\nswitch (mqBody.getCommandType()) {\n    case SUBSCRIBE_ACK:\n    case SEND_SUCCESS_ACK:\n    case SEND_NO_TOPIC_ACK:\n    case SUBSCRIBE_NO_TOPIC_ACK:\n    case SUBSCRIBE_NO_CLIENT_ID_ACK:\n    case SEND_SERVER_ERROR:\n    case SUBSCRIBE_SERVER_ERROR:\n    case SEND_EXCEED_LIMIT_ACK:\n        winData = mqController.removeResendMsg(mqBody.getSessionId());\n        if (winData == null || winData.getMqBody() == null) {\n            LOGGER.debug(\"get window data null from {}\", mqBody);\n            break;\n        }\n        winData.setStatus(SendMsgStatusEnum.getByCommand(mqBody.getCommandType()));\n        //将服务端返回的消息赋值给重发队列中的消息\n        MqBody mqBodyInClient = winData.getMqBody();\n        mqBodyInClient.setMessageId(mqBody.getMessageId());\n        mqBodyInClient.setCommandType(mqBody.getCommandType());\n        winData.setDmqBody(mqBodyInClient);\n        mqController.offerNotifyMsg(winData);\n        break;\n    case CONSUMER_PUSH:\n        winData = new WinData(mqBody, -1, null);\n        boolean isDistinct = mqController.offerDistinctMsg(mqBody.getSessionId(),mqBody.getClientID());\n        if (isDistinct) {\n            winData.setNioChannel(this);\n            //将推送来的消息放入消息接收队列\n            mqController.offerReceiveMsg(winData);\n        } else {\n            LOGGER.debug(\"repeat msg {}\", mqBody);\n        }\n        break;\n    case SERVER_REBOOT:\n        LOGGER.debug(\"server is rebooting\");\n        mqController.removeSubServer(server);\n        server.setState(RESTART);\n        break;\n    case SERVER_HEALTH:\n        LOGGER.debug(\"server is health\");\n        server.setState(HEALTH);\n        server.setErrorTime(Long.MAX_VALUE);\n        break;\n    case SERVER__HEARTBEAT:\n        LOGGER.debug(\"receive server heartbeat \");\n        break;\n    default:\n        throw new SerializeException(\"un know commandType \" + mqBody.getCommandType());\n}\n``` \n    \n### 2.4 生产者问题\n``` bash\n1、消息存入队列中，若队列数据量大，此时机器挂机，会出现消息丢失，数据丢失时，依赖业务方日志由业务方自己重发消息，未提供持久化支持。可以采用QMQ方式，支持消息的持久化。    \n```\n# 三、MQ server\n\n### 3.1 启动过程\n\n\n![dmq](2019-07-24-dmq/mq-server-start.png)\n\n    a、zk注册，拉取主题号、client等信息，并启动定时任务去更新每3s一次。\n    b、初始化DB。\n    c、启动定时任务去发送离线消息。\n    d、启动TcpServer，监听请求，并对请求进行相应的分发处理。\n    e、启动telnetServer。\n\n### 3.2 订阅者注册\n- tcpServer接收到订阅者注册消息，将消息分发给SubscribeHandler。然后通过线程池创建相应的线程去处理，将当前消费者的client设置到该主题号下。\n\n![dmq](2019-07-24-dmq/mq-server-sub.png)\n\n以下为代码：\n\n    subExecutor.submit(new Runnable() {\n        public void run() {\n            try {\n                MqBody mqBody = mqContext.getMqBody();\n                // validate topic\n                List<Client> clientList = clientService.getClientList(mqBody.getTopic());\n                if (CollectionUtils.isEmpty(clientList)) {\n                    // ack consumer no topic\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_NO_TOPIC_ACK, \"\");\n                    return;\n                }\n                // add new channel for consumer\n                if (addChannel(clientList, mqBody.getClientID(), mqContext.getChannel())) {\n                    // ack consumer\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_ACK, \"\");\n                } else {\n                    // ack consumer no client id\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_NO_CLIENT_ID_ACK, \"\");\n                    return;\n                }\n                offlineExecutor.schedule(getInstance(mqBody), OFFLINE_DELAY_TIME, TimeUnit.MILLISECONDS);\n            } catch (Exception e) {\n                clientService.ackClient(mqContext.getMqBody(), mqContext.getChannel(), SUBSCRIBE_SERVER_ERROR, Throwables.getStackTraceAsString(e));\n            }\n        }\n    });   \n\n### 3.3 接收消息\n- tcpServer接收到生产者发送消息，将消息分发给SendMsgHandler。然后通过线程池创建相应的线程去处理消息的存储、ack及推送。\n\n![dmq](2019-07-24-dmq/mq-server-send.png)\n\n    可靠消息：\n        1、先进行存储至DB\n        2、入DB成功后，恢复Client进行消息通知。\n        3、再进行数据的推送。\n    延迟消息：\n        1、先进行存储至延迟DB\n        2、入DB成功后，恢复Client进行消息通知。\n\n以下为代码：\n\n    public void run() {\n        try {\n            MqBody mqBody = mqContext.getMqBody();\n            mqBody.setMessageId(IdUtil.generateId());\n            // validate topic\n            List<Client> clientList = clientService.getClientList(mqBody.getTopic());\n            if (CollectionUtils.isEmpty(clientList)) {\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_NO_TOPIC_ACK, \"\");\n                return;\n            }\n            if (mqBody.getMsgTypeEnum() == MsgTypeEnum.RELIABLE) {\n                // 可靠消息存储\n                if (messageService.saveMessage(mqBody, clientList)) {\n                    // 成功ack给生产者\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SUCCESS_ACK, \"\");\n                    // 推送给消费者\n                    clientService.pushMsg(mqBody, clientList, false);\n                } else {\n                    // 存储失败，通知生产者异常ack\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SERVER_ERROR, Util.getMqConfig().serverErrorDes());\n                }\n            } else if (mqBody.getMsgTypeEnum() == MsgTypeEnum.DELAY) {\n                if(delayMsgService.insert(mqBody)){//延迟消息入库\n                    //成功ack\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SUCCESS_ACK, \"\");\n                }else{\n                    //失败ack\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SERVER_ERROR, Util.getMqConfig().serverErrorDes());\n                }\n            }\n        } catch (Exception e) {\n            //异常ack\n            clientService.ackClient(mqContext.getMqBody(), mqContext.getChannel(), SEND_SERVER_ERROR, Throwables.getStackTraceAsString(e));\n        } finally {\n        }\n    }\n\n### 3.4 接收重复消息\n![dmq](2019-07-24-dmq/mq-server-resend.png)\n\n### 3.5 死信消息\n消息入死信队列情况：\n\n    1、超过QPS限流。\n    2、入DB异常。\n    3、消息过期。\n    \n死信消息上报时，单独持久化至DB。由MQ管理平台控制，死信消息由人工处理，可以进行重发或者删除。\n\n# 四、消费者\n    1、查看文章图二，ReceiveQueue存放的是生产者发送的消息，该队列的消费线程poll队列消息，调用相应的ReceiveHandler进行相应的业务逻辑处理。\n    2、此时消费者可以设置是否自动ack，回复ack，此时会将库中的持久化数据进行删除；若不ack，则会一直发送。\n\n# 延迟消息\n* 接收到延迟消息后，写入fragment，存入Delay_DB。\n    * mq.properties添加配置项：fragment\n    * fragment：\n    * 例如：fragment为8，则每条延迟消息fragment字段的数值为1-8之间的随机数\n        *DelayJOB的发送线程thread_count设定为2，则线程1处理fragment字段为1-4的延迟消息，线程2处理5-8。\n\n# 六、总结\n\n![dmq](2019-07-24-dmq/mq-总结.png)\n1、问题一：Producer会将消息存放在本地的queue中，若producer宕机，会出现消息丢失问题。\n    \n    解决方法一：实时发送至server。\n    解决方法二：producer提供持久化方式，如入库、写文件。\n    \n2、问题二：server写DB时只写入os cache，此时DB挂机可能出现server消息丢失。\n\n    解决方法一：写DB强制写入磁盘，效率较低。\n    解决方案二：customer返回ack时才通知producer发送成功ack。","source":"_posts/2019-07-24-DMQ.md","raw":"---\ntitle: DMQ\ndate: 2019-07-24 22:29:49\ncategories: MQ\n---\n\n# 一、注册中心\n注册中心，基于zookeeper来实现。\n- /dmq/topic下为主题号，主题号下为客户端。\n- /dmq/node下为server节点。\n\n<!--more-->  \n\n![dmq](2019-07-24-dmq/mq-center.png)\n``` bash\n1、server心跳节点上报到注册中心，节点变化，由注册中心通知client，client每一小时拉取一次全量的配置信息\n2、client和一台注册中心保持长连接，定时查询server信息，如果该register server挂掉，消费者会自动连接下一个registerserver，直到有可用连接为止，并能自动重连；\n3、心跳保持30s的好处是，可以及时的检测server状态；\n```\n# 二、生产者\n### 2.0 初始化启动过程\n![dmq](2019-07-24-dmq/mq-client-center.png)\n\n>- 1、初始化serverPoll\n>- 2、解析URL服务器地址，生成相应serverConfig，并初始化连接。\n\n### 2.1 生产过程：\n![dmq](2019-07-24-dmq/mq-client-server-3.png)\n- 1、mqClient.send(msg)，客户端API发送消息。\n- 2、内部消息队列控制器（MsgQueueController）将消息存入发送消息队列（sendQueue）\n    - 2.1、sessionid<0或者消息体超过64kb直接放入通知队列\n    - 2.2、队列超长之后进行回调处理\n\n### 2.2 消息处理过程：\n***2.2.1 发送消息队列***\n- 1、sendRunner循环从sendQueue取数据。\n- 2、主题路由获取server，向server发送数据。\n    - 2.1、若发送出现异常，则将消息入接收消息队列（notifyQueue）。\n- 3、判断消息类型（非ack && 非resend）\n    - 3.1、将消息放入消息重发map（resendMap;<Long, value>=<sessionId, WinData）。\n\n```\nwhile (mqController.isOpen()) {\n    MqBody mqBody = null;\n    try {\n        WinData winData = mqController.getSendMsg();\n  \t\tif (winData != null && winData.getMqBody() != null) {\n  \t\t    mqBody = winData.getMqBody();\n  \t\t    try {\n  \t\t\t    if (mqBody.getCommandType() == UP_SUBSCRIBE) {\n  \t\t\t\t    winData.getNioChannel().getServer().send(mqBody);\n  \t\t\t    } else {\n  \t\t\t\t    topicRoute.send(false, winData, mqController);\n  \t\t\t    }\n  \t\t\t} catch (Exception e) {\n  \t\t\t    winData.setStatus(SOCKET_ERROR);\n  \t\t\t    mqController.offerNotifyMsg(winData);\n  \t\t\t    continue;\n  \t\t\t}\n  \t\t\tif (mqBody.getCommandType() != UP_CONSUMER_ACK && mqBody.getCommandType() != UP_PRODUCER_RESEND) {\n  \t\t\t    mqController.offerResendMsg(winData);\n  \t\t\t}\n  \t\t}\n  \t} catch (Exception e) {\n  \t}\n}\n```\n\n\n***2.2.2 消息重发map***\n- 1、resendRunner循环从resendMap取数据。\n- 2、判断消息的重发次数小于3\n    - 2.1、若消息发送时间已经超过30s，则将消息发送至sendQueue\n- 3、发送次数>3\n    - 3.1、将消息从resendMap中删除。\n    - 3.2、将消息发送至notifyQueue中。\n    \n```\nwhile (mqController.isOpen()) {\n    try {\n        for (Map.Entry<Long, WinData> entry : mqController.getResendMap().entrySet()) {\n            WinData winData = entry.getValue();\n            if (winData == null || winData.getMqBody() == null) {\n                continue;\n            }\n            //MqBody clone = winData.getMqBody().clone();\n            //防止订阅者重发时在获得channel时出现空指针，将windowdata直接clone放入重发队列\n            WinData clone = winData.clone();\n            long last = System.currentTimeMillis() - clone.getMqBody().getTimestamp();\n            if(winData.getCount() > 0){\n            \tif(last > MQConst.OUT_TIME * (RESEND_TIME - winData.getCount() + 1)){\n                    if(clone.getMqBody().getCommandType().getCode()!=UP_SUBSCRIBE.getCode()){\n                        clone.getMqBody().setCommandType(UP_PRODUCER_RESEND);\n                    }\n                    winData.setCount(winData.getCount() - 1);\n                    //mqController.offerSendMsg(clone, winData.getCount() - 1, winData.getISendCallback());\n                    //将clone出来的windowdata放入发送队列\n                    mqController.offerSendWin(clone);\n            \t}\n            }else{\n            \tWinData remove = mqController.removeResendMsg(clone.getMqBody().getSessionId());\n                remove.setStatus(SendMsgStatusEnum.OUT_OF_RETRY);\n                mqController.offerNotifyMsg(remove);\n            }\n        }\n        Thread.sleep(1000);\n    } catch (Exception e) {\n    }\n}\n```\n    \n消息最多重发3次，每隔30s进行重发，超过以后不进行重发。  \n\n***2.2.3 接收消息队列***\n- 1、notifyMsgRunner循环从notifyQueue取数据。\n- 2、判断消息类型\n    - 2.1、消费者类型消息，调用相应handler进行相应处理。\n    - 2.2、ack类型消息，调用callback进行相应处理。\n\n\n### 2.3 接收server的ack\n- 1、通过NIOChannel进行通信，将结果回传。\n- 2、根据ack类型，进行相应处理\n    - 2.1、下发成功、主题号异常、服务异常：此时会将消息从重发Map中去除、并将消息放入notifyQueue中。\n    - 2.2、机器重启：将该主题号下的重启服务去除。\n    - 2.3、生产者消息：调用消费者的ReceiveHandler业务处理逻辑，进行相应处理。\n    \n```\nswitch (mqBody.getCommandType()) {\n    case SUBSCRIBE_ACK:\n    case SEND_SUCCESS_ACK:\n    case SEND_NO_TOPIC_ACK:\n    case SUBSCRIBE_NO_TOPIC_ACK:\n    case SUBSCRIBE_NO_CLIENT_ID_ACK:\n    case SEND_SERVER_ERROR:\n    case SUBSCRIBE_SERVER_ERROR:\n    case SEND_EXCEED_LIMIT_ACK:\n        winData = mqController.removeResendMsg(mqBody.getSessionId());\n        if (winData == null || winData.getMqBody() == null) {\n            LOGGER.debug(\"get window data null from {}\", mqBody);\n            break;\n        }\n        winData.setStatus(SendMsgStatusEnum.getByCommand(mqBody.getCommandType()));\n        //将服务端返回的消息赋值给重发队列中的消息\n        MqBody mqBodyInClient = winData.getMqBody();\n        mqBodyInClient.setMessageId(mqBody.getMessageId());\n        mqBodyInClient.setCommandType(mqBody.getCommandType());\n        winData.setDmqBody(mqBodyInClient);\n        mqController.offerNotifyMsg(winData);\n        break;\n    case CONSUMER_PUSH:\n        winData = new WinData(mqBody, -1, null);\n        boolean isDistinct = mqController.offerDistinctMsg(mqBody.getSessionId(),mqBody.getClientID());\n        if (isDistinct) {\n            winData.setNioChannel(this);\n            //将推送来的消息放入消息接收队列\n            mqController.offerReceiveMsg(winData);\n        } else {\n            LOGGER.debug(\"repeat msg {}\", mqBody);\n        }\n        break;\n    case SERVER_REBOOT:\n        LOGGER.debug(\"server is rebooting\");\n        mqController.removeSubServer(server);\n        server.setState(RESTART);\n        break;\n    case SERVER_HEALTH:\n        LOGGER.debug(\"server is health\");\n        server.setState(HEALTH);\n        server.setErrorTime(Long.MAX_VALUE);\n        break;\n    case SERVER__HEARTBEAT:\n        LOGGER.debug(\"receive server heartbeat \");\n        break;\n    default:\n        throw new SerializeException(\"un know commandType \" + mqBody.getCommandType());\n}\n``` \n    \n### 2.4 生产者问题\n``` bash\n1、消息存入队列中，若队列数据量大，此时机器挂机，会出现消息丢失，数据丢失时，依赖业务方日志由业务方自己重发消息，未提供持久化支持。可以采用QMQ方式，支持消息的持久化。    \n```\n# 三、MQ server\n\n### 3.1 启动过程\n\n\n![dmq](2019-07-24-dmq/mq-server-start.png)\n\n    a、zk注册，拉取主题号、client等信息，并启动定时任务去更新每3s一次。\n    b、初始化DB。\n    c、启动定时任务去发送离线消息。\n    d、启动TcpServer，监听请求，并对请求进行相应的分发处理。\n    e、启动telnetServer。\n\n### 3.2 订阅者注册\n- tcpServer接收到订阅者注册消息，将消息分发给SubscribeHandler。然后通过线程池创建相应的线程去处理，将当前消费者的client设置到该主题号下。\n\n![dmq](2019-07-24-dmq/mq-server-sub.png)\n\n以下为代码：\n\n    subExecutor.submit(new Runnable() {\n        public void run() {\n            try {\n                MqBody mqBody = mqContext.getMqBody();\n                // validate topic\n                List<Client> clientList = clientService.getClientList(mqBody.getTopic());\n                if (CollectionUtils.isEmpty(clientList)) {\n                    // ack consumer no topic\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_NO_TOPIC_ACK, \"\");\n                    return;\n                }\n                // add new channel for consumer\n                if (addChannel(clientList, mqBody.getClientID(), mqContext.getChannel())) {\n                    // ack consumer\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_ACK, \"\");\n                } else {\n                    // ack consumer no client id\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_NO_CLIENT_ID_ACK, \"\");\n                    return;\n                }\n                offlineExecutor.schedule(getInstance(mqBody), OFFLINE_DELAY_TIME, TimeUnit.MILLISECONDS);\n            } catch (Exception e) {\n                clientService.ackClient(mqContext.getMqBody(), mqContext.getChannel(), SUBSCRIBE_SERVER_ERROR, Throwables.getStackTraceAsString(e));\n            }\n        }\n    });   \n\n### 3.3 接收消息\n- tcpServer接收到生产者发送消息，将消息分发给SendMsgHandler。然后通过线程池创建相应的线程去处理消息的存储、ack及推送。\n\n![dmq](2019-07-24-dmq/mq-server-send.png)\n\n    可靠消息：\n        1、先进行存储至DB\n        2、入DB成功后，恢复Client进行消息通知。\n        3、再进行数据的推送。\n    延迟消息：\n        1、先进行存储至延迟DB\n        2、入DB成功后，恢复Client进行消息通知。\n\n以下为代码：\n\n    public void run() {\n        try {\n            MqBody mqBody = mqContext.getMqBody();\n            mqBody.setMessageId(IdUtil.generateId());\n            // validate topic\n            List<Client> clientList = clientService.getClientList(mqBody.getTopic());\n            if (CollectionUtils.isEmpty(clientList)) {\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_NO_TOPIC_ACK, \"\");\n                return;\n            }\n            if (mqBody.getMsgTypeEnum() == MsgTypeEnum.RELIABLE) {\n                // 可靠消息存储\n                if (messageService.saveMessage(mqBody, clientList)) {\n                    // 成功ack给生产者\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SUCCESS_ACK, \"\");\n                    // 推送给消费者\n                    clientService.pushMsg(mqBody, clientList, false);\n                } else {\n                    // 存储失败，通知生产者异常ack\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SERVER_ERROR, Util.getMqConfig().serverErrorDes());\n                }\n            } else if (mqBody.getMsgTypeEnum() == MsgTypeEnum.DELAY) {\n                if(delayMsgService.insert(mqBody)){//延迟消息入库\n                    //成功ack\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SUCCESS_ACK, \"\");\n                }else{\n                    //失败ack\n                    clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SERVER_ERROR, Util.getMqConfig().serverErrorDes());\n                }\n            }\n        } catch (Exception e) {\n            //异常ack\n            clientService.ackClient(mqContext.getMqBody(), mqContext.getChannel(), SEND_SERVER_ERROR, Throwables.getStackTraceAsString(e));\n        } finally {\n        }\n    }\n\n### 3.4 接收重复消息\n![dmq](2019-07-24-dmq/mq-server-resend.png)\n\n### 3.5 死信消息\n消息入死信队列情况：\n\n    1、超过QPS限流。\n    2、入DB异常。\n    3、消息过期。\n    \n死信消息上报时，单独持久化至DB。由MQ管理平台控制，死信消息由人工处理，可以进行重发或者删除。\n\n# 四、消费者\n    1、查看文章图二，ReceiveQueue存放的是生产者发送的消息，该队列的消费线程poll队列消息，调用相应的ReceiveHandler进行相应的业务逻辑处理。\n    2、此时消费者可以设置是否自动ack，回复ack，此时会将库中的持久化数据进行删除；若不ack，则会一直发送。\n\n# 延迟消息\n* 接收到延迟消息后，写入fragment，存入Delay_DB。\n    * mq.properties添加配置项：fragment\n    * fragment：\n    * 例如：fragment为8，则每条延迟消息fragment字段的数值为1-8之间的随机数\n        *DelayJOB的发送线程thread_count设定为2，则线程1处理fragment字段为1-4的延迟消息，线程2处理5-8。\n\n# 六、总结\n\n![dmq](2019-07-24-dmq/mq-总结.png)\n1、问题一：Producer会将消息存放在本地的queue中，若producer宕机，会出现消息丢失问题。\n    \n    解决方法一：实时发送至server。\n    解决方法二：producer提供持久化方式，如入库、写文件。\n    \n2、问题二：server写DB时只写入os cache，此时DB挂机可能出现server消息丢失。\n\n    解决方法一：写DB强制写入磁盘，效率较低。\n    解决方案二：customer返回ack时才通知producer发送成功ack。","slug":"2019-07-24-DMQ","published":1,"updated":"2024-10-14T09:38:11.987Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnvi0016a13ke2azn86f","content":"<h1 id=\"一、注册中心\"><a href=\"#一、注册中心\" class=\"headerlink\" title=\"一、注册中心\"></a>一、注册中心</h1><p>注册中心，基于zookeeper来实现。</p>\n<ul>\n<li>/dmq/topic下为主题号，主题号下为客户端。</li>\n<li>/dmq/node下为server节点。</li>\n</ul>\n<a id=\"more\"></a>  \n\n<p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-center.png\" alt=\"dmq\"></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、server心跳节点上报到注册中心，节点变化，由注册中心通知client，client每一小时拉取一次全量的配置信息</span><br><span class=\"line\">2、client和一台注册中心保持长连接，定时查询server信息，如果该register server挂掉，消费者会自动连接下一个registerserver，直到有可用连接为止，并能自动重连；</span><br><span class=\"line\">3、心跳保持30s的好处是，可以及时的检测server状态；</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、生产者\"><a href=\"#二、生产者\" class=\"headerlink\" title=\"二、生产者\"></a>二、生产者</h1><h3 id=\"2-0-初始化启动过程\"><a href=\"#2-0-初始化启动过程\" class=\"headerlink\" title=\"2.0 初始化启动过程\"></a>2.0 初始化启动过程</h3><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-client-center.png\" alt=\"dmq\"></p>\n<blockquote>\n<ul>\n<li>1、初始化serverPoll</li>\n<li>2、解析URL服务器地址，生成相应serverConfig，并初始化连接。</li>\n</ul>\n</blockquote>\n<h3 id=\"2-1-生产过程：\"><a href=\"#2-1-生产过程：\" class=\"headerlink\" title=\"2.1 生产过程：\"></a>2.1 生产过程：</h3><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-client-server-3.png\" alt=\"dmq\"></p>\n<ul>\n<li>1、mqClient.send(msg)，客户端API发送消息。</li>\n<li>2、内部消息队列控制器（MsgQueueController）将消息存入发送消息队列（sendQueue）<ul>\n<li>2.1、sessionid&lt;0或者消息体超过64kb直接放入通知队列</li>\n<li>2.2、队列超长之后进行回调处理</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-2-消息处理过程：\"><a href=\"#2-2-消息处理过程：\" class=\"headerlink\" title=\"2.2 消息处理过程：\"></a>2.2 消息处理过程：</h3><p><strong><em>2.2.1 发送消息队列</em></strong></p>\n<ul>\n<li>1、sendRunner循环从sendQueue取数据。</li>\n<li>2、主题路由获取server，向server发送数据。<ul>\n<li>2.1、若发送出现异常，则将消息入接收消息队列（notifyQueue）。</li>\n</ul>\n</li>\n<li>3、判断消息类型（非ack &amp;&amp; 非resend）<ul>\n<li>3.1、将消息放入消息重发map（resendMap;&lt;Long, value&gt;=&lt;sessionId, WinData）。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while (mqController.isOpen()) &#123;</span><br><span class=\"line\">    MqBody mqBody = null;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        WinData winData = mqController.getSendMsg();</span><br><span class=\"line\">  \t\tif (winData != null &amp;&amp; winData.getMqBody() != null) &#123;</span><br><span class=\"line\">  \t\t    mqBody = winData.getMqBody();</span><br><span class=\"line\">  \t\t    try &#123;</span><br><span class=\"line\">  \t\t\t    if (mqBody.getCommandType() == UP_SUBSCRIBE) &#123;</span><br><span class=\"line\">  \t\t\t\t    winData.getNioChannel().getServer().send(mqBody);</span><br><span class=\"line\">  \t\t\t    &#125; else &#123;</span><br><span class=\"line\">  \t\t\t\t    topicRoute.send(false, winData, mqController);</span><br><span class=\"line\">  \t\t\t    &#125;</span><br><span class=\"line\">  \t\t\t&#125; catch (Exception e) &#123;</span><br><span class=\"line\">  \t\t\t    winData.setStatus(SOCKET_ERROR);</span><br><span class=\"line\">  \t\t\t    mqController.offerNotifyMsg(winData);</span><br><span class=\"line\">  \t\t\t    continue;</span><br><span class=\"line\">  \t\t\t&#125;</span><br><span class=\"line\">  \t\t\tif (mqBody.getCommandType() != UP_CONSUMER_ACK &amp;&amp; mqBody.getCommandType() != UP_PRODUCER_RESEND) &#123;</span><br><span class=\"line\">  \t\t\t    mqController.offerResendMsg(winData);</span><br><span class=\"line\">  \t\t\t&#125;</span><br><span class=\"line\">  \t\t&#125;</span><br><span class=\"line\">  \t&#125; catch (Exception e) &#123;</span><br><span class=\"line\">  \t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong><em>2.2.2 消息重发map</em></strong></p>\n<ul>\n<li>1、resendRunner循环从resendMap取数据。</li>\n<li>2、判断消息的重发次数小于3<ul>\n<li>2.1、若消息发送时间已经超过30s，则将消息发送至sendQueue</li>\n</ul>\n</li>\n<li>3、发送次数&gt;3<ul>\n<li>3.1、将消息从resendMap中删除。</li>\n<li>3.2、将消息发送至notifyQueue中。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while (mqController.isOpen()) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        for (Map.Entry&lt;Long, WinData&gt; entry : mqController.getResendMap().entrySet()) &#123;</span><br><span class=\"line\">            WinData winData = entry.getValue();</span><br><span class=\"line\">            if (winData == null || winData.getMqBody() == null) &#123;</span><br><span class=\"line\">                continue;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            //MqBody clone = winData.getMqBody().clone();</span><br><span class=\"line\">            //防止订阅者重发时在获得channel时出现空指针，将windowdata直接clone放入重发队列</span><br><span class=\"line\">            WinData clone = winData.clone();</span><br><span class=\"line\">            long last = System.currentTimeMillis() - clone.getMqBody().getTimestamp();</span><br><span class=\"line\">            if(winData.getCount() &gt; 0)&#123;</span><br><span class=\"line\">            \tif(last &gt; MQConst.OUT_TIME * (RESEND_TIME - winData.getCount() + 1))&#123;</span><br><span class=\"line\">                    if(clone.getMqBody().getCommandType().getCode()!=UP_SUBSCRIBE.getCode())&#123;</span><br><span class=\"line\">                        clone.getMqBody().setCommandType(UP_PRODUCER_RESEND);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    winData.setCount(winData.getCount() - 1);</span><br><span class=\"line\">                    //mqController.offerSendMsg(clone, winData.getCount() - 1, winData.getISendCallback());</span><br><span class=\"line\">                    //将clone出来的windowdata放入发送队列</span><br><span class=\"line\">                    mqController.offerSendWin(clone);</span><br><span class=\"line\">            \t&#125;</span><br><span class=\"line\">            &#125;else&#123;</span><br><span class=\"line\">            \tWinData remove = mqController.removeResendMsg(clone.getMqBody().getSessionId());</span><br><span class=\"line\">                remove.setStatus(SendMsgStatusEnum.OUT_OF_RETRY);</span><br><span class=\"line\">                mqController.offerNotifyMsg(remove);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Thread.sleep(1000);</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<p>消息最多重发3次，每隔30s进行重发，超过以后不进行重发。  </p>\n<p><strong><em>2.2.3 接收消息队列</em></strong></p>\n<ul>\n<li>1、notifyMsgRunner循环从notifyQueue取数据。</li>\n<li>2、判断消息类型<ul>\n<li>2.1、消费者类型消息，调用相应handler进行相应处理。</li>\n<li>2.2、ack类型消息，调用callback进行相应处理。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-3-接收server的ack\"><a href=\"#2-3-接收server的ack\" class=\"headerlink\" title=\"2.3 接收server的ack\"></a>2.3 接收server的ack</h3><ul>\n<li>1、通过NIOChannel进行通信，将结果回传。</li>\n<li>2、根据ack类型，进行相应处理<ul>\n<li>2.1、下发成功、主题号异常、服务异常：此时会将消息从重发Map中去除、并将消息放入notifyQueue中。</li>\n<li>2.2、机器重启：将该主题号下的重启服务去除。</li>\n<li>2.3、生产者消息：调用消费者的ReceiveHandler业务处理逻辑，进行相应处理。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">switch (mqBody.getCommandType()) &#123;</span><br><span class=\"line\">    case SUBSCRIBE_ACK:</span><br><span class=\"line\">    case SEND_SUCCESS_ACK:</span><br><span class=\"line\">    case SEND_NO_TOPIC_ACK:</span><br><span class=\"line\">    case SUBSCRIBE_NO_TOPIC_ACK:</span><br><span class=\"line\">    case SUBSCRIBE_NO_CLIENT_ID_ACK:</span><br><span class=\"line\">    case SEND_SERVER_ERROR:</span><br><span class=\"line\">    case SUBSCRIBE_SERVER_ERROR:</span><br><span class=\"line\">    case SEND_EXCEED_LIMIT_ACK:</span><br><span class=\"line\">        winData = mqController.removeResendMsg(mqBody.getSessionId());</span><br><span class=\"line\">        if (winData == null || winData.getMqBody() == null) &#123;</span><br><span class=\"line\">            LOGGER.debug(&quot;get window data null from &#123;&#125;&quot;, mqBody);</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        winData.setStatus(SendMsgStatusEnum.getByCommand(mqBody.getCommandType()));</span><br><span class=\"line\">        //将服务端返回的消息赋值给重发队列中的消息</span><br><span class=\"line\">        MqBody mqBodyInClient = winData.getMqBody();</span><br><span class=\"line\">        mqBodyInClient.setMessageId(mqBody.getMessageId());</span><br><span class=\"line\">        mqBodyInClient.setCommandType(mqBody.getCommandType());</span><br><span class=\"line\">        winData.setDmqBody(mqBodyInClient);</span><br><span class=\"line\">        mqController.offerNotifyMsg(winData);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    case CONSUMER_PUSH:</span><br><span class=\"line\">        winData = new WinData(mqBody, -1, null);</span><br><span class=\"line\">        boolean isDistinct = mqController.offerDistinctMsg(mqBody.getSessionId(),mqBody.getClientID());</span><br><span class=\"line\">        if (isDistinct) &#123;</span><br><span class=\"line\">            winData.setNioChannel(this);</span><br><span class=\"line\">            //将推送来的消息放入消息接收队列</span><br><span class=\"line\">            mqController.offerReceiveMsg(winData);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            LOGGER.debug(&quot;repeat msg &#123;&#125;&quot;, mqBody);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    case SERVER_REBOOT:</span><br><span class=\"line\">        LOGGER.debug(&quot;server is rebooting&quot;);</span><br><span class=\"line\">        mqController.removeSubServer(server);</span><br><span class=\"line\">        server.setState(RESTART);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    case SERVER_HEALTH:</span><br><span class=\"line\">        LOGGER.debug(&quot;server is health&quot;);</span><br><span class=\"line\">        server.setState(HEALTH);</span><br><span class=\"line\">        server.setErrorTime(Long.MAX_VALUE);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    case SERVER__HEARTBEAT:</span><br><span class=\"line\">        LOGGER.debug(&quot;receive server heartbeat &quot;);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    default:</span><br><span class=\"line\">        throw new SerializeException(&quot;un know commandType &quot; + mqBody.getCommandType());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">``` </span><br><span class=\"line\">    </span><br><span class=\"line\">### 2.4 生产者问题</span><br><span class=\"line\">``` bash</span><br><span class=\"line\">1、消息存入队列中，若队列数据量大，此时机器挂机，会出现消息丢失，数据丢失时，依赖业务方日志由业务方自己重发消息，未提供持久化支持。可以采用QMQ方式，支持消息的持久化。</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、MQ-server\"><a href=\"#三、MQ-server\" class=\"headerlink\" title=\"三、MQ server\"></a>三、MQ server</h1><h3 id=\"3-1-启动过程\"><a href=\"#3-1-启动过程\" class=\"headerlink\" title=\"3.1 启动过程\"></a>3.1 启动过程</h3><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-server-start.png\" alt=\"dmq\"></p>\n<pre><code>a、zk注册，拉取主题号、client等信息，并启动定时任务去更新每3s一次。\nb、初始化DB。\nc、启动定时任务去发送离线消息。\nd、启动TcpServer，监听请求，并对请求进行相应的分发处理。\ne、启动telnetServer。</code></pre><h3 id=\"3-2-订阅者注册\"><a href=\"#3-2-订阅者注册\" class=\"headerlink\" title=\"3.2 订阅者注册\"></a>3.2 订阅者注册</h3><ul>\n<li>tcpServer接收到订阅者注册消息，将消息分发给SubscribeHandler。然后通过线程池创建相应的线程去处理，将当前消费者的client设置到该主题号下。</li>\n</ul>\n<p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-server-sub.png\" alt=\"dmq\"></p>\n<p>以下为代码：</p>\n<pre><code>subExecutor.submit(new Runnable() {\n    public void run() {\n        try {\n            MqBody mqBody = mqContext.getMqBody();\n            // validate topic\n            List&lt;Client&gt; clientList = clientService.getClientList(mqBody.getTopic());\n            if (CollectionUtils.isEmpty(clientList)) {\n                // ack consumer no topic\n                clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_NO_TOPIC_ACK, &quot;&quot;);\n                return;\n            }\n            // add new channel for consumer\n            if (addChannel(clientList, mqBody.getClientID(), mqContext.getChannel())) {\n                // ack consumer\n                clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_ACK, &quot;&quot;);\n            } else {\n                // ack consumer no client id\n                clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_NO_CLIENT_ID_ACK, &quot;&quot;);\n                return;\n            }\n            offlineExecutor.schedule(getInstance(mqBody), OFFLINE_DELAY_TIME, TimeUnit.MILLISECONDS);\n        } catch (Exception e) {\n            clientService.ackClient(mqContext.getMqBody(), mqContext.getChannel(), SUBSCRIBE_SERVER_ERROR, Throwables.getStackTraceAsString(e));\n        }\n    }\n});   </code></pre><h3 id=\"3-3-接收消息\"><a href=\"#3-3-接收消息\" class=\"headerlink\" title=\"3.3 接收消息\"></a>3.3 接收消息</h3><ul>\n<li>tcpServer接收到生产者发送消息，将消息分发给SendMsgHandler。然后通过线程池创建相应的线程去处理消息的存储、ack及推送。</li>\n</ul>\n<p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-server-send.png\" alt=\"dmq\"></p>\n<pre><code>可靠消息：\n    1、先进行存储至DB\n    2、入DB成功后，恢复Client进行消息通知。\n    3、再进行数据的推送。\n延迟消息：\n    1、先进行存储至延迟DB\n    2、入DB成功后，恢复Client进行消息通知。</code></pre><p>以下为代码：</p>\n<pre><code>public void run() {\n    try {\n        MqBody mqBody = mqContext.getMqBody();\n        mqBody.setMessageId(IdUtil.generateId());\n        // validate topic\n        List&lt;Client&gt; clientList = clientService.getClientList(mqBody.getTopic());\n        if (CollectionUtils.isEmpty(clientList)) {\n            clientService.ackClient(mqBody, mqContext.getChannel(), SEND_NO_TOPIC_ACK, &quot;&quot;);\n            return;\n        }\n        if (mqBody.getMsgTypeEnum() == MsgTypeEnum.RELIABLE) {\n            // 可靠消息存储\n            if (messageService.saveMessage(mqBody, clientList)) {\n                // 成功ack给生产者\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SUCCESS_ACK, &quot;&quot;);\n                // 推送给消费者\n                clientService.pushMsg(mqBody, clientList, false);\n            } else {\n                // 存储失败，通知生产者异常ack\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SERVER_ERROR, Util.getMqConfig().serverErrorDes());\n            }\n        } else if (mqBody.getMsgTypeEnum() == MsgTypeEnum.DELAY) {\n            if(delayMsgService.insert(mqBody)){//延迟消息入库\n                //成功ack\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SUCCESS_ACK, &quot;&quot;);\n            }else{\n                //失败ack\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SERVER_ERROR, Util.getMqConfig().serverErrorDes());\n            }\n        }\n    } catch (Exception e) {\n        //异常ack\n        clientService.ackClient(mqContext.getMqBody(), mqContext.getChannel(), SEND_SERVER_ERROR, Throwables.getStackTraceAsString(e));\n    } finally {\n    }\n}</code></pre><h3 id=\"3-4-接收重复消息\"><a href=\"#3-4-接收重复消息\" class=\"headerlink\" title=\"3.4 接收重复消息\"></a>3.4 接收重复消息</h3><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-server-resend.png\" alt=\"dmq\"></p>\n<h3 id=\"3-5-死信消息\"><a href=\"#3-5-死信消息\" class=\"headerlink\" title=\"3.5 死信消息\"></a>3.5 死信消息</h3><p>消息入死信队列情况：</p>\n<pre><code>1、超过QPS限流。\n2、入DB异常。\n3、消息过期。</code></pre><p>死信消息上报时，单独持久化至DB。由MQ管理平台控制，死信消息由人工处理，可以进行重发或者删除。</p>\n<h1 id=\"四、消费者\"><a href=\"#四、消费者\" class=\"headerlink\" title=\"四、消费者\"></a>四、消费者</h1><pre><code>1、查看文章图二，ReceiveQueue存放的是生产者发送的消息，该队列的消费线程poll队列消息，调用相应的ReceiveHandler进行相应的业务逻辑处理。\n2、此时消费者可以设置是否自动ack，回复ack，此时会将库中的持久化数据进行删除；若不ack，则会一直发送。</code></pre><h1 id=\"延迟消息\"><a href=\"#延迟消息\" class=\"headerlink\" title=\"延迟消息\"></a>延迟消息</h1><ul>\n<li>接收到延迟消息后，写入fragment，存入Delay_DB。<ul>\n<li>mq.properties添加配置项：fragment</li>\n<li>fragment：</li>\n<li>例如：fragment为8，则每条延迟消息fragment字段的数值为1-8之间的随机数<br>  *DelayJOB的发送线程thread_count设定为2，则线程1处理fragment字段为1-4的延迟消息，线程2处理5-8。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"六、总结\"><a href=\"#六、总结\" class=\"headerlink\" title=\"六、总结\"></a>六、总结</h1><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-%E6%80%BB%E7%BB%93.png\" alt=\"dmq\"><br>1、问题一：Producer会将消息存放在本地的queue中，若producer宕机，会出现消息丢失问题。</p>\n<pre><code>解决方法一：实时发送至server。\n解决方法二：producer提供持久化方式，如入库、写文件。</code></pre><p>2、问题二：server写DB时只写入os cache，此时DB挂机可能出现server消息丢失。</p>\n<pre><code>解决方法一：写DB强制写入磁盘，效率较低。\n解决方案二：customer返回ack时才通知producer发送成功ack。</code></pre>","site":{"data":{}},"excerpt":"<h1 id=\"一、注册中心\"><a href=\"#一、注册中心\" class=\"headerlink\" title=\"一、注册中心\"></a>一、注册中心</h1><p>注册中心，基于zookeeper来实现。</p>\n<ul>\n<li>/dmq/topic下为主题号，主题号下为客户端。</li>\n<li>/dmq/node下为server节点。</li>\n</ul>","more":"<p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-center.png\" alt=\"dmq\"></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、server心跳节点上报到注册中心，节点变化，由注册中心通知client，client每一小时拉取一次全量的配置信息</span><br><span class=\"line\">2、client和一台注册中心保持长连接，定时查询server信息，如果该register server挂掉，消费者会自动连接下一个registerserver，直到有可用连接为止，并能自动重连；</span><br><span class=\"line\">3、心跳保持30s的好处是，可以及时的检测server状态；</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、生产者\"><a href=\"#二、生产者\" class=\"headerlink\" title=\"二、生产者\"></a>二、生产者</h1><h3 id=\"2-0-初始化启动过程\"><a href=\"#2-0-初始化启动过程\" class=\"headerlink\" title=\"2.0 初始化启动过程\"></a>2.0 初始化启动过程</h3><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-client-center.png\" alt=\"dmq\"></p>\n<blockquote>\n<ul>\n<li>1、初始化serverPoll</li>\n<li>2、解析URL服务器地址，生成相应serverConfig，并初始化连接。</li>\n</ul>\n</blockquote>\n<h3 id=\"2-1-生产过程：\"><a href=\"#2-1-生产过程：\" class=\"headerlink\" title=\"2.1 生产过程：\"></a>2.1 生产过程：</h3><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-client-server-3.png\" alt=\"dmq\"></p>\n<ul>\n<li>1、mqClient.send(msg)，客户端API发送消息。</li>\n<li>2、内部消息队列控制器（MsgQueueController）将消息存入发送消息队列（sendQueue）<ul>\n<li>2.1、sessionid&lt;0或者消息体超过64kb直接放入通知队列</li>\n<li>2.2、队列超长之后进行回调处理</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-2-消息处理过程：\"><a href=\"#2-2-消息处理过程：\" class=\"headerlink\" title=\"2.2 消息处理过程：\"></a>2.2 消息处理过程：</h3><p><strong><em>2.2.1 发送消息队列</em></strong></p>\n<ul>\n<li>1、sendRunner循环从sendQueue取数据。</li>\n<li>2、主题路由获取server，向server发送数据。<ul>\n<li>2.1、若发送出现异常，则将消息入接收消息队列（notifyQueue）。</li>\n</ul>\n</li>\n<li>3、判断消息类型（非ack &amp;&amp; 非resend）<ul>\n<li>3.1、将消息放入消息重发map（resendMap;&lt;Long, value&gt;=&lt;sessionId, WinData）。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while (mqController.isOpen()) &#123;</span><br><span class=\"line\">    MqBody mqBody = null;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        WinData winData = mqController.getSendMsg();</span><br><span class=\"line\">  \t\tif (winData != null &amp;&amp; winData.getMqBody() != null) &#123;</span><br><span class=\"line\">  \t\t    mqBody = winData.getMqBody();</span><br><span class=\"line\">  \t\t    try &#123;</span><br><span class=\"line\">  \t\t\t    if (mqBody.getCommandType() == UP_SUBSCRIBE) &#123;</span><br><span class=\"line\">  \t\t\t\t    winData.getNioChannel().getServer().send(mqBody);</span><br><span class=\"line\">  \t\t\t    &#125; else &#123;</span><br><span class=\"line\">  \t\t\t\t    topicRoute.send(false, winData, mqController);</span><br><span class=\"line\">  \t\t\t    &#125;</span><br><span class=\"line\">  \t\t\t&#125; catch (Exception e) &#123;</span><br><span class=\"line\">  \t\t\t    winData.setStatus(SOCKET_ERROR);</span><br><span class=\"line\">  \t\t\t    mqController.offerNotifyMsg(winData);</span><br><span class=\"line\">  \t\t\t    continue;</span><br><span class=\"line\">  \t\t\t&#125;</span><br><span class=\"line\">  \t\t\tif (mqBody.getCommandType() != UP_CONSUMER_ACK &amp;&amp; mqBody.getCommandType() != UP_PRODUCER_RESEND) &#123;</span><br><span class=\"line\">  \t\t\t    mqController.offerResendMsg(winData);</span><br><span class=\"line\">  \t\t\t&#125;</span><br><span class=\"line\">  \t\t&#125;</span><br><span class=\"line\">  \t&#125; catch (Exception e) &#123;</span><br><span class=\"line\">  \t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong><em>2.2.2 消息重发map</em></strong></p>\n<ul>\n<li>1、resendRunner循环从resendMap取数据。</li>\n<li>2、判断消息的重发次数小于3<ul>\n<li>2.1、若消息发送时间已经超过30s，则将消息发送至sendQueue</li>\n</ul>\n</li>\n<li>3、发送次数&gt;3<ul>\n<li>3.1、将消息从resendMap中删除。</li>\n<li>3.2、将消息发送至notifyQueue中。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">while (mqController.isOpen()) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        for (Map.Entry&lt;Long, WinData&gt; entry : mqController.getResendMap().entrySet()) &#123;</span><br><span class=\"line\">            WinData winData = entry.getValue();</span><br><span class=\"line\">            if (winData == null || winData.getMqBody() == null) &#123;</span><br><span class=\"line\">                continue;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            //MqBody clone = winData.getMqBody().clone();</span><br><span class=\"line\">            //防止订阅者重发时在获得channel时出现空指针，将windowdata直接clone放入重发队列</span><br><span class=\"line\">            WinData clone = winData.clone();</span><br><span class=\"line\">            long last = System.currentTimeMillis() - clone.getMqBody().getTimestamp();</span><br><span class=\"line\">            if(winData.getCount() &gt; 0)&#123;</span><br><span class=\"line\">            \tif(last &gt; MQConst.OUT_TIME * (RESEND_TIME - winData.getCount() + 1))&#123;</span><br><span class=\"line\">                    if(clone.getMqBody().getCommandType().getCode()!=UP_SUBSCRIBE.getCode())&#123;</span><br><span class=\"line\">                        clone.getMqBody().setCommandType(UP_PRODUCER_RESEND);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    winData.setCount(winData.getCount() - 1);</span><br><span class=\"line\">                    //mqController.offerSendMsg(clone, winData.getCount() - 1, winData.getISendCallback());</span><br><span class=\"line\">                    //将clone出来的windowdata放入发送队列</span><br><span class=\"line\">                    mqController.offerSendWin(clone);</span><br><span class=\"line\">            \t&#125;</span><br><span class=\"line\">            &#125;else&#123;</span><br><span class=\"line\">            \tWinData remove = mqController.removeResendMsg(clone.getMqBody().getSessionId());</span><br><span class=\"line\">                remove.setStatus(SendMsgStatusEnum.OUT_OF_RETRY);</span><br><span class=\"line\">                mqController.offerNotifyMsg(remove);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Thread.sleep(1000);</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<p>消息最多重发3次，每隔30s进行重发，超过以后不进行重发。  </p>\n<p><strong><em>2.2.3 接收消息队列</em></strong></p>\n<ul>\n<li>1、notifyMsgRunner循环从notifyQueue取数据。</li>\n<li>2、判断消息类型<ul>\n<li>2.1、消费者类型消息，调用相应handler进行相应处理。</li>\n<li>2.2、ack类型消息，调用callback进行相应处理。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-3-接收server的ack\"><a href=\"#2-3-接收server的ack\" class=\"headerlink\" title=\"2.3 接收server的ack\"></a>2.3 接收server的ack</h3><ul>\n<li>1、通过NIOChannel进行通信，将结果回传。</li>\n<li>2、根据ack类型，进行相应处理<ul>\n<li>2.1、下发成功、主题号异常、服务异常：此时会将消息从重发Map中去除、并将消息放入notifyQueue中。</li>\n<li>2.2、机器重启：将该主题号下的重启服务去除。</li>\n<li>2.3、生产者消息：调用消费者的ReceiveHandler业务处理逻辑，进行相应处理。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">switch (mqBody.getCommandType()) &#123;</span><br><span class=\"line\">    case SUBSCRIBE_ACK:</span><br><span class=\"line\">    case SEND_SUCCESS_ACK:</span><br><span class=\"line\">    case SEND_NO_TOPIC_ACK:</span><br><span class=\"line\">    case SUBSCRIBE_NO_TOPIC_ACK:</span><br><span class=\"line\">    case SUBSCRIBE_NO_CLIENT_ID_ACK:</span><br><span class=\"line\">    case SEND_SERVER_ERROR:</span><br><span class=\"line\">    case SUBSCRIBE_SERVER_ERROR:</span><br><span class=\"line\">    case SEND_EXCEED_LIMIT_ACK:</span><br><span class=\"line\">        winData = mqController.removeResendMsg(mqBody.getSessionId());</span><br><span class=\"line\">        if (winData == null || winData.getMqBody() == null) &#123;</span><br><span class=\"line\">            LOGGER.debug(&quot;get window data null from &#123;&#125;&quot;, mqBody);</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        winData.setStatus(SendMsgStatusEnum.getByCommand(mqBody.getCommandType()));</span><br><span class=\"line\">        //将服务端返回的消息赋值给重发队列中的消息</span><br><span class=\"line\">        MqBody mqBodyInClient = winData.getMqBody();</span><br><span class=\"line\">        mqBodyInClient.setMessageId(mqBody.getMessageId());</span><br><span class=\"line\">        mqBodyInClient.setCommandType(mqBody.getCommandType());</span><br><span class=\"line\">        winData.setDmqBody(mqBodyInClient);</span><br><span class=\"line\">        mqController.offerNotifyMsg(winData);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    case CONSUMER_PUSH:</span><br><span class=\"line\">        winData = new WinData(mqBody, -1, null);</span><br><span class=\"line\">        boolean isDistinct = mqController.offerDistinctMsg(mqBody.getSessionId(),mqBody.getClientID());</span><br><span class=\"line\">        if (isDistinct) &#123;</span><br><span class=\"line\">            winData.setNioChannel(this);</span><br><span class=\"line\">            //将推送来的消息放入消息接收队列</span><br><span class=\"line\">            mqController.offerReceiveMsg(winData);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            LOGGER.debug(&quot;repeat msg &#123;&#125;&quot;, mqBody);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    case SERVER_REBOOT:</span><br><span class=\"line\">        LOGGER.debug(&quot;server is rebooting&quot;);</span><br><span class=\"line\">        mqController.removeSubServer(server);</span><br><span class=\"line\">        server.setState(RESTART);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    case SERVER_HEALTH:</span><br><span class=\"line\">        LOGGER.debug(&quot;server is health&quot;);</span><br><span class=\"line\">        server.setState(HEALTH);</span><br><span class=\"line\">        server.setErrorTime(Long.MAX_VALUE);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    case SERVER__HEARTBEAT:</span><br><span class=\"line\">        LOGGER.debug(&quot;receive server heartbeat &quot;);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    default:</span><br><span class=\"line\">        throw new SerializeException(&quot;un know commandType &quot; + mqBody.getCommandType());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">``` </span><br><span class=\"line\">    </span><br><span class=\"line\">### 2.4 生产者问题</span><br><span class=\"line\">``` bash</span><br><span class=\"line\">1、消息存入队列中，若队列数据量大，此时机器挂机，会出现消息丢失，数据丢失时，依赖业务方日志由业务方自己重发消息，未提供持久化支持。可以采用QMQ方式，支持消息的持久化。</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、MQ-server\"><a href=\"#三、MQ-server\" class=\"headerlink\" title=\"三、MQ server\"></a>三、MQ server</h1><h3 id=\"3-1-启动过程\"><a href=\"#3-1-启动过程\" class=\"headerlink\" title=\"3.1 启动过程\"></a>3.1 启动过程</h3><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-server-start.png\" alt=\"dmq\"></p>\n<pre><code>a、zk注册，拉取主题号、client等信息，并启动定时任务去更新每3s一次。\nb、初始化DB。\nc、启动定时任务去发送离线消息。\nd、启动TcpServer，监听请求，并对请求进行相应的分发处理。\ne、启动telnetServer。</code></pre><h3 id=\"3-2-订阅者注册\"><a href=\"#3-2-订阅者注册\" class=\"headerlink\" title=\"3.2 订阅者注册\"></a>3.2 订阅者注册</h3><ul>\n<li>tcpServer接收到订阅者注册消息，将消息分发给SubscribeHandler。然后通过线程池创建相应的线程去处理，将当前消费者的client设置到该主题号下。</li>\n</ul>\n<p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-server-sub.png\" alt=\"dmq\"></p>\n<p>以下为代码：</p>\n<pre><code>subExecutor.submit(new Runnable() {\n    public void run() {\n        try {\n            MqBody mqBody = mqContext.getMqBody();\n            // validate topic\n            List&lt;Client&gt; clientList = clientService.getClientList(mqBody.getTopic());\n            if (CollectionUtils.isEmpty(clientList)) {\n                // ack consumer no topic\n                clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_NO_TOPIC_ACK, &quot;&quot;);\n                return;\n            }\n            // add new channel for consumer\n            if (addChannel(clientList, mqBody.getClientID(), mqContext.getChannel())) {\n                // ack consumer\n                clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_ACK, &quot;&quot;);\n            } else {\n                // ack consumer no client id\n                clientService.ackClient(mqBody, mqContext.getChannel(), SUBSCRIBE_NO_CLIENT_ID_ACK, &quot;&quot;);\n                return;\n            }\n            offlineExecutor.schedule(getInstance(mqBody), OFFLINE_DELAY_TIME, TimeUnit.MILLISECONDS);\n        } catch (Exception e) {\n            clientService.ackClient(mqContext.getMqBody(), mqContext.getChannel(), SUBSCRIBE_SERVER_ERROR, Throwables.getStackTraceAsString(e));\n        }\n    }\n});   </code></pre><h3 id=\"3-3-接收消息\"><a href=\"#3-3-接收消息\" class=\"headerlink\" title=\"3.3 接收消息\"></a>3.3 接收消息</h3><ul>\n<li>tcpServer接收到生产者发送消息，将消息分发给SendMsgHandler。然后通过线程池创建相应的线程去处理消息的存储、ack及推送。</li>\n</ul>\n<p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-server-send.png\" alt=\"dmq\"></p>\n<pre><code>可靠消息：\n    1、先进行存储至DB\n    2、入DB成功后，恢复Client进行消息通知。\n    3、再进行数据的推送。\n延迟消息：\n    1、先进行存储至延迟DB\n    2、入DB成功后，恢复Client进行消息通知。</code></pre><p>以下为代码：</p>\n<pre><code>public void run() {\n    try {\n        MqBody mqBody = mqContext.getMqBody();\n        mqBody.setMessageId(IdUtil.generateId());\n        // validate topic\n        List&lt;Client&gt; clientList = clientService.getClientList(mqBody.getTopic());\n        if (CollectionUtils.isEmpty(clientList)) {\n            clientService.ackClient(mqBody, mqContext.getChannel(), SEND_NO_TOPIC_ACK, &quot;&quot;);\n            return;\n        }\n        if (mqBody.getMsgTypeEnum() == MsgTypeEnum.RELIABLE) {\n            // 可靠消息存储\n            if (messageService.saveMessage(mqBody, clientList)) {\n                // 成功ack给生产者\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SUCCESS_ACK, &quot;&quot;);\n                // 推送给消费者\n                clientService.pushMsg(mqBody, clientList, false);\n            } else {\n                // 存储失败，通知生产者异常ack\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SERVER_ERROR, Util.getMqConfig().serverErrorDes());\n            }\n        } else if (mqBody.getMsgTypeEnum() == MsgTypeEnum.DELAY) {\n            if(delayMsgService.insert(mqBody)){//延迟消息入库\n                //成功ack\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SUCCESS_ACK, &quot;&quot;);\n            }else{\n                //失败ack\n                clientService.ackClient(mqBody, mqContext.getChannel(), SEND_SERVER_ERROR, Util.getMqConfig().serverErrorDes());\n            }\n        }\n    } catch (Exception e) {\n        //异常ack\n        clientService.ackClient(mqContext.getMqBody(), mqContext.getChannel(), SEND_SERVER_ERROR, Throwables.getStackTraceAsString(e));\n    } finally {\n    }\n}</code></pre><h3 id=\"3-4-接收重复消息\"><a href=\"#3-4-接收重复消息\" class=\"headerlink\" title=\"3.4 接收重复消息\"></a>3.4 接收重复消息</h3><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-server-resend.png\" alt=\"dmq\"></p>\n<h3 id=\"3-5-死信消息\"><a href=\"#3-5-死信消息\" class=\"headerlink\" title=\"3.5 死信消息\"></a>3.5 死信消息</h3><p>消息入死信队列情况：</p>\n<pre><code>1、超过QPS限流。\n2、入DB异常。\n3、消息过期。</code></pre><p>死信消息上报时，单独持久化至DB。由MQ管理平台控制，死信消息由人工处理，可以进行重发或者删除。</p>\n<h1 id=\"四、消费者\"><a href=\"#四、消费者\" class=\"headerlink\" title=\"四、消费者\"></a>四、消费者</h1><pre><code>1、查看文章图二，ReceiveQueue存放的是生产者发送的消息，该队列的消费线程poll队列消息，调用相应的ReceiveHandler进行相应的业务逻辑处理。\n2、此时消费者可以设置是否自动ack，回复ack，此时会将库中的持久化数据进行删除；若不ack，则会一直发送。</code></pre><h1 id=\"延迟消息\"><a href=\"#延迟消息\" class=\"headerlink\" title=\"延迟消息\"></a>延迟消息</h1><ul>\n<li>接收到延迟消息后，写入fragment，存入Delay_DB。<ul>\n<li>mq.properties添加配置项：fragment</li>\n<li>fragment：</li>\n<li>例如：fragment为8，则每条延迟消息fragment字段的数值为1-8之间的随机数<br>  *DelayJOB的发送线程thread_count设定为2，则线程1处理fragment字段为1-4的延迟消息，线程2处理5-8。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"六、总结\"><a href=\"#六、总结\" class=\"headerlink\" title=\"六、总结\"></a>六、总结</h1><p><img src=\"/2019/07/24/2019-07-24-DMQ/mq-%E6%80%BB%E7%BB%93.png\" alt=\"dmq\"><br>1、问题一：Producer会将消息存放在本地的queue中，若producer宕机，会出现消息丢失问题。</p>\n<pre><code>解决方法一：实时发送至server。\n解决方法二：producer提供持久化方式，如入库、写文件。</code></pre><p>2、问题二：server写DB时只写入os cache，此时DB挂机可能出现server消息丢失。</p>\n<pre><code>解决方法一：写DB强制写入磁盘，效率较低。\n解决方案二：customer返回ack时才通知producer发送成功ack。</code></pre>"},{"title":"熔断降级","date":"2019-08-21T10:26:30.000Z","_content":"\n# 一、背景\n* 线索系统调用更新权限接口，调用量过大，导致权限系统资源消耗过大\n    * 线索系统业务受到影响\n    * 权限系统无法对外提供服务\n    * 其他系统业务然后都收到影响\n    \n此时需要对服务做服务降级处理。  \n\n<!--more-->    \n\n# 一、服务雪崩\n\n例如三个系统，A，B，C，\n* 调用关系：A -> B -> C，调用链\n    * 如果此时C服务异常，无法提供服务\n    * B服务此时因为C服务不可用，可能B服务会去重试，资源容易消耗殆尽，变得不可用\n    * 最终结果是，三个服务都不可用\n    \n如何解决服务雪崩呢？做降级处理，降级的方案\n* 限流降级\n* 熔断降级\n\n# 二、限流降级\n例如C服务，因为瞬时的访问量突然变大，而导致自己不可用，可以考虑限流处理，防止自己宕机，这是一种降级处理。\n\n\n# 三、熔断降级\n调用链上，C服务不可用，B服务也将不可用，那么服务B然后解决因为下游系统不可用导致的服务雪崩问题呢？\n* 使用熔断降级\n    * B服务调用C服务，例如每20个请求内有50%失败，则打开熔断降级开关，进行降级处理，B服务降级处理可以是返回错误码\n* 熔断逻辑如下几种：    \n```\nHystrix\n//滑动窗口的大小，默认为20\ncircuitBreaker.requestVolumeThreshold \n//过多长时间，熔断器再次检测是否开启，默认为5000，即5s钟\ncircuitBreaker.sleepWindowInMilliseconds \n//错误率，默认50%\ncircuitBreaker.errorThresholdPercentage\n```\n\n# 四、分布式限流\n采用滑动窗口实现限流。\n\n限流的实现方式：\n* 计数器：\n    * 给定一定数量，例如使用Redis的计数器。\n* 漏斗模式：\n    * 固定流出，不支持瞬时流量突增。\n    * 实现：例如线程池，固定的队列大小，固定线程数去消费\n* 令牌桶：\n    * 固定流入，支持瞬时流量突增。\n* 滑动窗口：\n    * \n\n\n\n## 分布式限流\n一种是基于Redis做分布式限流，另一种类似于Sentinel分布式限流。\n\n### Sentinel\nSentinel分布式限流是启动一个token server服务器，其他sentinel client端就是token client端，当做限流操作时，\n从token server获取token，获取成功表示未触发限流；否则表示触发了限流；通信出现异常，可配置降级走本地Sentinel限流机制。\n分布式限流文档：Sentinel集群流控\n\nsentinel的分布式限流是token client调用以下方法到服务端获取token，相当于是每次都会获取acquireCount个token：\n\n\n","source":"_posts/2019-08-21-熔断降级.md","raw":"---\ntitle: 熔断降级\ndate: 2019-08-21 18:26:30\ntags:\n---\n\n# 一、背景\n* 线索系统调用更新权限接口，调用量过大，导致权限系统资源消耗过大\n    * 线索系统业务受到影响\n    * 权限系统无法对外提供服务\n    * 其他系统业务然后都收到影响\n    \n此时需要对服务做服务降级处理。  \n\n<!--more-->    \n\n# 一、服务雪崩\n\n例如三个系统，A，B，C，\n* 调用关系：A -> B -> C，调用链\n    * 如果此时C服务异常，无法提供服务\n    * B服务此时因为C服务不可用，可能B服务会去重试，资源容易消耗殆尽，变得不可用\n    * 最终结果是，三个服务都不可用\n    \n如何解决服务雪崩呢？做降级处理，降级的方案\n* 限流降级\n* 熔断降级\n\n# 二、限流降级\n例如C服务，因为瞬时的访问量突然变大，而导致自己不可用，可以考虑限流处理，防止自己宕机，这是一种降级处理。\n\n\n# 三、熔断降级\n调用链上，C服务不可用，B服务也将不可用，那么服务B然后解决因为下游系统不可用导致的服务雪崩问题呢？\n* 使用熔断降级\n    * B服务调用C服务，例如每20个请求内有50%失败，则打开熔断降级开关，进行降级处理，B服务降级处理可以是返回错误码\n* 熔断逻辑如下几种：    \n```\nHystrix\n//滑动窗口的大小，默认为20\ncircuitBreaker.requestVolumeThreshold \n//过多长时间，熔断器再次检测是否开启，默认为5000，即5s钟\ncircuitBreaker.sleepWindowInMilliseconds \n//错误率，默认50%\ncircuitBreaker.errorThresholdPercentage\n```\n\n# 四、分布式限流\n采用滑动窗口实现限流。\n\n限流的实现方式：\n* 计数器：\n    * 给定一定数量，例如使用Redis的计数器。\n* 漏斗模式：\n    * 固定流出，不支持瞬时流量突增。\n    * 实现：例如线程池，固定的队列大小，固定线程数去消费\n* 令牌桶：\n    * 固定流入，支持瞬时流量突增。\n* 滑动窗口：\n    * \n\n\n\n## 分布式限流\n一种是基于Redis做分布式限流，另一种类似于Sentinel分布式限流。\n\n### Sentinel\nSentinel分布式限流是启动一个token server服务器，其他sentinel client端就是token client端，当做限流操作时，\n从token server获取token，获取成功表示未触发限流；否则表示触发了限流；通信出现异常，可配置降级走本地Sentinel限流机制。\n分布式限流文档：Sentinel集群流控\n\nsentinel的分布式限流是token client调用以下方法到服务端获取token，相当于是每次都会获取acquireCount个token：\n\n\n","slug":"2019-08-21-熔断降级","published":1,"updated":"2024-10-14T09:38:12.014Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnvo001aa13k8cvga55o","content":"<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><ul>\n<li>线索系统调用更新权限接口，调用量过大，导致权限系统资源消耗过大<ul>\n<li>线索系统业务受到影响</li>\n<li>权限系统无法对外提供服务</li>\n<li>其他系统业务然后都收到影响</li>\n</ul>\n</li>\n</ul>\n<p>此时需要对服务做服务降级处理。  </p>\n<a id=\"more\"></a>    \n\n<h1 id=\"一、服务雪崩\"><a href=\"#一、服务雪崩\" class=\"headerlink\" title=\"一、服务雪崩\"></a>一、服务雪崩</h1><p>例如三个系统，A，B，C，</p>\n<ul>\n<li>调用关系：A -&gt; B -&gt; C，调用链<ul>\n<li>如果此时C服务异常，无法提供服务</li>\n<li>B服务此时因为C服务不可用，可能B服务会去重试，资源容易消耗殆尽，变得不可用</li>\n<li>最终结果是，三个服务都不可用</li>\n</ul>\n</li>\n</ul>\n<p>如何解决服务雪崩呢？做降级处理，降级的方案</p>\n<ul>\n<li>限流降级</li>\n<li>熔断降级</li>\n</ul>\n<h1 id=\"二、限流降级\"><a href=\"#二、限流降级\" class=\"headerlink\" title=\"二、限流降级\"></a>二、限流降级</h1><p>例如C服务，因为瞬时的访问量突然变大，而导致自己不可用，可以考虑限流处理，防止自己宕机，这是一种降级处理。</p>\n<h1 id=\"三、熔断降级\"><a href=\"#三、熔断降级\" class=\"headerlink\" title=\"三、熔断降级\"></a>三、熔断降级</h1><p>调用链上，C服务不可用，B服务也将不可用，那么服务B然后解决因为下游系统不可用导致的服务雪崩问题呢？</p>\n<ul>\n<li>使用熔断降级<ul>\n<li>B服务调用C服务，例如每20个请求内有50%失败，则打开熔断降级开关，进行降级处理，B服务降级处理可以是返回错误码</li>\n</ul>\n</li>\n<li>熔断逻辑如下几种：    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Hystrix</span><br><span class=\"line\">//滑动窗口的大小，默认为20</span><br><span class=\"line\">circuitBreaker.requestVolumeThreshold </span><br><span class=\"line\">//过多长时间，熔断器再次检测是否开启，默认为5000，即5s钟</span><br><span class=\"line\">circuitBreaker.sleepWindowInMilliseconds </span><br><span class=\"line\">//错误率，默认50%</span><br><span class=\"line\">circuitBreaker.errorThresholdPercentage</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h1 id=\"四、分布式限流\"><a href=\"#四、分布式限流\" class=\"headerlink\" title=\"四、分布式限流\"></a>四、分布式限流</h1><p>采用滑动窗口实现限流。</p>\n<p>限流的实现方式：</p>\n<ul>\n<li>计数器：<ul>\n<li>给定一定数量，例如使用Redis的计数器。</li>\n</ul>\n</li>\n<li>漏斗模式：<ul>\n<li>固定流出，不支持瞬时流量突增。</li>\n<li>实现：例如线程池，固定的队列大小，固定线程数去消费</li>\n</ul>\n</li>\n<li>令牌桶：<ul>\n<li>固定流入，支持瞬时流量突增。</li>\n</ul>\n</li>\n<li>滑动窗口：<ul>\n<li></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"分布式限流\"><a href=\"#分布式限流\" class=\"headerlink\" title=\"分布式限流\"></a>分布式限流</h2><p>一种是基于Redis做分布式限流，另一种类似于Sentinel分布式限流。</p>\n<h3 id=\"Sentinel\"><a href=\"#Sentinel\" class=\"headerlink\" title=\"Sentinel\"></a>Sentinel</h3><p>Sentinel分布式限流是启动一个token server服务器，其他sentinel client端就是token client端，当做限流操作时，<br>从token server获取token，获取成功表示未触发限流；否则表示触发了限流；通信出现异常，可配置降级走本地Sentinel限流机制。<br>分布式限流文档：Sentinel集群流控</p>\n<p>sentinel的分布式限流是token client调用以下方法到服务端获取token，相当于是每次都会获取acquireCount个token：</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><ul>\n<li>线索系统调用更新权限接口，调用量过大，导致权限系统资源消耗过大<ul>\n<li>线索系统业务受到影响</li>\n<li>权限系统无法对外提供服务</li>\n<li>其他系统业务然后都收到影响</li>\n</ul>\n</li>\n</ul>\n<p>此时需要对服务做服务降级处理。  </p>","more":"<h1 id=\"一、服务雪崩\"><a href=\"#一、服务雪崩\" class=\"headerlink\" title=\"一、服务雪崩\"></a>一、服务雪崩</h1><p>例如三个系统，A，B，C，</p>\n<ul>\n<li>调用关系：A -&gt; B -&gt; C，调用链<ul>\n<li>如果此时C服务异常，无法提供服务</li>\n<li>B服务此时因为C服务不可用，可能B服务会去重试，资源容易消耗殆尽，变得不可用</li>\n<li>最终结果是，三个服务都不可用</li>\n</ul>\n</li>\n</ul>\n<p>如何解决服务雪崩呢？做降级处理，降级的方案</p>\n<ul>\n<li>限流降级</li>\n<li>熔断降级</li>\n</ul>\n<h1 id=\"二、限流降级\"><a href=\"#二、限流降级\" class=\"headerlink\" title=\"二、限流降级\"></a>二、限流降级</h1><p>例如C服务，因为瞬时的访问量突然变大，而导致自己不可用，可以考虑限流处理，防止自己宕机，这是一种降级处理。</p>\n<h1 id=\"三、熔断降级\"><a href=\"#三、熔断降级\" class=\"headerlink\" title=\"三、熔断降级\"></a>三、熔断降级</h1><p>调用链上，C服务不可用，B服务也将不可用，那么服务B然后解决因为下游系统不可用导致的服务雪崩问题呢？</p>\n<ul>\n<li>使用熔断降级<ul>\n<li>B服务调用C服务，例如每20个请求内有50%失败，则打开熔断降级开关，进行降级处理，B服务降级处理可以是返回错误码</li>\n</ul>\n</li>\n<li>熔断逻辑如下几种：    <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Hystrix</span><br><span class=\"line\">//滑动窗口的大小，默认为20</span><br><span class=\"line\">circuitBreaker.requestVolumeThreshold </span><br><span class=\"line\">//过多长时间，熔断器再次检测是否开启，默认为5000，即5s钟</span><br><span class=\"line\">circuitBreaker.sleepWindowInMilliseconds </span><br><span class=\"line\">//错误率，默认50%</span><br><span class=\"line\">circuitBreaker.errorThresholdPercentage</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h1 id=\"四、分布式限流\"><a href=\"#四、分布式限流\" class=\"headerlink\" title=\"四、分布式限流\"></a>四、分布式限流</h1><p>采用滑动窗口实现限流。</p>\n<p>限流的实现方式：</p>\n<ul>\n<li>计数器：<ul>\n<li>给定一定数量，例如使用Redis的计数器。</li>\n</ul>\n</li>\n<li>漏斗模式：<ul>\n<li>固定流出，不支持瞬时流量突增。</li>\n<li>实现：例如线程池，固定的队列大小，固定线程数去消费</li>\n</ul>\n</li>\n<li>令牌桶：<ul>\n<li>固定流入，支持瞬时流量突增。</li>\n</ul>\n</li>\n<li>滑动窗口：<ul>\n<li></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"分布式限流\"><a href=\"#分布式限流\" class=\"headerlink\" title=\"分布式限流\"></a>分布式限流</h2><p>一种是基于Redis做分布式限流，另一种类似于Sentinel分布式限流。</p>\n<h3 id=\"Sentinel\"><a href=\"#Sentinel\" class=\"headerlink\" title=\"Sentinel\"></a>Sentinel</h3><p>Sentinel分布式限流是启动一个token server服务器，其他sentinel client端就是token client端，当做限流操作时，<br>从token server获取token，获取成功表示未触发限流；否则表示触发了限流；通信出现异常，可配置降级走本地Sentinel限流机制。<br>分布式限流文档：Sentinel集群流控</p>\n<p>sentinel的分布式限流是token client调用以下方法到服务端获取token，相当于是每次都会获取acquireCount个token：</p>"},{"title":"tomcat架构","date":"2019-11-30T05:49:54.000Z","_content":"\ntomcat处理请求，要怎么做呢？\n> * 1、监听某个接口，捕获HTTP请求\n> * 2、将HTTP请求封装成request对象，同时创建response对象\n> * 3、加载servlet对象，将request、response传入，然后再调用servlet的具体service方法。\n\n### 一、Tomcat的一个简单架构图\n\n<!--more-->  \n\n![tomcat架构](2019-11-30-tomcat架构/tomcat-framework.jpg)\n\n可以看出Tomcat的一个整体架构\n> * 一个server服务器，可以包含多个服务；\n> * service中包含多个connector(连接器)，一个container(容器)；及其他一些组件\n\n\n\n#### 1、Connector架构(连接器架构)\n\n在tomcat中，是coyote组件，负责具体协议的解析及IO的相关操作\n![tomcat架构](2019-11-30-tomcat架构/coyote-frame.png)\n![tomcat架构](2019-11-30-tomcat架构/connect-framework.jpeg)\n\nIO模型\n> * NIO\n> * NIO2\n> * APR\n\n应用层协议\n> * HTTP 1.1\n> * AJP\n> * HTTP 2\n\n还是可以看见connector中三大块\n> * ProtocolHandler\n> * Mapper\n> * Adapter\n\n##### 1.1、NioEndpoint的主要流程\n![tomcat架构](2019-11-30-tomcat架构/connect-flow.jpeg)\n\n> * EndPoint：coyote通信端点，是具体的socket的接收和发送器。\n> * AbstractEndPoint：tomcat的具体实现，有两个内部类，accepter和SocketProcesser。由accepter接收具体的socket连接；由SocketProcesser去处理，它实现了runnable接口，在run方法中去调用processer。\n\n#### 2、Container架构\n\n![tomcat架构](2019-11-30-tomcat架构/container-framework.jpeg)\n\n\n> * Engine：没有父容器，一个 Engine代表一个完整的 Servlet 引擎，它接收来自Connector的请求，并决定传给哪个Host来处理，Host处理完请求后，将结果返回给Engine，Engine再将结果返回给Connector。\n> * Host：Engine可以包含多个Host，每个Host代表一个虚拟主机，这个虚拟主机的作用就是运行多个应用，它负责安装和展开这些应用，并且标识这个应用以便能够区分它们，每个虚拟主机对应的一个域名，不同Host容器接受处理对应不同域名的请求。\n> * Context：Host可以包含多个Context，Context是Servlet规范的实现，它提供了Servlet的基本环境，一个Context代表一个运行在Host上的Web应用\n> * Wrapper: Context可以包含多个Wrapper, Wrapper 代表一个 Servlet，它负责管理一个 Servlet，包括的 Servlet 的装载、初始化、执行以及资源回收。Wrapper 是最底层的容器，它没有子容器了，所以调用它的 addChild 将会报错。\n\n\n\n要想搞清楚，记得看源码。结合启动过程，更清晰。\n\n\n\nTomcat例子，将组件都组合在一起\n```java\npackage ex05.pyrmont.startup;\n\nimport ex05.pyrmont.core.SimpleContext;\nimport ex05.pyrmont.core.SimpleContextMapper;\nimport ex05.pyrmont.core.SimpleLoader;\nimport ex05.pyrmont.core.SimpleWrapper;\nimport ex05.pyrmont.valves.ClientIPLoggerValve;\nimport ex05.pyrmont.valves.HeaderLoggerValve;\nimport org.apache.catalina.Context;\nimport org.apache.catalina.Loader;\nimport org.apache.catalina.Mapper;\nimport org.apache.catalina.Pipeline;\nimport org.apache.catalina.Valve;\nimport org.apache.catalina.Wrapper;\nimport org.apache.catalina.connector.http.HttpConnector;\n\npublic final class Bootstrap2 {\n  public static void main(String[] args) {\n    HttpConnector connector = new HttpConnector();\n    //继承了Wrapper，每一个实例里面都是会有一个Servlet的\n    Wrapper wrapper1 = new SimpleWrapper();\n    //设置Servlet的映射地址\n    wrapper1.setName(\"Primitive\");\n　  //设置Servlet的名字\n    wrapper1.setServletClass(\"PrimitiveServlet\");\n    Wrapper wrapper2 = new SimpleWrapper();\n    wrapper2.setName(\"Modern\");\n    wrapper2.setServletClass(\"ModernServlet\");\n　\n    //context是一个容器可以包含wrapper这个最底层的容器\n    Context context = new SimpleContext();\n    context.addChild(wrapper1);\n    context.addChild(wrapper2);\n\n    Valve valve1 = new HeaderLoggerValve();\n    Valve valve2 = new ClientIPLoggerValve();\n    //容器中除了其他容器之外还有Valve\n    //另外要注意的是每一个context都是实现了Pipeline和Context接口的\n    ((Pipeline) context).addValve(valve1);\n    ((Pipeline) context).addValve(valve2);\n    //这个mapper是做什么的呢？\n    Mapper mapper = new SimpleContextMapper();\n    mapper.setProtocol(\"http\");\n    context.addMapper(mapper);\n    Loader loader = new SimpleLoader();\n    //容器中还需要加载器，通过反射加载真正的Servlet对象\n     context.setLoader(loader);\n    // context.addServletMapping(pattern, name);\n　  //context里面初始化了一个HashMap，存储映射和Servlet名字\n    context.addServletMapping(\"/Primitive\", \"Primitive\");\n    context.addServletMapping(\"/Modern\", \"Modern\");\n    //因为connector封装好Reqeust之后会调用容器，所以将容器的声明给Connector\n    connector.setContainer(context);\n    try {\n      connector.initialize();\n       //connector开始监听端口，要明白底层肯定使用ServerSocket来实现的\n      connector.start();\n\n      // make the application wait until we press a key.\n      System.in.read();\n    }\n    catch (Exception e) {\n      e.printStackTrace();\n    }\n  }\n}\n```\n\n\n参考\n[How Tomcat Works读书笔记](https://www.jianshu.com/p/b21520f4ed69)        \n[Tomcat工作原理](https://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/index.html)\n[Tomcat整体架构浅析](https://blog.csdn.net/cx520forever/article/details/52743166)\n[tomcat架构分析 (connector NIO 实现)](https://blog.51cto.com/2839840/2046166)","source":"_posts/2019-11-30-tomcat架构.md","raw":"---\ntitle: tomcat架构\ndate: 2019-11-30 13:49:54\ntags: tomcat\n---\n\ntomcat处理请求，要怎么做呢？\n> * 1、监听某个接口，捕获HTTP请求\n> * 2、将HTTP请求封装成request对象，同时创建response对象\n> * 3、加载servlet对象，将request、response传入，然后再调用servlet的具体service方法。\n\n### 一、Tomcat的一个简单架构图\n\n<!--more-->  \n\n![tomcat架构](2019-11-30-tomcat架构/tomcat-framework.jpg)\n\n可以看出Tomcat的一个整体架构\n> * 一个server服务器，可以包含多个服务；\n> * service中包含多个connector(连接器)，一个container(容器)；及其他一些组件\n\n\n\n#### 1、Connector架构(连接器架构)\n\n在tomcat中，是coyote组件，负责具体协议的解析及IO的相关操作\n![tomcat架构](2019-11-30-tomcat架构/coyote-frame.png)\n![tomcat架构](2019-11-30-tomcat架构/connect-framework.jpeg)\n\nIO模型\n> * NIO\n> * NIO2\n> * APR\n\n应用层协议\n> * HTTP 1.1\n> * AJP\n> * HTTP 2\n\n还是可以看见connector中三大块\n> * ProtocolHandler\n> * Mapper\n> * Adapter\n\n##### 1.1、NioEndpoint的主要流程\n![tomcat架构](2019-11-30-tomcat架构/connect-flow.jpeg)\n\n> * EndPoint：coyote通信端点，是具体的socket的接收和发送器。\n> * AbstractEndPoint：tomcat的具体实现，有两个内部类，accepter和SocketProcesser。由accepter接收具体的socket连接；由SocketProcesser去处理，它实现了runnable接口，在run方法中去调用processer。\n\n#### 2、Container架构\n\n![tomcat架构](2019-11-30-tomcat架构/container-framework.jpeg)\n\n\n> * Engine：没有父容器，一个 Engine代表一个完整的 Servlet 引擎，它接收来自Connector的请求，并决定传给哪个Host来处理，Host处理完请求后，将结果返回给Engine，Engine再将结果返回给Connector。\n> * Host：Engine可以包含多个Host，每个Host代表一个虚拟主机，这个虚拟主机的作用就是运行多个应用，它负责安装和展开这些应用，并且标识这个应用以便能够区分它们，每个虚拟主机对应的一个域名，不同Host容器接受处理对应不同域名的请求。\n> * Context：Host可以包含多个Context，Context是Servlet规范的实现，它提供了Servlet的基本环境，一个Context代表一个运行在Host上的Web应用\n> * Wrapper: Context可以包含多个Wrapper, Wrapper 代表一个 Servlet，它负责管理一个 Servlet，包括的 Servlet 的装载、初始化、执行以及资源回收。Wrapper 是最底层的容器，它没有子容器了，所以调用它的 addChild 将会报错。\n\n\n\n要想搞清楚，记得看源码。结合启动过程，更清晰。\n\n\n\nTomcat例子，将组件都组合在一起\n```java\npackage ex05.pyrmont.startup;\n\nimport ex05.pyrmont.core.SimpleContext;\nimport ex05.pyrmont.core.SimpleContextMapper;\nimport ex05.pyrmont.core.SimpleLoader;\nimport ex05.pyrmont.core.SimpleWrapper;\nimport ex05.pyrmont.valves.ClientIPLoggerValve;\nimport ex05.pyrmont.valves.HeaderLoggerValve;\nimport org.apache.catalina.Context;\nimport org.apache.catalina.Loader;\nimport org.apache.catalina.Mapper;\nimport org.apache.catalina.Pipeline;\nimport org.apache.catalina.Valve;\nimport org.apache.catalina.Wrapper;\nimport org.apache.catalina.connector.http.HttpConnector;\n\npublic final class Bootstrap2 {\n  public static void main(String[] args) {\n    HttpConnector connector = new HttpConnector();\n    //继承了Wrapper，每一个实例里面都是会有一个Servlet的\n    Wrapper wrapper1 = new SimpleWrapper();\n    //设置Servlet的映射地址\n    wrapper1.setName(\"Primitive\");\n　  //设置Servlet的名字\n    wrapper1.setServletClass(\"PrimitiveServlet\");\n    Wrapper wrapper2 = new SimpleWrapper();\n    wrapper2.setName(\"Modern\");\n    wrapper2.setServletClass(\"ModernServlet\");\n　\n    //context是一个容器可以包含wrapper这个最底层的容器\n    Context context = new SimpleContext();\n    context.addChild(wrapper1);\n    context.addChild(wrapper2);\n\n    Valve valve1 = new HeaderLoggerValve();\n    Valve valve2 = new ClientIPLoggerValve();\n    //容器中除了其他容器之外还有Valve\n    //另外要注意的是每一个context都是实现了Pipeline和Context接口的\n    ((Pipeline) context).addValve(valve1);\n    ((Pipeline) context).addValve(valve2);\n    //这个mapper是做什么的呢？\n    Mapper mapper = new SimpleContextMapper();\n    mapper.setProtocol(\"http\");\n    context.addMapper(mapper);\n    Loader loader = new SimpleLoader();\n    //容器中还需要加载器，通过反射加载真正的Servlet对象\n     context.setLoader(loader);\n    // context.addServletMapping(pattern, name);\n　  //context里面初始化了一个HashMap，存储映射和Servlet名字\n    context.addServletMapping(\"/Primitive\", \"Primitive\");\n    context.addServletMapping(\"/Modern\", \"Modern\");\n    //因为connector封装好Reqeust之后会调用容器，所以将容器的声明给Connector\n    connector.setContainer(context);\n    try {\n      connector.initialize();\n       //connector开始监听端口，要明白底层肯定使用ServerSocket来实现的\n      connector.start();\n\n      // make the application wait until we press a key.\n      System.in.read();\n    }\n    catch (Exception e) {\n      e.printStackTrace();\n    }\n  }\n}\n```\n\n\n参考\n[How Tomcat Works读书笔记](https://www.jianshu.com/p/b21520f4ed69)        \n[Tomcat工作原理](https://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/index.html)\n[Tomcat整体架构浅析](https://blog.csdn.net/cx520forever/article/details/52743166)\n[tomcat架构分析 (connector NIO 实现)](https://blog.51cto.com/2839840/2046166)","slug":"2019-11-30-tomcat架构","published":1,"updated":"2024-10-14T09:38:12.014Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnvs001da13kyprn6yhe","content":"<p>tomcat处理请求，要怎么做呢？</p>\n<blockquote>\n<ul>\n<li>1、监听某个接口，捕获HTTP请求</li>\n<li>2、将HTTP请求封装成request对象，同时创建response对象</li>\n<li>3、加载servlet对象，将request、response传入，然后再调用servlet的具体service方法。</li>\n</ul>\n</blockquote>\n<h3 id=\"一、Tomcat的一个简单架构图\"><a href=\"#一、Tomcat的一个简单架构图\" class=\"headerlink\" title=\"一、Tomcat的一个简单架构图\"></a>一、Tomcat的一个简单架构图</h3><a id=\"more\"></a>  \n\n<p><img src=\"/2019/11/30/2019-11-30-tomcat架构/tomcat-framework.jpg\" alt=\"tomcat架构\"></p>\n<p>可以看出Tomcat的一个整体架构</p>\n<blockquote>\n<ul>\n<li>一个server服务器，可以包含多个服务；</li>\n<li>service中包含多个connector(连接器)，一个container(容器)；及其他一些组件</li>\n</ul>\n</blockquote>\n<h4 id=\"1、Connector架构-连接器架构\"><a href=\"#1、Connector架构-连接器架构\" class=\"headerlink\" title=\"1、Connector架构(连接器架构)\"></a>1、Connector架构(连接器架构)</h4><p>在tomcat中，是coyote组件，负责具体协议的解析及IO的相关操作<br><img src=\"/2019/11/30/2019-11-30-tomcat架构/coyote-frame.png\" alt=\"tomcat架构\"><br><img src=\"/2019/11/30/2019-11-30-tomcat架构/connect-framework.jpeg\" alt=\"tomcat架构\"></p>\n<p>IO模型</p>\n<blockquote>\n<ul>\n<li>NIO</li>\n<li>NIO2</li>\n<li>APR</li>\n</ul>\n</blockquote>\n<p>应用层协议</p>\n<blockquote>\n<ul>\n<li>HTTP 1.1</li>\n<li>AJP</li>\n<li>HTTP 2</li>\n</ul>\n</blockquote>\n<p>还是可以看见connector中三大块</p>\n<blockquote>\n<ul>\n<li>ProtocolHandler</li>\n<li>Mapper</li>\n<li>Adapter</li>\n</ul>\n</blockquote>\n<h5 id=\"1-1、NioEndpoint的主要流程\"><a href=\"#1-1、NioEndpoint的主要流程\" class=\"headerlink\" title=\"1.1、NioEndpoint的主要流程\"></a>1.1、NioEndpoint的主要流程</h5><p><img src=\"/2019/11/30/2019-11-30-tomcat架构/connect-flow.jpeg\" alt=\"tomcat架构\"></p>\n<blockquote>\n<ul>\n<li>EndPoint：coyote通信端点，是具体的socket的接收和发送器。</li>\n<li>AbstractEndPoint：tomcat的具体实现，有两个内部类，accepter和SocketProcesser。由accepter接收具体的socket连接；由SocketProcesser去处理，它实现了runnable接口，在run方法中去调用processer。</li>\n</ul>\n</blockquote>\n<h4 id=\"2、Container架构\"><a href=\"#2、Container架构\" class=\"headerlink\" title=\"2、Container架构\"></a>2、Container架构</h4><p><img src=\"/2019/11/30/2019-11-30-tomcat架构/container-framework.jpeg\" alt=\"tomcat架构\"></p>\n<blockquote>\n<ul>\n<li>Engine：没有父容器，一个 Engine代表一个完整的 Servlet 引擎，它接收来自Connector的请求，并决定传给哪个Host来处理，Host处理完请求后，将结果返回给Engine，Engine再将结果返回给Connector。</li>\n<li>Host：Engine可以包含多个Host，每个Host代表一个虚拟主机，这个虚拟主机的作用就是运行多个应用，它负责安装和展开这些应用，并且标识这个应用以便能够区分它们，每个虚拟主机对应的一个域名，不同Host容器接受处理对应不同域名的请求。</li>\n<li>Context：Host可以包含多个Context，Context是Servlet规范的实现，它提供了Servlet的基本环境，一个Context代表一个运行在Host上的Web应用</li>\n<li>Wrapper: Context可以包含多个Wrapper, Wrapper 代表一个 Servlet，它负责管理一个 Servlet，包括的 Servlet 的装载、初始化、执行以及资源回收。Wrapper 是最底层的容器，它没有子容器了，所以调用它的 addChild 将会报错。</li>\n</ul>\n</blockquote>\n<p>要想搞清楚，记得看源码。结合启动过程，更清晰。</p>\n<p>Tomcat例子，将组件都组合在一起</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> ex05.pyrmont.startup;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.core.SimpleContext;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.core.SimpleContextMapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.core.SimpleLoader;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.core.SimpleWrapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.valves.ClientIPLoggerValve;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.valves.HeaderLoggerValve;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Context;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Loader;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Mapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Pipeline;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Valve;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Wrapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.connector.http.HttpConnector;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Bootstrap2</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    HttpConnector connector = <span class=\"keyword\">new</span> HttpConnector();</span><br><span class=\"line\">    <span class=\"comment\">//继承了Wrapper，每一个实例里面都是会有一个Servlet的</span></span><br><span class=\"line\">    Wrapper wrapper1 = <span class=\"keyword\">new</span> SimpleWrapper();</span><br><span class=\"line\">    <span class=\"comment\">//设置Servlet的映射地址</span></span><br><span class=\"line\">    wrapper1.setName(<span class=\"string\">\"Primitive\"</span>);</span><br><span class=\"line\">　  <span class=\"comment\">//设置Servlet的名字</span></span><br><span class=\"line\">    wrapper1.setServletClass(<span class=\"string\">\"PrimitiveServlet\"</span>);</span><br><span class=\"line\">    Wrapper wrapper2 = <span class=\"keyword\">new</span> SimpleWrapper();</span><br><span class=\"line\">    wrapper2.setName(<span class=\"string\">\"Modern\"</span>);</span><br><span class=\"line\">    wrapper2.setServletClass(<span class=\"string\">\"ModernServlet\"</span>);</span><br><span class=\"line\">　</span><br><span class=\"line\">    <span class=\"comment\">//context是一个容器可以包含wrapper这个最底层的容器</span></span><br><span class=\"line\">    Context context = <span class=\"keyword\">new</span> SimpleContext();</span><br><span class=\"line\">    context.addChild(wrapper1);</span><br><span class=\"line\">    context.addChild(wrapper2);</span><br><span class=\"line\"></span><br><span class=\"line\">    Valve valve1 = <span class=\"keyword\">new</span> HeaderLoggerValve();</span><br><span class=\"line\">    Valve valve2 = <span class=\"keyword\">new</span> ClientIPLoggerValve();</span><br><span class=\"line\">    <span class=\"comment\">//容器中除了其他容器之外还有Valve</span></span><br><span class=\"line\">    <span class=\"comment\">//另外要注意的是每一个context都是实现了Pipeline和Context接口的</span></span><br><span class=\"line\">    ((Pipeline) context).addValve(valve1);</span><br><span class=\"line\">    ((Pipeline) context).addValve(valve2);</span><br><span class=\"line\">    <span class=\"comment\">//这个mapper是做什么的呢？</span></span><br><span class=\"line\">    Mapper mapper = <span class=\"keyword\">new</span> SimpleContextMapper();</span><br><span class=\"line\">    mapper.setProtocol(<span class=\"string\">\"http\"</span>);</span><br><span class=\"line\">    context.addMapper(mapper);</span><br><span class=\"line\">    Loader loader = <span class=\"keyword\">new</span> SimpleLoader();</span><br><span class=\"line\">    <span class=\"comment\">//容器中还需要加载器，通过反射加载真正的Servlet对象</span></span><br><span class=\"line\">     context.setLoader(loader);</span><br><span class=\"line\">    <span class=\"comment\">// context.addServletMapping(pattern, name);</span></span><br><span class=\"line\">　  <span class=\"comment\">//context里面初始化了一个HashMap，存储映射和Servlet名字</span></span><br><span class=\"line\">    context.addServletMapping(<span class=\"string\">\"/Primitive\"</span>, <span class=\"string\">\"Primitive\"</span>);</span><br><span class=\"line\">    context.addServletMapping(<span class=\"string\">\"/Modern\"</span>, <span class=\"string\">\"Modern\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">//因为connector封装好Reqeust之后会调用容器，所以将容器的声明给Connector</span></span><br><span class=\"line\">    connector.setContainer(context);</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">      connector.initialize();</span><br><span class=\"line\">       <span class=\"comment\">//connector开始监听端口，要明白底层肯定使用ServerSocket来实现的</span></span><br><span class=\"line\">      connector.start();</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// make the application wait until we press a key.</span></span><br><span class=\"line\">      System.in.read();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">      e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>参考<br><a href=\"https://www.jianshu.com/p/b21520f4ed69\" target=\"_blank\" rel=\"noopener\">How Tomcat Works读书笔记</a><br><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/index.html\" target=\"_blank\" rel=\"noopener\">Tomcat工作原理</a><br><a href=\"https://blog.csdn.net/cx520forever/article/details/52743166\" target=\"_blank\" rel=\"noopener\">Tomcat整体架构浅析</a><br><a href=\"https://blog.51cto.com/2839840/2046166\" target=\"_blank\" rel=\"noopener\">tomcat架构分析 (connector NIO 实现)</a></p>\n","site":{"data":{}},"excerpt":"<p>tomcat处理请求，要怎么做呢？</p>\n<blockquote>\n<ul>\n<li>1、监听某个接口，捕获HTTP请求</li>\n<li>2、将HTTP请求封装成request对象，同时创建response对象</li>\n<li>3、加载servlet对象，将request、response传入，然后再调用servlet的具体service方法。</li>\n</ul>\n</blockquote>\n<h3 id=\"一、Tomcat的一个简单架构图\"><a href=\"#一、Tomcat的一个简单架构图\" class=\"headerlink\" title=\"一、Tomcat的一个简单架构图\"></a>一、Tomcat的一个简单架构图</h3>","more":"<p><img src=\"/2019/11/30/2019-11-30-tomcat架构/tomcat-framework.jpg\" alt=\"tomcat架构\"></p>\n<p>可以看出Tomcat的一个整体架构</p>\n<blockquote>\n<ul>\n<li>一个server服务器，可以包含多个服务；</li>\n<li>service中包含多个connector(连接器)，一个container(容器)；及其他一些组件</li>\n</ul>\n</blockquote>\n<h4 id=\"1、Connector架构-连接器架构\"><a href=\"#1、Connector架构-连接器架构\" class=\"headerlink\" title=\"1、Connector架构(连接器架构)\"></a>1、Connector架构(连接器架构)</h4><p>在tomcat中，是coyote组件，负责具体协议的解析及IO的相关操作<br><img src=\"/2019/11/30/2019-11-30-tomcat架构/coyote-frame.png\" alt=\"tomcat架构\"><br><img src=\"/2019/11/30/2019-11-30-tomcat架构/connect-framework.jpeg\" alt=\"tomcat架构\"></p>\n<p>IO模型</p>\n<blockquote>\n<ul>\n<li>NIO</li>\n<li>NIO2</li>\n<li>APR</li>\n</ul>\n</blockquote>\n<p>应用层协议</p>\n<blockquote>\n<ul>\n<li>HTTP 1.1</li>\n<li>AJP</li>\n<li>HTTP 2</li>\n</ul>\n</blockquote>\n<p>还是可以看见connector中三大块</p>\n<blockquote>\n<ul>\n<li>ProtocolHandler</li>\n<li>Mapper</li>\n<li>Adapter</li>\n</ul>\n</blockquote>\n<h5 id=\"1-1、NioEndpoint的主要流程\"><a href=\"#1-1、NioEndpoint的主要流程\" class=\"headerlink\" title=\"1.1、NioEndpoint的主要流程\"></a>1.1、NioEndpoint的主要流程</h5><p><img src=\"/2019/11/30/2019-11-30-tomcat架构/connect-flow.jpeg\" alt=\"tomcat架构\"></p>\n<blockquote>\n<ul>\n<li>EndPoint：coyote通信端点，是具体的socket的接收和发送器。</li>\n<li>AbstractEndPoint：tomcat的具体实现，有两个内部类，accepter和SocketProcesser。由accepter接收具体的socket连接；由SocketProcesser去处理，它实现了runnable接口，在run方法中去调用processer。</li>\n</ul>\n</blockquote>\n<h4 id=\"2、Container架构\"><a href=\"#2、Container架构\" class=\"headerlink\" title=\"2、Container架构\"></a>2、Container架构</h4><p><img src=\"/2019/11/30/2019-11-30-tomcat架构/container-framework.jpeg\" alt=\"tomcat架构\"></p>\n<blockquote>\n<ul>\n<li>Engine：没有父容器，一个 Engine代表一个完整的 Servlet 引擎，它接收来自Connector的请求，并决定传给哪个Host来处理，Host处理完请求后，将结果返回给Engine，Engine再将结果返回给Connector。</li>\n<li>Host：Engine可以包含多个Host，每个Host代表一个虚拟主机，这个虚拟主机的作用就是运行多个应用，它负责安装和展开这些应用，并且标识这个应用以便能够区分它们，每个虚拟主机对应的一个域名，不同Host容器接受处理对应不同域名的请求。</li>\n<li>Context：Host可以包含多个Context，Context是Servlet规范的实现，它提供了Servlet的基本环境，一个Context代表一个运行在Host上的Web应用</li>\n<li>Wrapper: Context可以包含多个Wrapper, Wrapper 代表一个 Servlet，它负责管理一个 Servlet，包括的 Servlet 的装载、初始化、执行以及资源回收。Wrapper 是最底层的容器，它没有子容器了，所以调用它的 addChild 将会报错。</li>\n</ul>\n</blockquote>\n<p>要想搞清楚，记得看源码。结合启动过程，更清晰。</p>\n<p>Tomcat例子，将组件都组合在一起</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> ex05.pyrmont.startup;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.core.SimpleContext;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.core.SimpleContextMapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.core.SimpleLoader;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.core.SimpleWrapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.valves.ClientIPLoggerValve;</span><br><span class=\"line\"><span class=\"keyword\">import</span> ex05.pyrmont.valves.HeaderLoggerValve;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Context;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Loader;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Mapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Pipeline;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Valve;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.Wrapper;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.catalina.connector.http.HttpConnector;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Bootstrap2</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    HttpConnector connector = <span class=\"keyword\">new</span> HttpConnector();</span><br><span class=\"line\">    <span class=\"comment\">//继承了Wrapper，每一个实例里面都是会有一个Servlet的</span></span><br><span class=\"line\">    Wrapper wrapper1 = <span class=\"keyword\">new</span> SimpleWrapper();</span><br><span class=\"line\">    <span class=\"comment\">//设置Servlet的映射地址</span></span><br><span class=\"line\">    wrapper1.setName(<span class=\"string\">\"Primitive\"</span>);</span><br><span class=\"line\">　  <span class=\"comment\">//设置Servlet的名字</span></span><br><span class=\"line\">    wrapper1.setServletClass(<span class=\"string\">\"PrimitiveServlet\"</span>);</span><br><span class=\"line\">    Wrapper wrapper2 = <span class=\"keyword\">new</span> SimpleWrapper();</span><br><span class=\"line\">    wrapper2.setName(<span class=\"string\">\"Modern\"</span>);</span><br><span class=\"line\">    wrapper2.setServletClass(<span class=\"string\">\"ModernServlet\"</span>);</span><br><span class=\"line\">　</span><br><span class=\"line\">    <span class=\"comment\">//context是一个容器可以包含wrapper这个最底层的容器</span></span><br><span class=\"line\">    Context context = <span class=\"keyword\">new</span> SimpleContext();</span><br><span class=\"line\">    context.addChild(wrapper1);</span><br><span class=\"line\">    context.addChild(wrapper2);</span><br><span class=\"line\"></span><br><span class=\"line\">    Valve valve1 = <span class=\"keyword\">new</span> HeaderLoggerValve();</span><br><span class=\"line\">    Valve valve2 = <span class=\"keyword\">new</span> ClientIPLoggerValve();</span><br><span class=\"line\">    <span class=\"comment\">//容器中除了其他容器之外还有Valve</span></span><br><span class=\"line\">    <span class=\"comment\">//另外要注意的是每一个context都是实现了Pipeline和Context接口的</span></span><br><span class=\"line\">    ((Pipeline) context).addValve(valve1);</span><br><span class=\"line\">    ((Pipeline) context).addValve(valve2);</span><br><span class=\"line\">    <span class=\"comment\">//这个mapper是做什么的呢？</span></span><br><span class=\"line\">    Mapper mapper = <span class=\"keyword\">new</span> SimpleContextMapper();</span><br><span class=\"line\">    mapper.setProtocol(<span class=\"string\">\"http\"</span>);</span><br><span class=\"line\">    context.addMapper(mapper);</span><br><span class=\"line\">    Loader loader = <span class=\"keyword\">new</span> SimpleLoader();</span><br><span class=\"line\">    <span class=\"comment\">//容器中还需要加载器，通过反射加载真正的Servlet对象</span></span><br><span class=\"line\">     context.setLoader(loader);</span><br><span class=\"line\">    <span class=\"comment\">// context.addServletMapping(pattern, name);</span></span><br><span class=\"line\">　  <span class=\"comment\">//context里面初始化了一个HashMap，存储映射和Servlet名字</span></span><br><span class=\"line\">    context.addServletMapping(<span class=\"string\">\"/Primitive\"</span>, <span class=\"string\">\"Primitive\"</span>);</span><br><span class=\"line\">    context.addServletMapping(<span class=\"string\">\"/Modern\"</span>, <span class=\"string\">\"Modern\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">//因为connector封装好Reqeust之后会调用容器，所以将容器的声明给Connector</span></span><br><span class=\"line\">    connector.setContainer(context);</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">      connector.initialize();</span><br><span class=\"line\">       <span class=\"comment\">//connector开始监听端口，要明白底层肯定使用ServerSocket来实现的</span></span><br><span class=\"line\">      connector.start();</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// make the application wait until we press a key.</span></span><br><span class=\"line\">      System.in.read();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">      e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>参考<br><a href=\"https://www.jianshu.com/p/b21520f4ed69\" target=\"_blank\" rel=\"noopener\">How Tomcat Works读书笔记</a><br><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-tomcat1/index.html\" target=\"_blank\" rel=\"noopener\">Tomcat工作原理</a><br><a href=\"https://blog.csdn.net/cx520forever/article/details/52743166\" target=\"_blank\" rel=\"noopener\">Tomcat整体架构浅析</a><br><a href=\"https://blog.51cto.com/2839840/2046166\" target=\"_blank\" rel=\"noopener\">tomcat架构分析 (connector NIO 实现)</a></p>"},{"title":"tomcat启动过程","date":"2019-12-20T13:39:13.000Z","_content":"\n# 一、tomcat的启动过程\n* 执行start.sh，实际将执行catalina.sh，\njava命令执行Bootstrap类的main方法，将start作为参数传入\n\n# 二、Load过程\n## 1.1、Boostrap.java\n```\npublic static void main(String args[]) {\n    synchronized (daemonLock) {\n        Bootstrap daemon = new Bootstrap();\n        if (command.equals(\"startd\")) {\n            args[args.length - 1] = \"start\";\n            daemon.load(args);\n            daemon.start();\n        }\n    }\n```\n执行Boostrap的main方法，此时tomcat就在JVM作为一个线程启动了。\n\n<!--more-->\n\n分成两步\n> * 1、资源初始化，load()，绑定serverSocket\n> * 2、资源启动，start()，connector创建acceptor连接线程池。    \n\n执行Load方法\n```\n/**\n * Load daemon.\n */\nprivate void load(String[] arguments) throws Exception {\n    // Call the load() method\n    String methodName = \"load\";\n    Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes);\n```\n通过反射，执行Catalina.java的load方法    \n\n## 1.2、Catalina.java\n```\npublic void load() {\n    //首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。\n    Digester digester = createStartDigester();\n    InputSource inputSource = null;\n    InputStream inputStream = null;\n    File file = null;\n    try {\n        //解析server.xml\n        file = new File(\"conf/server.xml\");\n        inputStream = new FileInputStream(file);\n        inputSource = new InputSource(file.toURI().toURL().toString());\n    } catch (Exception e) {\n    }\n    \n    // Start the new server\n    try {\n        getServer().init();\n    } catch (LifecycleException e) {\n    }\n}\n```\n1. 解析server.xml文件，首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。\n    依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。。\n2. 然后拿到StandardServer实例调用init()方法初始化Tomcat容器的一系列组件。一些容器初始化的的时候，都会调用其子容器的init()方法，初始化它的子容器。\n    顺序是StandardServer、StandardService、StandardEngine、Connector。\n    每个容器都在初始化自身相关设置的同时，将子容器初始化。\n\n## 1.3、StandardServer:\n实际的server实现是StandardServer\n```\nprotected void initInternal() throws LifecycleException {\n    // Register global String cache\n    // Note although the cache is global, if there are multiple Servers\n    // present in the JVM (may happen when embedding) then the same cache\n    // will be registered under multiple names\n    onameStringCache = register(new StringCache(), \"type=StringCache\");\n    // Register the MBeanFactory\n    MBeanFactory factory = new MBeanFactory();\n    factory.setContainer(this);\n    onameMBeanFactory = register(factory, \"type=MBeanFactory\");\n    // Register the naming resources\n    globalNamingResources.init();\n    \n    // Initialize our defined Services\n    for (int i = 0; i < services.length; i++) {\n        services[i].init();\n    }\n}\n```\n1. 加载Server、Service、Connector、Container、Engine、Host、Context、Wrapper一系列的容器。\n2. 初始化service，从server的初始化上看，一个server有多个service。\n\n## 1.4、StandardService:\n实际的service实现是StandardService\n```\nprotected void initInternal() throws LifecycleException {\n    if (engine != null) {\n        engine.init();\n    }\n    // Initialize any Executors\n    for (Executor executor : findExecutors()) {\n        if (executor instanceof JmxEnabled) {\n            ((JmxEnabled) executor).setDomain(getDomain());\n        }\n        executor.init();\n    }\n    // Initialize mapper listener\n    mapperListener.init();\n    // Initialize our defined Connectors\n    synchronized (connectorsLock) {\n        for (Connector connector : connectors) {\n            try {\n                connector.init();\n            } catch (Exception e) {\n                String message = sm.getString(\n                        \"standardService.connector.initFailed\", connector);\n                log.error(message, e);\n                if (Boolean.getBoolean(\"org.apache.catalina.startup.EXIT_ON_INIT_FAILURE\"))\n                    throw new LifecycleException(message);\n}}}}\n```\n1. service执行engine的初始化。(engine继承Container，所以实际是进行container的初始化)\n2. 然后创建一组线程池。executor是Tomcat自己实现的线程池。【】\n3. 然后进行连接器(connector)的初始化（一组连接器，server.xml中配置的多个connector，对应了端口号和协议）\n\n## 1.5、Connector:连接器\n```\nprotected void initInternal() throws LifecycleException {\n    // Initialize adapter\n    adapter = new CoyoteAdapter(this);\n    protocolHandler.setAdapter(adapter);\n    try {\n        protocolHandler.init();\n    } \n}\n```\n![连接器](2019-12-20-tomcat启动过程/连接器.png)\n1. 创建adapter适配器，当processor解析socket之后生成的Request和Response不能直接传入到容器中，需要通过adapter\n将Request和Response转换成ServletRequest和ServletResponse.\n2. 初始化protocolHandler，有两个重要组件：Endpoint和Processer\n    * Endpoint：端口监听，接收Socket后进行解析，基于TCP/IP协议。\n    * Processer：用来实现HTTP协议。将Endpoint的socket字节流解析成Tomcat的Request和Response，并通过Adapter交给容器处理。\n#############\n* connector在解析server.xml时创建，看connector的构造器，会生成Http11Protocol协议解析器。\n* Http11Protocol的构造器，会创建NIOEndPoint\n* EndPoint.init，会bind绑定端口，等待请求、接收请求\n* EndPoint内有processor处理线程。\n\n\n\n## 1.6、protocolHandler:协议处理器\n```\npublic void init() throws Exception {\n    endpoint.init();\n}\n```\n初始化终端\n\n## 1.7、endpoint:终端\n```\npublic void init() throws Exception {\n    if (bindOnInit) {\n        bind();\n        bindState = BindState.BOUND_ON_INIT;\n    }\n}\n终端的初始化，需要创建socket并绑定端口号。\n\npublic void bind() throws Exception {\n    if (!getUseInheritedChannel()) {\n        serverSock = ServerSocketChannel.open();\n        socketProperties.setProperties(serverSock.socket());\n        InetSocketAddress addr = (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort()));\n        serverSock.socket().bind(addr,getAcceptCount());\n    } else {\n        // Retrieve the channel provided by the OS\n        Channel ic = System.inheritedChannel();\n        if (ic instanceof ServerSocketChannel) {\n            serverSock = (ServerSocketChannel) ic;\n        }\n        if (serverSock == null) {\n            throw new IllegalArgumentException(sm.getString(\"endpoint.init.bind.inherited\"));\n        }\n    }\n    serverSock.configureBlocking(true); //mimic APR behavior\n    selectorPool.open();\n}\n\nEndPoint结构：\n```\n\n# 三、start过程\n\n\n\n## 初始化过程总结：\n![启动过程](2019-12-20-tomcat启动过程/启动过程.png)\n\n参考\n[Tomcat整体架构浅析](https://blog.csdn.net/cx520forever/article/details/52743166)","source":"_posts/2019-12-20-tomcat启动过程.md","raw":"---\ntitle: tomcat启动过程\ndate: 2019-12-20 21:39:13\ntags: Tomcat\n---\n\n# 一、tomcat的启动过程\n* 执行start.sh，实际将执行catalina.sh，\njava命令执行Bootstrap类的main方法，将start作为参数传入\n\n# 二、Load过程\n## 1.1、Boostrap.java\n```\npublic static void main(String args[]) {\n    synchronized (daemonLock) {\n        Bootstrap daemon = new Bootstrap();\n        if (command.equals(\"startd\")) {\n            args[args.length - 1] = \"start\";\n            daemon.load(args);\n            daemon.start();\n        }\n    }\n```\n执行Boostrap的main方法，此时tomcat就在JVM作为一个线程启动了。\n\n<!--more-->\n\n分成两步\n> * 1、资源初始化，load()，绑定serverSocket\n> * 2、资源启动，start()，connector创建acceptor连接线程池。    \n\n执行Load方法\n```\n/**\n * Load daemon.\n */\nprivate void load(String[] arguments) throws Exception {\n    // Call the load() method\n    String methodName = \"load\";\n    Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes);\n```\n通过反射，执行Catalina.java的load方法    \n\n## 1.2、Catalina.java\n```\npublic void load() {\n    //首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。\n    Digester digester = createStartDigester();\n    InputSource inputSource = null;\n    InputStream inputStream = null;\n    File file = null;\n    try {\n        //解析server.xml\n        file = new File(\"conf/server.xml\");\n        inputStream = new FileInputStream(file);\n        inputSource = new InputSource(file.toURI().toURL().toString());\n    } catch (Exception e) {\n    }\n    \n    // Start the new server\n    try {\n        getServer().init();\n    } catch (LifecycleException e) {\n    }\n}\n```\n1. 解析server.xml文件，首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。\n    依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。。\n2. 然后拿到StandardServer实例调用init()方法初始化Tomcat容器的一系列组件。一些容器初始化的的时候，都会调用其子容器的init()方法，初始化它的子容器。\n    顺序是StandardServer、StandardService、StandardEngine、Connector。\n    每个容器都在初始化自身相关设置的同时，将子容器初始化。\n\n## 1.3、StandardServer:\n实际的server实现是StandardServer\n```\nprotected void initInternal() throws LifecycleException {\n    // Register global String cache\n    // Note although the cache is global, if there are multiple Servers\n    // present in the JVM (may happen when embedding) then the same cache\n    // will be registered under multiple names\n    onameStringCache = register(new StringCache(), \"type=StringCache\");\n    // Register the MBeanFactory\n    MBeanFactory factory = new MBeanFactory();\n    factory.setContainer(this);\n    onameMBeanFactory = register(factory, \"type=MBeanFactory\");\n    // Register the naming resources\n    globalNamingResources.init();\n    \n    // Initialize our defined Services\n    for (int i = 0; i < services.length; i++) {\n        services[i].init();\n    }\n}\n```\n1. 加载Server、Service、Connector、Container、Engine、Host、Context、Wrapper一系列的容器。\n2. 初始化service，从server的初始化上看，一个server有多个service。\n\n## 1.4、StandardService:\n实际的service实现是StandardService\n```\nprotected void initInternal() throws LifecycleException {\n    if (engine != null) {\n        engine.init();\n    }\n    // Initialize any Executors\n    for (Executor executor : findExecutors()) {\n        if (executor instanceof JmxEnabled) {\n            ((JmxEnabled) executor).setDomain(getDomain());\n        }\n        executor.init();\n    }\n    // Initialize mapper listener\n    mapperListener.init();\n    // Initialize our defined Connectors\n    synchronized (connectorsLock) {\n        for (Connector connector : connectors) {\n            try {\n                connector.init();\n            } catch (Exception e) {\n                String message = sm.getString(\n                        \"standardService.connector.initFailed\", connector);\n                log.error(message, e);\n                if (Boolean.getBoolean(\"org.apache.catalina.startup.EXIT_ON_INIT_FAILURE\"))\n                    throw new LifecycleException(message);\n}}}}\n```\n1. service执行engine的初始化。(engine继承Container，所以实际是进行container的初始化)\n2. 然后创建一组线程池。executor是Tomcat自己实现的线程池。【】\n3. 然后进行连接器(connector)的初始化（一组连接器，server.xml中配置的多个connector，对应了端口号和协议）\n\n## 1.5、Connector:连接器\n```\nprotected void initInternal() throws LifecycleException {\n    // Initialize adapter\n    adapter = new CoyoteAdapter(this);\n    protocolHandler.setAdapter(adapter);\n    try {\n        protocolHandler.init();\n    } \n}\n```\n![连接器](2019-12-20-tomcat启动过程/连接器.png)\n1. 创建adapter适配器，当processor解析socket之后生成的Request和Response不能直接传入到容器中，需要通过adapter\n将Request和Response转换成ServletRequest和ServletResponse.\n2. 初始化protocolHandler，有两个重要组件：Endpoint和Processer\n    * Endpoint：端口监听，接收Socket后进行解析，基于TCP/IP协议。\n    * Processer：用来实现HTTP协议。将Endpoint的socket字节流解析成Tomcat的Request和Response，并通过Adapter交给容器处理。\n#############\n* connector在解析server.xml时创建，看connector的构造器，会生成Http11Protocol协议解析器。\n* Http11Protocol的构造器，会创建NIOEndPoint\n* EndPoint.init，会bind绑定端口，等待请求、接收请求\n* EndPoint内有processor处理线程。\n\n\n\n## 1.6、protocolHandler:协议处理器\n```\npublic void init() throws Exception {\n    endpoint.init();\n}\n```\n初始化终端\n\n## 1.7、endpoint:终端\n```\npublic void init() throws Exception {\n    if (bindOnInit) {\n        bind();\n        bindState = BindState.BOUND_ON_INIT;\n    }\n}\n终端的初始化，需要创建socket并绑定端口号。\n\npublic void bind() throws Exception {\n    if (!getUseInheritedChannel()) {\n        serverSock = ServerSocketChannel.open();\n        socketProperties.setProperties(serverSock.socket());\n        InetSocketAddress addr = (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort()));\n        serverSock.socket().bind(addr,getAcceptCount());\n    } else {\n        // Retrieve the channel provided by the OS\n        Channel ic = System.inheritedChannel();\n        if (ic instanceof ServerSocketChannel) {\n            serverSock = (ServerSocketChannel) ic;\n        }\n        if (serverSock == null) {\n            throw new IllegalArgumentException(sm.getString(\"endpoint.init.bind.inherited\"));\n        }\n    }\n    serverSock.configureBlocking(true); //mimic APR behavior\n    selectorPool.open();\n}\n\nEndPoint结构：\n```\n\n# 三、start过程\n\n\n\n## 初始化过程总结：\n![启动过程](2019-12-20-tomcat启动过程/启动过程.png)\n\n参考\n[Tomcat整体架构浅析](https://blog.csdn.net/cx520forever/article/details/52743166)","slug":"2019-12-20-tomcat启动过程","published":1,"updated":"2024-10-14T09:38:12.019Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnvx001ga13kxmwzgl9u","content":"<h1 id=\"一、tomcat的启动过程\"><a href=\"#一、tomcat的启动过程\" class=\"headerlink\" title=\"一、tomcat的启动过程\"></a>一、tomcat的启动过程</h1><ul>\n<li>执行start.sh，实际将执行catalina.sh，<br>java命令执行Bootstrap类的main方法，将start作为参数传入</li>\n</ul>\n<h1 id=\"二、Load过程\"><a href=\"#二、Load过程\" class=\"headerlink\" title=\"二、Load过程\"></a>二、Load过程</h1><h2 id=\"1-1、Boostrap-java\"><a href=\"#1-1、Boostrap-java\" class=\"headerlink\" title=\"1.1、Boostrap.java\"></a>1.1、Boostrap.java</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String args[]) &#123;</span><br><span class=\"line\">    synchronized (daemonLock) &#123;</span><br><span class=\"line\">        Bootstrap daemon = new Bootstrap();</span><br><span class=\"line\">        if (command.equals(&quot;startd&quot;)) &#123;</span><br><span class=\"line\">            args[args.length - 1] = &quot;start&quot;;</span><br><span class=\"line\">            daemon.load(args);</span><br><span class=\"line\">            daemon.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>执行Boostrap的main方法，此时tomcat就在JVM作为一个线程启动了。</p>\n<a id=\"more\"></a>\n\n<p>分成两步</p>\n<blockquote>\n<ul>\n<li>1、资源初始化，load()，绑定serverSocket</li>\n<li>2、资源启动，start()，connector创建acceptor连接线程池。    </li>\n</ul>\n</blockquote>\n<p>执行Load方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Load daemon.</span><br><span class=\"line\"> */</span><br><span class=\"line\">private void load(String[] arguments) throws Exception &#123;</span><br><span class=\"line\">    // Call the load() method</span><br><span class=\"line\">    String methodName = &quot;load&quot;;</span><br><span class=\"line\">    Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes);</span><br></pre></td></tr></table></figure>\n\n<p>通过反射，执行Catalina.java的load方法    </p>\n<h2 id=\"1-2、Catalina-java\"><a href=\"#1-2、Catalina-java\" class=\"headerlink\" title=\"1.2、Catalina.java\"></a>1.2、Catalina.java</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void load() &#123;</span><br><span class=\"line\">    //首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。</span><br><span class=\"line\">    Digester digester = createStartDigester();</span><br><span class=\"line\">    InputSource inputSource = null;</span><br><span class=\"line\">    InputStream inputStream = null;</span><br><span class=\"line\">    File file = null;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        //解析server.xml</span><br><span class=\"line\">        file = new File(&quot;conf/server.xml&quot;);</span><br><span class=\"line\">        inputStream = new FileInputStream(file);</span><br><span class=\"line\">        inputSource = new InputSource(file.toURI().toURL().toString());</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Start the new server</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        getServer().init();</span><br><span class=\"line\">    &#125; catch (LifecycleException e) &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>解析server.xml文件，首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。<br> 依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。。</li>\n<li>然后拿到StandardServer实例调用init()方法初始化Tomcat容器的一系列组件。一些容器初始化的的时候，都会调用其子容器的init()方法，初始化它的子容器。<br> 顺序是StandardServer、StandardService、StandardEngine、Connector。<br> 每个容器都在初始化自身相关设置的同时，将子容器初始化。</li>\n</ol>\n<h2 id=\"1-3、StandardServer\"><a href=\"#1-3、StandardServer\" class=\"headerlink\" title=\"1.3、StandardServer:\"></a>1.3、StandardServer:</h2><p>实际的server实现是StandardServer</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void initInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Register global String cache</span><br><span class=\"line\">    // Note although the cache is global, if there are multiple Servers</span><br><span class=\"line\">    // present in the JVM (may happen when embedding) then the same cache</span><br><span class=\"line\">    // will be registered under multiple names</span><br><span class=\"line\">    onameStringCache = register(new StringCache(), &quot;type=StringCache&quot;);</span><br><span class=\"line\">    // Register the MBeanFactory</span><br><span class=\"line\">    MBeanFactory factory = new MBeanFactory();</span><br><span class=\"line\">    factory.setContainer(this);</span><br><span class=\"line\">    onameMBeanFactory = register(factory, &quot;type=MBeanFactory&quot;);</span><br><span class=\"line\">    // Register the naming resources</span><br><span class=\"line\">    globalNamingResources.init();</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Initialize our defined Services</span><br><span class=\"line\">    for (int i = 0; i &lt; services.length; i++) &#123;</span><br><span class=\"line\">        services[i].init();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>加载Server、Service、Connector、Container、Engine、Host、Context、Wrapper一系列的容器。</li>\n<li>初始化service，从server的初始化上看，一个server有多个service。</li>\n</ol>\n<h2 id=\"1-4、StandardService\"><a href=\"#1-4、StandardService\" class=\"headerlink\" title=\"1.4、StandardService:\"></a>1.4、StandardService:</h2><p>实际的service实现是StandardService</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void initInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    if (engine != null) &#123;</span><br><span class=\"line\">        engine.init();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Initialize any Executors</span><br><span class=\"line\">    for (Executor executor : findExecutors()) &#123;</span><br><span class=\"line\">        if (executor instanceof JmxEnabled) &#123;</span><br><span class=\"line\">            ((JmxEnabled) executor).setDomain(getDomain());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        executor.init();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Initialize mapper listener</span><br><span class=\"line\">    mapperListener.init();</span><br><span class=\"line\">    // Initialize our defined Connectors</span><br><span class=\"line\">    synchronized (connectorsLock) &#123;</span><br><span class=\"line\">        for (Connector connector : connectors) &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                connector.init();</span><br><span class=\"line\">            &#125; catch (Exception e) &#123;</span><br><span class=\"line\">                String message = sm.getString(</span><br><span class=\"line\">                        &quot;standardService.connector.initFailed&quot;, connector);</span><br><span class=\"line\">                log.error(message, e);</span><br><span class=\"line\">                if (Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;))</span><br><span class=\"line\">                    throw new LifecycleException(message);</span><br><span class=\"line\">&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>service执行engine的初始化。(engine继承Container，所以实际是进行container的初始化)</li>\n<li>然后创建一组线程池。executor是Tomcat自己实现的线程池。【】</li>\n<li>然后进行连接器(connector)的初始化（一组连接器，server.xml中配置的多个connector，对应了端口号和协议）</li>\n</ol>\n<h2 id=\"1-5、Connector-连接器\"><a href=\"#1-5、Connector-连接器\" class=\"headerlink\" title=\"1.5、Connector:连接器\"></a>1.5、Connector:连接器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void initInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Initialize adapter</span><br><span class=\"line\">    adapter = new CoyoteAdapter(this);</span><br><span class=\"line\">    protocolHandler.setAdapter(adapter);</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        protocolHandler.init();</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2019/12/20/2019-12-20-tomcat启动过程/%E8%BF%9E%E6%8E%A5%E5%99%A8.png\" alt=\"连接器\"></p>\n<ol>\n<li>创建adapter适配器，当processor解析socket之后生成的Request和Response不能直接传入到容器中，需要通过adapter<br>将Request和Response转换成ServletRequest和ServletResponse.</li>\n<li>初始化protocolHandler，有两个重要组件：Endpoint和Processer<ul>\n<li>Endpoint：端口监听，接收Socket后进行解析，基于TCP/IP协议。</li>\n<li>Processer：用来实现HTTP协议。将Endpoint的socket字节流解析成Tomcat的Request和Response，并通过Adapter交给容器处理。<br>#############</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>connector在解析server.xml时创建，看connector的构造器，会生成Http11Protocol协议解析器。</li>\n<li>Http11Protocol的构造器，会创建NIOEndPoint</li>\n<li>EndPoint.init，会bind绑定端口，等待请求、接收请求</li>\n<li>EndPoint内有processor处理线程。</li>\n</ul>\n<h2 id=\"1-6、protocolHandler-协议处理器\"><a href=\"#1-6、protocolHandler-协议处理器\" class=\"headerlink\" title=\"1.6、protocolHandler:协议处理器\"></a>1.6、protocolHandler:协议处理器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void init() throws Exception &#123;</span><br><span class=\"line\">    endpoint.init();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>初始化终端</p>\n<h2 id=\"1-7、endpoint-终端\"><a href=\"#1-7、endpoint-终端\" class=\"headerlink\" title=\"1.7、endpoint:终端\"></a>1.7、endpoint:终端</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void init() throws Exception &#123;</span><br><span class=\"line\">    if (bindOnInit) &#123;</span><br><span class=\"line\">        bind();</span><br><span class=\"line\">        bindState = BindState.BOUND_ON_INIT;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">终端的初始化，需要创建socket并绑定端口号。</span><br><span class=\"line\"></span><br><span class=\"line\">public void bind() throws Exception &#123;</span><br><span class=\"line\">    if (!getUseInheritedChannel()) &#123;</span><br><span class=\"line\">        serverSock = ServerSocketChannel.open();</span><br><span class=\"line\">        socketProperties.setProperties(serverSock.socket());</span><br><span class=\"line\">        InetSocketAddress addr = (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort()));</span><br><span class=\"line\">        serverSock.socket().bind(addr,getAcceptCount());</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        // Retrieve the channel provided by the OS</span><br><span class=\"line\">        Channel ic = System.inheritedChannel();</span><br><span class=\"line\">        if (ic instanceof ServerSocketChannel) &#123;</span><br><span class=\"line\">            serverSock = (ServerSocketChannel) ic;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (serverSock == null) &#123;</span><br><span class=\"line\">            throw new IllegalArgumentException(sm.getString(&quot;endpoint.init.bind.inherited&quot;));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    serverSock.configureBlocking(true); //mimic APR behavior</span><br><span class=\"line\">    selectorPool.open();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">EndPoint结构：</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、start过程\"><a href=\"#三、start过程\" class=\"headerlink\" title=\"三、start过程\"></a>三、start过程</h1><h2 id=\"初始化过程总结：\"><a href=\"#初始化过程总结：\" class=\"headerlink\" title=\"初始化过程总结：\"></a>初始化过程总结：</h2><p><img src=\"/2019/12/20/2019-12-20-tomcat启动过程/%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B.png\" alt=\"启动过程\"></p>\n<p>参考<br><a href=\"https://blog.csdn.net/cx520forever/article/details/52743166\" target=\"_blank\" rel=\"noopener\">Tomcat整体架构浅析</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、tomcat的启动过程\"><a href=\"#一、tomcat的启动过程\" class=\"headerlink\" title=\"一、tomcat的启动过程\"></a>一、tomcat的启动过程</h1><ul>\n<li>执行start.sh，实际将执行catalina.sh，<br>java命令执行Bootstrap类的main方法，将start作为参数传入</li>\n</ul>\n<h1 id=\"二、Load过程\"><a href=\"#二、Load过程\" class=\"headerlink\" title=\"二、Load过程\"></a>二、Load过程</h1><h2 id=\"1-1、Boostrap-java\"><a href=\"#1-1、Boostrap-java\" class=\"headerlink\" title=\"1.1、Boostrap.java\"></a>1.1、Boostrap.java</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String args[]) &#123;</span><br><span class=\"line\">    synchronized (daemonLock) &#123;</span><br><span class=\"line\">        Bootstrap daemon = new Bootstrap();</span><br><span class=\"line\">        if (command.equals(&quot;startd&quot;)) &#123;</span><br><span class=\"line\">            args[args.length - 1] = &quot;start&quot;;</span><br><span class=\"line\">            daemon.load(args);</span><br><span class=\"line\">            daemon.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>执行Boostrap的main方法，此时tomcat就在JVM作为一个线程启动了。</p>","more":"<p>分成两步</p>\n<blockquote>\n<ul>\n<li>1、资源初始化，load()，绑定serverSocket</li>\n<li>2、资源启动，start()，connector创建acceptor连接线程池。    </li>\n</ul>\n</blockquote>\n<p>执行Load方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Load daemon.</span><br><span class=\"line\"> */</span><br><span class=\"line\">private void load(String[] arguments) throws Exception &#123;</span><br><span class=\"line\">    // Call the load() method</span><br><span class=\"line\">    String methodName = &quot;load&quot;;</span><br><span class=\"line\">    Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes);</span><br></pre></td></tr></table></figure>\n\n<p>通过反射，执行Catalina.java的load方法    </p>\n<h2 id=\"1-2、Catalina-java\"><a href=\"#1-2、Catalina-java\" class=\"headerlink\" title=\"1.2、Catalina.java\"></a>1.2、Catalina.java</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void load() &#123;</span><br><span class=\"line\">    //首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。</span><br><span class=\"line\">    Digester digester = createStartDigester();</span><br><span class=\"line\">    InputSource inputSource = null;</span><br><span class=\"line\">    InputStream inputStream = null;</span><br><span class=\"line\">    File file = null;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        //解析server.xml</span><br><span class=\"line\">        file = new File(&quot;conf/server.xml&quot;);</span><br><span class=\"line\">        inputStream = new FileInputStream(file);</span><br><span class=\"line\">        inputSource = new InputSource(file.toURI().toURL().toString());</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Start the new server</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        getServer().init();</span><br><span class=\"line\">    &#125; catch (LifecycleException e) &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>解析server.xml文件，首先利用Digester类解析server.xml文件，得到容器的配置，并创建相应的对象，并关联父子容器。<br> 依次创建的是StandardServer、StandardService、StandardEngine、StandardHost。。</li>\n<li>然后拿到StandardServer实例调用init()方法初始化Tomcat容器的一系列组件。一些容器初始化的的时候，都会调用其子容器的init()方法，初始化它的子容器。<br> 顺序是StandardServer、StandardService、StandardEngine、Connector。<br> 每个容器都在初始化自身相关设置的同时，将子容器初始化。</li>\n</ol>\n<h2 id=\"1-3、StandardServer\"><a href=\"#1-3、StandardServer\" class=\"headerlink\" title=\"1.3、StandardServer:\"></a>1.3、StandardServer:</h2><p>实际的server实现是StandardServer</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void initInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Register global String cache</span><br><span class=\"line\">    // Note although the cache is global, if there are multiple Servers</span><br><span class=\"line\">    // present in the JVM (may happen when embedding) then the same cache</span><br><span class=\"line\">    // will be registered under multiple names</span><br><span class=\"line\">    onameStringCache = register(new StringCache(), &quot;type=StringCache&quot;);</span><br><span class=\"line\">    // Register the MBeanFactory</span><br><span class=\"line\">    MBeanFactory factory = new MBeanFactory();</span><br><span class=\"line\">    factory.setContainer(this);</span><br><span class=\"line\">    onameMBeanFactory = register(factory, &quot;type=MBeanFactory&quot;);</span><br><span class=\"line\">    // Register the naming resources</span><br><span class=\"line\">    globalNamingResources.init();</span><br><span class=\"line\">    </span><br><span class=\"line\">    // Initialize our defined Services</span><br><span class=\"line\">    for (int i = 0; i &lt; services.length; i++) &#123;</span><br><span class=\"line\">        services[i].init();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>加载Server、Service、Connector、Container、Engine、Host、Context、Wrapper一系列的容器。</li>\n<li>初始化service，从server的初始化上看，一个server有多个service。</li>\n</ol>\n<h2 id=\"1-4、StandardService\"><a href=\"#1-4、StandardService\" class=\"headerlink\" title=\"1.4、StandardService:\"></a>1.4、StandardService:</h2><p>实际的service实现是StandardService</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void initInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    if (engine != null) &#123;</span><br><span class=\"line\">        engine.init();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Initialize any Executors</span><br><span class=\"line\">    for (Executor executor : findExecutors()) &#123;</span><br><span class=\"line\">        if (executor instanceof JmxEnabled) &#123;</span><br><span class=\"line\">            ((JmxEnabled) executor).setDomain(getDomain());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        executor.init();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Initialize mapper listener</span><br><span class=\"line\">    mapperListener.init();</span><br><span class=\"line\">    // Initialize our defined Connectors</span><br><span class=\"line\">    synchronized (connectorsLock) &#123;</span><br><span class=\"line\">        for (Connector connector : connectors) &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                connector.init();</span><br><span class=\"line\">            &#125; catch (Exception e) &#123;</span><br><span class=\"line\">                String message = sm.getString(</span><br><span class=\"line\">                        &quot;standardService.connector.initFailed&quot;, connector);</span><br><span class=\"line\">                log.error(message, e);</span><br><span class=\"line\">                if (Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;))</span><br><span class=\"line\">                    throw new LifecycleException(message);</span><br><span class=\"line\">&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>service执行engine的初始化。(engine继承Container，所以实际是进行container的初始化)</li>\n<li>然后创建一组线程池。executor是Tomcat自己实现的线程池。【】</li>\n<li>然后进行连接器(connector)的初始化（一组连接器，server.xml中配置的多个connector，对应了端口号和协议）</li>\n</ol>\n<h2 id=\"1-5、Connector-连接器\"><a href=\"#1-5、Connector-连接器\" class=\"headerlink\" title=\"1.5、Connector:连接器\"></a>1.5、Connector:连接器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void initInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Initialize adapter</span><br><span class=\"line\">    adapter = new CoyoteAdapter(this);</span><br><span class=\"line\">    protocolHandler.setAdapter(adapter);</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        protocolHandler.init();</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2019/12/20/2019-12-20-tomcat启动过程/%E8%BF%9E%E6%8E%A5%E5%99%A8.png\" alt=\"连接器\"></p>\n<ol>\n<li>创建adapter适配器，当processor解析socket之后生成的Request和Response不能直接传入到容器中，需要通过adapter<br>将Request和Response转换成ServletRequest和ServletResponse.</li>\n<li>初始化protocolHandler，有两个重要组件：Endpoint和Processer<ul>\n<li>Endpoint：端口监听，接收Socket后进行解析，基于TCP/IP协议。</li>\n<li>Processer：用来实现HTTP协议。将Endpoint的socket字节流解析成Tomcat的Request和Response，并通过Adapter交给容器处理。<br>#############</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>connector在解析server.xml时创建，看connector的构造器，会生成Http11Protocol协议解析器。</li>\n<li>Http11Protocol的构造器，会创建NIOEndPoint</li>\n<li>EndPoint.init，会bind绑定端口，等待请求、接收请求</li>\n<li>EndPoint内有processor处理线程。</li>\n</ul>\n<h2 id=\"1-6、protocolHandler-协议处理器\"><a href=\"#1-6、protocolHandler-协议处理器\" class=\"headerlink\" title=\"1.6、protocolHandler:协议处理器\"></a>1.6、protocolHandler:协议处理器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void init() throws Exception &#123;</span><br><span class=\"line\">    endpoint.init();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>初始化终端</p>\n<h2 id=\"1-7、endpoint-终端\"><a href=\"#1-7、endpoint-终端\" class=\"headerlink\" title=\"1.7、endpoint:终端\"></a>1.7、endpoint:终端</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void init() throws Exception &#123;</span><br><span class=\"line\">    if (bindOnInit) &#123;</span><br><span class=\"line\">        bind();</span><br><span class=\"line\">        bindState = BindState.BOUND_ON_INIT;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">终端的初始化，需要创建socket并绑定端口号。</span><br><span class=\"line\"></span><br><span class=\"line\">public void bind() throws Exception &#123;</span><br><span class=\"line\">    if (!getUseInheritedChannel()) &#123;</span><br><span class=\"line\">        serverSock = ServerSocketChannel.open();</span><br><span class=\"line\">        socketProperties.setProperties(serverSock.socket());</span><br><span class=\"line\">        InetSocketAddress addr = (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort()));</span><br><span class=\"line\">        serverSock.socket().bind(addr,getAcceptCount());</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        // Retrieve the channel provided by the OS</span><br><span class=\"line\">        Channel ic = System.inheritedChannel();</span><br><span class=\"line\">        if (ic instanceof ServerSocketChannel) &#123;</span><br><span class=\"line\">            serverSock = (ServerSocketChannel) ic;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (serverSock == null) &#123;</span><br><span class=\"line\">            throw new IllegalArgumentException(sm.getString(&quot;endpoint.init.bind.inherited&quot;));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    serverSock.configureBlocking(true); //mimic APR behavior</span><br><span class=\"line\">    selectorPool.open();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">EndPoint结构：</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、start过程\"><a href=\"#三、start过程\" class=\"headerlink\" title=\"三、start过程\"></a>三、start过程</h1><h2 id=\"初始化过程总结：\"><a href=\"#初始化过程总结：\" class=\"headerlink\" title=\"初始化过程总结：\"></a>初始化过程总结：</h2><p><img src=\"/2019/12/20/2019-12-20-tomcat启动过程/%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B.png\" alt=\"启动过程\"></p>\n<p>参考<br><a href=\"https://blog.csdn.net/cx520forever/article/details/52743166\" target=\"_blank\" rel=\"noopener\">Tomcat整体架构浅析</a></p>"},{"title":"hbase梳理","date":"2019-07-07T13:38:49.000Z","_content":"\n\n# 一、什么是HBASE\n1、面向列存储的分布式存储系统。   \n2、概念有row key和cloumn family。   \n3、仅能通过行键(row key)和行键序列来检索数据，仅支持单行事务。  \n\n<!--more-->  \n\n> 下图为hbase的整体架构图：\n\n![hbase工作原理](2019-07-07-hbase梳理/HBASE工作原理.png)  \n\nZookeepr负责维护集群的memberlist, 哪台服务器在线,哪台服务器宕机都由zookeeper探测和管理. Region server, 主备Master节点主动连接Zookeeper, 维护一个Session连接,\n\n从图可以看出，HBase中的存储包括HMaster、HRegionServer、HRegion、Store、MemStore、StoreFile、HFile、HLog等\n1. HMaster：协调HRegionServer的负载均衡，\n2. HRegionServer：管理region，处理对region的IO请求。\n3. HRegion：存储数据，按行进行分割，每个region最大256M，超过将分割成两个region。\n4. Store：为每一个columnFamily创建一个store\n5. MEMStore\n6. StoreFile：HFile的轻量封装。\n7. HFile：KeyValue的存储格式，是Hadoop的二进制存储文件。\n8. Hlog：一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况\n\n# 二、基本类型\nHBASE中每一个表叫做BigTable，bigtable会存储一系列的行数据，行的三个基本类型的定义：\n1.逻辑存储：\n\n![hbase工作原理](2019-07-07-hbase梳理/逻辑存储.png)\n\n2.三个类型定义：\n1.RowKey\n是行在BigTable中的唯一标识。\n2.TimeStamp：\n是每一次数据操作对应关联的时间戳，可以看作SVN的版本。\n3.Column：\n定义为:，通过这两部分可以指定唯一的数据的存储列，family的定义和修改需要对HBase进行类似于DB的DDL操作，\n而label，不需要定义直接可以使用，这也为动态定制列提供了一种手段。family另一个作用体现在物理存储优化读写操作上，同family\n的数据物理上保存的会比较接近，因此在业务设计的过程中可以利用这个特性。\n\n```\n示例：\nRow row =new Row();\nList<Column> columns = new ArrayList<>();\ncolumns.add(new Column(\"id\",dto.getId().toString()));\ncolumns.add(new Column(\"operation\",dto.getOperation()));\ncolumns.add(new Column(\"operationId\",String.valueOf(dto.getOperationId())));\ncolumns.add(new Column(\"recordId\",dto.getRecordId().toString()));\ncolumns.add(new Column(\"beforeData\",dto.getBeforeData()));\ncolumns.add(new Column(\"afterData\",dto.getAfterData()));\nrow.setColumnList(columns);\n```\n\n将这些字段都放入到一个column family内。\n![hbase工作原理](2019-07-07-hbase梳理/数据表格.png)\n\n\n# 三、各个模块的结构\n1、HMaster\n> 1、协调各个regsion server的负载均衡。   \n> 2、负责给region分配region server。   \n> 3、通过zk可以实现master的集群部署，但是同时只有一个master提供服务。\n\n```\n**************************\n**** HBase Meta Table ****\n**************************\nMeta table存储所有region的列表\nMeta table的结构如下:\n- Key: region的开始row key, region id\n- Values: Region server\n\n```\n\n2、Region Server\n结构及流程图：\n\n![hbase工作原理](2019-07-07-hbase梳理/逻辑存储.png)\n\n2.1、Region\n1、根据Row Key的区域分成多个Region（按照rowkey分成region，若一个region存储不下则开辟新的region）\n2、每个HRegion对应Table中一个Region，HRegion由多个HStore组成；\n3、每个HStore对应Table中一个Column Family的存储；\n4、flush的最小单位是region。\n5、每个region最大1GB(默认)。\n\n\n案例：\n假设一个region只能存储一条数据，那么现在两条数据，则会生成两个region。\n\n一条数据怎么存储呢？通过store存储。\n现在一行数据有两个column family：info和area。\n每个column family都使用store存储，那么现在会有两个store。\n那一个store怎么存储呢？\n通过keyvalue的方式存储，key=name,value=age\n那怎么对应到物理文件中呢？\n使用HFile进行存储，将keyvalue封装成Data block。Data block是HBASE IO的最基本单元。\n\n\n2.2、MemStore\n1、每一个cloumn family对应一个memstore，\n2、采用LSM数据结构存储，并在内存中排序，提高写入速度。\n3、若rowkey的cf过多，则会导致memstore过多，导致region的flush。\n\n\n\n2.3、Store File\nHFile的轻量封装。\n\n2.4、HFile\n1、HFile中存储有序的Key-Value对. 当Memstore满了之后, Memstore中的所有数据写入HDFS中,形成一个新的HFile\n2、HFile文件主要分为4个部分：Scanned block部分、Non-scanned block部分、Load-on-open部分和Trailer。\n\n> HFile结构：\n\n![hbase工作原理](2019-07-07-hbase梳理/hfile结构.png)\n\n首先HFile文件是不定长的，长度固定的只有其中的两块：Trailer和FileInfo。Trailer中又指针指向其他数据块的起始点，FileInfo记录了文件的一些meta信息。\nHFile由一个一个Data block组成，Data block中存储一个一个的key value。\n\n> keyvalue结构：\n\n![hbase工作原理](2019-07-07-hbase梳理/keyvalue结构.png)\n\n2.5、HLog\n一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况。\n每个region server都有一个HLog。\n\n\n# 四、数据读取过程\nClient 请求读取数据时，先转发到 ZK 集群，在 ZK 集群中寻找到相对应的 Region Server，再找到对应的 Region，先是查 MemStore，如果在 MemStore 中获取到数据，那么就会直接返回，否则就是再由 Region 找到对应的 Store File，从而查到具体的数据。\n在整个架构中，HMaster 和 HRegion Server 可以是同一个节点上，可以有多个 HMaster 存在，但是只有一个 HMaster 在活跃。\n在 Client 端会进行 rowkey-> HRegion 映射关系的缓存，降低下次寻址的压力。\n\nclient -> zk -> hmaster -> hregionServer -> hRegion -> MemStore -> HFile -> HDFS -> NameNode -> DataNode\n\nZookeepr负责维护集群的memberlist, 哪台服务器在线,哪台服务器宕机都由zookeeper探测和管理. Region server, 主备Master节点主动连接Zookeeper, 维护一个Session连接,\nHBase的第一次读写流程\n\nHBase把各个region的位置信息存储在一个特殊的表中, 这个表叫做Meta table.\nZookeeper里面存储了这个Meta table的位置信息.\n\nHBase的访问流程:\n1. 客户端访问Zookeep, 得到了具体Meta table的位置\n2. 客户端再访问真正的Meta table, 从Meta table里面得到row key所在的region server\n3. 访问rowkey所在的region server, 得到需要的真正数据.\n\n# 五、数据写入过程\n\n先是 Client 进行发起数据的插入请求，如果 Client 本身存储了关于 Rowkey 和 Region 的映射关系的话，那么就会先查找到具体的对应关系，如果没有的话，就会在ZK中进行查找到对应 Region server，然后再转发到具体的 Region 上。所有的数据在写入的时候先是记录在 WAL 中，同时检查关于 MemStore 是否满了，如果是满了，那么就会进行刷盘，输出到一个 Hfile 中，如果没有满的话，那么就是先写进 Memstore 中，然后再刷到 WAL 中。\n\nhttps://www.infoq.cn/article/iehfj_irzkiuepm6udza\n\n\nHBase Meta Table\nMeta table存储所有region的列表\nMeta table用类似于Btree的方式存储\nMeta table的结构如下:\n- Key: region的开始row key, region id\n- Values: Region server\n\n# 六、region分区及定位?\n每张表一开始只有一个 Region，但是随着数据的插入，HBase 会根据一定的规则将表进行水平拆分，形成两个 Region。当表中的行越来越多时，就会产生越来越多的 Region，而这些 Region 无法存储到一台机器上时，则可将其分布存储到多台机器上。\n表的所有行都是按照 RowKey 的字典序排列的，表在行的方向上分割为多个分区（Region），如下图所示。\n\n6.1、region分区\nregion两个重要属性：startKey与endKey，代表该region维护的rowkey范围。\n如果一开始，一张表只有一个region，当数据put超过region的存储容量，则会发生分区，找到一个midkey，将region一分为二。\n问题：\n* 如果rowkey是递增的，那么数据会一直往大的分区写，则分割的另外一半没有满。\n散列+预分区，二者结合是比较好的方式。预分区一开始就预建好了一部分region,这些region都维护着自已的start-end keys，再配合上随机散列，写数据能均等地命中这些预建的region，就能解决上面的那些缺点，大大地提高了性能\n\n6.2、理解rowkey的字典序：\nHBase是三维有序存储的，是指rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度是依照ASCII码表排序的。（比如A排在a前面）\n* 先rowkey升序排序，\n* rowkey相同则column key升序排序\n* rowkey、column key相同则timestamp降序排序\n如下： 假设存在table：test，family：info\nscan表得到结果如下：\n```\n//列族默认VERSIONS值为1，可以通过命令：alter 'tableName','familyName',VERSINOS =>5来设置\n//不同version保存不同时间戳的数据，默认是只显示最新version数据。要想显示所有，scan时应该加上{VERSIONS =>5}\nhbase(main):009:0> scan 'test', {VERSIONS =>5}\nROW                                                    COLUMN+CELL                                                                                                                                                   \n 12Aabb                                                column=info:name,timestamp=1519957330893,value=123                                                                                                      \n 3aabb                                                 column=info:name,timestamp=1519963129863,value=3234                                                                                                         \n 3aabb                                                 column=info:name,timestamp=1519962895984,value=234                                                                                                          \n 3aabb                                                 column=info:name,timestamp=1519962889791,value=234                                                                                                          \n 3aabb                                                 column=info:name,timestamp=1519960252203,value=999                                                                                                          \n Aabb                                                  column=info:address,timestamp=1519969857611,value=cccc                                                                                                      \n Aabb                                                  column=info:friend,timestamp=1519969916299,value=jack                                                                                                       \n Aabb                                                  column=info:name,timestamp=1519957330890,value=123                                                                                                         \n aabb                                                  column=info:name,timestamp=1519957330859,value=123                                                                                                          \n4 row(s) in 0.0530 seconds\n```\n\n\n\n# 七、Rowkey的设计原则\n## 1、rowkey长度原则\nrowkey是一个二进制码流，可以是任意字符串，最大长度64kb，实际应用中一般为10-100bytes，以byte[]形式保存，一般设计成定长。\n建议越短越好，不要超过16个字节，原因如下：\n\n数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w=10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；\nMemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。\n目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。\n## 2、rowkey散列原则\n如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样将提高数据均衡分布在每个RegionServer，以实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。\n## 3、rowkey唯一原则\n必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。\n\n## 什么是热点？\nHBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的行存取在临近位置，便于scan。然而糟糕的rowkey设计是热点的源头。 热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。大量访问会使热点region所在的单个机器超出自身承受能力，引起性能下降甚至region不可用，这也会影响同一个RegionServer上的其他region，由于主机无法服务其他region的请求。 设计良好的数据访问模式以使集群被充分，均衡的利用。\n为了避免写热点，设计rowkey使得不同行在同一个region，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。\n\n下面是一些常见的避免热点的方法以及它们的优缺点：\n* 加盐\n这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。\n* 哈希\n哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据\n* 反转\n第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。\n反转rowkey的例子以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题\n时间戳反转\n一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用 Long.Max_Value - timestamp 追加到key的末尾，例如 [key][reverse_timestamp] , [key] 的最新值可以通过scan [key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。\n比如需要保存一个用户的操作记录，按照操作时间倒序排序，在设计rowkey的时候，可以这样设计\n[userId反转][Long.Max_Value - timestamp]，在查询用户的所有操作记录数据的时候，直接指定反转后的userId，startRow是[userId反转][000000000000],stopRow是[userId反转][Long.Max_Value - timestamp]\n如果需要查询某段时间的操作记录，startRow是[user反转][Long.Max_Value - 起始时间]，stopRow是[userId反转][Long.Max_Value - 结束时间]\n\n# 八、使用案例\n```\n示例：\nRow row =new Row();\nList<Column> columns = new ArrayList<>();\ncolumns.add(new Column(\"id\",dto.getId().toString()));\ncolumns.add(new Column(\"operation\",dto.getOperation()));\ncolumns.add(new Column(\"operationId\",String.valueOf(dto.getOperationId())));\ncolumns.add(new Column(\"recordId\",dto.getRecordId().toString()));\ncolumns.add(new Column(\"beforeData\",dto.getBeforeData()));\ncolumns.add(new Column(\"afterData\",dto.getAfterData()));\nrow.setColumnList(columns);\n\nprivate String getRowKey(BusinessLogDto dto){\n    if(dto.getRecordId()!=null&&dto.getModuleId()!=null&&dto.getId()!=null){\n        StringBuilder stringBuilder = new StringBuilder(dto.getRecordId()+Constants.ROW_KEY_SEPARATION+dto.getModuleId());\n        if(dto.getChildModuleId()!=null){\n            stringBuilder.append(Constants.ROW_KEY_SEPARATION+dto.getChildModuleId());\n        }\n        stringBuilder.append(Constants.ROW_KEY_SEPARATION+dto.getOperationId()+Constants.ROW_KEY_SEPARATION+dto.getId());\n        String rowkey =stringBuilder.toString();\n        log.info(\"upload create rowkey:\"+rowkey);\n        return  rowkey;\n    }\n    log.info(\"upload create rowkey is null\");\n    return null;\n}\n```\n将这些字段都放入到一个column family内。\n\n![hbase工作原理](2019-07-07-hbase梳理/数据表格.png)\n\n\n\n## 8.1、row key设计：\n 业务ID+_+系统ID(+_+子模块ID(如需要自行定义))+_+业务系统操作ID+_+生成的唯一ID(时间毫秒数+4位计数（0000-9999）)\n* 1、热点考虑：业务ID本身是唯一的，这样可以保证不产生热点问题，又能保证系统的业务ID可以进入相同的region内。\n* 2、长度考虑：long + long + long + long +long (8byte*5=40byte)，emmmm，这里有问题？长度不固定并且长度大于了16byte。\n\n实际实现：业务ID+系统ID+业务系统操作ID\n\nhttps://www.cnblogs.com/yangjiming/p/9429169.html\nhttp://c.biancheng.net/view/6528.html","source":"_posts/2019-07-07-hbase梳理.md","raw":"---\ntitle: hbase梳理\ndate: 2019-07-07 21:38:49\ntags:\n---\n\n\n# 一、什么是HBASE\n1、面向列存储的分布式存储系统。   \n2、概念有row key和cloumn family。   \n3、仅能通过行键(row key)和行键序列来检索数据，仅支持单行事务。  \n\n<!--more-->  \n\n> 下图为hbase的整体架构图：\n\n![hbase工作原理](2019-07-07-hbase梳理/HBASE工作原理.png)  \n\nZookeepr负责维护集群的memberlist, 哪台服务器在线,哪台服务器宕机都由zookeeper探测和管理. Region server, 主备Master节点主动连接Zookeeper, 维护一个Session连接,\n\n从图可以看出，HBase中的存储包括HMaster、HRegionServer、HRegion、Store、MemStore、StoreFile、HFile、HLog等\n1. HMaster：协调HRegionServer的负载均衡，\n2. HRegionServer：管理region，处理对region的IO请求。\n3. HRegion：存储数据，按行进行分割，每个region最大256M，超过将分割成两个region。\n4. Store：为每一个columnFamily创建一个store\n5. MEMStore\n6. StoreFile：HFile的轻量封装。\n7. HFile：KeyValue的存储格式，是Hadoop的二进制存储文件。\n8. Hlog：一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况\n\n# 二、基本类型\nHBASE中每一个表叫做BigTable，bigtable会存储一系列的行数据，行的三个基本类型的定义：\n1.逻辑存储：\n\n![hbase工作原理](2019-07-07-hbase梳理/逻辑存储.png)\n\n2.三个类型定义：\n1.RowKey\n是行在BigTable中的唯一标识。\n2.TimeStamp：\n是每一次数据操作对应关联的时间戳，可以看作SVN的版本。\n3.Column：\n定义为:，通过这两部分可以指定唯一的数据的存储列，family的定义和修改需要对HBase进行类似于DB的DDL操作，\n而label，不需要定义直接可以使用，这也为动态定制列提供了一种手段。family另一个作用体现在物理存储优化读写操作上，同family\n的数据物理上保存的会比较接近，因此在业务设计的过程中可以利用这个特性。\n\n```\n示例：\nRow row =new Row();\nList<Column> columns = new ArrayList<>();\ncolumns.add(new Column(\"id\",dto.getId().toString()));\ncolumns.add(new Column(\"operation\",dto.getOperation()));\ncolumns.add(new Column(\"operationId\",String.valueOf(dto.getOperationId())));\ncolumns.add(new Column(\"recordId\",dto.getRecordId().toString()));\ncolumns.add(new Column(\"beforeData\",dto.getBeforeData()));\ncolumns.add(new Column(\"afterData\",dto.getAfterData()));\nrow.setColumnList(columns);\n```\n\n将这些字段都放入到一个column family内。\n![hbase工作原理](2019-07-07-hbase梳理/数据表格.png)\n\n\n# 三、各个模块的结构\n1、HMaster\n> 1、协调各个regsion server的负载均衡。   \n> 2、负责给region分配region server。   \n> 3、通过zk可以实现master的集群部署，但是同时只有一个master提供服务。\n\n```\n**************************\n**** HBase Meta Table ****\n**************************\nMeta table存储所有region的列表\nMeta table的结构如下:\n- Key: region的开始row key, region id\n- Values: Region server\n\n```\n\n2、Region Server\n结构及流程图：\n\n![hbase工作原理](2019-07-07-hbase梳理/逻辑存储.png)\n\n2.1、Region\n1、根据Row Key的区域分成多个Region（按照rowkey分成region，若一个region存储不下则开辟新的region）\n2、每个HRegion对应Table中一个Region，HRegion由多个HStore组成；\n3、每个HStore对应Table中一个Column Family的存储；\n4、flush的最小单位是region。\n5、每个region最大1GB(默认)。\n\n\n案例：\n假设一个region只能存储一条数据，那么现在两条数据，则会生成两个region。\n\n一条数据怎么存储呢？通过store存储。\n现在一行数据有两个column family：info和area。\n每个column family都使用store存储，那么现在会有两个store。\n那一个store怎么存储呢？\n通过keyvalue的方式存储，key=name,value=age\n那怎么对应到物理文件中呢？\n使用HFile进行存储，将keyvalue封装成Data block。Data block是HBASE IO的最基本单元。\n\n\n2.2、MemStore\n1、每一个cloumn family对应一个memstore，\n2、采用LSM数据结构存储，并在内存中排序，提高写入速度。\n3、若rowkey的cf过多，则会导致memstore过多，导致region的flush。\n\n\n\n2.3、Store File\nHFile的轻量封装。\n\n2.4、HFile\n1、HFile中存储有序的Key-Value对. 当Memstore满了之后, Memstore中的所有数据写入HDFS中,形成一个新的HFile\n2、HFile文件主要分为4个部分：Scanned block部分、Non-scanned block部分、Load-on-open部分和Trailer。\n\n> HFile结构：\n\n![hbase工作原理](2019-07-07-hbase梳理/hfile结构.png)\n\n首先HFile文件是不定长的，长度固定的只有其中的两块：Trailer和FileInfo。Trailer中又指针指向其他数据块的起始点，FileInfo记录了文件的一些meta信息。\nHFile由一个一个Data block组成，Data block中存储一个一个的key value。\n\n> keyvalue结构：\n\n![hbase工作原理](2019-07-07-hbase梳理/keyvalue结构.png)\n\n2.5、HLog\n一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况。\n每个region server都有一个HLog。\n\n\n# 四、数据读取过程\nClient 请求读取数据时，先转发到 ZK 集群，在 ZK 集群中寻找到相对应的 Region Server，再找到对应的 Region，先是查 MemStore，如果在 MemStore 中获取到数据，那么就会直接返回，否则就是再由 Region 找到对应的 Store File，从而查到具体的数据。\n在整个架构中，HMaster 和 HRegion Server 可以是同一个节点上，可以有多个 HMaster 存在，但是只有一个 HMaster 在活跃。\n在 Client 端会进行 rowkey-> HRegion 映射关系的缓存，降低下次寻址的压力。\n\nclient -> zk -> hmaster -> hregionServer -> hRegion -> MemStore -> HFile -> HDFS -> NameNode -> DataNode\n\nZookeepr负责维护集群的memberlist, 哪台服务器在线,哪台服务器宕机都由zookeeper探测和管理. Region server, 主备Master节点主动连接Zookeeper, 维护一个Session连接,\nHBase的第一次读写流程\n\nHBase把各个region的位置信息存储在一个特殊的表中, 这个表叫做Meta table.\nZookeeper里面存储了这个Meta table的位置信息.\n\nHBase的访问流程:\n1. 客户端访问Zookeep, 得到了具体Meta table的位置\n2. 客户端再访问真正的Meta table, 从Meta table里面得到row key所在的region server\n3. 访问rowkey所在的region server, 得到需要的真正数据.\n\n# 五、数据写入过程\n\n先是 Client 进行发起数据的插入请求，如果 Client 本身存储了关于 Rowkey 和 Region 的映射关系的话，那么就会先查找到具体的对应关系，如果没有的话，就会在ZK中进行查找到对应 Region server，然后再转发到具体的 Region 上。所有的数据在写入的时候先是记录在 WAL 中，同时检查关于 MemStore 是否满了，如果是满了，那么就会进行刷盘，输出到一个 Hfile 中，如果没有满的话，那么就是先写进 Memstore 中，然后再刷到 WAL 中。\n\nhttps://www.infoq.cn/article/iehfj_irzkiuepm6udza\n\n\nHBase Meta Table\nMeta table存储所有region的列表\nMeta table用类似于Btree的方式存储\nMeta table的结构如下:\n- Key: region的开始row key, region id\n- Values: Region server\n\n# 六、region分区及定位?\n每张表一开始只有一个 Region，但是随着数据的插入，HBase 会根据一定的规则将表进行水平拆分，形成两个 Region。当表中的行越来越多时，就会产生越来越多的 Region，而这些 Region 无法存储到一台机器上时，则可将其分布存储到多台机器上。\n表的所有行都是按照 RowKey 的字典序排列的，表在行的方向上分割为多个分区（Region），如下图所示。\n\n6.1、region分区\nregion两个重要属性：startKey与endKey，代表该region维护的rowkey范围。\n如果一开始，一张表只有一个region，当数据put超过region的存储容量，则会发生分区，找到一个midkey，将region一分为二。\n问题：\n* 如果rowkey是递增的，那么数据会一直往大的分区写，则分割的另外一半没有满。\n散列+预分区，二者结合是比较好的方式。预分区一开始就预建好了一部分region,这些region都维护着自已的start-end keys，再配合上随机散列，写数据能均等地命中这些预建的region，就能解决上面的那些缺点，大大地提高了性能\n\n6.2、理解rowkey的字典序：\nHBase是三维有序存储的，是指rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度是依照ASCII码表排序的。（比如A排在a前面）\n* 先rowkey升序排序，\n* rowkey相同则column key升序排序\n* rowkey、column key相同则timestamp降序排序\n如下： 假设存在table：test，family：info\nscan表得到结果如下：\n```\n//列族默认VERSIONS值为1，可以通过命令：alter 'tableName','familyName',VERSINOS =>5来设置\n//不同version保存不同时间戳的数据，默认是只显示最新version数据。要想显示所有，scan时应该加上{VERSIONS =>5}\nhbase(main):009:0> scan 'test', {VERSIONS =>5}\nROW                                                    COLUMN+CELL                                                                                                                                                   \n 12Aabb                                                column=info:name,timestamp=1519957330893,value=123                                                                                                      \n 3aabb                                                 column=info:name,timestamp=1519963129863,value=3234                                                                                                         \n 3aabb                                                 column=info:name,timestamp=1519962895984,value=234                                                                                                          \n 3aabb                                                 column=info:name,timestamp=1519962889791,value=234                                                                                                          \n 3aabb                                                 column=info:name,timestamp=1519960252203,value=999                                                                                                          \n Aabb                                                  column=info:address,timestamp=1519969857611,value=cccc                                                                                                      \n Aabb                                                  column=info:friend,timestamp=1519969916299,value=jack                                                                                                       \n Aabb                                                  column=info:name,timestamp=1519957330890,value=123                                                                                                         \n aabb                                                  column=info:name,timestamp=1519957330859,value=123                                                                                                          \n4 row(s) in 0.0530 seconds\n```\n\n\n\n# 七、Rowkey的设计原则\n## 1、rowkey长度原则\nrowkey是一个二进制码流，可以是任意字符串，最大长度64kb，实际应用中一般为10-100bytes，以byte[]形式保存，一般设计成定长。\n建议越短越好，不要超过16个字节，原因如下：\n\n数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w=10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；\nMemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。\n目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。\n## 2、rowkey散列原则\n如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样将提高数据均衡分布在每个RegionServer，以实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。\n## 3、rowkey唯一原则\n必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。\n\n## 什么是热点？\nHBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的行存取在临近位置，便于scan。然而糟糕的rowkey设计是热点的源头。 热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。大量访问会使热点region所在的单个机器超出自身承受能力，引起性能下降甚至region不可用，这也会影响同一个RegionServer上的其他region，由于主机无法服务其他region的请求。 设计良好的数据访问模式以使集群被充分，均衡的利用。\n为了避免写热点，设计rowkey使得不同行在同一个region，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。\n\n下面是一些常见的避免热点的方法以及它们的优缺点：\n* 加盐\n这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。\n* 哈希\n哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据\n* 反转\n第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。\n反转rowkey的例子以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题\n时间戳反转\n一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用 Long.Max_Value - timestamp 追加到key的末尾，例如 [key][reverse_timestamp] , [key] 的最新值可以通过scan [key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。\n比如需要保存一个用户的操作记录，按照操作时间倒序排序，在设计rowkey的时候，可以这样设计\n[userId反转][Long.Max_Value - timestamp]，在查询用户的所有操作记录数据的时候，直接指定反转后的userId，startRow是[userId反转][000000000000],stopRow是[userId反转][Long.Max_Value - timestamp]\n如果需要查询某段时间的操作记录，startRow是[user反转][Long.Max_Value - 起始时间]，stopRow是[userId反转][Long.Max_Value - 结束时间]\n\n# 八、使用案例\n```\n示例：\nRow row =new Row();\nList<Column> columns = new ArrayList<>();\ncolumns.add(new Column(\"id\",dto.getId().toString()));\ncolumns.add(new Column(\"operation\",dto.getOperation()));\ncolumns.add(new Column(\"operationId\",String.valueOf(dto.getOperationId())));\ncolumns.add(new Column(\"recordId\",dto.getRecordId().toString()));\ncolumns.add(new Column(\"beforeData\",dto.getBeforeData()));\ncolumns.add(new Column(\"afterData\",dto.getAfterData()));\nrow.setColumnList(columns);\n\nprivate String getRowKey(BusinessLogDto dto){\n    if(dto.getRecordId()!=null&&dto.getModuleId()!=null&&dto.getId()!=null){\n        StringBuilder stringBuilder = new StringBuilder(dto.getRecordId()+Constants.ROW_KEY_SEPARATION+dto.getModuleId());\n        if(dto.getChildModuleId()!=null){\n            stringBuilder.append(Constants.ROW_KEY_SEPARATION+dto.getChildModuleId());\n        }\n        stringBuilder.append(Constants.ROW_KEY_SEPARATION+dto.getOperationId()+Constants.ROW_KEY_SEPARATION+dto.getId());\n        String rowkey =stringBuilder.toString();\n        log.info(\"upload create rowkey:\"+rowkey);\n        return  rowkey;\n    }\n    log.info(\"upload create rowkey is null\");\n    return null;\n}\n```\n将这些字段都放入到一个column family内。\n\n![hbase工作原理](2019-07-07-hbase梳理/数据表格.png)\n\n\n\n## 8.1、row key设计：\n 业务ID+_+系统ID(+_+子模块ID(如需要自行定义))+_+业务系统操作ID+_+生成的唯一ID(时间毫秒数+4位计数（0000-9999）)\n* 1、热点考虑：业务ID本身是唯一的，这样可以保证不产生热点问题，又能保证系统的业务ID可以进入相同的region内。\n* 2、长度考虑：long + long + long + long +long (8byte*5=40byte)，emmmm，这里有问题？长度不固定并且长度大于了16byte。\n\n实际实现：业务ID+系统ID+业务系统操作ID\n\nhttps://www.cnblogs.com/yangjiming/p/9429169.html\nhttp://c.biancheng.net/view/6528.html","slug":"2019-07-07-hbase梳理","published":1,"updated":"2024-10-14T09:38:11.919Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnw0001ia13k6k3twovz","content":"<h1 id=\"一、什么是HBASE\"><a href=\"#一、什么是HBASE\" class=\"headerlink\" title=\"一、什么是HBASE\"></a>一、什么是HBASE</h1><p>1、面向列存储的分布式存储系统。<br>2、概念有row key和cloumn family。<br>3、仅能通过行键(row key)和行键序列来检索数据，仅支持单行事务。  </p>\n<a id=\"more\"></a>  \n\n<blockquote>\n<p>下图为hbase的整体架构图：</p>\n</blockquote>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/HBASE%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png\" alt=\"hbase工作原理\">  </p>\n<p>Zookeepr负责维护集群的memberlist, 哪台服务器在线,哪台服务器宕机都由zookeeper探测和管理. Region server, 主备Master节点主动连接Zookeeper, 维护一个Session连接,</p>\n<p>从图可以看出，HBase中的存储包括HMaster、HRegionServer、HRegion、Store、MemStore、StoreFile、HFile、HLog等</p>\n<ol>\n<li>HMaster：协调HRegionServer的负载均衡，</li>\n<li>HRegionServer：管理region，处理对region的IO请求。</li>\n<li>HRegion：存储数据，按行进行分割，每个region最大256M，超过将分割成两个region。</li>\n<li>Store：为每一个columnFamily创建一个store</li>\n<li>MEMStore</li>\n<li>StoreFile：HFile的轻量封装。</li>\n<li>HFile：KeyValue的存储格式，是Hadoop的二进制存储文件。</li>\n<li>Hlog：一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况</li>\n</ol>\n<h1 id=\"二、基本类型\"><a href=\"#二、基本类型\" class=\"headerlink\" title=\"二、基本类型\"></a>二、基本类型</h1><p>HBASE中每一个表叫做BigTable，bigtable会存储一系列的行数据，行的三个基本类型的定义：<br>1.逻辑存储：</p>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/%E9%80%BB%E8%BE%91%E5%AD%98%E5%82%A8.png\" alt=\"hbase工作原理\"></p>\n<p>2.三个类型定义：<br>1.RowKey<br>是行在BigTable中的唯一标识。<br>2.TimeStamp：<br>是每一次数据操作对应关联的时间戳，可以看作SVN的版本。<br>3.Column：<br>定义为:，通过这两部分可以指定唯一的数据的存储列，family的定义和修改需要对HBase进行类似于DB的DDL操作，<br>而label，不需要定义直接可以使用，这也为动态定制列提供了一种手段。family另一个作用体现在物理存储优化读写操作上，同family<br>的数据物理上保存的会比较接近，因此在业务设计的过程中可以利用这个特性。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">示例：</span><br><span class=\"line\">Row row =new Row();</span><br><span class=\"line\">List&lt;Column&gt; columns = new ArrayList&lt;&gt;();</span><br><span class=\"line\">columns.add(new Column(&quot;id&quot;,dto.getId().toString()));</span><br><span class=\"line\">columns.add(new Column(&quot;operation&quot;,dto.getOperation()));</span><br><span class=\"line\">columns.add(new Column(&quot;operationId&quot;,String.valueOf(dto.getOperationId())));</span><br><span class=\"line\">columns.add(new Column(&quot;recordId&quot;,dto.getRecordId().toString()));</span><br><span class=\"line\">columns.add(new Column(&quot;beforeData&quot;,dto.getBeforeData()));</span><br><span class=\"line\">columns.add(new Column(&quot;afterData&quot;,dto.getAfterData()));</span><br><span class=\"line\">row.setColumnList(columns);</span><br></pre></td></tr></table></figure>\n\n<p>将这些字段都放入到一个column family内。<br><img src=\"/2019/07/07/2019-07-07-hbase梳理/%E6%95%B0%E6%8D%AE%E8%A1%A8%E6%A0%BC.png\" alt=\"hbase工作原理\"></p>\n<h1 id=\"三、各个模块的结构\"><a href=\"#三、各个模块的结构\" class=\"headerlink\" title=\"三、各个模块的结构\"></a>三、各个模块的结构</h1><p>1、HMaster</p>\n<blockquote>\n<p>1、协调各个regsion server的负载均衡。<br>2、负责给region分配region server。<br>3、通过zk可以实现master的集群部署，但是同时只有一个master提供服务。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">**************************</span><br><span class=\"line\">**** HBase Meta Table ****</span><br><span class=\"line\">**************************</span><br><span class=\"line\">Meta table存储所有region的列表</span><br><span class=\"line\">Meta table的结构如下:</span><br><span class=\"line\">- Key: region的开始row key, region id</span><br><span class=\"line\">- Values: Region server</span><br></pre></td></tr></table></figure>\n\n<p>2、Region Server<br>结构及流程图：</p>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/%E9%80%BB%E8%BE%91%E5%AD%98%E5%82%A8.png\" alt=\"hbase工作原理\"></p>\n<p>2.1、Region<br>1、根据Row Key的区域分成多个Region（按照rowkey分成region，若一个region存储不下则开辟新的region）<br>2、每个HRegion对应Table中一个Region，HRegion由多个HStore组成；<br>3、每个HStore对应Table中一个Column Family的存储；<br>4、flush的最小单位是region。<br>5、每个region最大1GB(默认)。</p>\n<p>案例：<br>假设一个region只能存储一条数据，那么现在两条数据，则会生成两个region。</p>\n<p>一条数据怎么存储呢？通过store存储。<br>现在一行数据有两个column family：info和area。<br>每个column family都使用store存储，那么现在会有两个store。<br>那一个store怎么存储呢？<br>通过keyvalue的方式存储，key=name,value=age<br>那怎么对应到物理文件中呢？<br>使用HFile进行存储，将keyvalue封装成Data block。Data block是HBASE IO的最基本单元。</p>\n<p>2.2、MemStore<br>1、每一个cloumn family对应一个memstore，<br>2、采用LSM数据结构存储，并在内存中排序，提高写入速度。<br>3、若rowkey的cf过多，则会导致memstore过多，导致region的flush。</p>\n<p>2.3、Store File<br>HFile的轻量封装。</p>\n<p>2.4、HFile<br>1、HFile中存储有序的Key-Value对. 当Memstore满了之后, Memstore中的所有数据写入HDFS中,形成一个新的HFile<br>2、HFile文件主要分为4个部分：Scanned block部分、Non-scanned block部分、Load-on-open部分和Trailer。</p>\n<blockquote>\n<p>HFile结构：</p>\n</blockquote>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/hfile%E7%BB%93%E6%9E%84.png\" alt=\"hbase工作原理\"></p>\n<p>首先HFile文件是不定长的，长度固定的只有其中的两块：Trailer和FileInfo。Trailer中又指针指向其他数据块的起始点，FileInfo记录了文件的一些meta信息。<br>HFile由一个一个Data block组成，Data block中存储一个一个的key value。</p>\n<blockquote>\n<p>keyvalue结构：</p>\n</blockquote>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/keyvalue%E7%BB%93%E6%9E%84.png\" alt=\"hbase工作原理\"></p>\n<p>2.5、HLog<br>一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况。<br>每个region server都有一个HLog。</p>\n<h1 id=\"四、数据读取过程\"><a href=\"#四、数据读取过程\" class=\"headerlink\" title=\"四、数据读取过程\"></a>四、数据读取过程</h1><p>Client 请求读取数据时，先转发到 ZK 集群，在 ZK 集群中寻找到相对应的 Region Server，再找到对应的 Region，先是查 MemStore，如果在 MemStore 中获取到数据，那么就会直接返回，否则就是再由 Region 找到对应的 Store File，从而查到具体的数据。<br>在整个架构中，HMaster 和 HRegion Server 可以是同一个节点上，可以有多个 HMaster 存在，但是只有一个 HMaster 在活跃。<br>在 Client 端会进行 rowkey-&gt; HRegion 映射关系的缓存，降低下次寻址的压力。</p>\n<p>client -&gt; zk -&gt; hmaster -&gt; hregionServer -&gt; hRegion -&gt; MemStore -&gt; HFile -&gt; HDFS -&gt; NameNode -&gt; DataNode</p>\n<p>Zookeepr负责维护集群的memberlist, 哪台服务器在线,哪台服务器宕机都由zookeeper探测和管理. Region server, 主备Master节点主动连接Zookeeper, 维护一个Session连接,<br>HBase的第一次读写流程</p>\n<p>HBase把各个region的位置信息存储在一个特殊的表中, 这个表叫做Meta table.<br>Zookeeper里面存储了这个Meta table的位置信息.</p>\n<p>HBase的访问流程:</p>\n<ol>\n<li>客户端访问Zookeep, 得到了具体Meta table的位置</li>\n<li>客户端再访问真正的Meta table, 从Meta table里面得到row key所在的region server</li>\n<li>访问rowkey所在的region server, 得到需要的真正数据.</li>\n</ol>\n<h1 id=\"五、数据写入过程\"><a href=\"#五、数据写入过程\" class=\"headerlink\" title=\"五、数据写入过程\"></a>五、数据写入过程</h1><p>先是 Client 进行发起数据的插入请求，如果 Client 本身存储了关于 Rowkey 和 Region 的映射关系的话，那么就会先查找到具体的对应关系，如果没有的话，就会在ZK中进行查找到对应 Region server，然后再转发到具体的 Region 上。所有的数据在写入的时候先是记录在 WAL 中，同时检查关于 MemStore 是否满了，如果是满了，那么就会进行刷盘，输出到一个 Hfile 中，如果没有满的话，那么就是先写进 Memstore 中，然后再刷到 WAL 中。</p>\n<p><a href=\"https://www.infoq.cn/article/iehfj_irzkiuepm6udza\" target=\"_blank\" rel=\"noopener\">https://www.infoq.cn/article/iehfj_irzkiuepm6udza</a></p>\n<p>HBase Meta Table<br>Meta table存储所有region的列表<br>Meta table用类似于Btree的方式存储<br>Meta table的结构如下:</p>\n<ul>\n<li>Key: region的开始row key, region id</li>\n<li>Values: Region server</li>\n</ul>\n<h1 id=\"六、region分区及定位\"><a href=\"#六、region分区及定位\" class=\"headerlink\" title=\"六、region分区及定位?\"></a>六、region分区及定位?</h1><p>每张表一开始只有一个 Region，但是随着数据的插入，HBase 会根据一定的规则将表进行水平拆分，形成两个 Region。当表中的行越来越多时，就会产生越来越多的 Region，而这些 Region 无法存储到一台机器上时，则可将其分布存储到多台机器上。<br>表的所有行都是按照 RowKey 的字典序排列的，表在行的方向上分割为多个分区（Region），如下图所示。</p>\n<p>6.1、region分区<br>region两个重要属性：startKey与endKey，代表该region维护的rowkey范围。<br>如果一开始，一张表只有一个region，当数据put超过region的存储容量，则会发生分区，找到一个midkey，将region一分为二。<br>问题：</p>\n<ul>\n<li>如果rowkey是递增的，那么数据会一直往大的分区写，则分割的另外一半没有满。<br>散列+预分区，二者结合是比较好的方式。预分区一开始就预建好了一部分region,这些region都维护着自已的start-end keys，再配合上随机散列，写数据能均等地命中这些预建的region，就能解决上面的那些缺点，大大地提高了性能</li>\n</ul>\n<p>6.2、理解rowkey的字典序：<br>HBase是三维有序存储的，是指rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度是依照ASCII码表排序的。（比如A排在a前面）</p>\n<ul>\n<li>先rowkey升序排序，</li>\n<li>rowkey相同则column key升序排序</li>\n<li>rowkey、column key相同则timestamp降序排序<br>如下： 假设存在table：test，family：info<br>scan表得到结果如下：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//列族默认VERSIONS值为1，可以通过命令：alter &apos;tableName&apos;,&apos;familyName&apos;,VERSINOS =&gt;5来设置</span><br><span class=\"line\">//不同version保存不同时间戳的数据，默认是只显示最新version数据。要想显示所有，scan时应该加上&#123;VERSIONS =&gt;5&#125;</span><br><span class=\"line\">hbase(main):009:0&gt; scan &apos;test&apos;, &#123;VERSIONS =&gt;5&#125;</span><br><span class=\"line\">ROW                                                    COLUMN+CELL                                                                                                                                                   </span><br><span class=\"line\"> 12Aabb                                                column=info:name,timestamp=1519957330893,value=123                                                                                                      </span><br><span class=\"line\"> 3aabb                                                 column=info:name,timestamp=1519963129863,value=3234                                                                                                         </span><br><span class=\"line\"> 3aabb                                                 column=info:name,timestamp=1519962895984,value=234                                                                                                          </span><br><span class=\"line\"> 3aabb                                                 column=info:name,timestamp=1519962889791,value=234                                                                                                          </span><br><span class=\"line\"> 3aabb                                                 column=info:name,timestamp=1519960252203,value=999                                                                                                          </span><br><span class=\"line\"> Aabb                                                  column=info:address,timestamp=1519969857611,value=cccc                                                                                                      </span><br><span class=\"line\"> Aabb                                                  column=info:friend,timestamp=1519969916299,value=jack                                                                                                       </span><br><span class=\"line\"> Aabb                                                  column=info:name,timestamp=1519957330890,value=123                                                                                                         </span><br><span class=\"line\"> aabb                                                  column=info:name,timestamp=1519957330859,value=123                                                                                                          </span><br><span class=\"line\">4 row(s) in 0.0530 seconds</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h1 id=\"七、Rowkey的设计原则\"><a href=\"#七、Rowkey的设计原则\" class=\"headerlink\" title=\"七、Rowkey的设计原则\"></a>七、Rowkey的设计原则</h1><h2 id=\"1、rowkey长度原则\"><a href=\"#1、rowkey长度原则\" class=\"headerlink\" title=\"1、rowkey长度原则\"></a>1、rowkey长度原则</h2><p>rowkey是一个二进制码流，可以是任意字符串，最大长度64kb，实际应用中一般为10-100bytes，以byte[]形式保存，一般设计成定长。<br>建议越短越好，不要超过16个字节，原因如下：</p>\n<p>数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w=10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；<br>MemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。<br>目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。</p>\n<h2 id=\"2、rowkey散列原则\"><a href=\"#2、rowkey散列原则\" class=\"headerlink\" title=\"2、rowkey散列原则\"></a>2、rowkey散列原则</h2><p>如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样将提高数据均衡分布在每个RegionServer，以实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。</p>\n<h2 id=\"3、rowkey唯一原则\"><a href=\"#3、rowkey唯一原则\" class=\"headerlink\" title=\"3、rowkey唯一原则\"></a>3、rowkey唯一原则</h2><p>必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。</p>\n<h2 id=\"什么是热点？\"><a href=\"#什么是热点？\" class=\"headerlink\" title=\"什么是热点？\"></a>什么是热点？</h2><p>HBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的行存取在临近位置，便于scan。然而糟糕的rowkey设计是热点的源头。 热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。大量访问会使热点region所在的单个机器超出自身承受能力，引起性能下降甚至region不可用，这也会影响同一个RegionServer上的其他region，由于主机无法服务其他region的请求。 设计良好的数据访问模式以使集群被充分，均衡的利用。<br>为了避免写热点，设计rowkey使得不同行在同一个region，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。</p>\n<p>下面是一些常见的避免热点的方法以及它们的优缺点：</p>\n<ul>\n<li>加盐<br>这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。</li>\n<li>哈希<br>哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据</li>\n<li>反转<br>第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。<br>反转rowkey的例子以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题<br>时间戳反转<br>一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用 Long.Max_Value - timestamp 追加到key的末尾，例如 [key][reverse_timestamp] , [key] 的最新值可以通过scan [key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。<br>比如需要保存一个用户的操作记录，按照操作时间倒序排序，在设计rowkey的时候，可以这样设计<br>[userId反转][Long.Max_Value - timestamp]，在查询用户的所有操作记录数据的时候，直接指定反转后的userId，startRow是[userId反转][000000000000],stopRow是[userId反转][Long.Max_Value - timestamp]<br>如果需要查询某段时间的操作记录，startRow是[user反转][Long.Max_Value - 起始时间]，stopRow是[userId反转][Long.Max_Value - 结束时间]</li>\n</ul>\n<h1 id=\"八、使用案例\"><a href=\"#八、使用案例\" class=\"headerlink\" title=\"八、使用案例\"></a>八、使用案例</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">示例：</span><br><span class=\"line\">Row row =new Row();</span><br><span class=\"line\">List&lt;Column&gt; columns = new ArrayList&lt;&gt;();</span><br><span class=\"line\">columns.add(new Column(&quot;id&quot;,dto.getId().toString()));</span><br><span class=\"line\">columns.add(new Column(&quot;operation&quot;,dto.getOperation()));</span><br><span class=\"line\">columns.add(new Column(&quot;operationId&quot;,String.valueOf(dto.getOperationId())));</span><br><span class=\"line\">columns.add(new Column(&quot;recordId&quot;,dto.getRecordId().toString()));</span><br><span class=\"line\">columns.add(new Column(&quot;beforeData&quot;,dto.getBeforeData()));</span><br><span class=\"line\">columns.add(new Column(&quot;afterData&quot;,dto.getAfterData()));</span><br><span class=\"line\">row.setColumnList(columns);</span><br><span class=\"line\"></span><br><span class=\"line\">private String getRowKey(BusinessLogDto dto)&#123;</span><br><span class=\"line\">    if(dto.getRecordId()!=null&amp;&amp;dto.getModuleId()!=null&amp;&amp;dto.getId()!=null)&#123;</span><br><span class=\"line\">        StringBuilder stringBuilder = new StringBuilder(dto.getRecordId()+Constants.ROW_KEY_SEPARATION+dto.getModuleId());</span><br><span class=\"line\">        if(dto.getChildModuleId()!=null)&#123;</span><br><span class=\"line\">            stringBuilder.append(Constants.ROW_KEY_SEPARATION+dto.getChildModuleId());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        stringBuilder.append(Constants.ROW_KEY_SEPARATION+dto.getOperationId()+Constants.ROW_KEY_SEPARATION+dto.getId());</span><br><span class=\"line\">        String rowkey =stringBuilder.toString();</span><br><span class=\"line\">        log.info(&quot;upload create rowkey:&quot;+rowkey);</span><br><span class=\"line\">        return  rowkey;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log.info(&quot;upload create rowkey is null&quot;);</span><br><span class=\"line\">    return null;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>将这些字段都放入到一个column family内。</p>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/%E6%95%B0%E6%8D%AE%E8%A1%A8%E6%A0%BC.png\" alt=\"hbase工作原理\"></p>\n<h2 id=\"8-1、row-key设计：\"><a href=\"#8-1、row-key设计：\" class=\"headerlink\" title=\"8.1、row key设计：\"></a>8.1、row key设计：</h2><p> 业务ID+<em>+系统ID(+</em>+子模块ID(如需要自行定义))+<em>+业务系统操作ID+</em>+生成的唯一ID(时间毫秒数+4位计数（0000-9999）)</p>\n<ul>\n<li>1、热点考虑：业务ID本身是唯一的，这样可以保证不产生热点问题，又能保证系统的业务ID可以进入相同的region内。</li>\n<li>2、长度考虑：long + long + long + long +long (8byte*5=40byte)，emmmm，这里有问题？长度不固定并且长度大于了16byte。</li>\n</ul>\n<p>实际实现：业务ID+系统ID+业务系统操作ID</p>\n<p><a href=\"https://www.cnblogs.com/yangjiming/p/9429169.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/yangjiming/p/9429169.html</a><br><a href=\"http://c.biancheng.net/view/6528.html\" target=\"_blank\" rel=\"noopener\">http://c.biancheng.net/view/6528.html</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、什么是HBASE\"><a href=\"#一、什么是HBASE\" class=\"headerlink\" title=\"一、什么是HBASE\"></a>一、什么是HBASE</h1><p>1、面向列存储的分布式存储系统。<br>2、概念有row key和cloumn family。<br>3、仅能通过行键(row key)和行键序列来检索数据，仅支持单行事务。  </p>","more":"<blockquote>\n<p>下图为hbase的整体架构图：</p>\n</blockquote>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/HBASE%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png\" alt=\"hbase工作原理\">  </p>\n<p>Zookeepr负责维护集群的memberlist, 哪台服务器在线,哪台服务器宕机都由zookeeper探测和管理. Region server, 主备Master节点主动连接Zookeeper, 维护一个Session连接,</p>\n<p>从图可以看出，HBase中的存储包括HMaster、HRegionServer、HRegion、Store、MemStore、StoreFile、HFile、HLog等</p>\n<ol>\n<li>HMaster：协调HRegionServer的负载均衡，</li>\n<li>HRegionServer：管理region，处理对region的IO请求。</li>\n<li>HRegion：存储数据，按行进行分割，每个region最大256M，超过将分割成两个region。</li>\n<li>Store：为每一个columnFamily创建一个store</li>\n<li>MEMStore</li>\n<li>StoreFile：HFile的轻量封装。</li>\n<li>HFile：KeyValue的存储格式，是Hadoop的二进制存储文件。</li>\n<li>Hlog：一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况</li>\n</ol>\n<h1 id=\"二、基本类型\"><a href=\"#二、基本类型\" class=\"headerlink\" title=\"二、基本类型\"></a>二、基本类型</h1><p>HBASE中每一个表叫做BigTable，bigtable会存储一系列的行数据，行的三个基本类型的定义：<br>1.逻辑存储：</p>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/%E9%80%BB%E8%BE%91%E5%AD%98%E5%82%A8.png\" alt=\"hbase工作原理\"></p>\n<p>2.三个类型定义：<br>1.RowKey<br>是行在BigTable中的唯一标识。<br>2.TimeStamp：<br>是每一次数据操作对应关联的时间戳，可以看作SVN的版本。<br>3.Column：<br>定义为:，通过这两部分可以指定唯一的数据的存储列，family的定义和修改需要对HBase进行类似于DB的DDL操作，<br>而label，不需要定义直接可以使用，这也为动态定制列提供了一种手段。family另一个作用体现在物理存储优化读写操作上，同family<br>的数据物理上保存的会比较接近，因此在业务设计的过程中可以利用这个特性。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">示例：</span><br><span class=\"line\">Row row =new Row();</span><br><span class=\"line\">List&lt;Column&gt; columns = new ArrayList&lt;&gt;();</span><br><span class=\"line\">columns.add(new Column(&quot;id&quot;,dto.getId().toString()));</span><br><span class=\"line\">columns.add(new Column(&quot;operation&quot;,dto.getOperation()));</span><br><span class=\"line\">columns.add(new Column(&quot;operationId&quot;,String.valueOf(dto.getOperationId())));</span><br><span class=\"line\">columns.add(new Column(&quot;recordId&quot;,dto.getRecordId().toString()));</span><br><span class=\"line\">columns.add(new Column(&quot;beforeData&quot;,dto.getBeforeData()));</span><br><span class=\"line\">columns.add(new Column(&quot;afterData&quot;,dto.getAfterData()));</span><br><span class=\"line\">row.setColumnList(columns);</span><br></pre></td></tr></table></figure>\n\n<p>将这些字段都放入到一个column family内。<br><img src=\"/2019/07/07/2019-07-07-hbase梳理/%E6%95%B0%E6%8D%AE%E8%A1%A8%E6%A0%BC.png\" alt=\"hbase工作原理\"></p>\n<h1 id=\"三、各个模块的结构\"><a href=\"#三、各个模块的结构\" class=\"headerlink\" title=\"三、各个模块的结构\"></a>三、各个模块的结构</h1><p>1、HMaster</p>\n<blockquote>\n<p>1、协调各个regsion server的负载均衡。<br>2、负责给region分配region server。<br>3、通过zk可以实现master的集群部署，但是同时只有一个master提供服务。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">**************************</span><br><span class=\"line\">**** HBase Meta Table ****</span><br><span class=\"line\">**************************</span><br><span class=\"line\">Meta table存储所有region的列表</span><br><span class=\"line\">Meta table的结构如下:</span><br><span class=\"line\">- Key: region的开始row key, region id</span><br><span class=\"line\">- Values: Region server</span><br></pre></td></tr></table></figure>\n\n<p>2、Region Server<br>结构及流程图：</p>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/%E9%80%BB%E8%BE%91%E5%AD%98%E5%82%A8.png\" alt=\"hbase工作原理\"></p>\n<p>2.1、Region<br>1、根据Row Key的区域分成多个Region（按照rowkey分成region，若一个region存储不下则开辟新的region）<br>2、每个HRegion对应Table中一个Region，HRegion由多个HStore组成；<br>3、每个HStore对应Table中一个Column Family的存储；<br>4、flush的最小单位是region。<br>5、每个region最大1GB(默认)。</p>\n<p>案例：<br>假设一个region只能存储一条数据，那么现在两条数据，则会生成两个region。</p>\n<p>一条数据怎么存储呢？通过store存储。<br>现在一行数据有两个column family：info和area。<br>每个column family都使用store存储，那么现在会有两个store。<br>那一个store怎么存储呢？<br>通过keyvalue的方式存储，key=name,value=age<br>那怎么对应到物理文件中呢？<br>使用HFile进行存储，将keyvalue封装成Data block。Data block是HBASE IO的最基本单元。</p>\n<p>2.2、MemStore<br>1、每一个cloumn family对应一个memstore，<br>2、采用LSM数据结构存储，并在内存中排序，提高写入速度。<br>3、若rowkey的cf过多，则会导致memstore过多，导致region的flush。</p>\n<p>2.3、Store File<br>HFile的轻量封装。</p>\n<p>2.4、HFile<br>1、HFile中存储有序的Key-Value对. 当Memstore满了之后, Memstore中的所有数据写入HDFS中,形成一个新的HFile<br>2、HFile文件主要分为4个部分：Scanned block部分、Non-scanned block部分、Load-on-open部分和Trailer。</p>\n<blockquote>\n<p>HFile结构：</p>\n</blockquote>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/hfile%E7%BB%93%E6%9E%84.png\" alt=\"hbase工作原理\"></p>\n<p>首先HFile文件是不定长的，长度固定的只有其中的两块：Trailer和FileInfo。Trailer中又指针指向其他数据块的起始点，FileInfo记录了文件的一些meta信息。<br>HFile由一个一个Data block组成，Data block中存储一个一个的key value。</p>\n<blockquote>\n<p>keyvalue结构：</p>\n</blockquote>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/keyvalue%E7%BB%93%E6%9E%84.png\" alt=\"hbase工作原理\"></p>\n<p>2.5、HLog<br>一旦HRegionServer意外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况。<br>每个region server都有一个HLog。</p>\n<h1 id=\"四、数据读取过程\"><a href=\"#四、数据读取过程\" class=\"headerlink\" title=\"四、数据读取过程\"></a>四、数据读取过程</h1><p>Client 请求读取数据时，先转发到 ZK 集群，在 ZK 集群中寻找到相对应的 Region Server，再找到对应的 Region，先是查 MemStore，如果在 MemStore 中获取到数据，那么就会直接返回，否则就是再由 Region 找到对应的 Store File，从而查到具体的数据。<br>在整个架构中，HMaster 和 HRegion Server 可以是同一个节点上，可以有多个 HMaster 存在，但是只有一个 HMaster 在活跃。<br>在 Client 端会进行 rowkey-&gt; HRegion 映射关系的缓存，降低下次寻址的压力。</p>\n<p>client -&gt; zk -&gt; hmaster -&gt; hregionServer -&gt; hRegion -&gt; MemStore -&gt; HFile -&gt; HDFS -&gt; NameNode -&gt; DataNode</p>\n<p>Zookeepr负责维护集群的memberlist, 哪台服务器在线,哪台服务器宕机都由zookeeper探测和管理. Region server, 主备Master节点主动连接Zookeeper, 维护一个Session连接,<br>HBase的第一次读写流程</p>\n<p>HBase把各个region的位置信息存储在一个特殊的表中, 这个表叫做Meta table.<br>Zookeeper里面存储了这个Meta table的位置信息.</p>\n<p>HBase的访问流程:</p>\n<ol>\n<li>客户端访问Zookeep, 得到了具体Meta table的位置</li>\n<li>客户端再访问真正的Meta table, 从Meta table里面得到row key所在的region server</li>\n<li>访问rowkey所在的region server, 得到需要的真正数据.</li>\n</ol>\n<h1 id=\"五、数据写入过程\"><a href=\"#五、数据写入过程\" class=\"headerlink\" title=\"五、数据写入过程\"></a>五、数据写入过程</h1><p>先是 Client 进行发起数据的插入请求，如果 Client 本身存储了关于 Rowkey 和 Region 的映射关系的话，那么就会先查找到具体的对应关系，如果没有的话，就会在ZK中进行查找到对应 Region server，然后再转发到具体的 Region 上。所有的数据在写入的时候先是记录在 WAL 中，同时检查关于 MemStore 是否满了，如果是满了，那么就会进行刷盘，输出到一个 Hfile 中，如果没有满的话，那么就是先写进 Memstore 中，然后再刷到 WAL 中。</p>\n<p><a href=\"https://www.infoq.cn/article/iehfj_irzkiuepm6udza\" target=\"_blank\" rel=\"noopener\">https://www.infoq.cn/article/iehfj_irzkiuepm6udza</a></p>\n<p>HBase Meta Table<br>Meta table存储所有region的列表<br>Meta table用类似于Btree的方式存储<br>Meta table的结构如下:</p>\n<ul>\n<li>Key: region的开始row key, region id</li>\n<li>Values: Region server</li>\n</ul>\n<h1 id=\"六、region分区及定位\"><a href=\"#六、region分区及定位\" class=\"headerlink\" title=\"六、region分区及定位?\"></a>六、region分区及定位?</h1><p>每张表一开始只有一个 Region，但是随着数据的插入，HBase 会根据一定的规则将表进行水平拆分，形成两个 Region。当表中的行越来越多时，就会产生越来越多的 Region，而这些 Region 无法存储到一台机器上时，则可将其分布存储到多台机器上。<br>表的所有行都是按照 RowKey 的字典序排列的，表在行的方向上分割为多个分区（Region），如下图所示。</p>\n<p>6.1、region分区<br>region两个重要属性：startKey与endKey，代表该region维护的rowkey范围。<br>如果一开始，一张表只有一个region，当数据put超过region的存储容量，则会发生分区，找到一个midkey，将region一分为二。<br>问题：</p>\n<ul>\n<li>如果rowkey是递增的，那么数据会一直往大的分区写，则分割的另外一半没有满。<br>散列+预分区，二者结合是比较好的方式。预分区一开始就预建好了一部分region,这些region都维护着自已的start-end keys，再配合上随机散列，写数据能均等地命中这些预建的region，就能解决上面的那些缺点，大大地提高了性能</li>\n</ul>\n<p>6.2、理解rowkey的字典序：<br>HBase是三维有序存储的，是指rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度是依照ASCII码表排序的。（比如A排在a前面）</p>\n<ul>\n<li>先rowkey升序排序，</li>\n<li>rowkey相同则column key升序排序</li>\n<li>rowkey、column key相同则timestamp降序排序<br>如下： 假设存在table：test，family：info<br>scan表得到结果如下：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//列族默认VERSIONS值为1，可以通过命令：alter &apos;tableName&apos;,&apos;familyName&apos;,VERSINOS =&gt;5来设置</span><br><span class=\"line\">//不同version保存不同时间戳的数据，默认是只显示最新version数据。要想显示所有，scan时应该加上&#123;VERSIONS =&gt;5&#125;</span><br><span class=\"line\">hbase(main):009:0&gt; scan &apos;test&apos;, &#123;VERSIONS =&gt;5&#125;</span><br><span class=\"line\">ROW                                                    COLUMN+CELL                                                                                                                                                   </span><br><span class=\"line\"> 12Aabb                                                column=info:name,timestamp=1519957330893,value=123                                                                                                      </span><br><span class=\"line\"> 3aabb                                                 column=info:name,timestamp=1519963129863,value=3234                                                                                                         </span><br><span class=\"line\"> 3aabb                                                 column=info:name,timestamp=1519962895984,value=234                                                                                                          </span><br><span class=\"line\"> 3aabb                                                 column=info:name,timestamp=1519962889791,value=234                                                                                                          </span><br><span class=\"line\"> 3aabb                                                 column=info:name,timestamp=1519960252203,value=999                                                                                                          </span><br><span class=\"line\"> Aabb                                                  column=info:address,timestamp=1519969857611,value=cccc                                                                                                      </span><br><span class=\"line\"> Aabb                                                  column=info:friend,timestamp=1519969916299,value=jack                                                                                                       </span><br><span class=\"line\"> Aabb                                                  column=info:name,timestamp=1519957330890,value=123                                                                                                         </span><br><span class=\"line\"> aabb                                                  column=info:name,timestamp=1519957330859,value=123                                                                                                          </span><br><span class=\"line\">4 row(s) in 0.0530 seconds</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h1 id=\"七、Rowkey的设计原则\"><a href=\"#七、Rowkey的设计原则\" class=\"headerlink\" title=\"七、Rowkey的设计原则\"></a>七、Rowkey的设计原则</h1><h2 id=\"1、rowkey长度原则\"><a href=\"#1、rowkey长度原则\" class=\"headerlink\" title=\"1、rowkey长度原则\"></a>1、rowkey长度原则</h2><p>rowkey是一个二进制码流，可以是任意字符串，最大长度64kb，实际应用中一般为10-100bytes，以byte[]形式保存，一般设计成定长。<br>建议越短越好，不要超过16个字节，原因如下：</p>\n<p>数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w=10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；<br>MemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。<br>目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。</p>\n<h2 id=\"2、rowkey散列原则\"><a href=\"#2、rowkey散列原则\" class=\"headerlink\" title=\"2、rowkey散列原则\"></a>2、rowkey散列原则</h2><p>如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样将提高数据均衡分布在每个RegionServer，以实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。</p>\n<h2 id=\"3、rowkey唯一原则\"><a href=\"#3、rowkey唯一原则\" class=\"headerlink\" title=\"3、rowkey唯一原则\"></a>3、rowkey唯一原则</h2><p>必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。</p>\n<h2 id=\"什么是热点？\"><a href=\"#什么是热点？\" class=\"headerlink\" title=\"什么是热点？\"></a>什么是热点？</h2><p>HBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的行存取在临近位置，便于scan。然而糟糕的rowkey设计是热点的源头。 热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。大量访问会使热点region所在的单个机器超出自身承受能力，引起性能下降甚至region不可用，这也会影响同一个RegionServer上的其他region，由于主机无法服务其他region的请求。 设计良好的数据访问模式以使集群被充分，均衡的利用。<br>为了避免写热点，设计rowkey使得不同行在同一个region，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。</p>\n<p>下面是一些常见的避免热点的方法以及它们的优缺点：</p>\n<ul>\n<li>加盐<br>这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。</li>\n<li>哈希<br>哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据</li>\n<li>反转<br>第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。<br>反转rowkey的例子以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题<br>时间戳反转<br>一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用 Long.Max_Value - timestamp 追加到key的末尾，例如 [key][reverse_timestamp] , [key] 的最新值可以通过scan [key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。<br>比如需要保存一个用户的操作记录，按照操作时间倒序排序，在设计rowkey的时候，可以这样设计<br>[userId反转][Long.Max_Value - timestamp]，在查询用户的所有操作记录数据的时候，直接指定反转后的userId，startRow是[userId反转][000000000000],stopRow是[userId反转][Long.Max_Value - timestamp]<br>如果需要查询某段时间的操作记录，startRow是[user反转][Long.Max_Value - 起始时间]，stopRow是[userId反转][Long.Max_Value - 结束时间]</li>\n</ul>\n<h1 id=\"八、使用案例\"><a href=\"#八、使用案例\" class=\"headerlink\" title=\"八、使用案例\"></a>八、使用案例</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">示例：</span><br><span class=\"line\">Row row =new Row();</span><br><span class=\"line\">List&lt;Column&gt; columns = new ArrayList&lt;&gt;();</span><br><span class=\"line\">columns.add(new Column(&quot;id&quot;,dto.getId().toString()));</span><br><span class=\"line\">columns.add(new Column(&quot;operation&quot;,dto.getOperation()));</span><br><span class=\"line\">columns.add(new Column(&quot;operationId&quot;,String.valueOf(dto.getOperationId())));</span><br><span class=\"line\">columns.add(new Column(&quot;recordId&quot;,dto.getRecordId().toString()));</span><br><span class=\"line\">columns.add(new Column(&quot;beforeData&quot;,dto.getBeforeData()));</span><br><span class=\"line\">columns.add(new Column(&quot;afterData&quot;,dto.getAfterData()));</span><br><span class=\"line\">row.setColumnList(columns);</span><br><span class=\"line\"></span><br><span class=\"line\">private String getRowKey(BusinessLogDto dto)&#123;</span><br><span class=\"line\">    if(dto.getRecordId()!=null&amp;&amp;dto.getModuleId()!=null&amp;&amp;dto.getId()!=null)&#123;</span><br><span class=\"line\">        StringBuilder stringBuilder = new StringBuilder(dto.getRecordId()+Constants.ROW_KEY_SEPARATION+dto.getModuleId());</span><br><span class=\"line\">        if(dto.getChildModuleId()!=null)&#123;</span><br><span class=\"line\">            stringBuilder.append(Constants.ROW_KEY_SEPARATION+dto.getChildModuleId());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        stringBuilder.append(Constants.ROW_KEY_SEPARATION+dto.getOperationId()+Constants.ROW_KEY_SEPARATION+dto.getId());</span><br><span class=\"line\">        String rowkey =stringBuilder.toString();</span><br><span class=\"line\">        log.info(&quot;upload create rowkey:&quot;+rowkey);</span><br><span class=\"line\">        return  rowkey;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log.info(&quot;upload create rowkey is null&quot;);</span><br><span class=\"line\">    return null;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>将这些字段都放入到一个column family内。</p>\n<p><img src=\"/2019/07/07/2019-07-07-hbase梳理/%E6%95%B0%E6%8D%AE%E8%A1%A8%E6%A0%BC.png\" alt=\"hbase工作原理\"></p>\n<h2 id=\"8-1、row-key设计：\"><a href=\"#8-1、row-key设计：\" class=\"headerlink\" title=\"8.1、row key设计：\"></a>8.1、row key设计：</h2><p> 业务ID+<em>+系统ID(+</em>+子模块ID(如需要自行定义))+<em>+业务系统操作ID+</em>+生成的唯一ID(时间毫秒数+4位计数（0000-9999）)</p>\n<ul>\n<li>1、热点考虑：业务ID本身是唯一的，这样可以保证不产生热点问题，又能保证系统的业务ID可以进入相同的region内。</li>\n<li>2、长度考虑：long + long + long + long +long (8byte*5=40byte)，emmmm，这里有问题？长度不固定并且长度大于了16byte。</li>\n</ul>\n<p>实际实现：业务ID+系统ID+业务系统操作ID</p>\n<p><a href=\"https://www.cnblogs.com/yangjiming/p/9429169.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/yangjiming/p/9429169.html</a><br><a href=\"http://c.biancheng.net/view/6528.html\" target=\"_blank\" rel=\"noopener\">http://c.biancheng.net/view/6528.html</a></p>"},{"title":"tomcat-webxml解析","date":"2019-12-22T10:08:35.000Z","_content":"# 一、解析顺序\n先解析server.xml，再解析web.xml\n\n\n# 二、server.xml解析，在加载阶段\n\nCatalina的load方法，此时会去解析server.xml文件\n\n<!--more-->\n```\npublic void load() {\n    // Create and execute our Digester\n    Digester digester = createStartDigester();\n    file = configFile();\n    inputStream = new FileInputStream(file);\n    inputSource = new InputSource(file.toURI().toURL().toString());\n    inputSource.setByteStream(inputStream);\n    digester.push(this);\n    digester.parse(inputSource);//解析流，进行类\n}    \n\nprotected Digester createStartDigester() {\n    long t1=System.currentTimeMillis();\n    // Initialize the digester\n    Digester digester = new Digester();\n    digester.setValidating(false);\n    digester.setRulesValidation(true);\n    Map<Class<?>, List<String>> fakeAttributes = new HashMap<>();\n    List<String> objectAttrs = new ArrayList<>();\n    objectAttrs.add(\"className\");\n    fakeAttributes.put(Object.class, objectAttrs);\n    // Ignore attribute added by Eclipse for its internal tracking\n    List<String> contextAttrs = new ArrayList<>();\n    contextAttrs.add(\"source\");\n    fakeAttributes.put(StandardContext.class, contextAttrs);\n    digester.setFakeAttributes(fakeAttributes);\n    digester.setUseContextClassLoader(true);\n\n    //创建StandardServer对象，设置其对象的属性，调用父节点Catalina的setServer方法将Server添加到Catalina中。\n    digester.addObjectCreate(\"Server\",\n                             \"org.apache.catalina.core.StandardServer\",\n                             \"className\");\n    digester.addSetProperties(\"Server\");\n    digester.addSetNext(\"Server\",\n                        \"setServer\",\n                        \"org.apache.catalina.Server\");\n\n    digester.addObjectCreate(\"Server/GlobalNamingResources\",\n                             \"org.apache.catalina.deploy.NamingResourcesImpl\");\n    digester.addSetProperties(\"Server/GlobalNamingResources\");\n    digester.addSetNext(\"Server/GlobalNamingResources\",\n                        \"setGlobalNamingResources\",\n                        \"org.apache.catalina.deploy.NamingResourcesImpl\");\n\n    digester.addObjectCreate(\"Server/Listener\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(\"Server/Listener\");\n    digester.addSetNext(\"Server/Listener\",\n                        \"addLifecycleListener\",\n                        \"org.apache.catalina.LifecycleListener\");\n\n    digester.addObjectCreate(\"Server/Service\",\n                             \"org.apache.catalina.core.StandardService\",\n                             \"className\");\n    digester.addSetProperties(\"Server/Service\");\n    digester.addSetNext(\"Server/Service\",\n                        \"addService\",\n                        \"org.apache.catalina.Service\");\n\n    digester.addObjectCreate(\"Server/Service/Listener\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(\"Server/Service/Listener\");\n    digester.addSetNext(\"Server/Service/Listener\",\n                        \"addLifecycleListener\",\n                        \"org.apache.catalina.LifecycleListener\");\n\n    //Executor\n    digester.addObjectCreate(\"Server/Service/Executor\",\n                     \"org.apache.catalina.core.StandardThreadExecutor\",\n                     \"className\");\n    digester.addSetProperties(\"Server/Service/Executor\");\n\n    digester.addSetNext(\"Server/Service/Executor\",\n                        \"addExecutor\",\n                        \"org.apache.catalina.Executor\");\n\n\n    digester.addRule(\"Server/Service/Connector\",\n                     new ConnectorCreateRule());\n    digester.addRule(\"Server/Service/Connector\",\n                     new SetAllPropertiesRule(new String[]{\"executor\", \"sslImplementationName\"}));\n    digester.addSetNext(\"Server/Service/Connector\",\n                        \"addConnector\",\n                        \"org.apache.catalina.connector.Connector\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/SSLHostConfig\",\n                             \"org.apache.tomcat.util.net.SSLHostConfig\");\n    digester.addSetProperties(\"Server/Service/Connector/SSLHostConfig\");\n    digester.addSetNext(\"Server/Service/Connector/SSLHostConfig\",\n            \"addSslHostConfig\",\n            \"org.apache.tomcat.util.net.SSLHostConfig\");\n\n    digester.addRule(\"Server/Service/Connector/SSLHostConfig/Certificate\",\n                     new CertificateCreateRule());\n    digester.addRule(\"Server/Service/Connector/SSLHostConfig/Certificate\",\n                     new SetAllPropertiesRule(new String[]{\"type\"}));\n    digester.addSetNext(\"Server/Service/Connector/SSLHostConfig/Certificate\",\n                        \"addCertificate\",\n                        \"org.apache.tomcat.util.net.SSLHostConfigCertificate\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf\",\n                             \"org.apache.tomcat.util.net.openssl.OpenSSLConf\");\n    digester.addSetProperties(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf\");\n    digester.addSetNext(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf\",\n                        \"setOpenSslConf\",\n                        \"org.apache.tomcat.util.net.openssl.OpenSSLConf\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd\",\n                             \"org.apache.tomcat.util.net.openssl.OpenSSLConfCmd\");\n    digester.addSetProperties(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd\");\n    digester.addSetNext(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd\",\n                        \"addCmd\",\n                        \"org.apache.tomcat.util.net.openssl.OpenSSLConfCmd\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/Listener\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(\"Server/Service/Connector/Listener\");\n    digester.addSetNext(\"Server/Service/Connector/Listener\",\n                        \"addLifecycleListener\",\n                        \"org.apache.catalina.LifecycleListener\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/UpgradeProtocol\",\n                              null, // MUST be specified in the element\n                              \"className\");\n    digester.addSetProperties(\"Server/Service/Connector/UpgradeProtocol\");\n    digester.addSetNext(\"Server/Service/Connector/UpgradeProtocol\",\n                        \"addUpgradeProtocol\",\n                        \"org.apache.coyote.UpgradeProtocol\");\n\n    // Add RuleSets for nested elements\n    digester.addRuleSet(new NamingRuleSet(\"Server/GlobalNamingResources/\"));\n    //EngineRuleSet中，将实例化StandardEngine\n    digester.addRuleSet(new EngineRuleSet(\"Server/Service/\"));\n    //HostRuleSet中，将实例化StandardHost\n    digester.addRuleSet(new HostRuleSet(\"Server/Service/Engine/\"))\n    //ContextRuleSet中，将实例化StandardContext\n    digester.addRuleSet(new ContextRuleSet(\"Server/Service/Engine/Host/\"));\n    addClusterRuleSet(digester, \"Server/Service/Engine/Host/Cluster/\");\n    digester.addRuleSet(new NamingRuleSet(\"Server/Service/Engine/Host/Context/\"));\n\n    // When the 'engine' is found, set the parentClassLoader.\n    digester.addRule(\"Server/Service/Engine\",\n                     new SetParentClassLoaderRule(parentClassLoader));\n    addClusterRuleSet(digester, \"Server/Service/Engine/Cluster/\");\n\n    long t2=System.currentTimeMillis();\n    if (log.isDebugEnabled()) {\n        log.debug(\"Digester for server.xml created \" + ( t2-t1 ));\n    }\n    return digester;\n}\n```\nserver.xml的解析，主要是去创建相应的实例对象，并设置层级关系。\n\n \n## 2.1、StandardContext的创建时机\n\n```\nContextRuleSet\n/**\n * <p>Add the set of Rule instances defined in this RuleSet to the\n * specified <code>Digester</code> instance, associating them with\n * our namespace URI (if any).  This method should only be called\n * by a Digester instance.</p>\n *\n * @param digester Digester instance to which the new Rule instances\n *  should be added.\n */\n //只能被Digester\npublic void addRuleInstances(Digester digester) {\n \n    // 1. 创建Context实例，通过server.xml配置Context时，create是true，需要创建Context实例；通过HostConfig创建Context时，create为false，此时仅需要解析节点即可\n    if (create) {\n        digester.addObjectCreate(prefix + \"Context\",\n                \"org.apache.catalina.core.StandardContext\", \"className\");\n        digester.addSetProperties(prefix + \"Context\");\n    } else {\n        digester.addSetProperties(prefix + \"Context\", new String[]{\"path\", \"docBase\"});\n    }\n \n    if (create) {\n        digester.addRule(prefix + \"Context\",\n                         new LifecycleListenerRule\n                             (\"org.apache.catalina.startup.ContextConfig\",\n                              \"configClass\"));\n        digester.addSetNext(prefix + \"Context\",\n                            \"addChild\",\n                            \"org.apache.catalina.Container\");\n    }\n \n    // 2. 为Context添加生命周期监听器\n    digester.addObjectCreate(prefix + \"Context/Listener\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Listener\");\n    digester.addSetNext(prefix + \"Context/Listener\",\n                        \"addLifecycleListener\",\n                        \"org.apache.catalina.LifecycleListener\");\n \n    // 3. 为Context指定类加载器，默认为org.apache.catalina.loader.WebappLoader\n    digester.addObjectCreate(prefix + \"Context/Loader\",\n                        \"org.apache.catalina.loader.WebappLoader\",\n                        \"className\");\n    digester.addSetProperties(prefix + \"Context/Loader\");\n    digester.addSetNext(prefix + \"Context/Loader\",\n                        \"setLoader\",\n                        \"org.apache.catalina.Loader\");\n \n    // 4. 为Context添加会话管理器，默认实现为StandardManager\n    digester.addObjectCreate(prefix + \"Context/Manager\",\n                             \"org.apache.catalina.session.StandardManager\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Manager\");\n    digester.addSetNext(prefix + \"Context/Manager\",\n                        \"setManager\",\n                        \"org.apache.catalina.Manager\");\n \n    digester.addObjectCreate(prefix + \"Context/Manager/Store\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Manager/Store\");\n    digester.addSetNext(prefix + \"Context/Manager/Store\",\n                        \"setStore\",\n                        \"org.apache.catalina.Store\");\n \n    digester.addObjectCreate(prefix + \"Context/Manager/SessionIdGenerator\",\n                             \"org.apache.catalina.util.StandardSessionIdGenerator\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Manager/SessionIdGenerator\");\n    digester.addSetNext(prefix + \"Context/Manager/SessionIdGenerator\",\n                        \"setSessionIdGenerator\",\n                        \"org.apache.catalina.SessionIdGenerator\");\n \n    //5. 为Context添加初始化参数，通过该配置，为Context添加初始化参数\n    digester.addObjectCreate(prefix + \"Context/Parameter\",\n                             \"org.apache.tomcat.util.descriptor.web.ApplicationParameter\");\n    digester.addSetProperties(prefix + \"Context/Parameter\");\n    digester.addSetNext(prefix + \"Context/Parameter\",\n                        \"addApplicationParameter\",\n                        \"org.apache.tomcat.util.descriptor.web.ApplicationParameter\");\n \n    // 6. 为Context添加安全配置以及web资源配置\n    digester.addRuleSet(new RealmRuleSet(prefix + \"Context/\"));\n \n    digester.addObjectCreate(prefix + \"Context/Resources\",\n                             \"org.apache.catalina.webresources.StandardRoot\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Resources\");\n    digester.addSetNext(prefix + \"Context/Resources\",\n                        \"setResources\",\n                        \"org.apache.catalina.WebResourceRoot\");\n \n    digester.addObjectCreate(prefix + \"Context/Resources/PreResources\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Resources/PreResources\");\n    digester.addSetNext(prefix + \"Context/Resources/PreResources\",\n                        \"addPreResources\",\n                        \"org.apache.catalina.WebResourceSet\");\n \n    digester.addObjectCreate(prefix + \"Context/Resources/JarResources\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Resources/JarResources\");\n    digester.addSetNext(prefix + \"Context/Resources/JarResources\",\n                        \"addJarResources\",\n                        \"org.apache.catalina.WebResourceSet\");\n \n    digester.addObjectCreate(prefix + \"Context/Resources/PostResources\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Resources/PostResources\");\n    digester.addSetNext(prefix + \"Context/Resources/PostResources\",\n                        \"addPostResources\",\n                        \"org.apache.catalina.WebResourceSet\");\n \n    // 7. 为Context添加资源连接，默认为ContextResourceLink，用于J2EE命名服务\n    digester.addObjectCreate(prefix + \"Context/ResourceLink\",\n            \"org.apache.tomcat.util.descriptor.web.ContextResourceLink\");\n    digester.addSetProperties(prefix + \"Context/ResourceLink\");\n    digester.addRule(prefix + \"Context/ResourceLink\",\n            new SetNextNamingRule(\"addResourceLink\",\n                    \"org.apache.tomcat.util.descriptor.web.ContextResourceLink\"));\n \n    // 8. 为Context添加Valve\n    digester.addObjectCreate(prefix + \"Context/Valve\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Valve\");\n    digester.addSetNext(prefix + \"Context/Valve\",\n                        \"addValve\",\n                        \"org.apache.catalina.Valve\");\n \n    // 9. 为Context添加守护资源配置\n    digester.addCallMethod(prefix + \"Context/WatchedResource\",\n                           \"addWatchedResource\", 0);\n \n    digester.addCallMethod(prefix + \"Context/WrapperLifecycle\",\n                           \"addWrapperLifecycle\", 0);\n \n    digester.addCallMethod(prefix + \"Context/WrapperListener\",\n                           \"addWrapperListener\", 0);\n \n    digester.addObjectCreate(prefix + \"Context/JarScanner\",\n                             \"org.apache.tomcat.util.scan.StandardJarScanner\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/JarScanner\");\n    digester.addSetNext(prefix + \"Context/JarScanner\",\n                        \"setJarScanner\",\n                        \"org.apache.tomcat.JarScanner\");\n \n    digester.addObjectCreate(prefix + \"Context/JarScanner/JarScanFilter\",\n                             \"org.apache.tomcat.util.scan.StandardJarScanFilter\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/JarScanner/JarScanFilter\");\n    digester.addSetNext(prefix + \"Context/JarScanner/JarScanFilter\",\n                        \"setJarScanFilter\",\n                        \"org.apache.tomcat.JarScanFilter\");\n \n    // 10. 为Context添加Cookie处理器\n    digester.addObjectCreate(prefix + \"Context/CookieProcessor\",\n                             \"org.apache.tomcat.util.http.Rfc6265CookieProcessor\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/CookieProcessor\");\n    digester.addSetNext(prefix + \"Context/CookieProcessor\",\n                        \"setCookieProcessor\",\n                        \"org.apache.tomcat.util.http.CookieProcessor\");\n}\n```\nContextRuleSet定义了创建规则，digester会通过规则创建StandardContext对象\n\n\n# 三、web.xml的解析时机，在启动阶段\n## 1. StandardServer.startInternal()方法\n```\nprotected void startInternal() throws LifecycleException {\n    //通知容器启动事件\n    fireLifecycleEvent(CONFIGURE_START_EVENT, null);\n    setState(LifecycleState.STARTING);\n    globalNamingResources.start();\n    // Start our defined Services\n    synchronized (servicesLock) {\n        for (int i = 0; i < services.length; i++) {\n            services[i].start();\n        }\n    }\n}\n```\n## 2. StandardContext.startInternal()方法\n```\nprotected synchronized void startInternal() throws LifecycleException {\n    // Notify our interested LifecycleListeners\n    //1、通知容器启动事件，去解析web.xml\n    fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null);\n    //2、进行listener的创建和启动\n    if (ok) {\n        if (!listenerStart()) {\n            log.error(sm.getString(\"standardContext.listenerFail\"));\n            ok = false;\n        }\n    }\n    // 3、filter的创建和启动\n    if (ok) {\n        if (!filterStart()) {\n            log.error(sm.getString(\"standardContext.filterFail\"));\n            ok = false;\n        }\n    }\n    //加载和实例化servlet\n    // Load and initialize all \"load on startup\" servlets\n    if (ok) {\n        if (!loadOnStartup(findChildren())){\n            log.error(sm.getString(\"standardContext.servletFail\"));\n            ok = false;\n        }\n    }\n}\n\n```\n## 3、ContextConfig.lifecycleEvent()方法\n触发事件，进行文件的解析\n```\npublic void lifecycleEvent(LifecycleEvent event) {\n    // Process the event that has occurred\n    if (event.getType().equals(Lifecycle.CONFIGURE_START_EVENT)) {\n        //进行配置文件的解析，ContextConfig事件\n        configureStart();\n    } else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) {\n     \n\n}\n```\n\n\n### 3.1、ContextConfig事件\n```\n/**\n * Process a \"contextConfig\" event for this Context.\n */\nprotected synchronized void configureStart() {\n    // Called from StandardContext.start()\n\n    if (log.isDebugEnabled()) {\n        log.debug(sm.getString(\"contextConfig.start\"));\n    }\n\n    if (log.isDebugEnabled()) {\n        log.debug(sm.getString(\"contextConfig.xmlSettings\",\n                context.getName(),\n                Boolean.valueOf(context.getXmlValidation()),\n                Boolean.valueOf(context.getXmlNamespaceAware())));\n    }\n    //进行web.xml的具体解析工作\n    webConfig();\n\n    if (!context.getIgnoreAnnotations()) {\n        applicationAnnotationsConfig();\n    }\n    if (ok) {\n        validateSecurityRoles();\n    }\n\n    // Configure an authenticator if we need one\n    if (ok) {\n        authenticatorConfig();\n    }\n\n    // Dump the contents of this pipeline if requested\n    if (log.isDebugEnabled()) {\n        log.debug(\"Pipeline Configuration:\");\n        Pipeline pipeline = context.getPipeline();\n        Valve valves[] = null;\n        if (pipeline != null) {\n            valves = pipeline.getValves();\n        }\n        if (valves != null) {\n            for (int i = 0; i < valves.length; i++) {\n                log.debug(\"  \" + valves[i].getClass().getName());\n            }\n        }\n        log.debug(\"======================\");\n    }\n\n    // Make our application available if no problems were encountered\n    if (ok) {\n        context.setConfigured(true);\n    } else {\n        log.error(sm.getString(\"contextConfig.unavailable\"));\n        context.setConfigured(false);\n    }\n}\n```\n\n\n### 3.2、webConfig()方法，会根据web.xml中的配置进行listen，filter，servlet的信息设置\n```\nprivate void configureContext(WebXml webxml) {\n    \n    //filter的解析，此处未进行创建\n    for (FilterDef filter : webxml.getFilters().values()) {\n        if (filter.getAsyncSupported() == null) {\n            filter.setAsyncSupported(\"false\");\n        }\n        context.addFilterDef(filter);\n    }\n    //listen解析，此处未进行创建\n    for (String listener : webxml.getListeners()) {\n        context.addApplicationListener(listener);\n    }\n    \n    //创建wraper，servlet并未创建\n    for (ServletDef servlet : webxml.getServlets().values()) {\n        Wrapper wrapper = context.createWrapper();\n        if (servlet.getLoadOnStartup() != null) {\n            wrapper.setLoadOnStartup(servlet.getLoadOnStartup().intValue());\n        }\n        if (servlet.getEnabled() != null) {\n            wrapper.setEnabled(servlet.getEnabled().booleanValue());\n        }\n        wrapper.setName(servlet.getServletName());\n        Map<String,String> params = servlet.getParameterMap();\n        for (Entry<String, String> entry : params.entrySet()) {\n            wrapper.addInitParameter(entry.getKey(), entry.getValue());\n        }\n        wrapper.setRunAs(servlet.getRunAs());\n        Set<SecurityRoleRef> roleRefs = servlet.getSecurityRoleRefs();\n        for (SecurityRoleRef roleRef : roleRefs) {\n            wrapper.addSecurityReference(\n                    roleRef.getName(), roleRef.getLink());\n        }\n        wrapper.setServletClass(servlet.getServletClass());\n        MultipartDef multipartdef = servlet.getMultipartDef();\n        if (multipartdef != null) {\n            if (multipartdef.getMaxFileSize() != null &&\n                    multipartdef.getMaxRequestSize()!= null &&\n                    multipartdef.getFileSizeThreshold() != null) {\n                wrapper.setMultipartConfigElement(new MultipartConfigElement(\n                        multipartdef.getLocation(),\n                        Long.parseLong(multipartdef.getMaxFileSize()),\n                        Long.parseLong(multipartdef.getMaxRequestSize()),\n                        Integer.parseInt(\n                                multipartdef.getFileSizeThreshold())));\n            } else {\n                wrapper.setMultipartConfigElement(new MultipartConfigElement(\n                        multipartdef.getLocation()));\n            }\n        }\n        if (servlet.getAsyncSupported() != null) {\n            wrapper.setAsyncSupported(\n                    servlet.getAsyncSupported().booleanValue());\n        }\n        wrapper.setOverridable(servlet.isOverridable());\n        context.addChild(wrapper);\n    }\n}\n```\n\n### 3.3、listen filter servlet的创建\nStandardContext.startInternal()方法进行web.xml解析后，就会进行listen和filter和servlet的创建\n```\npublic boolean listenerStart() {\n     // Instantiate the required listeners\n    String listeners[] = findApplicationListeners();\n    Object results[] = new Object[listeners.length];\n    boolean ok = true;\n    for (int i = 0; i < results.length; i++) {\n        if (getLogger().isDebugEnabled())\n            getLogger().debug(\" Configuring event listener class '\" +\n                listeners[i] + \"'\");\n        try {\n            String listener = listeners[i];\n            results[i] = getInstanceManager().newInstance(listener);\n        } catch (Throwable t) {\n            t = ExceptionUtils.unwrapInvocationTargetException(t);\n            ExceptionUtils.handleThrowable(t);\n            getLogger().error(sm.getString(\"standardContext.applicationListener\", listeners[i]), t);\n            ok = false;\n        }\n    }   \n}    \n\n\npublic boolean filterStart() {\n    if (getLogger().isDebugEnabled()) {\n        getLogger().debug(\"Starting filters\");\n    }\n    // Instantiate and record a FilterConfig for each defined filter\n    boolean ok = true;\n    synchronized (filterConfigs) {\n        filterConfigs.clear();\n        for (Entry<String,FilterDef> entry : filterDefs.entrySet()) {\n            String name = entry.getKey();\n            if (getLogger().isDebugEnabled()) {\n                getLogger().debug(\" Starting filter '\" + name + \"'\");\n            }\n            try {\n                ApplicationFilterConfig filterConfig = new ApplicationFilterConfig(this, entry.getValue());\n                filterConfigs.put(name, filterConfig);\n            } catch (Throwable t) {\n                t = ExceptionUtils.unwrapInvocationTargetException(t);\n                ExceptionUtils.handleThrowable(t);\n                getLogger().error(sm.getString(\n                        \"standardContext.filterStart\", name), t);\n                ok = false;\n            }\n        }\n    }\n    return ok;\n}\n```\n\n\n当然这种加载只是针对配置了 load-on-startup 属性的 Servlet 而言，\n其它一般 Servlet 的加载和初始化会推迟到真正请求访问 web 应用而第一次调用该 Servlet 时，\n下面会看到这种情况下代码分析。\n```\npublic boolean loadOnStartup(Container children[]) {\n\n    // Collect \"load on startup\" servlets that need to be initialized\n    TreeMap<Integer, ArrayList<Wrapper>> map = new TreeMap<>();\n    for (int i = 0; i < children.length; i++) {\n        Wrapper wrapper = (Wrapper) children[i];\n        int loadOnStartup = wrapper.getLoadOnStartup();\n        if (loadOnStartup < 0)\n            continue;\n        Integer key = Integer.valueOf(loadOnStartup);\n        ArrayList<Wrapper> list = map.get(key);\n        if (list == null) {\n            list = new ArrayList<>();\n            map.put(key, list);\n        }\n        list.add(wrapper);\n    }\n\n    // Load the collected \"load on startup\" servlets\n    for (ArrayList<Wrapper> list : map.values()) {\n        for (Wrapper wrapper : list) {\n            try {\n                wrapper.load();\n            } catch (ServletException e) {            }\n        }\n    }\n    return true;\n}\n//StandardWrapper\npublic synchronized void load() throws ServletException {\n    instance = loadServlet();\n    if (!instanceInitialized) {\n        //Servlet servlet = instanceManager.newInstance(servletClass);\n        initServlet(instance);\n    }\n}\n```\n\n> servlet执行时机\n1. servlet = wrapper.allocate(); 调用StandardWrapper#allocate()方法，获取到servlet实例\n2. ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);为当前请求创建一个过滤链，（非异步情况下）并调用filterChain.doFilter(request.getRequest(), response.getResponse());\n3. filter#doFilter()、servlet#service()的执行是在filterChain.doFilter(request.getRequest(), response.getResponse());代码内部执行的。\n\n> sevletRequestListener执行时机\n```\nStandardHostValve.invoke\n// context.fireRequestInitEvent，会去通知Listener\npublic final void invoke(Request request, Response response)\n    throws IOException, ServletException {\n    try {\n        context.bind(Globals.IS_SECURITY_ENABLED, MY_CLASSLOADER);\n        if (!asyncAtStart && !context.fireRequestInitEvent(request.getRequest())) {\n            return;\n        }\n}     \n```   \n\n//请求过来时，会去执行listener\n```\npublic boolean fireRequestInitEvent(ServletRequest request) {\n    Object instances[] = getApplicationEventListeners();\n    if ((instances != null) && (instances.length > 0)) {\n        ServletRequestEvent event = new ServletRequestEvent(getServletContext(), request);\n            try {\n                listener.requestInitialized(event);\n            } catch (Throwable t) {\n            }\n        }\n    }\n    return true;\n}\n```\n\n# 五、请求执行过程\nStandardContext.startInternal()方法进行web.xml解析后，就会进行listen和filter和servlet（ServletWarpper）的创建\n1. StandardHostValve.invoke，会调用StanardContext.fireRequestInitEvent\n2. StandardContext.fireRequestInitEvent的 **listener（servletListener）** 的requestInitialized方法\n3. 然后StandardContextValve.invoke，根据URL选择servlet\n4. 然后StandardWrapperValve.invoke\n    1. 会先判断servlet是否存在，不存在则创建。非load-on-startup类型的servlet会在第一次请求时创建。\n    2. 执行过滤链，当所有的过滤器执行完成后，最后一个过滤器会调用步骤3\n    3. 执行servlet.service方法\n\n\n> 多种listener\n1. ServletContextListener：监听ServletContext域对象的创建和销毁\n2. HttpSessionListener：接口用于监听HttpSession对象的创建和销毁\n3. ServletRequestListener：接口用于监听ServletRequest 对象的创建和销毁\n\n\nlistener -> filter -> servlet：执行顺序\n\n![启动过程](2019-12-22-tomcat-webxml解析/启动过程.png)\n\n\n\n\n","source":"_posts/2019-12-22-tomcat-webxml解析.md","raw":"---\ntitle: tomcat-webxml解析\ndate: 2019-12-22 18:08:35\ntags: Tomcat\n---\n# 一、解析顺序\n先解析server.xml，再解析web.xml\n\n\n# 二、server.xml解析，在加载阶段\n\nCatalina的load方法，此时会去解析server.xml文件\n\n<!--more-->\n```\npublic void load() {\n    // Create and execute our Digester\n    Digester digester = createStartDigester();\n    file = configFile();\n    inputStream = new FileInputStream(file);\n    inputSource = new InputSource(file.toURI().toURL().toString());\n    inputSource.setByteStream(inputStream);\n    digester.push(this);\n    digester.parse(inputSource);//解析流，进行类\n}    \n\nprotected Digester createStartDigester() {\n    long t1=System.currentTimeMillis();\n    // Initialize the digester\n    Digester digester = new Digester();\n    digester.setValidating(false);\n    digester.setRulesValidation(true);\n    Map<Class<?>, List<String>> fakeAttributes = new HashMap<>();\n    List<String> objectAttrs = new ArrayList<>();\n    objectAttrs.add(\"className\");\n    fakeAttributes.put(Object.class, objectAttrs);\n    // Ignore attribute added by Eclipse for its internal tracking\n    List<String> contextAttrs = new ArrayList<>();\n    contextAttrs.add(\"source\");\n    fakeAttributes.put(StandardContext.class, contextAttrs);\n    digester.setFakeAttributes(fakeAttributes);\n    digester.setUseContextClassLoader(true);\n\n    //创建StandardServer对象，设置其对象的属性，调用父节点Catalina的setServer方法将Server添加到Catalina中。\n    digester.addObjectCreate(\"Server\",\n                             \"org.apache.catalina.core.StandardServer\",\n                             \"className\");\n    digester.addSetProperties(\"Server\");\n    digester.addSetNext(\"Server\",\n                        \"setServer\",\n                        \"org.apache.catalina.Server\");\n\n    digester.addObjectCreate(\"Server/GlobalNamingResources\",\n                             \"org.apache.catalina.deploy.NamingResourcesImpl\");\n    digester.addSetProperties(\"Server/GlobalNamingResources\");\n    digester.addSetNext(\"Server/GlobalNamingResources\",\n                        \"setGlobalNamingResources\",\n                        \"org.apache.catalina.deploy.NamingResourcesImpl\");\n\n    digester.addObjectCreate(\"Server/Listener\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(\"Server/Listener\");\n    digester.addSetNext(\"Server/Listener\",\n                        \"addLifecycleListener\",\n                        \"org.apache.catalina.LifecycleListener\");\n\n    digester.addObjectCreate(\"Server/Service\",\n                             \"org.apache.catalina.core.StandardService\",\n                             \"className\");\n    digester.addSetProperties(\"Server/Service\");\n    digester.addSetNext(\"Server/Service\",\n                        \"addService\",\n                        \"org.apache.catalina.Service\");\n\n    digester.addObjectCreate(\"Server/Service/Listener\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(\"Server/Service/Listener\");\n    digester.addSetNext(\"Server/Service/Listener\",\n                        \"addLifecycleListener\",\n                        \"org.apache.catalina.LifecycleListener\");\n\n    //Executor\n    digester.addObjectCreate(\"Server/Service/Executor\",\n                     \"org.apache.catalina.core.StandardThreadExecutor\",\n                     \"className\");\n    digester.addSetProperties(\"Server/Service/Executor\");\n\n    digester.addSetNext(\"Server/Service/Executor\",\n                        \"addExecutor\",\n                        \"org.apache.catalina.Executor\");\n\n\n    digester.addRule(\"Server/Service/Connector\",\n                     new ConnectorCreateRule());\n    digester.addRule(\"Server/Service/Connector\",\n                     new SetAllPropertiesRule(new String[]{\"executor\", \"sslImplementationName\"}));\n    digester.addSetNext(\"Server/Service/Connector\",\n                        \"addConnector\",\n                        \"org.apache.catalina.connector.Connector\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/SSLHostConfig\",\n                             \"org.apache.tomcat.util.net.SSLHostConfig\");\n    digester.addSetProperties(\"Server/Service/Connector/SSLHostConfig\");\n    digester.addSetNext(\"Server/Service/Connector/SSLHostConfig\",\n            \"addSslHostConfig\",\n            \"org.apache.tomcat.util.net.SSLHostConfig\");\n\n    digester.addRule(\"Server/Service/Connector/SSLHostConfig/Certificate\",\n                     new CertificateCreateRule());\n    digester.addRule(\"Server/Service/Connector/SSLHostConfig/Certificate\",\n                     new SetAllPropertiesRule(new String[]{\"type\"}));\n    digester.addSetNext(\"Server/Service/Connector/SSLHostConfig/Certificate\",\n                        \"addCertificate\",\n                        \"org.apache.tomcat.util.net.SSLHostConfigCertificate\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf\",\n                             \"org.apache.tomcat.util.net.openssl.OpenSSLConf\");\n    digester.addSetProperties(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf\");\n    digester.addSetNext(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf\",\n                        \"setOpenSslConf\",\n                        \"org.apache.tomcat.util.net.openssl.OpenSSLConf\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd\",\n                             \"org.apache.tomcat.util.net.openssl.OpenSSLConfCmd\");\n    digester.addSetProperties(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd\");\n    digester.addSetNext(\"Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd\",\n                        \"addCmd\",\n                        \"org.apache.tomcat.util.net.openssl.OpenSSLConfCmd\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/Listener\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(\"Server/Service/Connector/Listener\");\n    digester.addSetNext(\"Server/Service/Connector/Listener\",\n                        \"addLifecycleListener\",\n                        \"org.apache.catalina.LifecycleListener\");\n\n    digester.addObjectCreate(\"Server/Service/Connector/UpgradeProtocol\",\n                              null, // MUST be specified in the element\n                              \"className\");\n    digester.addSetProperties(\"Server/Service/Connector/UpgradeProtocol\");\n    digester.addSetNext(\"Server/Service/Connector/UpgradeProtocol\",\n                        \"addUpgradeProtocol\",\n                        \"org.apache.coyote.UpgradeProtocol\");\n\n    // Add RuleSets for nested elements\n    digester.addRuleSet(new NamingRuleSet(\"Server/GlobalNamingResources/\"));\n    //EngineRuleSet中，将实例化StandardEngine\n    digester.addRuleSet(new EngineRuleSet(\"Server/Service/\"));\n    //HostRuleSet中，将实例化StandardHost\n    digester.addRuleSet(new HostRuleSet(\"Server/Service/Engine/\"))\n    //ContextRuleSet中，将实例化StandardContext\n    digester.addRuleSet(new ContextRuleSet(\"Server/Service/Engine/Host/\"));\n    addClusterRuleSet(digester, \"Server/Service/Engine/Host/Cluster/\");\n    digester.addRuleSet(new NamingRuleSet(\"Server/Service/Engine/Host/Context/\"));\n\n    // When the 'engine' is found, set the parentClassLoader.\n    digester.addRule(\"Server/Service/Engine\",\n                     new SetParentClassLoaderRule(parentClassLoader));\n    addClusterRuleSet(digester, \"Server/Service/Engine/Cluster/\");\n\n    long t2=System.currentTimeMillis();\n    if (log.isDebugEnabled()) {\n        log.debug(\"Digester for server.xml created \" + ( t2-t1 ));\n    }\n    return digester;\n}\n```\nserver.xml的解析，主要是去创建相应的实例对象，并设置层级关系。\n\n \n## 2.1、StandardContext的创建时机\n\n```\nContextRuleSet\n/**\n * <p>Add the set of Rule instances defined in this RuleSet to the\n * specified <code>Digester</code> instance, associating them with\n * our namespace URI (if any).  This method should only be called\n * by a Digester instance.</p>\n *\n * @param digester Digester instance to which the new Rule instances\n *  should be added.\n */\n //只能被Digester\npublic void addRuleInstances(Digester digester) {\n \n    // 1. 创建Context实例，通过server.xml配置Context时，create是true，需要创建Context实例；通过HostConfig创建Context时，create为false，此时仅需要解析节点即可\n    if (create) {\n        digester.addObjectCreate(prefix + \"Context\",\n                \"org.apache.catalina.core.StandardContext\", \"className\");\n        digester.addSetProperties(prefix + \"Context\");\n    } else {\n        digester.addSetProperties(prefix + \"Context\", new String[]{\"path\", \"docBase\"});\n    }\n \n    if (create) {\n        digester.addRule(prefix + \"Context\",\n                         new LifecycleListenerRule\n                             (\"org.apache.catalina.startup.ContextConfig\",\n                              \"configClass\"));\n        digester.addSetNext(prefix + \"Context\",\n                            \"addChild\",\n                            \"org.apache.catalina.Container\");\n    }\n \n    // 2. 为Context添加生命周期监听器\n    digester.addObjectCreate(prefix + \"Context/Listener\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Listener\");\n    digester.addSetNext(prefix + \"Context/Listener\",\n                        \"addLifecycleListener\",\n                        \"org.apache.catalina.LifecycleListener\");\n \n    // 3. 为Context指定类加载器，默认为org.apache.catalina.loader.WebappLoader\n    digester.addObjectCreate(prefix + \"Context/Loader\",\n                        \"org.apache.catalina.loader.WebappLoader\",\n                        \"className\");\n    digester.addSetProperties(prefix + \"Context/Loader\");\n    digester.addSetNext(prefix + \"Context/Loader\",\n                        \"setLoader\",\n                        \"org.apache.catalina.Loader\");\n \n    // 4. 为Context添加会话管理器，默认实现为StandardManager\n    digester.addObjectCreate(prefix + \"Context/Manager\",\n                             \"org.apache.catalina.session.StandardManager\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Manager\");\n    digester.addSetNext(prefix + \"Context/Manager\",\n                        \"setManager\",\n                        \"org.apache.catalina.Manager\");\n \n    digester.addObjectCreate(prefix + \"Context/Manager/Store\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Manager/Store\");\n    digester.addSetNext(prefix + \"Context/Manager/Store\",\n                        \"setStore\",\n                        \"org.apache.catalina.Store\");\n \n    digester.addObjectCreate(prefix + \"Context/Manager/SessionIdGenerator\",\n                             \"org.apache.catalina.util.StandardSessionIdGenerator\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Manager/SessionIdGenerator\");\n    digester.addSetNext(prefix + \"Context/Manager/SessionIdGenerator\",\n                        \"setSessionIdGenerator\",\n                        \"org.apache.catalina.SessionIdGenerator\");\n \n    //5. 为Context添加初始化参数，通过该配置，为Context添加初始化参数\n    digester.addObjectCreate(prefix + \"Context/Parameter\",\n                             \"org.apache.tomcat.util.descriptor.web.ApplicationParameter\");\n    digester.addSetProperties(prefix + \"Context/Parameter\");\n    digester.addSetNext(prefix + \"Context/Parameter\",\n                        \"addApplicationParameter\",\n                        \"org.apache.tomcat.util.descriptor.web.ApplicationParameter\");\n \n    // 6. 为Context添加安全配置以及web资源配置\n    digester.addRuleSet(new RealmRuleSet(prefix + \"Context/\"));\n \n    digester.addObjectCreate(prefix + \"Context/Resources\",\n                             \"org.apache.catalina.webresources.StandardRoot\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Resources\");\n    digester.addSetNext(prefix + \"Context/Resources\",\n                        \"setResources\",\n                        \"org.apache.catalina.WebResourceRoot\");\n \n    digester.addObjectCreate(prefix + \"Context/Resources/PreResources\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Resources/PreResources\");\n    digester.addSetNext(prefix + \"Context/Resources/PreResources\",\n                        \"addPreResources\",\n                        \"org.apache.catalina.WebResourceSet\");\n \n    digester.addObjectCreate(prefix + \"Context/Resources/JarResources\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Resources/JarResources\");\n    digester.addSetNext(prefix + \"Context/Resources/JarResources\",\n                        \"addJarResources\",\n                        \"org.apache.catalina.WebResourceSet\");\n \n    digester.addObjectCreate(prefix + \"Context/Resources/PostResources\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Resources/PostResources\");\n    digester.addSetNext(prefix + \"Context/Resources/PostResources\",\n                        \"addPostResources\",\n                        \"org.apache.catalina.WebResourceSet\");\n \n    // 7. 为Context添加资源连接，默认为ContextResourceLink，用于J2EE命名服务\n    digester.addObjectCreate(prefix + \"Context/ResourceLink\",\n            \"org.apache.tomcat.util.descriptor.web.ContextResourceLink\");\n    digester.addSetProperties(prefix + \"Context/ResourceLink\");\n    digester.addRule(prefix + \"Context/ResourceLink\",\n            new SetNextNamingRule(\"addResourceLink\",\n                    \"org.apache.tomcat.util.descriptor.web.ContextResourceLink\"));\n \n    // 8. 为Context添加Valve\n    digester.addObjectCreate(prefix + \"Context/Valve\",\n                             null, // MUST be specified in the element\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/Valve\");\n    digester.addSetNext(prefix + \"Context/Valve\",\n                        \"addValve\",\n                        \"org.apache.catalina.Valve\");\n \n    // 9. 为Context添加守护资源配置\n    digester.addCallMethod(prefix + \"Context/WatchedResource\",\n                           \"addWatchedResource\", 0);\n \n    digester.addCallMethod(prefix + \"Context/WrapperLifecycle\",\n                           \"addWrapperLifecycle\", 0);\n \n    digester.addCallMethod(prefix + \"Context/WrapperListener\",\n                           \"addWrapperListener\", 0);\n \n    digester.addObjectCreate(prefix + \"Context/JarScanner\",\n                             \"org.apache.tomcat.util.scan.StandardJarScanner\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/JarScanner\");\n    digester.addSetNext(prefix + \"Context/JarScanner\",\n                        \"setJarScanner\",\n                        \"org.apache.tomcat.JarScanner\");\n \n    digester.addObjectCreate(prefix + \"Context/JarScanner/JarScanFilter\",\n                             \"org.apache.tomcat.util.scan.StandardJarScanFilter\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/JarScanner/JarScanFilter\");\n    digester.addSetNext(prefix + \"Context/JarScanner/JarScanFilter\",\n                        \"setJarScanFilter\",\n                        \"org.apache.tomcat.JarScanFilter\");\n \n    // 10. 为Context添加Cookie处理器\n    digester.addObjectCreate(prefix + \"Context/CookieProcessor\",\n                             \"org.apache.tomcat.util.http.Rfc6265CookieProcessor\",\n                             \"className\");\n    digester.addSetProperties(prefix + \"Context/CookieProcessor\");\n    digester.addSetNext(prefix + \"Context/CookieProcessor\",\n                        \"setCookieProcessor\",\n                        \"org.apache.tomcat.util.http.CookieProcessor\");\n}\n```\nContextRuleSet定义了创建规则，digester会通过规则创建StandardContext对象\n\n\n# 三、web.xml的解析时机，在启动阶段\n## 1. StandardServer.startInternal()方法\n```\nprotected void startInternal() throws LifecycleException {\n    //通知容器启动事件\n    fireLifecycleEvent(CONFIGURE_START_EVENT, null);\n    setState(LifecycleState.STARTING);\n    globalNamingResources.start();\n    // Start our defined Services\n    synchronized (servicesLock) {\n        for (int i = 0; i < services.length; i++) {\n            services[i].start();\n        }\n    }\n}\n```\n## 2. StandardContext.startInternal()方法\n```\nprotected synchronized void startInternal() throws LifecycleException {\n    // Notify our interested LifecycleListeners\n    //1、通知容器启动事件，去解析web.xml\n    fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null);\n    //2、进行listener的创建和启动\n    if (ok) {\n        if (!listenerStart()) {\n            log.error(sm.getString(\"standardContext.listenerFail\"));\n            ok = false;\n        }\n    }\n    // 3、filter的创建和启动\n    if (ok) {\n        if (!filterStart()) {\n            log.error(sm.getString(\"standardContext.filterFail\"));\n            ok = false;\n        }\n    }\n    //加载和实例化servlet\n    // Load and initialize all \"load on startup\" servlets\n    if (ok) {\n        if (!loadOnStartup(findChildren())){\n            log.error(sm.getString(\"standardContext.servletFail\"));\n            ok = false;\n        }\n    }\n}\n\n```\n## 3、ContextConfig.lifecycleEvent()方法\n触发事件，进行文件的解析\n```\npublic void lifecycleEvent(LifecycleEvent event) {\n    // Process the event that has occurred\n    if (event.getType().equals(Lifecycle.CONFIGURE_START_EVENT)) {\n        //进行配置文件的解析，ContextConfig事件\n        configureStart();\n    } else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) {\n     \n\n}\n```\n\n\n### 3.1、ContextConfig事件\n```\n/**\n * Process a \"contextConfig\" event for this Context.\n */\nprotected synchronized void configureStart() {\n    // Called from StandardContext.start()\n\n    if (log.isDebugEnabled()) {\n        log.debug(sm.getString(\"contextConfig.start\"));\n    }\n\n    if (log.isDebugEnabled()) {\n        log.debug(sm.getString(\"contextConfig.xmlSettings\",\n                context.getName(),\n                Boolean.valueOf(context.getXmlValidation()),\n                Boolean.valueOf(context.getXmlNamespaceAware())));\n    }\n    //进行web.xml的具体解析工作\n    webConfig();\n\n    if (!context.getIgnoreAnnotations()) {\n        applicationAnnotationsConfig();\n    }\n    if (ok) {\n        validateSecurityRoles();\n    }\n\n    // Configure an authenticator if we need one\n    if (ok) {\n        authenticatorConfig();\n    }\n\n    // Dump the contents of this pipeline if requested\n    if (log.isDebugEnabled()) {\n        log.debug(\"Pipeline Configuration:\");\n        Pipeline pipeline = context.getPipeline();\n        Valve valves[] = null;\n        if (pipeline != null) {\n            valves = pipeline.getValves();\n        }\n        if (valves != null) {\n            for (int i = 0; i < valves.length; i++) {\n                log.debug(\"  \" + valves[i].getClass().getName());\n            }\n        }\n        log.debug(\"======================\");\n    }\n\n    // Make our application available if no problems were encountered\n    if (ok) {\n        context.setConfigured(true);\n    } else {\n        log.error(sm.getString(\"contextConfig.unavailable\"));\n        context.setConfigured(false);\n    }\n}\n```\n\n\n### 3.2、webConfig()方法，会根据web.xml中的配置进行listen，filter，servlet的信息设置\n```\nprivate void configureContext(WebXml webxml) {\n    \n    //filter的解析，此处未进行创建\n    for (FilterDef filter : webxml.getFilters().values()) {\n        if (filter.getAsyncSupported() == null) {\n            filter.setAsyncSupported(\"false\");\n        }\n        context.addFilterDef(filter);\n    }\n    //listen解析，此处未进行创建\n    for (String listener : webxml.getListeners()) {\n        context.addApplicationListener(listener);\n    }\n    \n    //创建wraper，servlet并未创建\n    for (ServletDef servlet : webxml.getServlets().values()) {\n        Wrapper wrapper = context.createWrapper();\n        if (servlet.getLoadOnStartup() != null) {\n            wrapper.setLoadOnStartup(servlet.getLoadOnStartup().intValue());\n        }\n        if (servlet.getEnabled() != null) {\n            wrapper.setEnabled(servlet.getEnabled().booleanValue());\n        }\n        wrapper.setName(servlet.getServletName());\n        Map<String,String> params = servlet.getParameterMap();\n        for (Entry<String, String> entry : params.entrySet()) {\n            wrapper.addInitParameter(entry.getKey(), entry.getValue());\n        }\n        wrapper.setRunAs(servlet.getRunAs());\n        Set<SecurityRoleRef> roleRefs = servlet.getSecurityRoleRefs();\n        for (SecurityRoleRef roleRef : roleRefs) {\n            wrapper.addSecurityReference(\n                    roleRef.getName(), roleRef.getLink());\n        }\n        wrapper.setServletClass(servlet.getServletClass());\n        MultipartDef multipartdef = servlet.getMultipartDef();\n        if (multipartdef != null) {\n            if (multipartdef.getMaxFileSize() != null &&\n                    multipartdef.getMaxRequestSize()!= null &&\n                    multipartdef.getFileSizeThreshold() != null) {\n                wrapper.setMultipartConfigElement(new MultipartConfigElement(\n                        multipartdef.getLocation(),\n                        Long.parseLong(multipartdef.getMaxFileSize()),\n                        Long.parseLong(multipartdef.getMaxRequestSize()),\n                        Integer.parseInt(\n                                multipartdef.getFileSizeThreshold())));\n            } else {\n                wrapper.setMultipartConfigElement(new MultipartConfigElement(\n                        multipartdef.getLocation()));\n            }\n        }\n        if (servlet.getAsyncSupported() != null) {\n            wrapper.setAsyncSupported(\n                    servlet.getAsyncSupported().booleanValue());\n        }\n        wrapper.setOverridable(servlet.isOverridable());\n        context.addChild(wrapper);\n    }\n}\n```\n\n### 3.3、listen filter servlet的创建\nStandardContext.startInternal()方法进行web.xml解析后，就会进行listen和filter和servlet的创建\n```\npublic boolean listenerStart() {\n     // Instantiate the required listeners\n    String listeners[] = findApplicationListeners();\n    Object results[] = new Object[listeners.length];\n    boolean ok = true;\n    for (int i = 0; i < results.length; i++) {\n        if (getLogger().isDebugEnabled())\n            getLogger().debug(\" Configuring event listener class '\" +\n                listeners[i] + \"'\");\n        try {\n            String listener = listeners[i];\n            results[i] = getInstanceManager().newInstance(listener);\n        } catch (Throwable t) {\n            t = ExceptionUtils.unwrapInvocationTargetException(t);\n            ExceptionUtils.handleThrowable(t);\n            getLogger().error(sm.getString(\"standardContext.applicationListener\", listeners[i]), t);\n            ok = false;\n        }\n    }   \n}    \n\n\npublic boolean filterStart() {\n    if (getLogger().isDebugEnabled()) {\n        getLogger().debug(\"Starting filters\");\n    }\n    // Instantiate and record a FilterConfig for each defined filter\n    boolean ok = true;\n    synchronized (filterConfigs) {\n        filterConfigs.clear();\n        for (Entry<String,FilterDef> entry : filterDefs.entrySet()) {\n            String name = entry.getKey();\n            if (getLogger().isDebugEnabled()) {\n                getLogger().debug(\" Starting filter '\" + name + \"'\");\n            }\n            try {\n                ApplicationFilterConfig filterConfig = new ApplicationFilterConfig(this, entry.getValue());\n                filterConfigs.put(name, filterConfig);\n            } catch (Throwable t) {\n                t = ExceptionUtils.unwrapInvocationTargetException(t);\n                ExceptionUtils.handleThrowable(t);\n                getLogger().error(sm.getString(\n                        \"standardContext.filterStart\", name), t);\n                ok = false;\n            }\n        }\n    }\n    return ok;\n}\n```\n\n\n当然这种加载只是针对配置了 load-on-startup 属性的 Servlet 而言，\n其它一般 Servlet 的加载和初始化会推迟到真正请求访问 web 应用而第一次调用该 Servlet 时，\n下面会看到这种情况下代码分析。\n```\npublic boolean loadOnStartup(Container children[]) {\n\n    // Collect \"load on startup\" servlets that need to be initialized\n    TreeMap<Integer, ArrayList<Wrapper>> map = new TreeMap<>();\n    for (int i = 0; i < children.length; i++) {\n        Wrapper wrapper = (Wrapper) children[i];\n        int loadOnStartup = wrapper.getLoadOnStartup();\n        if (loadOnStartup < 0)\n            continue;\n        Integer key = Integer.valueOf(loadOnStartup);\n        ArrayList<Wrapper> list = map.get(key);\n        if (list == null) {\n            list = new ArrayList<>();\n            map.put(key, list);\n        }\n        list.add(wrapper);\n    }\n\n    // Load the collected \"load on startup\" servlets\n    for (ArrayList<Wrapper> list : map.values()) {\n        for (Wrapper wrapper : list) {\n            try {\n                wrapper.load();\n            } catch (ServletException e) {            }\n        }\n    }\n    return true;\n}\n//StandardWrapper\npublic synchronized void load() throws ServletException {\n    instance = loadServlet();\n    if (!instanceInitialized) {\n        //Servlet servlet = instanceManager.newInstance(servletClass);\n        initServlet(instance);\n    }\n}\n```\n\n> servlet执行时机\n1. servlet = wrapper.allocate(); 调用StandardWrapper#allocate()方法，获取到servlet实例\n2. ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);为当前请求创建一个过滤链，（非异步情况下）并调用filterChain.doFilter(request.getRequest(), response.getResponse());\n3. filter#doFilter()、servlet#service()的执行是在filterChain.doFilter(request.getRequest(), response.getResponse());代码内部执行的。\n\n> sevletRequestListener执行时机\n```\nStandardHostValve.invoke\n// context.fireRequestInitEvent，会去通知Listener\npublic final void invoke(Request request, Response response)\n    throws IOException, ServletException {\n    try {\n        context.bind(Globals.IS_SECURITY_ENABLED, MY_CLASSLOADER);\n        if (!asyncAtStart && !context.fireRequestInitEvent(request.getRequest())) {\n            return;\n        }\n}     \n```   \n\n//请求过来时，会去执行listener\n```\npublic boolean fireRequestInitEvent(ServletRequest request) {\n    Object instances[] = getApplicationEventListeners();\n    if ((instances != null) && (instances.length > 0)) {\n        ServletRequestEvent event = new ServletRequestEvent(getServletContext(), request);\n            try {\n                listener.requestInitialized(event);\n            } catch (Throwable t) {\n            }\n        }\n    }\n    return true;\n}\n```\n\n# 五、请求执行过程\nStandardContext.startInternal()方法进行web.xml解析后，就会进行listen和filter和servlet（ServletWarpper）的创建\n1. StandardHostValve.invoke，会调用StanardContext.fireRequestInitEvent\n2. StandardContext.fireRequestInitEvent的 **listener（servletListener）** 的requestInitialized方法\n3. 然后StandardContextValve.invoke，根据URL选择servlet\n4. 然后StandardWrapperValve.invoke\n    1. 会先判断servlet是否存在，不存在则创建。非load-on-startup类型的servlet会在第一次请求时创建。\n    2. 执行过滤链，当所有的过滤器执行完成后，最后一个过滤器会调用步骤3\n    3. 执行servlet.service方法\n\n\n> 多种listener\n1. ServletContextListener：监听ServletContext域对象的创建和销毁\n2. HttpSessionListener：接口用于监听HttpSession对象的创建和销毁\n3. ServletRequestListener：接口用于监听ServletRequest 对象的创建和销毁\n\n\nlistener -> filter -> servlet：执行顺序\n\n![启动过程](2019-12-22-tomcat-webxml解析/启动过程.png)\n\n\n\n\n","slug":"2019-12-22-tomcat-webxml解析","published":1,"updated":"2024-10-14T09:38:12.034Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnw5001la13kfdlutnhn","content":"<h1 id=\"一、解析顺序\"><a href=\"#一、解析顺序\" class=\"headerlink\" title=\"一、解析顺序\"></a>一、解析顺序</h1><p>先解析server.xml，再解析web.xml</p>\n<h1 id=\"二、server-xml解析，在加载阶段\"><a href=\"#二、server-xml解析，在加载阶段\" class=\"headerlink\" title=\"二、server.xml解析，在加载阶段\"></a>二、server.xml解析，在加载阶段</h1><p>Catalina的load方法，此时会去解析server.xml文件</p>\n<a id=\"more\"></a>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void load() &#123;</span><br><span class=\"line\">    // Create and execute our Digester</span><br><span class=\"line\">    Digester digester = createStartDigester();</span><br><span class=\"line\">    file = configFile();</span><br><span class=\"line\">    inputStream = new FileInputStream(file);</span><br><span class=\"line\">    inputSource = new InputSource(file.toURI().toURL().toString());</span><br><span class=\"line\">    inputSource.setByteStream(inputStream);</span><br><span class=\"line\">    digester.push(this);</span><br><span class=\"line\">    digester.parse(inputSource);//解析流，进行类</span><br><span class=\"line\">&#125;    </span><br><span class=\"line\"></span><br><span class=\"line\">protected Digester createStartDigester() &#123;</span><br><span class=\"line\">    long t1=System.currentTimeMillis();</span><br><span class=\"line\">    // Initialize the digester</span><br><span class=\"line\">    Digester digester = new Digester();</span><br><span class=\"line\">    digester.setValidating(false);</span><br><span class=\"line\">    digester.setRulesValidation(true);</span><br><span class=\"line\">    Map&lt;Class&lt;?&gt;, List&lt;String&gt;&gt; fakeAttributes = new HashMap&lt;&gt;();</span><br><span class=\"line\">    List&lt;String&gt; objectAttrs = new ArrayList&lt;&gt;();</span><br><span class=\"line\">    objectAttrs.add(&quot;className&quot;);</span><br><span class=\"line\">    fakeAttributes.put(Object.class, objectAttrs);</span><br><span class=\"line\">    // Ignore attribute added by Eclipse for its internal tracking</span><br><span class=\"line\">    List&lt;String&gt; contextAttrs = new ArrayList&lt;&gt;();</span><br><span class=\"line\">    contextAttrs.add(&quot;source&quot;);</span><br><span class=\"line\">    fakeAttributes.put(StandardContext.class, contextAttrs);</span><br><span class=\"line\">    digester.setFakeAttributes(fakeAttributes);</span><br><span class=\"line\">    digester.setUseContextClassLoader(true);</span><br><span class=\"line\"></span><br><span class=\"line\">    //创建StandardServer对象，设置其对象的属性，调用父节点Catalina的setServer方法将Server添加到Catalina中。</span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.core.StandardServer&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server&quot;,</span><br><span class=\"line\">                        &quot;setServer&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Server&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/GlobalNamingResources&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.deploy.NamingResourcesImpl&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/GlobalNamingResources&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/GlobalNamingResources&quot;,</span><br><span class=\"line\">                        &quot;setGlobalNamingResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.deploy.NamingResourcesImpl&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Listener&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Listener&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Listener&quot;,</span><br><span class=\"line\">                        &quot;addLifecycleListener&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.LifecycleListener&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.core.StandardService&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service&quot;,</span><br><span class=\"line\">                        &quot;addService&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Service&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Listener&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Listener&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Listener&quot;,</span><br><span class=\"line\">                        &quot;addLifecycleListener&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.LifecycleListener&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    //Executor</span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Executor&quot;,</span><br><span class=\"line\">                     &quot;org.apache.catalina.core.StandardThreadExecutor&quot;,</span><br><span class=\"line\">                     &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Executor&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Executor&quot;,</span><br><span class=\"line\">                        &quot;addExecutor&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Executor&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Connector&quot;,</span><br><span class=\"line\">                     new ConnectorCreateRule());</span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Connector&quot;,</span><br><span class=\"line\">                     new SetAllPropertiesRule(new String[]&#123;&quot;executor&quot;, &quot;sslImplementationName&quot;&#125;));</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector&quot;,</span><br><span class=\"line\">                        &quot;addConnector&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.connector.Connector&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/SSLHostConfig&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.net.SSLHostConfig&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/SSLHostConfig&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/SSLHostConfig&quot;,</span><br><span class=\"line\">            &quot;addSslHostConfig&quot;,</span><br><span class=\"line\">            &quot;org.apache.tomcat.util.net.SSLHostConfig&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Connector/SSLHostConfig/Certificate&quot;,</span><br><span class=\"line\">                     new CertificateCreateRule());</span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Connector/SSLHostConfig/Certificate&quot;,</span><br><span class=\"line\">                     new SetAllPropertiesRule(new String[]&#123;&quot;type&quot;&#125;));</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/SSLHostConfig/Certificate&quot;,</span><br><span class=\"line\">                        &quot;addCertificate&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.net.SSLHostConfigCertificate&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.net.openssl.OpenSSLConf&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf&quot;,</span><br><span class=\"line\">                        &quot;setOpenSslConf&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.net.openssl.OpenSSLConf&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.net.openssl.OpenSSLConfCmd&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd&quot;,</span><br><span class=\"line\">                        &quot;addCmd&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.net.openssl.OpenSSLConfCmd&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/Listener&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/Listener&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/Listener&quot;,</span><br><span class=\"line\">                        &quot;addLifecycleListener&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.LifecycleListener&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/UpgradeProtocol&quot;,</span><br><span class=\"line\">                              null, // MUST be specified in the element</span><br><span class=\"line\">                              &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/UpgradeProtocol&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/UpgradeProtocol&quot;,</span><br><span class=\"line\">                        &quot;addUpgradeProtocol&quot;,</span><br><span class=\"line\">                        &quot;org.apache.coyote.UpgradeProtocol&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    // Add RuleSets for nested elements</span><br><span class=\"line\">    digester.addRuleSet(new NamingRuleSet(&quot;Server/GlobalNamingResources/&quot;));</span><br><span class=\"line\">    //EngineRuleSet中，将实例化StandardEngine</span><br><span class=\"line\">    digester.addRuleSet(new EngineRuleSet(&quot;Server/Service/&quot;));</span><br><span class=\"line\">    //HostRuleSet中，将实例化StandardHost</span><br><span class=\"line\">    digester.addRuleSet(new HostRuleSet(&quot;Server/Service/Engine/&quot;))</span><br><span class=\"line\">    //ContextRuleSet中，将实例化StandardContext</span><br><span class=\"line\">    digester.addRuleSet(new ContextRuleSet(&quot;Server/Service/Engine/Host/&quot;));</span><br><span class=\"line\">    addClusterRuleSet(digester, &quot;Server/Service/Engine/Host/Cluster/&quot;);</span><br><span class=\"line\">    digester.addRuleSet(new NamingRuleSet(&quot;Server/Service/Engine/Host/Context/&quot;));</span><br><span class=\"line\"></span><br><span class=\"line\">    // When the &apos;engine&apos; is found, set the parentClassLoader.</span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Engine&quot;,</span><br><span class=\"line\">                     new SetParentClassLoaderRule(parentClassLoader));</span><br><span class=\"line\">    addClusterRuleSet(digester, &quot;Server/Service/Engine/Cluster/&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    long t2=System.currentTimeMillis();</span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;Digester for server.xml created &quot; + ( t2-t1 ));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return digester;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>server.xml的解析，主要是去创建相应的实例对象，并设置层级关系。</p>\n<h2 id=\"2-1、StandardContext的创建时机\"><a href=\"#2-1、StandardContext的创建时机\" class=\"headerlink\" title=\"2.1、StandardContext的创建时机\"></a>2.1、StandardContext的创建时机</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ContextRuleSet</span><br><span class=\"line\">/**</span><br><span class=\"line\"> * &lt;p&gt;Add the set of Rule instances defined in this RuleSet to the</span><br><span class=\"line\"> * specified &lt;code&gt;Digester&lt;/code&gt; instance, associating them with</span><br><span class=\"line\"> * our namespace URI (if any).  This method should only be called</span><br><span class=\"line\"> * by a Digester instance.&lt;/p&gt;</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param digester Digester instance to which the new Rule instances</span><br><span class=\"line\"> *  should be added.</span><br><span class=\"line\"> */</span><br><span class=\"line\"> //只能被Digester</span><br><span class=\"line\">public void addRuleInstances(Digester digester) &#123;</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 1. 创建Context实例，通过server.xml配置Context时，create是true，需要创建Context实例；通过HostConfig创建Context时，create为false，此时仅需要解析节点即可</span><br><span class=\"line\">    if (create) &#123;</span><br><span class=\"line\">        digester.addObjectCreate(prefix + &quot;Context&quot;,</span><br><span class=\"line\">                &quot;org.apache.catalina.core.StandardContext&quot;, &quot;className&quot;);</span><br><span class=\"line\">        digester.addSetProperties(prefix + &quot;Context&quot;);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        digester.addSetProperties(prefix + &quot;Context&quot;, new String[]&#123;&quot;path&quot;, &quot;docBase&quot;&#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">    if (create) &#123;</span><br><span class=\"line\">        digester.addRule(prefix + &quot;Context&quot;,</span><br><span class=\"line\">                         new LifecycleListenerRule</span><br><span class=\"line\">                             (&quot;org.apache.catalina.startup.ContextConfig&quot;,</span><br><span class=\"line\">                              &quot;configClass&quot;));</span><br><span class=\"line\">        digester.addSetNext(prefix + &quot;Context&quot;,</span><br><span class=\"line\">                            &quot;addChild&quot;,</span><br><span class=\"line\">                            &quot;org.apache.catalina.Container&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 2. 为Context添加生命周期监听器</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Listener&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Listener&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Listener&quot;,</span><br><span class=\"line\">                        &quot;addLifecycleListener&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.LifecycleListener&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 3. 为Context指定类加载器，默认为org.apache.catalina.loader.WebappLoader</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Loader&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.loader.WebappLoader&quot;,</span><br><span class=\"line\">                        &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Loader&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Loader&quot;,</span><br><span class=\"line\">                        &quot;setLoader&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Loader&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 4. 为Context添加会话管理器，默认实现为StandardManager</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Manager&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.session.StandardManager&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Manager&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Manager&quot;,</span><br><span class=\"line\">                        &quot;setManager&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Manager&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Manager/Store&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Manager/Store&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Manager/Store&quot;,</span><br><span class=\"line\">                        &quot;setStore&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Store&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Manager/SessionIdGenerator&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.util.StandardSessionIdGenerator&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Manager/SessionIdGenerator&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Manager/SessionIdGenerator&quot;,</span><br><span class=\"line\">                        &quot;setSessionIdGenerator&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.SessionIdGenerator&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    //5. 为Context添加初始化参数，通过该配置，为Context添加初始化参数</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Parameter&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.descriptor.web.ApplicationParameter&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Parameter&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Parameter&quot;,</span><br><span class=\"line\">                        &quot;addApplicationParameter&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.descriptor.web.ApplicationParameter&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 6. 为Context添加安全配置以及web资源配置</span><br><span class=\"line\">    digester.addRuleSet(new RealmRuleSet(prefix + &quot;Context/&quot;));</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Resources&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.webresources.StandardRoot&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Resources&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Resources&quot;,</span><br><span class=\"line\">                        &quot;setResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.WebResourceRoot&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Resources/PreResources&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Resources/PreResources&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Resources/PreResources&quot;,</span><br><span class=\"line\">                        &quot;addPreResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.WebResourceSet&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Resources/JarResources&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Resources/JarResources&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Resources/JarResources&quot;,</span><br><span class=\"line\">                        &quot;addJarResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.WebResourceSet&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Resources/PostResources&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Resources/PostResources&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Resources/PostResources&quot;,</span><br><span class=\"line\">                        &quot;addPostResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.WebResourceSet&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 7. 为Context添加资源连接，默认为ContextResourceLink，用于J2EE命名服务</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/ResourceLink&quot;,</span><br><span class=\"line\">            &quot;org.apache.tomcat.util.descriptor.web.ContextResourceLink&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/ResourceLink&quot;);</span><br><span class=\"line\">    digester.addRule(prefix + &quot;Context/ResourceLink&quot;,</span><br><span class=\"line\">            new SetNextNamingRule(&quot;addResourceLink&quot;,</span><br><span class=\"line\">                    &quot;org.apache.tomcat.util.descriptor.web.ContextResourceLink&quot;));</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 8. 为Context添加Valve</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Valve&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Valve&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Valve&quot;,</span><br><span class=\"line\">                        &quot;addValve&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Valve&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 9. 为Context添加守护资源配置</span><br><span class=\"line\">    digester.addCallMethod(prefix + &quot;Context/WatchedResource&quot;,</span><br><span class=\"line\">                           &quot;addWatchedResource&quot;, 0);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addCallMethod(prefix + &quot;Context/WrapperLifecycle&quot;,</span><br><span class=\"line\">                           &quot;addWrapperLifecycle&quot;, 0);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addCallMethod(prefix + &quot;Context/WrapperListener&quot;,</span><br><span class=\"line\">                           &quot;addWrapperListener&quot;, 0);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/JarScanner&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.scan.StandardJarScanner&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/JarScanner&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/JarScanner&quot;,</span><br><span class=\"line\">                        &quot;setJarScanner&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.JarScanner&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/JarScanner/JarScanFilter&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.scan.StandardJarScanFilter&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/JarScanner/JarScanFilter&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/JarScanner/JarScanFilter&quot;,</span><br><span class=\"line\">                        &quot;setJarScanFilter&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.JarScanFilter&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 10. 为Context添加Cookie处理器</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/CookieProcessor&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.http.Rfc6265CookieProcessor&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/CookieProcessor&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/CookieProcessor&quot;,</span><br><span class=\"line\">                        &quot;setCookieProcessor&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.http.CookieProcessor&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>ContextRuleSet定义了创建规则，digester会通过规则创建StandardContext对象</p>\n<h1 id=\"三、web-xml的解析时机，在启动阶段\"><a href=\"#三、web-xml的解析时机，在启动阶段\" class=\"headerlink\" title=\"三、web.xml的解析时机，在启动阶段\"></a>三、web.xml的解析时机，在启动阶段</h1><h2 id=\"1-StandardServer-startInternal-方法\"><a href=\"#1-StandardServer-startInternal-方法\" class=\"headerlink\" title=\"1. StandardServer.startInternal()方法\"></a>1. StandardServer.startInternal()方法</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    //通知容器启动事件</span><br><span class=\"line\">    fireLifecycleEvent(CONFIGURE_START_EVENT, null);</span><br><span class=\"line\">    setState(LifecycleState.STARTING);</span><br><span class=\"line\">    globalNamingResources.start();</span><br><span class=\"line\">    // Start our defined Services</span><br><span class=\"line\">    synchronized (servicesLock) &#123;</span><br><span class=\"line\">        for (int i = 0; i &lt; services.length; i++) &#123;</span><br><span class=\"line\">            services[i].start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-StandardContext-startInternal-方法\"><a href=\"#2-StandardContext-startInternal-方法\" class=\"headerlink\" title=\"2. StandardContext.startInternal()方法\"></a>2. StandardContext.startInternal()方法</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected synchronized void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Notify our interested LifecycleListeners</span><br><span class=\"line\">    //1、通知容器启动事件，去解析web.xml</span><br><span class=\"line\">    fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null);</span><br><span class=\"line\">    //2、进行listener的创建和启动</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        if (!listenerStart()) &#123;</span><br><span class=\"line\">            log.error(sm.getString(&quot;standardContext.listenerFail&quot;));</span><br><span class=\"line\">            ok = false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // 3、filter的创建和启动</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        if (!filterStart()) &#123;</span><br><span class=\"line\">            log.error(sm.getString(&quot;standardContext.filterFail&quot;));</span><br><span class=\"line\">            ok = false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //加载和实例化servlet</span><br><span class=\"line\">    // Load and initialize all &quot;load on startup&quot; servlets</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        if (!loadOnStartup(findChildren()))&#123;</span><br><span class=\"line\">            log.error(sm.getString(&quot;standardContext.servletFail&quot;));</span><br><span class=\"line\">            ok = false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、ContextConfig-lifecycleEvent-方法\"><a href=\"#3、ContextConfig-lifecycleEvent-方法\" class=\"headerlink\" title=\"3、ContextConfig.lifecycleEvent()方法\"></a>3、ContextConfig.lifecycleEvent()方法</h2><p>触发事件，进行文件的解析</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void lifecycleEvent(LifecycleEvent event) &#123;</span><br><span class=\"line\">    // Process the event that has occurred</span><br><span class=\"line\">    if (event.getType().equals(Lifecycle.CONFIGURE_START_EVENT)) &#123;</span><br><span class=\"line\">        //进行配置文件的解析，ContextConfig事件</span><br><span class=\"line\">        configureStart();</span><br><span class=\"line\">    &#125; else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) &#123;</span><br><span class=\"line\">     </span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-1、ContextConfig事件\"><a href=\"#3-1、ContextConfig事件\" class=\"headerlink\" title=\"3.1、ContextConfig事件\"></a>3.1、ContextConfig事件</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Process a &quot;contextConfig&quot; event for this Context.</span><br><span class=\"line\"> */</span><br><span class=\"line\">protected synchronized void configureStart() &#123;</span><br><span class=\"line\">    // Called from StandardContext.start()</span><br><span class=\"line\"></span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(sm.getString(&quot;contextConfig.start&quot;));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(sm.getString(&quot;contextConfig.xmlSettings&quot;,</span><br><span class=\"line\">                context.getName(),</span><br><span class=\"line\">                Boolean.valueOf(context.getXmlValidation()),</span><br><span class=\"line\">                Boolean.valueOf(context.getXmlNamespaceAware())));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //进行web.xml的具体解析工作</span><br><span class=\"line\">    webConfig();</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!context.getIgnoreAnnotations()) &#123;</span><br><span class=\"line\">        applicationAnnotationsConfig();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        validateSecurityRoles();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Configure an authenticator if we need one</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        authenticatorConfig();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Dump the contents of this pipeline if requested</span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;Pipeline Configuration:&quot;);</span><br><span class=\"line\">        Pipeline pipeline = context.getPipeline();</span><br><span class=\"line\">        Valve valves[] = null;</span><br><span class=\"line\">        if (pipeline != null) &#123;</span><br><span class=\"line\">            valves = pipeline.getValves();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (valves != null) &#123;</span><br><span class=\"line\">            for (int i = 0; i &lt; valves.length; i++) &#123;</span><br><span class=\"line\">                log.debug(&quot;  &quot; + valves[i].getClass().getName());</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        log.debug(&quot;======================&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Make our application available if no problems were encountered</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        context.setConfigured(true);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        log.error(sm.getString(&quot;contextConfig.unavailable&quot;));</span><br><span class=\"line\">        context.setConfigured(false);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-2、webConfig-方法，会根据web-xml中的配置进行listen，filter，servlet的信息设置\"><a href=\"#3-2、webConfig-方法，会根据web-xml中的配置进行listen，filter，servlet的信息设置\" class=\"headerlink\" title=\"3.2、webConfig()方法，会根据web.xml中的配置进行listen，filter，servlet的信息设置\"></a>3.2、webConfig()方法，会根据web.xml中的配置进行listen，filter，servlet的信息设置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private void configureContext(WebXml webxml) &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    //filter的解析，此处未进行创建</span><br><span class=\"line\">    for (FilterDef filter : webxml.getFilters().values()) &#123;</span><br><span class=\"line\">        if (filter.getAsyncSupported() == null) &#123;</span><br><span class=\"line\">            filter.setAsyncSupported(&quot;false&quot;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        context.addFilterDef(filter);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //listen解析，此处未进行创建</span><br><span class=\"line\">    for (String listener : webxml.getListeners()) &#123;</span><br><span class=\"line\">        context.addApplicationListener(listener);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    //创建wraper，servlet并未创建</span><br><span class=\"line\">    for (ServletDef servlet : webxml.getServlets().values()) &#123;</span><br><span class=\"line\">        Wrapper wrapper = context.createWrapper();</span><br><span class=\"line\">        if (servlet.getLoadOnStartup() != null) &#123;</span><br><span class=\"line\">            wrapper.setLoadOnStartup(servlet.getLoadOnStartup().intValue());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (servlet.getEnabled() != null) &#123;</span><br><span class=\"line\">            wrapper.setEnabled(servlet.getEnabled().booleanValue());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        wrapper.setName(servlet.getServletName());</span><br><span class=\"line\">        Map&lt;String,String&gt; params = servlet.getParameterMap();</span><br><span class=\"line\">        for (Entry&lt;String, String&gt; entry : params.entrySet()) &#123;</span><br><span class=\"line\">            wrapper.addInitParameter(entry.getKey(), entry.getValue());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        wrapper.setRunAs(servlet.getRunAs());</span><br><span class=\"line\">        Set&lt;SecurityRoleRef&gt; roleRefs = servlet.getSecurityRoleRefs();</span><br><span class=\"line\">        for (SecurityRoleRef roleRef : roleRefs) &#123;</span><br><span class=\"line\">            wrapper.addSecurityReference(</span><br><span class=\"line\">                    roleRef.getName(), roleRef.getLink());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        wrapper.setServletClass(servlet.getServletClass());</span><br><span class=\"line\">        MultipartDef multipartdef = servlet.getMultipartDef();</span><br><span class=\"line\">        if (multipartdef != null) &#123;</span><br><span class=\"line\">            if (multipartdef.getMaxFileSize() != null &amp;&amp;</span><br><span class=\"line\">                    multipartdef.getMaxRequestSize()!= null &amp;&amp;</span><br><span class=\"line\">                    multipartdef.getFileSizeThreshold() != null) &#123;</span><br><span class=\"line\">                wrapper.setMultipartConfigElement(new MultipartConfigElement(</span><br><span class=\"line\">                        multipartdef.getLocation(),</span><br><span class=\"line\">                        Long.parseLong(multipartdef.getMaxFileSize()),</span><br><span class=\"line\">                        Long.parseLong(multipartdef.getMaxRequestSize()),</span><br><span class=\"line\">                        Integer.parseInt(</span><br><span class=\"line\">                                multipartdef.getFileSizeThreshold())));</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                wrapper.setMultipartConfigElement(new MultipartConfigElement(</span><br><span class=\"line\">                        multipartdef.getLocation()));</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (servlet.getAsyncSupported() != null) &#123;</span><br><span class=\"line\">            wrapper.setAsyncSupported(</span><br><span class=\"line\">                    servlet.getAsyncSupported().booleanValue());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        wrapper.setOverridable(servlet.isOverridable());</span><br><span class=\"line\">        context.addChild(wrapper);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-3、listen-filter-servlet的创建\"><a href=\"#3-3、listen-filter-servlet的创建\" class=\"headerlink\" title=\"3.3、listen filter servlet的创建\"></a>3.3、listen filter servlet的创建</h3><p>StandardContext.startInternal()方法进行web.xml解析后，就会进行listen和filter和servlet的创建</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public boolean listenerStart() &#123;</span><br><span class=\"line\">     // Instantiate the required listeners</span><br><span class=\"line\">    String listeners[] = findApplicationListeners();</span><br><span class=\"line\">    Object results[] = new Object[listeners.length];</span><br><span class=\"line\">    boolean ok = true;</span><br><span class=\"line\">    for (int i = 0; i &lt; results.length; i++) &#123;</span><br><span class=\"line\">        if (getLogger().isDebugEnabled())</span><br><span class=\"line\">            getLogger().debug(&quot; Configuring event listener class &apos;&quot; +</span><br><span class=\"line\">                listeners[i] + &quot;&apos;&quot;);</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            String listener = listeners[i];</span><br><span class=\"line\">            results[i] = getInstanceManager().newInstance(listener);</span><br><span class=\"line\">        &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">            t = ExceptionUtils.unwrapInvocationTargetException(t);</span><br><span class=\"line\">            ExceptionUtils.handleThrowable(t);</span><br><span class=\"line\">            getLogger().error(sm.getString(&quot;standardContext.applicationListener&quot;, listeners[i]), t);</span><br><span class=\"line\">            ok = false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">&#125;    </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">public boolean filterStart() &#123;</span><br><span class=\"line\">    if (getLogger().isDebugEnabled()) &#123;</span><br><span class=\"line\">        getLogger().debug(&quot;Starting filters&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Instantiate and record a FilterConfig for each defined filter</span><br><span class=\"line\">    boolean ok = true;</span><br><span class=\"line\">    synchronized (filterConfigs) &#123;</span><br><span class=\"line\">        filterConfigs.clear();</span><br><span class=\"line\">        for (Entry&lt;String,FilterDef&gt; entry : filterDefs.entrySet()) &#123;</span><br><span class=\"line\">            String name = entry.getKey();</span><br><span class=\"line\">            if (getLogger().isDebugEnabled()) &#123;</span><br><span class=\"line\">                getLogger().debug(&quot; Starting filter &apos;&quot; + name + &quot;&apos;&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                ApplicationFilterConfig filterConfig = new ApplicationFilterConfig(this, entry.getValue());</span><br><span class=\"line\">                filterConfigs.put(name, filterConfig);</span><br><span class=\"line\">            &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">                t = ExceptionUtils.unwrapInvocationTargetException(t);</span><br><span class=\"line\">                ExceptionUtils.handleThrowable(t);</span><br><span class=\"line\">                getLogger().error(sm.getString(</span><br><span class=\"line\">                        &quot;standardContext.filterStart&quot;, name), t);</span><br><span class=\"line\">                ok = false;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return ok;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当然这种加载只是针对配置了 load-on-startup 属性的 Servlet 而言，<br>其它一般 Servlet 的加载和初始化会推迟到真正请求访问 web 应用而第一次调用该 Servlet 时，<br>下面会看到这种情况下代码分析。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public boolean loadOnStartup(Container children[]) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Collect &quot;load on startup&quot; servlets that need to be initialized</span><br><span class=\"line\">    TreeMap&lt;Integer, ArrayList&lt;Wrapper&gt;&gt; map = new TreeMap&lt;&gt;();</span><br><span class=\"line\">    for (int i = 0; i &lt; children.length; i++) &#123;</span><br><span class=\"line\">        Wrapper wrapper = (Wrapper) children[i];</span><br><span class=\"line\">        int loadOnStartup = wrapper.getLoadOnStartup();</span><br><span class=\"line\">        if (loadOnStartup &lt; 0)</span><br><span class=\"line\">            continue;</span><br><span class=\"line\">        Integer key = Integer.valueOf(loadOnStartup);</span><br><span class=\"line\">        ArrayList&lt;Wrapper&gt; list = map.get(key);</span><br><span class=\"line\">        if (list == null) &#123;</span><br><span class=\"line\">            list = new ArrayList&lt;&gt;();</span><br><span class=\"line\">            map.put(key, list);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        list.add(wrapper);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Load the collected &quot;load on startup&quot; servlets</span><br><span class=\"line\">    for (ArrayList&lt;Wrapper&gt; list : map.values()) &#123;</span><br><span class=\"line\">        for (Wrapper wrapper : list) &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                wrapper.load();</span><br><span class=\"line\">            &#125; catch (ServletException e) &#123;            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//StandardWrapper</span><br><span class=\"line\">public synchronized void load() throws ServletException &#123;</span><br><span class=\"line\">    instance = loadServlet();</span><br><span class=\"line\">    if (!instanceInitialized) &#123;</span><br><span class=\"line\">        //Servlet servlet = instanceManager.newInstance(servletClass);</span><br><span class=\"line\">        initServlet(instance);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>servlet执行时机</p>\n<ol>\n<li>servlet = wrapper.allocate(); 调用StandardWrapper#allocate()方法，获取到servlet实例</li>\n<li>ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);为当前请求创建一个过滤链，（非异步情况下）并调用filterChain.doFilter(request.getRequest(), response.getResponse());</li>\n<li>filter#doFilter()、servlet#service()的执行是在filterChain.doFilter(request.getRequest(), response.getResponse());代码内部执行的。</li>\n</ol>\n</blockquote>\n<blockquote>\n<p>sevletRequestListener执行时机</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StandardHostValve.invoke</span><br><span class=\"line\">// context.fireRequestInitEvent，会去通知Listener</span><br><span class=\"line\">public final void invoke(Request request, Response response)</span><br><span class=\"line\">    throws IOException, ServletException &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        context.bind(Globals.IS_SECURITY_ENABLED, MY_CLASSLOADER);</span><br><span class=\"line\">        if (!asyncAtStart &amp;&amp; !context.fireRequestInitEvent(request.getRequest())) &#123;</span><br><span class=\"line\">            return;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;     </span><br><span class=\"line\">```   </span><br><span class=\"line\"></span><br><span class=\"line\">//请求过来时，会去执行listener</span><br></pre></td></tr></table></figure>\n\n<p>public boolean fireRequestInitEvent(ServletRequest request) {<br>    Object instances[] = getApplicationEventListeners();<br>    if ((instances != null) &amp;&amp; (instances.length &gt; 0)) {<br>        ServletRequestEvent event = new ServletRequestEvent(getServletContext(), request);<br>            try {<br>                listener.requestInitialized(event);<br>            } catch (Throwable t) {<br>            }<br>        }<br>    }<br>    return true;<br>}</p>\n<pre><code>\n# 五、请求执行过程\nStandardContext.startInternal()方法进行web.xml解析后，就会进行listen和filter和servlet（ServletWarpper）的创建\n1. StandardHostValve.invoke，会调用StanardContext.fireRequestInitEvent\n2. StandardContext.fireRequestInitEvent的 **listener（servletListener）** 的requestInitialized方法\n3. 然后StandardContextValve.invoke，根据URL选择servlet\n4. 然后StandardWrapperValve.invoke\n    1. 会先判断servlet是否存在，不存在则创建。非load-on-startup类型的servlet会在第一次请求时创建。\n    2. 执行过滤链，当所有的过滤器执行完成后，最后一个过滤器会调用步骤3\n    3. 执行servlet.service方法\n\n\n&gt; 多种listener\n1. ServletContextListener：监听ServletContext域对象的创建和销毁\n2. HttpSessionListener：接口用于监听HttpSession对象的创建和销毁\n3. ServletRequestListener：接口用于监听ServletRequest 对象的创建和销毁\n\n\nlistener -&gt; filter -&gt; servlet：执行顺序\n\n![启动过程](2019-12-22-tomcat-webxml解析/启动过程.png)\n\n\n\n</code></pre>","site":{"data":{}},"excerpt":"<h1 id=\"一、解析顺序\"><a href=\"#一、解析顺序\" class=\"headerlink\" title=\"一、解析顺序\"></a>一、解析顺序</h1><p>先解析server.xml，再解析web.xml</p>\n<h1 id=\"二、server-xml解析，在加载阶段\"><a href=\"#二、server-xml解析，在加载阶段\" class=\"headerlink\" title=\"二、server.xml解析，在加载阶段\"></a>二、server.xml解析，在加载阶段</h1><p>Catalina的load方法，此时会去解析server.xml文件</p>","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void load() &#123;</span><br><span class=\"line\">    // Create and execute our Digester</span><br><span class=\"line\">    Digester digester = createStartDigester();</span><br><span class=\"line\">    file = configFile();</span><br><span class=\"line\">    inputStream = new FileInputStream(file);</span><br><span class=\"line\">    inputSource = new InputSource(file.toURI().toURL().toString());</span><br><span class=\"line\">    inputSource.setByteStream(inputStream);</span><br><span class=\"line\">    digester.push(this);</span><br><span class=\"line\">    digester.parse(inputSource);//解析流，进行类</span><br><span class=\"line\">&#125;    </span><br><span class=\"line\"></span><br><span class=\"line\">protected Digester createStartDigester() &#123;</span><br><span class=\"line\">    long t1=System.currentTimeMillis();</span><br><span class=\"line\">    // Initialize the digester</span><br><span class=\"line\">    Digester digester = new Digester();</span><br><span class=\"line\">    digester.setValidating(false);</span><br><span class=\"line\">    digester.setRulesValidation(true);</span><br><span class=\"line\">    Map&lt;Class&lt;?&gt;, List&lt;String&gt;&gt; fakeAttributes = new HashMap&lt;&gt;();</span><br><span class=\"line\">    List&lt;String&gt; objectAttrs = new ArrayList&lt;&gt;();</span><br><span class=\"line\">    objectAttrs.add(&quot;className&quot;);</span><br><span class=\"line\">    fakeAttributes.put(Object.class, objectAttrs);</span><br><span class=\"line\">    // Ignore attribute added by Eclipse for its internal tracking</span><br><span class=\"line\">    List&lt;String&gt; contextAttrs = new ArrayList&lt;&gt;();</span><br><span class=\"line\">    contextAttrs.add(&quot;source&quot;);</span><br><span class=\"line\">    fakeAttributes.put(StandardContext.class, contextAttrs);</span><br><span class=\"line\">    digester.setFakeAttributes(fakeAttributes);</span><br><span class=\"line\">    digester.setUseContextClassLoader(true);</span><br><span class=\"line\"></span><br><span class=\"line\">    //创建StandardServer对象，设置其对象的属性，调用父节点Catalina的setServer方法将Server添加到Catalina中。</span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.core.StandardServer&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server&quot;,</span><br><span class=\"line\">                        &quot;setServer&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Server&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/GlobalNamingResources&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.deploy.NamingResourcesImpl&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/GlobalNamingResources&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/GlobalNamingResources&quot;,</span><br><span class=\"line\">                        &quot;setGlobalNamingResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.deploy.NamingResourcesImpl&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Listener&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Listener&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Listener&quot;,</span><br><span class=\"line\">                        &quot;addLifecycleListener&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.LifecycleListener&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.core.StandardService&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service&quot;,</span><br><span class=\"line\">                        &quot;addService&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Service&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Listener&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Listener&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Listener&quot;,</span><br><span class=\"line\">                        &quot;addLifecycleListener&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.LifecycleListener&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    //Executor</span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Executor&quot;,</span><br><span class=\"line\">                     &quot;org.apache.catalina.core.StandardThreadExecutor&quot;,</span><br><span class=\"line\">                     &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Executor&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Executor&quot;,</span><br><span class=\"line\">                        &quot;addExecutor&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Executor&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Connector&quot;,</span><br><span class=\"line\">                     new ConnectorCreateRule());</span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Connector&quot;,</span><br><span class=\"line\">                     new SetAllPropertiesRule(new String[]&#123;&quot;executor&quot;, &quot;sslImplementationName&quot;&#125;));</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector&quot;,</span><br><span class=\"line\">                        &quot;addConnector&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.connector.Connector&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/SSLHostConfig&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.net.SSLHostConfig&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/SSLHostConfig&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/SSLHostConfig&quot;,</span><br><span class=\"line\">            &quot;addSslHostConfig&quot;,</span><br><span class=\"line\">            &quot;org.apache.tomcat.util.net.SSLHostConfig&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Connector/SSLHostConfig/Certificate&quot;,</span><br><span class=\"line\">                     new CertificateCreateRule());</span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Connector/SSLHostConfig/Certificate&quot;,</span><br><span class=\"line\">                     new SetAllPropertiesRule(new String[]&#123;&quot;type&quot;&#125;));</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/SSLHostConfig/Certificate&quot;,</span><br><span class=\"line\">                        &quot;addCertificate&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.net.SSLHostConfigCertificate&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.net.openssl.OpenSSLConf&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf&quot;,</span><br><span class=\"line\">                        &quot;setOpenSslConf&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.net.openssl.OpenSSLConf&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.net.openssl.OpenSSLConfCmd&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/SSLHostConfig/OpenSSLConf/OpenSSLConfCmd&quot;,</span><br><span class=\"line\">                        &quot;addCmd&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.net.openssl.OpenSSLConfCmd&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/Listener&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/Listener&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/Listener&quot;,</span><br><span class=\"line\">                        &quot;addLifecycleListener&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.LifecycleListener&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    digester.addObjectCreate(&quot;Server/Service/Connector/UpgradeProtocol&quot;,</span><br><span class=\"line\">                              null, // MUST be specified in the element</span><br><span class=\"line\">                              &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(&quot;Server/Service/Connector/UpgradeProtocol&quot;);</span><br><span class=\"line\">    digester.addSetNext(&quot;Server/Service/Connector/UpgradeProtocol&quot;,</span><br><span class=\"line\">                        &quot;addUpgradeProtocol&quot;,</span><br><span class=\"line\">                        &quot;org.apache.coyote.UpgradeProtocol&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    // Add RuleSets for nested elements</span><br><span class=\"line\">    digester.addRuleSet(new NamingRuleSet(&quot;Server/GlobalNamingResources/&quot;));</span><br><span class=\"line\">    //EngineRuleSet中，将实例化StandardEngine</span><br><span class=\"line\">    digester.addRuleSet(new EngineRuleSet(&quot;Server/Service/&quot;));</span><br><span class=\"line\">    //HostRuleSet中，将实例化StandardHost</span><br><span class=\"line\">    digester.addRuleSet(new HostRuleSet(&quot;Server/Service/Engine/&quot;))</span><br><span class=\"line\">    //ContextRuleSet中，将实例化StandardContext</span><br><span class=\"line\">    digester.addRuleSet(new ContextRuleSet(&quot;Server/Service/Engine/Host/&quot;));</span><br><span class=\"line\">    addClusterRuleSet(digester, &quot;Server/Service/Engine/Host/Cluster/&quot;);</span><br><span class=\"line\">    digester.addRuleSet(new NamingRuleSet(&quot;Server/Service/Engine/Host/Context/&quot;));</span><br><span class=\"line\"></span><br><span class=\"line\">    // When the &apos;engine&apos; is found, set the parentClassLoader.</span><br><span class=\"line\">    digester.addRule(&quot;Server/Service/Engine&quot;,</span><br><span class=\"line\">                     new SetParentClassLoaderRule(parentClassLoader));</span><br><span class=\"line\">    addClusterRuleSet(digester, &quot;Server/Service/Engine/Cluster/&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    long t2=System.currentTimeMillis();</span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;Digester for server.xml created &quot; + ( t2-t1 ));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return digester;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>server.xml的解析，主要是去创建相应的实例对象，并设置层级关系。</p>\n<h2 id=\"2-1、StandardContext的创建时机\"><a href=\"#2-1、StandardContext的创建时机\" class=\"headerlink\" title=\"2.1、StandardContext的创建时机\"></a>2.1、StandardContext的创建时机</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ContextRuleSet</span><br><span class=\"line\">/**</span><br><span class=\"line\"> * &lt;p&gt;Add the set of Rule instances defined in this RuleSet to the</span><br><span class=\"line\"> * specified &lt;code&gt;Digester&lt;/code&gt; instance, associating them with</span><br><span class=\"line\"> * our namespace URI (if any).  This method should only be called</span><br><span class=\"line\"> * by a Digester instance.&lt;/p&gt;</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param digester Digester instance to which the new Rule instances</span><br><span class=\"line\"> *  should be added.</span><br><span class=\"line\"> */</span><br><span class=\"line\"> //只能被Digester</span><br><span class=\"line\">public void addRuleInstances(Digester digester) &#123;</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 1. 创建Context实例，通过server.xml配置Context时，create是true，需要创建Context实例；通过HostConfig创建Context时，create为false，此时仅需要解析节点即可</span><br><span class=\"line\">    if (create) &#123;</span><br><span class=\"line\">        digester.addObjectCreate(prefix + &quot;Context&quot;,</span><br><span class=\"line\">                &quot;org.apache.catalina.core.StandardContext&quot;, &quot;className&quot;);</span><br><span class=\"line\">        digester.addSetProperties(prefix + &quot;Context&quot;);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        digester.addSetProperties(prefix + &quot;Context&quot;, new String[]&#123;&quot;path&quot;, &quot;docBase&quot;&#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">    if (create) &#123;</span><br><span class=\"line\">        digester.addRule(prefix + &quot;Context&quot;,</span><br><span class=\"line\">                         new LifecycleListenerRule</span><br><span class=\"line\">                             (&quot;org.apache.catalina.startup.ContextConfig&quot;,</span><br><span class=\"line\">                              &quot;configClass&quot;));</span><br><span class=\"line\">        digester.addSetNext(prefix + &quot;Context&quot;,</span><br><span class=\"line\">                            &quot;addChild&quot;,</span><br><span class=\"line\">                            &quot;org.apache.catalina.Container&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 2. 为Context添加生命周期监听器</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Listener&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Listener&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Listener&quot;,</span><br><span class=\"line\">                        &quot;addLifecycleListener&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.LifecycleListener&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 3. 为Context指定类加载器，默认为org.apache.catalina.loader.WebappLoader</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Loader&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.loader.WebappLoader&quot;,</span><br><span class=\"line\">                        &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Loader&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Loader&quot;,</span><br><span class=\"line\">                        &quot;setLoader&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Loader&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 4. 为Context添加会话管理器，默认实现为StandardManager</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Manager&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.session.StandardManager&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Manager&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Manager&quot;,</span><br><span class=\"line\">                        &quot;setManager&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Manager&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Manager/Store&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Manager/Store&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Manager/Store&quot;,</span><br><span class=\"line\">                        &quot;setStore&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Store&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Manager/SessionIdGenerator&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.util.StandardSessionIdGenerator&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Manager/SessionIdGenerator&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Manager/SessionIdGenerator&quot;,</span><br><span class=\"line\">                        &quot;setSessionIdGenerator&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.SessionIdGenerator&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    //5. 为Context添加初始化参数，通过该配置，为Context添加初始化参数</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Parameter&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.descriptor.web.ApplicationParameter&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Parameter&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Parameter&quot;,</span><br><span class=\"line\">                        &quot;addApplicationParameter&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.descriptor.web.ApplicationParameter&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 6. 为Context添加安全配置以及web资源配置</span><br><span class=\"line\">    digester.addRuleSet(new RealmRuleSet(prefix + &quot;Context/&quot;));</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Resources&quot;,</span><br><span class=\"line\">                             &quot;org.apache.catalina.webresources.StandardRoot&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Resources&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Resources&quot;,</span><br><span class=\"line\">                        &quot;setResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.WebResourceRoot&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Resources/PreResources&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Resources/PreResources&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Resources/PreResources&quot;,</span><br><span class=\"line\">                        &quot;addPreResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.WebResourceSet&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Resources/JarResources&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Resources/JarResources&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Resources/JarResources&quot;,</span><br><span class=\"line\">                        &quot;addJarResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.WebResourceSet&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Resources/PostResources&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Resources/PostResources&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Resources/PostResources&quot;,</span><br><span class=\"line\">                        &quot;addPostResources&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.WebResourceSet&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 7. 为Context添加资源连接，默认为ContextResourceLink，用于J2EE命名服务</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/ResourceLink&quot;,</span><br><span class=\"line\">            &quot;org.apache.tomcat.util.descriptor.web.ContextResourceLink&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/ResourceLink&quot;);</span><br><span class=\"line\">    digester.addRule(prefix + &quot;Context/ResourceLink&quot;,</span><br><span class=\"line\">            new SetNextNamingRule(&quot;addResourceLink&quot;,</span><br><span class=\"line\">                    &quot;org.apache.tomcat.util.descriptor.web.ContextResourceLink&quot;));</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 8. 为Context添加Valve</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/Valve&quot;,</span><br><span class=\"line\">                             null, // MUST be specified in the element</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/Valve&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/Valve&quot;,</span><br><span class=\"line\">                        &quot;addValve&quot;,</span><br><span class=\"line\">                        &quot;org.apache.catalina.Valve&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 9. 为Context添加守护资源配置</span><br><span class=\"line\">    digester.addCallMethod(prefix + &quot;Context/WatchedResource&quot;,</span><br><span class=\"line\">                           &quot;addWatchedResource&quot;, 0);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addCallMethod(prefix + &quot;Context/WrapperLifecycle&quot;,</span><br><span class=\"line\">                           &quot;addWrapperLifecycle&quot;, 0);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addCallMethod(prefix + &quot;Context/WrapperListener&quot;,</span><br><span class=\"line\">                           &quot;addWrapperListener&quot;, 0);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/JarScanner&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.scan.StandardJarScanner&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/JarScanner&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/JarScanner&quot;,</span><br><span class=\"line\">                        &quot;setJarScanner&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.JarScanner&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/JarScanner/JarScanFilter&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.scan.StandardJarScanFilter&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/JarScanner/JarScanFilter&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/JarScanner/JarScanFilter&quot;,</span><br><span class=\"line\">                        &quot;setJarScanFilter&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.JarScanFilter&quot;);</span><br><span class=\"line\"> </span><br><span class=\"line\">    // 10. 为Context添加Cookie处理器</span><br><span class=\"line\">    digester.addObjectCreate(prefix + &quot;Context/CookieProcessor&quot;,</span><br><span class=\"line\">                             &quot;org.apache.tomcat.util.http.Rfc6265CookieProcessor&quot;,</span><br><span class=\"line\">                             &quot;className&quot;);</span><br><span class=\"line\">    digester.addSetProperties(prefix + &quot;Context/CookieProcessor&quot;);</span><br><span class=\"line\">    digester.addSetNext(prefix + &quot;Context/CookieProcessor&quot;,</span><br><span class=\"line\">                        &quot;setCookieProcessor&quot;,</span><br><span class=\"line\">                        &quot;org.apache.tomcat.util.http.CookieProcessor&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>ContextRuleSet定义了创建规则，digester会通过规则创建StandardContext对象</p>\n<h1 id=\"三、web-xml的解析时机，在启动阶段\"><a href=\"#三、web-xml的解析时机，在启动阶段\" class=\"headerlink\" title=\"三、web.xml的解析时机，在启动阶段\"></a>三、web.xml的解析时机，在启动阶段</h1><h2 id=\"1-StandardServer-startInternal-方法\"><a href=\"#1-StandardServer-startInternal-方法\" class=\"headerlink\" title=\"1. StandardServer.startInternal()方法\"></a>1. StandardServer.startInternal()方法</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    //通知容器启动事件</span><br><span class=\"line\">    fireLifecycleEvent(CONFIGURE_START_EVENT, null);</span><br><span class=\"line\">    setState(LifecycleState.STARTING);</span><br><span class=\"line\">    globalNamingResources.start();</span><br><span class=\"line\">    // Start our defined Services</span><br><span class=\"line\">    synchronized (servicesLock) &#123;</span><br><span class=\"line\">        for (int i = 0; i &lt; services.length; i++) &#123;</span><br><span class=\"line\">            services[i].start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-StandardContext-startInternal-方法\"><a href=\"#2-StandardContext-startInternal-方法\" class=\"headerlink\" title=\"2. StandardContext.startInternal()方法\"></a>2. StandardContext.startInternal()方法</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected synchronized void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Notify our interested LifecycleListeners</span><br><span class=\"line\">    //1、通知容器启动事件，去解析web.xml</span><br><span class=\"line\">    fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null);</span><br><span class=\"line\">    //2、进行listener的创建和启动</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        if (!listenerStart()) &#123;</span><br><span class=\"line\">            log.error(sm.getString(&quot;standardContext.listenerFail&quot;));</span><br><span class=\"line\">            ok = false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // 3、filter的创建和启动</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        if (!filterStart()) &#123;</span><br><span class=\"line\">            log.error(sm.getString(&quot;standardContext.filterFail&quot;));</span><br><span class=\"line\">            ok = false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //加载和实例化servlet</span><br><span class=\"line\">    // Load and initialize all &quot;load on startup&quot; servlets</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        if (!loadOnStartup(findChildren()))&#123;</span><br><span class=\"line\">            log.error(sm.getString(&quot;standardContext.servletFail&quot;));</span><br><span class=\"line\">            ok = false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、ContextConfig-lifecycleEvent-方法\"><a href=\"#3、ContextConfig-lifecycleEvent-方法\" class=\"headerlink\" title=\"3、ContextConfig.lifecycleEvent()方法\"></a>3、ContextConfig.lifecycleEvent()方法</h2><p>触发事件，进行文件的解析</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void lifecycleEvent(LifecycleEvent event) &#123;</span><br><span class=\"line\">    // Process the event that has occurred</span><br><span class=\"line\">    if (event.getType().equals(Lifecycle.CONFIGURE_START_EVENT)) &#123;</span><br><span class=\"line\">        //进行配置文件的解析，ContextConfig事件</span><br><span class=\"line\">        configureStart();</span><br><span class=\"line\">    &#125; else if (event.getType().equals(Lifecycle.BEFORE_START_EVENT)) &#123;</span><br><span class=\"line\">     </span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-1、ContextConfig事件\"><a href=\"#3-1、ContextConfig事件\" class=\"headerlink\" title=\"3.1、ContextConfig事件\"></a>3.1、ContextConfig事件</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Process a &quot;contextConfig&quot; event for this Context.</span><br><span class=\"line\"> */</span><br><span class=\"line\">protected synchronized void configureStart() &#123;</span><br><span class=\"line\">    // Called from StandardContext.start()</span><br><span class=\"line\"></span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(sm.getString(&quot;contextConfig.start&quot;));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(sm.getString(&quot;contextConfig.xmlSettings&quot;,</span><br><span class=\"line\">                context.getName(),</span><br><span class=\"line\">                Boolean.valueOf(context.getXmlValidation()),</span><br><span class=\"line\">                Boolean.valueOf(context.getXmlNamespaceAware())));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //进行web.xml的具体解析工作</span><br><span class=\"line\">    webConfig();</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!context.getIgnoreAnnotations()) &#123;</span><br><span class=\"line\">        applicationAnnotationsConfig();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        validateSecurityRoles();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Configure an authenticator if we need one</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        authenticatorConfig();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Dump the contents of this pipeline if requested</span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;Pipeline Configuration:&quot;);</span><br><span class=\"line\">        Pipeline pipeline = context.getPipeline();</span><br><span class=\"line\">        Valve valves[] = null;</span><br><span class=\"line\">        if (pipeline != null) &#123;</span><br><span class=\"line\">            valves = pipeline.getValves();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (valves != null) &#123;</span><br><span class=\"line\">            for (int i = 0; i &lt; valves.length; i++) &#123;</span><br><span class=\"line\">                log.debug(&quot;  &quot; + valves[i].getClass().getName());</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        log.debug(&quot;======================&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Make our application available if no problems were encountered</span><br><span class=\"line\">    if (ok) &#123;</span><br><span class=\"line\">        context.setConfigured(true);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        log.error(sm.getString(&quot;contextConfig.unavailable&quot;));</span><br><span class=\"line\">        context.setConfigured(false);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-2、webConfig-方法，会根据web-xml中的配置进行listen，filter，servlet的信息设置\"><a href=\"#3-2、webConfig-方法，会根据web-xml中的配置进行listen，filter，servlet的信息设置\" class=\"headerlink\" title=\"3.2、webConfig()方法，会根据web.xml中的配置进行listen，filter，servlet的信息设置\"></a>3.2、webConfig()方法，会根据web.xml中的配置进行listen，filter，servlet的信息设置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private void configureContext(WebXml webxml) &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    //filter的解析，此处未进行创建</span><br><span class=\"line\">    for (FilterDef filter : webxml.getFilters().values()) &#123;</span><br><span class=\"line\">        if (filter.getAsyncSupported() == null) &#123;</span><br><span class=\"line\">            filter.setAsyncSupported(&quot;false&quot;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        context.addFilterDef(filter);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //listen解析，此处未进行创建</span><br><span class=\"line\">    for (String listener : webxml.getListeners()) &#123;</span><br><span class=\"line\">        context.addApplicationListener(listener);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    //创建wraper，servlet并未创建</span><br><span class=\"line\">    for (ServletDef servlet : webxml.getServlets().values()) &#123;</span><br><span class=\"line\">        Wrapper wrapper = context.createWrapper();</span><br><span class=\"line\">        if (servlet.getLoadOnStartup() != null) &#123;</span><br><span class=\"line\">            wrapper.setLoadOnStartup(servlet.getLoadOnStartup().intValue());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (servlet.getEnabled() != null) &#123;</span><br><span class=\"line\">            wrapper.setEnabled(servlet.getEnabled().booleanValue());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        wrapper.setName(servlet.getServletName());</span><br><span class=\"line\">        Map&lt;String,String&gt; params = servlet.getParameterMap();</span><br><span class=\"line\">        for (Entry&lt;String, String&gt; entry : params.entrySet()) &#123;</span><br><span class=\"line\">            wrapper.addInitParameter(entry.getKey(), entry.getValue());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        wrapper.setRunAs(servlet.getRunAs());</span><br><span class=\"line\">        Set&lt;SecurityRoleRef&gt; roleRefs = servlet.getSecurityRoleRefs();</span><br><span class=\"line\">        for (SecurityRoleRef roleRef : roleRefs) &#123;</span><br><span class=\"line\">            wrapper.addSecurityReference(</span><br><span class=\"line\">                    roleRef.getName(), roleRef.getLink());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        wrapper.setServletClass(servlet.getServletClass());</span><br><span class=\"line\">        MultipartDef multipartdef = servlet.getMultipartDef();</span><br><span class=\"line\">        if (multipartdef != null) &#123;</span><br><span class=\"line\">            if (multipartdef.getMaxFileSize() != null &amp;&amp;</span><br><span class=\"line\">                    multipartdef.getMaxRequestSize()!= null &amp;&amp;</span><br><span class=\"line\">                    multipartdef.getFileSizeThreshold() != null) &#123;</span><br><span class=\"line\">                wrapper.setMultipartConfigElement(new MultipartConfigElement(</span><br><span class=\"line\">                        multipartdef.getLocation(),</span><br><span class=\"line\">                        Long.parseLong(multipartdef.getMaxFileSize()),</span><br><span class=\"line\">                        Long.parseLong(multipartdef.getMaxRequestSize()),</span><br><span class=\"line\">                        Integer.parseInt(</span><br><span class=\"line\">                                multipartdef.getFileSizeThreshold())));</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                wrapper.setMultipartConfigElement(new MultipartConfigElement(</span><br><span class=\"line\">                        multipartdef.getLocation()));</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (servlet.getAsyncSupported() != null) &#123;</span><br><span class=\"line\">            wrapper.setAsyncSupported(</span><br><span class=\"line\">                    servlet.getAsyncSupported().booleanValue());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        wrapper.setOverridable(servlet.isOverridable());</span><br><span class=\"line\">        context.addChild(wrapper);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-3、listen-filter-servlet的创建\"><a href=\"#3-3、listen-filter-servlet的创建\" class=\"headerlink\" title=\"3.3、listen filter servlet的创建\"></a>3.3、listen filter servlet的创建</h3><p>StandardContext.startInternal()方法进行web.xml解析后，就会进行listen和filter和servlet的创建</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public boolean listenerStart() &#123;</span><br><span class=\"line\">     // Instantiate the required listeners</span><br><span class=\"line\">    String listeners[] = findApplicationListeners();</span><br><span class=\"line\">    Object results[] = new Object[listeners.length];</span><br><span class=\"line\">    boolean ok = true;</span><br><span class=\"line\">    for (int i = 0; i &lt; results.length; i++) &#123;</span><br><span class=\"line\">        if (getLogger().isDebugEnabled())</span><br><span class=\"line\">            getLogger().debug(&quot; Configuring event listener class &apos;&quot; +</span><br><span class=\"line\">                listeners[i] + &quot;&apos;&quot;);</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            String listener = listeners[i];</span><br><span class=\"line\">            results[i] = getInstanceManager().newInstance(listener);</span><br><span class=\"line\">        &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">            t = ExceptionUtils.unwrapInvocationTargetException(t);</span><br><span class=\"line\">            ExceptionUtils.handleThrowable(t);</span><br><span class=\"line\">            getLogger().error(sm.getString(&quot;standardContext.applicationListener&quot;, listeners[i]), t);</span><br><span class=\"line\">            ok = false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">&#125;    </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">public boolean filterStart() &#123;</span><br><span class=\"line\">    if (getLogger().isDebugEnabled()) &#123;</span><br><span class=\"line\">        getLogger().debug(&quot;Starting filters&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Instantiate and record a FilterConfig for each defined filter</span><br><span class=\"line\">    boolean ok = true;</span><br><span class=\"line\">    synchronized (filterConfigs) &#123;</span><br><span class=\"line\">        filterConfigs.clear();</span><br><span class=\"line\">        for (Entry&lt;String,FilterDef&gt; entry : filterDefs.entrySet()) &#123;</span><br><span class=\"line\">            String name = entry.getKey();</span><br><span class=\"line\">            if (getLogger().isDebugEnabled()) &#123;</span><br><span class=\"line\">                getLogger().debug(&quot; Starting filter &apos;&quot; + name + &quot;&apos;&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                ApplicationFilterConfig filterConfig = new ApplicationFilterConfig(this, entry.getValue());</span><br><span class=\"line\">                filterConfigs.put(name, filterConfig);</span><br><span class=\"line\">            &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">                t = ExceptionUtils.unwrapInvocationTargetException(t);</span><br><span class=\"line\">                ExceptionUtils.handleThrowable(t);</span><br><span class=\"line\">                getLogger().error(sm.getString(</span><br><span class=\"line\">                        &quot;standardContext.filterStart&quot;, name), t);</span><br><span class=\"line\">                ok = false;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return ok;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当然这种加载只是针对配置了 load-on-startup 属性的 Servlet 而言，<br>其它一般 Servlet 的加载和初始化会推迟到真正请求访问 web 应用而第一次调用该 Servlet 时，<br>下面会看到这种情况下代码分析。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public boolean loadOnStartup(Container children[]) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Collect &quot;load on startup&quot; servlets that need to be initialized</span><br><span class=\"line\">    TreeMap&lt;Integer, ArrayList&lt;Wrapper&gt;&gt; map = new TreeMap&lt;&gt;();</span><br><span class=\"line\">    for (int i = 0; i &lt; children.length; i++) &#123;</span><br><span class=\"line\">        Wrapper wrapper = (Wrapper) children[i];</span><br><span class=\"line\">        int loadOnStartup = wrapper.getLoadOnStartup();</span><br><span class=\"line\">        if (loadOnStartup &lt; 0)</span><br><span class=\"line\">            continue;</span><br><span class=\"line\">        Integer key = Integer.valueOf(loadOnStartup);</span><br><span class=\"line\">        ArrayList&lt;Wrapper&gt; list = map.get(key);</span><br><span class=\"line\">        if (list == null) &#123;</span><br><span class=\"line\">            list = new ArrayList&lt;&gt;();</span><br><span class=\"line\">            map.put(key, list);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        list.add(wrapper);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Load the collected &quot;load on startup&quot; servlets</span><br><span class=\"line\">    for (ArrayList&lt;Wrapper&gt; list : map.values()) &#123;</span><br><span class=\"line\">        for (Wrapper wrapper : list) &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                wrapper.load();</span><br><span class=\"line\">            &#125; catch (ServletException e) &#123;            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//StandardWrapper</span><br><span class=\"line\">public synchronized void load() throws ServletException &#123;</span><br><span class=\"line\">    instance = loadServlet();</span><br><span class=\"line\">    if (!instanceInitialized) &#123;</span><br><span class=\"line\">        //Servlet servlet = instanceManager.newInstance(servletClass);</span><br><span class=\"line\">        initServlet(instance);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>servlet执行时机</p>\n<ol>\n<li>servlet = wrapper.allocate(); 调用StandardWrapper#allocate()方法，获取到servlet实例</li>\n<li>ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);为当前请求创建一个过滤链，（非异步情况下）并调用filterChain.doFilter(request.getRequest(), response.getResponse());</li>\n<li>filter#doFilter()、servlet#service()的执行是在filterChain.doFilter(request.getRequest(), response.getResponse());代码内部执行的。</li>\n</ol>\n</blockquote>\n<blockquote>\n<p>sevletRequestListener执行时机</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StandardHostValve.invoke</span><br><span class=\"line\">// context.fireRequestInitEvent，会去通知Listener</span><br><span class=\"line\">public final void invoke(Request request, Response response)</span><br><span class=\"line\">    throws IOException, ServletException &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        context.bind(Globals.IS_SECURITY_ENABLED, MY_CLASSLOADER);</span><br><span class=\"line\">        if (!asyncAtStart &amp;&amp; !context.fireRequestInitEvent(request.getRequest())) &#123;</span><br><span class=\"line\">            return;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;     </span><br><span class=\"line\">```   </span><br><span class=\"line\"></span><br><span class=\"line\">//请求过来时，会去执行listener</span><br></pre></td></tr></table></figure>\n\n<p>public boolean fireRequestInitEvent(ServletRequest request) {<br>    Object instances[] = getApplicationEventListeners();<br>    if ((instances != null) &amp;&amp; (instances.length &gt; 0)) {<br>        ServletRequestEvent event = new ServletRequestEvent(getServletContext(), request);<br>            try {<br>                listener.requestInitialized(event);<br>            } catch (Throwable t) {<br>            }<br>        }<br>    }<br>    return true;<br>}</p>\n<pre><code>\n# 五、请求执行过程\nStandardContext.startInternal()方法进行web.xml解析后，就会进行listen和filter和servlet（ServletWarpper）的创建\n1. StandardHostValve.invoke，会调用StanardContext.fireRequestInitEvent\n2. StandardContext.fireRequestInitEvent的 **listener（servletListener）** 的requestInitialized方法\n3. 然后StandardContextValve.invoke，根据URL选择servlet\n4. 然后StandardWrapperValve.invoke\n    1. 会先判断servlet是否存在，不存在则创建。非load-on-startup类型的servlet会在第一次请求时创建。\n    2. 执行过滤链，当所有的过滤器执行完成后，最后一个过滤器会调用步骤3\n    3. 执行servlet.service方法\n\n\n&gt; 多种listener\n1. ServletContextListener：监听ServletContext域对象的创建和销毁\n2. HttpSessionListener：接口用于监听HttpSession对象的创建和销毁\n3. ServletRequestListener：接口用于监听ServletRequest 对象的创建和销毁\n\n\nlistener -&gt; filter -&gt; servlet：执行顺序\n\n![启动过程](2019-12-22-tomcat-webxml解析/启动过程.png)\n\n\n\n</code></pre>"},{"title":"2020-03-29-磁盘局部性原理","date":"2020-03-29T09:15:35.000Z","_content":"\n\n# 一、局部性原理\n* 产生背景：CPU运行速度快，而去内存或者磁盘中获取数据慢，为了解决运行速度的差级问题，CPU缓存中（L1、L2)希望有CPU需要使用的数据。\n* 解决方案：\n>* 1、空间局部性：每次读取，都会将相邻的数据读取进来。称为预取。\n>* 2、时间局部性：\n\n<!--more-->  \n\n# 二、磁盘\n![dmq](2020-03-29-磁盘局部性原理/磁盘.png)\n\n磁头必须飞行在盘面上方，而不是接触盘面，这种位置可避免擦伤磁性涂层\n\n\n# 三、局部性原理和磁盘预读\n磁盘数据读取，根据扇区号去磁盘读取。   \n每次读取的数据量，是页的整数倍（内存页大小4k），物理内存和磁盘以页来交换数据。当程序发现内存中没有数据，将产生缺页中断，此时操作系统会向磁盘发出读盘信号。磁盘会根据数据的起始位置并向后读取一页或者几页读入内存中。\n>* 1、以页来交换数据。\n>* 2、每次读取是页的整数倍。","source":"_posts/2020-03-29-磁盘局部性原理.md","raw":"---\ntitle: 2020-03-29-磁盘局部性原理\ndate: 2020-03-29 17:15:35\ntags: Linux\n---\n\n\n# 一、局部性原理\n* 产生背景：CPU运行速度快，而去内存或者磁盘中获取数据慢，为了解决运行速度的差级问题，CPU缓存中（L1、L2)希望有CPU需要使用的数据。\n* 解决方案：\n>* 1、空间局部性：每次读取，都会将相邻的数据读取进来。称为预取。\n>* 2、时间局部性：\n\n<!--more-->  \n\n# 二、磁盘\n![dmq](2020-03-29-磁盘局部性原理/磁盘.png)\n\n磁头必须飞行在盘面上方，而不是接触盘面，这种位置可避免擦伤磁性涂层\n\n\n# 三、局部性原理和磁盘预读\n磁盘数据读取，根据扇区号去磁盘读取。   \n每次读取的数据量，是页的整数倍（内存页大小4k），物理内存和磁盘以页来交换数据。当程序发现内存中没有数据，将产生缺页中断，此时操作系统会向磁盘发出读盘信号。磁盘会根据数据的起始位置并向后读取一页或者几页读入内存中。\n>* 1、以页来交换数据。\n>* 2、每次读取是页的整数倍。","slug":"2020-03-29-磁盘局部性原理","published":1,"updated":"2024-10-14T09:38:12.044Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnw9001oa13kow4gwk3r","content":"<h1 id=\"一、局部性原理\"><a href=\"#一、局部性原理\" class=\"headerlink\" title=\"一、局部性原理\"></a>一、局部性原理</h1><ul>\n<li>产生背景：CPU运行速度快，而去内存或者磁盘中获取数据慢，为了解决运行速度的差级问题，CPU缓存中（L1、L2)希望有CPU需要使用的数据。</li>\n<li>解决方案：<blockquote>\n<ul>\n<li>1、空间局部性：每次读取，都会将相邻的数据读取进来。称为预取。</li>\n<li>2、时间局部性：</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<a id=\"more\"></a>  \n\n<h1 id=\"二、磁盘\"><a href=\"#二、磁盘\" class=\"headerlink\" title=\"二、磁盘\"></a>二、磁盘</h1><p><img src=\"/2020/03/29/2020-03-29-磁盘局部性原理/%E7%A3%81%E7%9B%98.png\" alt=\"dmq\"></p>\n<p>磁头必须飞行在盘面上方，而不是接触盘面，这种位置可避免擦伤磁性涂层</p>\n<h1 id=\"三、局部性原理和磁盘预读\"><a href=\"#三、局部性原理和磁盘预读\" class=\"headerlink\" title=\"三、局部性原理和磁盘预读\"></a>三、局部性原理和磁盘预读</h1><p>磁盘数据读取，根据扇区号去磁盘读取。<br>每次读取的数据量，是页的整数倍（内存页大小4k），物理内存和磁盘以页来交换数据。当程序发现内存中没有数据，将产生缺页中断，此时操作系统会向磁盘发出读盘信号。磁盘会根据数据的起始位置并向后读取一页或者几页读入内存中。</p>\n<blockquote>\n<ul>\n<li>1、以页来交换数据。</li>\n<li>2、每次读取是页的整数倍。</li>\n</ul>\n</blockquote>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、局部性原理\"><a href=\"#一、局部性原理\" class=\"headerlink\" title=\"一、局部性原理\"></a>一、局部性原理</h1><ul>\n<li>产生背景：CPU运行速度快，而去内存或者磁盘中获取数据慢，为了解决运行速度的差级问题，CPU缓存中（L1、L2)希望有CPU需要使用的数据。</li>\n<li>解决方案：<blockquote>\n<ul>\n<li>1、空间局部性：每次读取，都会将相邻的数据读取进来。称为预取。</li>\n<li>2、时间局部性：</li>\n</ul>\n</blockquote>\n</li>\n</ul>","more":"<h1 id=\"二、磁盘\"><a href=\"#二、磁盘\" class=\"headerlink\" title=\"二、磁盘\"></a>二、磁盘</h1><p><img src=\"/2020/03/29/2020-03-29-磁盘局部性原理/%E7%A3%81%E7%9B%98.png\" alt=\"dmq\"></p>\n<p>磁头必须飞行在盘面上方，而不是接触盘面，这种位置可避免擦伤磁性涂层</p>\n<h1 id=\"三、局部性原理和磁盘预读\"><a href=\"#三、局部性原理和磁盘预读\" class=\"headerlink\" title=\"三、局部性原理和磁盘预读\"></a>三、局部性原理和磁盘预读</h1><p>磁盘数据读取，根据扇区号去磁盘读取。<br>每次读取的数据量，是页的整数倍（内存页大小4k），物理内存和磁盘以页来交换数据。当程序发现内存中没有数据，将产生缺页中断，此时操作系统会向磁盘发出读盘信号。磁盘会根据数据的起始位置并向后读取一页或者几页读入内存中。</p>\n<blockquote>\n<ul>\n<li>1、以页来交换数据。</li>\n<li>2、每次读取是页的整数倍。</li>\n</ul>\n</blockquote>"},{"title":"tomcat启动过程","date":"2019-12-21T12:19:03.000Z","_content":"\n# 一、启动过程\n执行start.sh，实际将执行catalina.sh\njava命令执行Bootstrap类的main方法，将start作为参数传入\nBoostrap:\n\n<!--more-->\n\n```\npublic static void main(String args[]) {\n    synchronized (daemonLock) {\n        Bootstrap daemon = new Bootstrap();\n        if (command.equals(\"startd\")) {\n            args[args.length - 1] = \"start\";\n            daemon.load(args);\n            daemon.start();\n        }\n    }\n```\n执行Boostrap的main方法，此时tomcat就在JVM作为一个线程启动了    \n\n执行start方法\n```\npublic void start() throws Exception {\n    Method method = catalinaDaemon.getClass().getMethod(\"start\", (Class [])null);\n    method.invoke(catalinaDaemon, (Object [])null);\n}\n```\n通过反射，执行catlinaDaemon的start方法    \n\n# 二、start流程\n\n## 2.1、Catalina:\n```\npublic void start() {\n    // Start the new server\n    try {\n        getServer().start();\n    } catch (LifecycleException e) {\n}\n```\n进行服务的初始化\n\n## 2.2、StandardServer:\n实际的server实现是StandardServer\n```\nprotected void startInternal() throws LifecycleException {\n    // Start our defined Services\n    synchronized (servicesLock) {\n        for (int i = 0; i < services.length; i++) {\n            services[i].start();\n        }\n    }\n}\n```\n从server的启动上看，一个server有多个service\n\n## 2.3、StandardService:\n实际的service实现是StandardService\n```\nprotected void startInternal() throws LifecycleException {\n    // Start our defined Container first\n    if (engine != null) {\n        synchronized (engine) {\n            engine.start();\n        }\n    }\n    synchronized (executors) {\n        for (Executor executor: executors) {\n            executor.start();\n        }\n    }\n    mapperListener.start();\n    // Start our defined Connectors second\n    synchronized (connectorsLock) {\n        for (Connector connector: connectors) {\n            try {\n                // If it has already failed, don't try and start it\n                if (connector.getState() != LifecycleState.FAILED) {\n                    connector.start();\n                }\n            } catch (Exception e) {\n            }\n        }\n    }\n}\n```\n1. service执行engine的启动。(engine继承Container，所以实际是进行container的初始化)\n2. 然后创建一组线程池。executor是Tomcat自己实现的线程池。【此时会去创建具体的工作线程】\n3. 然后进行连接器的初始化（一组连接器，server.xml中可以配置）\n\n\n\n## 2.4、Executor---StandardThreadExecutor\n```\nprotected void startInternal() throws LifecycleException {\n    taskqueue = new TaskQueue(maxQueueSize);\n    TaskThreadFactory tf = new TaskThreadFactory(namePrefix,daemon,getThreadPriority());\n    executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), maxIdleTime, TimeUnit.MILLISECONDS,taskqueue, tf);\n    executor.setThreadRenewalDelay(threadRenewalDelay);\n    if (prestartminSpareThreads) {\n        executor.prestartAllCoreThreads();\n    }\n    taskqueue.setParent(executor);\n    setState(LifecycleState.STARTING);\n}\n```\n1. 创建任务队列\n2. 创建工作线程\n\n## 2.5、Connector\n连接器的启动\n```\nprotected void startInternal() throws LifecycleException {\n    try {\n        protocolHandler.start();//启动协议处理器\n    } catch (Exception e) {\n    }\n```\n   \n## 2.6、protocolHandler ---> AbstractHProtocal\n协议处理器的启动。 \n```\npublic void start() throws Exception {\n    endpoint.start();//启动端口\n}\n```\n\n## 2.7、endpoint ---> AbstractEndpoint --->  NIOEndpoint\n终端的启动\n```\n@Override\npublic void startInternal() throws Exception {\n\n    if (!running) {\n                processorCache = new SynchronizedStack<>(SynchronizedStack.DEFAULT_SIZE,\n                socketProperties.getProcessorCache());\n        eventCache = new SynchronizedStack<>(SynchronizedStack.DEFAULT_SIZE,\n                        socketProperties.getEventCache());\n        nioChannels = new SynchronizedStack<>(SynchronizedStack.DEFAULT_SIZE,\n                socketProperties.getBufferPool());\n        // Create worker collection\n        if ( getExecutor() == null ) {\n            createExecutor();\n        }\n        initializeConnectionLatch();\n        // Start poller threads【轮询线程】\n        pollers = new Poller[getPollerThreadCount()];\n        for (int i=0; i<pollers.length; i++) {\n            pollers[i] = new Poller();\n            Thread pollerThread = new Thread(pollers[i], getName() + \"-ClientPoller-\"+i);\n            pollerThread.setPriority(threadPriority);\n            pollerThread.setDaemon(true);\n            pollerThread.start();\n        }\n        //开启接收线程\n        startAcceptorThreads();\n    }\n}\n```\n1. 终端的启动，首先创建轮询线程(一般为1个，轮询selector多路复用器)\n    * poller是轮训selector的线程\n2. 然后启动接收线程【连接池线程数量】\n\n接收线程：NIOEndpoint.Acceptor\n```\nprotected class Acceptor extends AbstractEndpoint.Acceptor {\n\n    @Override\n    public void run() {\n\n        int errorDelay = 0;\n\n        // Loop until we receive a shutdown command\n        while (running) {\n            state = AcceptorState.RUNNING;\n            try {\n                //if we have reached max connections, wait\n                countUpOrAwaitConnection();\n                AsynchronousSocketChannel socket = null;\n                try {\n                    // Accept the next incoming connection from the server\n                    // socket\n                    socket = serverSock.accept().get();\n                } catch (Exception e) {\n                    // We didn't get a socket\n                    countDownConnection();\n                    if (running) {\n                        // Introduce delay if necessary\n                        errorDelay = handleExceptionWithDelay(errorDelay);\n                        // re-throw\n                        throw e;\n                    } else {\n                        break;\n                    }\n                }\n                // Configure the socket\n                if (running && !paused) {\n                    // setSocketOptions() will hand the socket off to\n                    // an appropriate processor if successful\n                    if (!setSocketOptions(socket)) {//处理请求！！！！！\n                        closeSocket(socket);\n                   }\n                } else {\n                    closeSocket(socket);\n                }\n            } catch (Throwable t) {\n            }\n        }\n        state = AcceptorState.ENDED;\n    }\n}\n```\n接收socket连接请求\n\n处理请求：setSocketOptions\n```\nprotected boolean setSocketOptions(SocketChannel socket) {\n    // Process the connection\n    try {\n        //disable blocking, APR style, we are gonna be polling it\n        socket.configureBlocking(false);\n        Socket sock = socket.socket();\n        socketProperties.setProperties(sock);\n        NioChannel channel = nioChannels.pop();\n        if (channel == null) {\n            SocketBufferHandler bufhandler = new SocketBufferHandler(\n                    socketProperties.getAppReadBufSize(),\n                    socketProperties.getAppWriteBufSize(),\n                    socketProperties.getDirectBuffer());\n            if (isSSLEnabled()) {\n                channel = new SecureNioChannel(socket, bufhandler, selectorPool, this);\n            } else {\n                channel = new NioChannel(socket, bufhandler);\n            }\n        } else {\n            channel.setIOChannel(socket);\n            channel.reset();\n        }\n        //将channer注册进Poller，poller相当于selector\n        getPoller0().register(channel);\n    } catch (Throwable t) {\n    }\n    return true;\n}\n//注册过程，创建PollerEvent，将事件注册进Poller\npublic void register(final NioChannel socket) {\n    socket.setPoller(this);\n    NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this);\n    socket.setSocketWrapper(ka);\n    ka.setPoller(this);\n    ka.setReadTimeout(getSocketProperties().getSoTimeout());\n    ka.setWriteTimeout(getSocketProperties().getSoTimeout());\n    ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests());\n    ka.setSecure(isSSLEnabled());\n    ka.setReadTimeout(getConnectionTimeout());\n    ka.setWriteTimeout(getConnectionTimeout());\n    PollerEvent r = eventCache.pop();\n    ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into.\n    if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER);\n    else r.reset(socket,ka,OP_REGISTER);\n    addEvent(r);\n}\n```\n\nPoller轮询：\n```\npublic void run() {\n    // Loop until destroy() is called\n    while (true) {\n        boolean hasEvents = false;\n        Iterator<SelectionKey> iterator =\n            keyCount > 0 ? selector.selectedKeys().iterator() : null;\n        // Walk through the collection of ready keys and dispatch\n        // any active event.\n        while (iterator != null && iterator.hasNext()) {\n            SelectionKey sk = iterator.next();\n            NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment();\n            // Attachment may be null if another thread has called\n            // cancelledKey()\n            if (attachment == null) {\n                iterator.remove();\n            } else {\n                iterator.remove();\n                processKey(sk, attachment);\n            }\n        }//while\n    }//while\n    getStopLatch().countDown();\n}\n1、迭代key并处理processKey\n```\n\nprocessKey\n```\nprotected void processKey(SelectionKey sk, NioSocketWrapper attachment) {\n    try {\n        if ( close ) {\n            cancelledKey(sk);\n        } else if ( sk.isValid() && attachment != null ) {\n            if (sk.isReadable() || sk.isWritable() ) {\n                if ( attachment.getSendfileData() != null ) {\n                    processSendfile(sk,attachment, false);\n                } else {\n                    unreg(sk, attachment, sk.readyOps());\n                    boolean closeSocket = false;\n                    // Read goes before write\n                    if (sk.isReadable()) {\n                        if (!processSocket(attachment, SocketEvent.OPEN_READ, true)) {\n                            closeSocket = true;\n                        }\n                    }\n                    if (!closeSocket && sk.isWritable()) {\n                        if (!processSocket(attachment, SocketEvent.OPEN_WRITE, true)) {\n                            closeSocket = true;\n                        }\n                    }\n                    if (closeSocket) {\n                        cancelledKey(sk);\n                    }\n                }\n            }\n        } else {\n            //invalid key\n            cancelledKey(sk);\n        }\n    } catch ( CancelledKeyException ckx ) {\n        cancelledKey(sk);\n    } catch (Throwable t) {\n        ExceptionUtils.handleThrowable(t);\n        log.error(\"\",t);\n    }\n}\n```\nprocessSocket\n```\npublic boolean processSocket(SocketWrapperBase<S> socketWrapper,\n        SocketEvent event, boolean dispatch) {\n    try {\n        if (socketWrapper == null) {\n            return false;\n        }\n        SocketProcessorBase<S> sc = processorCache.pop();\n        if (sc == null) {\n            sc = createSocketProcessor(socketWrapper, event);\n        } else {\n            sc.reset(socketWrapper, event);\n        }\n        Executor executor = getExecutor();\n        if (dispatch && executor != null) {\n            executor.execute(sc);\n        } else {\n            sc.run();\n        }\n    } catch (RejectedExecutionException ree) {\n        getLog().warn(sm.getString(\"endpoint.executor.fail\", socketWrapper) , ree);\n        return false;\n    } catch (Throwable t) {\n        ExceptionUtils.handleThrowable(t);\n        // This means we got an OOM or similar creating a thread, or that\n        // the pool and its queue are full\n        getLog().error(sm.getString(\"endpoint.process.fail\"), t);\n        return false;\n    }\n    return true;\n}\n```\n\n\n具体执行过程\n```\nprotected class SocketProcessor extends SocketProcessorBase<NioChannel> {\n    @Override\n    protected void doRun() {\n        NioChannel socket = socketWrapper.getSocket();\n        SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector());\n        try {\n            int handshake = -1;\n            try {\n                if (key != null) {\n                    if (socket.isHandshakeComplete()) {\n                        // No TLS handshaking required. Let the handler\n                        // process this socket / event combination.\n                        handshake = 0;\n                    } else if (event == SocketEvent.STOP || event == SocketEvent.DISCONNECT ||\n                            event == SocketEvent.ERROR) {\n                        // Unable to complete the TLS handshake. Treat it as\n                        // if the handshake failed.\n                        handshake = -1;\n                    } else {\n                        handshake = socket.handshake(key.isReadable(), key.isWritable());\n                        // The handshake process reads/writes from/to the\n                        // socket. status may therefore be OPEN_WRITE once\n                        // the handshake completes. However, the handshake\n                        // happens when the socket is opened so the status\n                        // must always be OPEN_READ after it completes. It\n                        // is OK to always set this as it is only used if\n                        // the handshake completes.\n                        event = SocketEvent.OPEN_READ;\n                    }\n                }\n            } catch (IOException x) {\n                handshake = -1;\n                if (log.isDebugEnabled()) log.debug(\"Error during SSL handshake\",x);\n            } catch (CancelledKeyException ckx) {\n                handshake = -1;\n            }\n            if (handshake == 0) {\n                SocketState state = SocketState.OPEN;\n                // Process the request from this socket\n                if (event == null) {\n                    state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ);\n                } else {\n                    state = getHandler().process(socketWrapper, event);\n                }\n                if (state == SocketState.CLOSED) {\n                    close(socket, key);\n                }\n            } else if (handshake == -1 ) {\n                getHandler().process(socketWrapper, SocketEvent.CONNECT_FAIL);\n                close(socket, key);\n            } else if (handshake == SelectionKey.OP_READ){\n                socketWrapper.registerReadInterest();\n            } else if (handshake == SelectionKey.OP_WRITE){\n                socketWrapper.registerWriteInterest();\n            }\n        } catch (CancelledKeyException cx) {\n            socket.getPoller().cancelledKey(key);\n        } catch (VirtualMachineError vme) {\n            ExceptionUtils.handleThrowable(vme);\n        } catch (Throwable t) {\n            log.error(\"\", t);\n            socket.getPoller().cancelledKey(key);\n        } finally {\n            socketWrapper = null;\n            event = null;\n            //return to cache\n            if (running && !paused) {\n                processorCache.push(this);\n            }\n        }\n    }\n}\n```\n\ngetHandler().process\n```\nAbstractProtocol\nstate = processor.process(wrapper, status);\nAbstractProtocal类中，获取processor后去执行任务\n```\n\nprocessor.process----AbstractProcessorLight\n```\npublic SocketState process(SocketWrapperBase<?> socketWrapper, SocketEvent status)\n        throws IOException {\n    SocketState state = SocketState.CLOSED;\n    Iterator<DispatchType> dispatches = null;\n    do {\n        //判断状态\n        } else if (status == SocketEvent.OPEN_READ) {\n            state = service(socketWrapper);\n        }\n    } while (state == SocketState.ASYNC_END ||\n            dispatches != null && state != SocketState.CLOSED);\n\n    return state;\n}\n```\nservice ----Http11Processor\n```\ngetAdapter().service(request, response);\n```\n\n\nadapter.service ---- CoyoteAdapter\n```\n// Parse and set Catalina and configuration specific\n// request parameters\npostParseSuccess = postParseRequest(req, request, res, response);\n// Calling the container\nconnector.getService().getContainer().getPipeline().getFirst().invoke(\n        request, response);\n```        \n        \n1. 根据请求信息解析, 将对应的Host, Context, Wrapper容器对象封装到request实例中(重点)\n2. 调用StandardEngine的pipeline对Request,Response进行处理, StandardHostValve保存在pipeline的first属性中\n\n\npostParseRequest\n```\nconnector.getService().getMapper().map(serverName, decodedURI,\n        version, request.getMappingData());\n```\n\n\n# 启动过程总结：\n1. Load阶段已经绑定了端口号\n2. start启动阶段，需要启动轮询线程、创建工作线程、连接池线程\n\n\n\n\n\nhttps://blog.csdn.net/qq_38975553/article/details/103443321\n\n\n","source":"_posts/2019-12-21-tomcat启动过程2.md","raw":"---\ntitle: tomcat启动过程\ndate: 2019-12-21 20:19:03\ntags: Tomcat\n---\n\n# 一、启动过程\n执行start.sh，实际将执行catalina.sh\njava命令执行Bootstrap类的main方法，将start作为参数传入\nBoostrap:\n\n<!--more-->\n\n```\npublic static void main(String args[]) {\n    synchronized (daemonLock) {\n        Bootstrap daemon = new Bootstrap();\n        if (command.equals(\"startd\")) {\n            args[args.length - 1] = \"start\";\n            daemon.load(args);\n            daemon.start();\n        }\n    }\n```\n执行Boostrap的main方法，此时tomcat就在JVM作为一个线程启动了    \n\n执行start方法\n```\npublic void start() throws Exception {\n    Method method = catalinaDaemon.getClass().getMethod(\"start\", (Class [])null);\n    method.invoke(catalinaDaemon, (Object [])null);\n}\n```\n通过反射，执行catlinaDaemon的start方法    \n\n# 二、start流程\n\n## 2.1、Catalina:\n```\npublic void start() {\n    // Start the new server\n    try {\n        getServer().start();\n    } catch (LifecycleException e) {\n}\n```\n进行服务的初始化\n\n## 2.2、StandardServer:\n实际的server实现是StandardServer\n```\nprotected void startInternal() throws LifecycleException {\n    // Start our defined Services\n    synchronized (servicesLock) {\n        for (int i = 0; i < services.length; i++) {\n            services[i].start();\n        }\n    }\n}\n```\n从server的启动上看，一个server有多个service\n\n## 2.3、StandardService:\n实际的service实现是StandardService\n```\nprotected void startInternal() throws LifecycleException {\n    // Start our defined Container first\n    if (engine != null) {\n        synchronized (engine) {\n            engine.start();\n        }\n    }\n    synchronized (executors) {\n        for (Executor executor: executors) {\n            executor.start();\n        }\n    }\n    mapperListener.start();\n    // Start our defined Connectors second\n    synchronized (connectorsLock) {\n        for (Connector connector: connectors) {\n            try {\n                // If it has already failed, don't try and start it\n                if (connector.getState() != LifecycleState.FAILED) {\n                    connector.start();\n                }\n            } catch (Exception e) {\n            }\n        }\n    }\n}\n```\n1. service执行engine的启动。(engine继承Container，所以实际是进行container的初始化)\n2. 然后创建一组线程池。executor是Tomcat自己实现的线程池。【此时会去创建具体的工作线程】\n3. 然后进行连接器的初始化（一组连接器，server.xml中可以配置）\n\n\n\n## 2.4、Executor---StandardThreadExecutor\n```\nprotected void startInternal() throws LifecycleException {\n    taskqueue = new TaskQueue(maxQueueSize);\n    TaskThreadFactory tf = new TaskThreadFactory(namePrefix,daemon,getThreadPriority());\n    executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), maxIdleTime, TimeUnit.MILLISECONDS,taskqueue, tf);\n    executor.setThreadRenewalDelay(threadRenewalDelay);\n    if (prestartminSpareThreads) {\n        executor.prestartAllCoreThreads();\n    }\n    taskqueue.setParent(executor);\n    setState(LifecycleState.STARTING);\n}\n```\n1. 创建任务队列\n2. 创建工作线程\n\n## 2.5、Connector\n连接器的启动\n```\nprotected void startInternal() throws LifecycleException {\n    try {\n        protocolHandler.start();//启动协议处理器\n    } catch (Exception e) {\n    }\n```\n   \n## 2.6、protocolHandler ---> AbstractHProtocal\n协议处理器的启动。 \n```\npublic void start() throws Exception {\n    endpoint.start();//启动端口\n}\n```\n\n## 2.7、endpoint ---> AbstractEndpoint --->  NIOEndpoint\n终端的启动\n```\n@Override\npublic void startInternal() throws Exception {\n\n    if (!running) {\n                processorCache = new SynchronizedStack<>(SynchronizedStack.DEFAULT_SIZE,\n                socketProperties.getProcessorCache());\n        eventCache = new SynchronizedStack<>(SynchronizedStack.DEFAULT_SIZE,\n                        socketProperties.getEventCache());\n        nioChannels = new SynchronizedStack<>(SynchronizedStack.DEFAULT_SIZE,\n                socketProperties.getBufferPool());\n        // Create worker collection\n        if ( getExecutor() == null ) {\n            createExecutor();\n        }\n        initializeConnectionLatch();\n        // Start poller threads【轮询线程】\n        pollers = new Poller[getPollerThreadCount()];\n        for (int i=0; i<pollers.length; i++) {\n            pollers[i] = new Poller();\n            Thread pollerThread = new Thread(pollers[i], getName() + \"-ClientPoller-\"+i);\n            pollerThread.setPriority(threadPriority);\n            pollerThread.setDaemon(true);\n            pollerThread.start();\n        }\n        //开启接收线程\n        startAcceptorThreads();\n    }\n}\n```\n1. 终端的启动，首先创建轮询线程(一般为1个，轮询selector多路复用器)\n    * poller是轮训selector的线程\n2. 然后启动接收线程【连接池线程数量】\n\n接收线程：NIOEndpoint.Acceptor\n```\nprotected class Acceptor extends AbstractEndpoint.Acceptor {\n\n    @Override\n    public void run() {\n\n        int errorDelay = 0;\n\n        // Loop until we receive a shutdown command\n        while (running) {\n            state = AcceptorState.RUNNING;\n            try {\n                //if we have reached max connections, wait\n                countUpOrAwaitConnection();\n                AsynchronousSocketChannel socket = null;\n                try {\n                    // Accept the next incoming connection from the server\n                    // socket\n                    socket = serverSock.accept().get();\n                } catch (Exception e) {\n                    // We didn't get a socket\n                    countDownConnection();\n                    if (running) {\n                        // Introduce delay if necessary\n                        errorDelay = handleExceptionWithDelay(errorDelay);\n                        // re-throw\n                        throw e;\n                    } else {\n                        break;\n                    }\n                }\n                // Configure the socket\n                if (running && !paused) {\n                    // setSocketOptions() will hand the socket off to\n                    // an appropriate processor if successful\n                    if (!setSocketOptions(socket)) {//处理请求！！！！！\n                        closeSocket(socket);\n                   }\n                } else {\n                    closeSocket(socket);\n                }\n            } catch (Throwable t) {\n            }\n        }\n        state = AcceptorState.ENDED;\n    }\n}\n```\n接收socket连接请求\n\n处理请求：setSocketOptions\n```\nprotected boolean setSocketOptions(SocketChannel socket) {\n    // Process the connection\n    try {\n        //disable blocking, APR style, we are gonna be polling it\n        socket.configureBlocking(false);\n        Socket sock = socket.socket();\n        socketProperties.setProperties(sock);\n        NioChannel channel = nioChannels.pop();\n        if (channel == null) {\n            SocketBufferHandler bufhandler = new SocketBufferHandler(\n                    socketProperties.getAppReadBufSize(),\n                    socketProperties.getAppWriteBufSize(),\n                    socketProperties.getDirectBuffer());\n            if (isSSLEnabled()) {\n                channel = new SecureNioChannel(socket, bufhandler, selectorPool, this);\n            } else {\n                channel = new NioChannel(socket, bufhandler);\n            }\n        } else {\n            channel.setIOChannel(socket);\n            channel.reset();\n        }\n        //将channer注册进Poller，poller相当于selector\n        getPoller0().register(channel);\n    } catch (Throwable t) {\n    }\n    return true;\n}\n//注册过程，创建PollerEvent，将事件注册进Poller\npublic void register(final NioChannel socket) {\n    socket.setPoller(this);\n    NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this);\n    socket.setSocketWrapper(ka);\n    ka.setPoller(this);\n    ka.setReadTimeout(getSocketProperties().getSoTimeout());\n    ka.setWriteTimeout(getSocketProperties().getSoTimeout());\n    ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests());\n    ka.setSecure(isSSLEnabled());\n    ka.setReadTimeout(getConnectionTimeout());\n    ka.setWriteTimeout(getConnectionTimeout());\n    PollerEvent r = eventCache.pop();\n    ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into.\n    if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER);\n    else r.reset(socket,ka,OP_REGISTER);\n    addEvent(r);\n}\n```\n\nPoller轮询：\n```\npublic void run() {\n    // Loop until destroy() is called\n    while (true) {\n        boolean hasEvents = false;\n        Iterator<SelectionKey> iterator =\n            keyCount > 0 ? selector.selectedKeys().iterator() : null;\n        // Walk through the collection of ready keys and dispatch\n        // any active event.\n        while (iterator != null && iterator.hasNext()) {\n            SelectionKey sk = iterator.next();\n            NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment();\n            // Attachment may be null if another thread has called\n            // cancelledKey()\n            if (attachment == null) {\n                iterator.remove();\n            } else {\n                iterator.remove();\n                processKey(sk, attachment);\n            }\n        }//while\n    }//while\n    getStopLatch().countDown();\n}\n1、迭代key并处理processKey\n```\n\nprocessKey\n```\nprotected void processKey(SelectionKey sk, NioSocketWrapper attachment) {\n    try {\n        if ( close ) {\n            cancelledKey(sk);\n        } else if ( sk.isValid() && attachment != null ) {\n            if (sk.isReadable() || sk.isWritable() ) {\n                if ( attachment.getSendfileData() != null ) {\n                    processSendfile(sk,attachment, false);\n                } else {\n                    unreg(sk, attachment, sk.readyOps());\n                    boolean closeSocket = false;\n                    // Read goes before write\n                    if (sk.isReadable()) {\n                        if (!processSocket(attachment, SocketEvent.OPEN_READ, true)) {\n                            closeSocket = true;\n                        }\n                    }\n                    if (!closeSocket && sk.isWritable()) {\n                        if (!processSocket(attachment, SocketEvent.OPEN_WRITE, true)) {\n                            closeSocket = true;\n                        }\n                    }\n                    if (closeSocket) {\n                        cancelledKey(sk);\n                    }\n                }\n            }\n        } else {\n            //invalid key\n            cancelledKey(sk);\n        }\n    } catch ( CancelledKeyException ckx ) {\n        cancelledKey(sk);\n    } catch (Throwable t) {\n        ExceptionUtils.handleThrowable(t);\n        log.error(\"\",t);\n    }\n}\n```\nprocessSocket\n```\npublic boolean processSocket(SocketWrapperBase<S> socketWrapper,\n        SocketEvent event, boolean dispatch) {\n    try {\n        if (socketWrapper == null) {\n            return false;\n        }\n        SocketProcessorBase<S> sc = processorCache.pop();\n        if (sc == null) {\n            sc = createSocketProcessor(socketWrapper, event);\n        } else {\n            sc.reset(socketWrapper, event);\n        }\n        Executor executor = getExecutor();\n        if (dispatch && executor != null) {\n            executor.execute(sc);\n        } else {\n            sc.run();\n        }\n    } catch (RejectedExecutionException ree) {\n        getLog().warn(sm.getString(\"endpoint.executor.fail\", socketWrapper) , ree);\n        return false;\n    } catch (Throwable t) {\n        ExceptionUtils.handleThrowable(t);\n        // This means we got an OOM or similar creating a thread, or that\n        // the pool and its queue are full\n        getLog().error(sm.getString(\"endpoint.process.fail\"), t);\n        return false;\n    }\n    return true;\n}\n```\n\n\n具体执行过程\n```\nprotected class SocketProcessor extends SocketProcessorBase<NioChannel> {\n    @Override\n    protected void doRun() {\n        NioChannel socket = socketWrapper.getSocket();\n        SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector());\n        try {\n            int handshake = -1;\n            try {\n                if (key != null) {\n                    if (socket.isHandshakeComplete()) {\n                        // No TLS handshaking required. Let the handler\n                        // process this socket / event combination.\n                        handshake = 0;\n                    } else if (event == SocketEvent.STOP || event == SocketEvent.DISCONNECT ||\n                            event == SocketEvent.ERROR) {\n                        // Unable to complete the TLS handshake. Treat it as\n                        // if the handshake failed.\n                        handshake = -1;\n                    } else {\n                        handshake = socket.handshake(key.isReadable(), key.isWritable());\n                        // The handshake process reads/writes from/to the\n                        // socket. status may therefore be OPEN_WRITE once\n                        // the handshake completes. However, the handshake\n                        // happens when the socket is opened so the status\n                        // must always be OPEN_READ after it completes. It\n                        // is OK to always set this as it is only used if\n                        // the handshake completes.\n                        event = SocketEvent.OPEN_READ;\n                    }\n                }\n            } catch (IOException x) {\n                handshake = -1;\n                if (log.isDebugEnabled()) log.debug(\"Error during SSL handshake\",x);\n            } catch (CancelledKeyException ckx) {\n                handshake = -1;\n            }\n            if (handshake == 0) {\n                SocketState state = SocketState.OPEN;\n                // Process the request from this socket\n                if (event == null) {\n                    state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ);\n                } else {\n                    state = getHandler().process(socketWrapper, event);\n                }\n                if (state == SocketState.CLOSED) {\n                    close(socket, key);\n                }\n            } else if (handshake == -1 ) {\n                getHandler().process(socketWrapper, SocketEvent.CONNECT_FAIL);\n                close(socket, key);\n            } else if (handshake == SelectionKey.OP_READ){\n                socketWrapper.registerReadInterest();\n            } else if (handshake == SelectionKey.OP_WRITE){\n                socketWrapper.registerWriteInterest();\n            }\n        } catch (CancelledKeyException cx) {\n            socket.getPoller().cancelledKey(key);\n        } catch (VirtualMachineError vme) {\n            ExceptionUtils.handleThrowable(vme);\n        } catch (Throwable t) {\n            log.error(\"\", t);\n            socket.getPoller().cancelledKey(key);\n        } finally {\n            socketWrapper = null;\n            event = null;\n            //return to cache\n            if (running && !paused) {\n                processorCache.push(this);\n            }\n        }\n    }\n}\n```\n\ngetHandler().process\n```\nAbstractProtocol\nstate = processor.process(wrapper, status);\nAbstractProtocal类中，获取processor后去执行任务\n```\n\nprocessor.process----AbstractProcessorLight\n```\npublic SocketState process(SocketWrapperBase<?> socketWrapper, SocketEvent status)\n        throws IOException {\n    SocketState state = SocketState.CLOSED;\n    Iterator<DispatchType> dispatches = null;\n    do {\n        //判断状态\n        } else if (status == SocketEvent.OPEN_READ) {\n            state = service(socketWrapper);\n        }\n    } while (state == SocketState.ASYNC_END ||\n            dispatches != null && state != SocketState.CLOSED);\n\n    return state;\n}\n```\nservice ----Http11Processor\n```\ngetAdapter().service(request, response);\n```\n\n\nadapter.service ---- CoyoteAdapter\n```\n// Parse and set Catalina and configuration specific\n// request parameters\npostParseSuccess = postParseRequest(req, request, res, response);\n// Calling the container\nconnector.getService().getContainer().getPipeline().getFirst().invoke(\n        request, response);\n```        \n        \n1. 根据请求信息解析, 将对应的Host, Context, Wrapper容器对象封装到request实例中(重点)\n2. 调用StandardEngine的pipeline对Request,Response进行处理, StandardHostValve保存在pipeline的first属性中\n\n\npostParseRequest\n```\nconnector.getService().getMapper().map(serverName, decodedURI,\n        version, request.getMappingData());\n```\n\n\n# 启动过程总结：\n1. Load阶段已经绑定了端口号\n2. start启动阶段，需要启动轮询线程、创建工作线程、连接池线程\n\n\n\n\n\nhttps://blog.csdn.net/qq_38975553/article/details/103443321\n\n\n","slug":"2019-12-21-tomcat启动过程2","published":1,"updated":"2024-10-14T09:38:12.028Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnwg001ra13k746lob2v","content":"<h1 id=\"一、启动过程\"><a href=\"#一、启动过程\" class=\"headerlink\" title=\"一、启动过程\"></a>一、启动过程</h1><p>执行start.sh，实际将执行catalina.sh<br>java命令执行Bootstrap类的main方法，将start作为参数传入<br>Boostrap:</p>\n<a id=\"more\"></a>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String args[]) &#123;</span><br><span class=\"line\">    synchronized (daemonLock) &#123;</span><br><span class=\"line\">        Bootstrap daemon = new Bootstrap();</span><br><span class=\"line\">        if (command.equals(&quot;startd&quot;)) &#123;</span><br><span class=\"line\">            args[args.length - 1] = &quot;start&quot;;</span><br><span class=\"line\">            daemon.load(args);</span><br><span class=\"line\">            daemon.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>执行Boostrap的main方法，此时tomcat就在JVM作为一个线程启动了    </p>\n<p>执行start方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void start() throws Exception &#123;</span><br><span class=\"line\">    Method method = catalinaDaemon.getClass().getMethod(&quot;start&quot;, (Class [])null);</span><br><span class=\"line\">    method.invoke(catalinaDaemon, (Object [])null);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>通过反射，执行catlinaDaemon的start方法    </p>\n<h1 id=\"二、start流程\"><a href=\"#二、start流程\" class=\"headerlink\" title=\"二、start流程\"></a>二、start流程</h1><h2 id=\"2-1、Catalina\"><a href=\"#2-1、Catalina\" class=\"headerlink\" title=\"2.1、Catalina:\"></a>2.1、Catalina:</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void start() &#123;</span><br><span class=\"line\">    // Start the new server</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        getServer().start();</span><br><span class=\"line\">    &#125; catch (LifecycleException e) &#123;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>进行服务的初始化</p>\n<h2 id=\"2-2、StandardServer\"><a href=\"#2-2、StandardServer\" class=\"headerlink\" title=\"2.2、StandardServer:\"></a>2.2、StandardServer:</h2><p>实际的server实现是StandardServer</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Start our defined Services</span><br><span class=\"line\">    synchronized (servicesLock) &#123;</span><br><span class=\"line\">        for (int i = 0; i &lt; services.length; i++) &#123;</span><br><span class=\"line\">            services[i].start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从server的启动上看，一个server有多个service</p>\n<h2 id=\"2-3、StandardService\"><a href=\"#2-3、StandardService\" class=\"headerlink\" title=\"2.3、StandardService:\"></a>2.3、StandardService:</h2><p>实际的service实现是StandardService</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Start our defined Container first</span><br><span class=\"line\">    if (engine != null) &#123;</span><br><span class=\"line\">        synchronized (engine) &#123;</span><br><span class=\"line\">            engine.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    synchronized (executors) &#123;</span><br><span class=\"line\">        for (Executor executor: executors) &#123;</span><br><span class=\"line\">            executor.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    mapperListener.start();</span><br><span class=\"line\">    // Start our defined Connectors second</span><br><span class=\"line\">    synchronized (connectorsLock) &#123;</span><br><span class=\"line\">        for (Connector connector: connectors) &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                // If it has already failed, don&apos;t try and start it</span><br><span class=\"line\">                if (connector.getState() != LifecycleState.FAILED) &#123;</span><br><span class=\"line\">                    connector.start();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; catch (Exception e) &#123;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>service执行engine的启动。(engine继承Container，所以实际是进行container的初始化)</li>\n<li>然后创建一组线程池。executor是Tomcat自己实现的线程池。【此时会去创建具体的工作线程】</li>\n<li>然后进行连接器的初始化（一组连接器，server.xml中可以配置）</li>\n</ol>\n<h2 id=\"2-4、Executor—StandardThreadExecutor\"><a href=\"#2-4、Executor—StandardThreadExecutor\" class=\"headerlink\" title=\"2.4、Executor—StandardThreadExecutor\"></a>2.4、Executor—StandardThreadExecutor</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    taskqueue = new TaskQueue(maxQueueSize);</span><br><span class=\"line\">    TaskThreadFactory tf = new TaskThreadFactory(namePrefix,daemon,getThreadPriority());</span><br><span class=\"line\">    executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), maxIdleTime, TimeUnit.MILLISECONDS,taskqueue, tf);</span><br><span class=\"line\">    executor.setThreadRenewalDelay(threadRenewalDelay);</span><br><span class=\"line\">    if (prestartminSpareThreads) &#123;</span><br><span class=\"line\">        executor.prestartAllCoreThreads();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    taskqueue.setParent(executor);</span><br><span class=\"line\">    setState(LifecycleState.STARTING);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>创建任务队列</li>\n<li>创建工作线程</li>\n</ol>\n<h2 id=\"2-5、Connector\"><a href=\"#2-5、Connector\" class=\"headerlink\" title=\"2.5、Connector\"></a>2.5、Connector</h2><p>连接器的启动</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        protocolHandler.start();//启动协议处理器</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"2-6、protocolHandler-—-gt-AbstractHProtocal\"><a href=\"#2-6、protocolHandler-—-gt-AbstractHProtocal\" class=\"headerlink\" title=\"2.6、protocolHandler —&gt; AbstractHProtocal\"></a>2.6、protocolHandler —&gt; AbstractHProtocal</h2><p>协议处理器的启动。 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void start() throws Exception &#123;</span><br><span class=\"line\">    endpoint.start();//启动端口</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-7、endpoint-—-gt-AbstractEndpoint-—-gt-NIOEndpoint\"><a href=\"#2-7、endpoint-—-gt-AbstractEndpoint-—-gt-NIOEndpoint\" class=\"headerlink\" title=\"2.7、endpoint —&gt; AbstractEndpoint —&gt;  NIOEndpoint\"></a>2.7、endpoint —&gt; AbstractEndpoint —&gt;  NIOEndpoint</h2><p>终端的启动</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public void startInternal() throws Exception &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!running) &#123;</span><br><span class=\"line\">                processorCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,</span><br><span class=\"line\">                socketProperties.getProcessorCache());</span><br><span class=\"line\">        eventCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,</span><br><span class=\"line\">                        socketProperties.getEventCache());</span><br><span class=\"line\">        nioChannels = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,</span><br><span class=\"line\">                socketProperties.getBufferPool());</span><br><span class=\"line\">        // Create worker collection</span><br><span class=\"line\">        if ( getExecutor() == null ) &#123;</span><br><span class=\"line\">            createExecutor();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        initializeConnectionLatch();</span><br><span class=\"line\">        // Start poller threads【轮询线程】</span><br><span class=\"line\">        pollers = new Poller[getPollerThreadCount()];</span><br><span class=\"line\">        for (int i=0; i&lt;pollers.length; i++) &#123;</span><br><span class=\"line\">            pollers[i] = new Poller();</span><br><span class=\"line\">            Thread pollerThread = new Thread(pollers[i], getName() + &quot;-ClientPoller-&quot;+i);</span><br><span class=\"line\">            pollerThread.setPriority(threadPriority);</span><br><span class=\"line\">            pollerThread.setDaemon(true);</span><br><span class=\"line\">            pollerThread.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //开启接收线程</span><br><span class=\"line\">        startAcceptorThreads();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>终端的启动，首先创建轮询线程(一般为1个，轮询selector多路复用器)<ul>\n<li>poller是轮训selector的线程</li>\n</ul>\n</li>\n<li>然后启动接收线程【连接池线程数量】</li>\n</ol>\n<p>接收线程：NIOEndpoint.Acceptor</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected class Acceptor extends AbstractEndpoint.Acceptor &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void run() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        int errorDelay = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">        // Loop until we receive a shutdown command</span><br><span class=\"line\">        while (running) &#123;</span><br><span class=\"line\">            state = AcceptorState.RUNNING;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                //if we have reached max connections, wait</span><br><span class=\"line\">                countUpOrAwaitConnection();</span><br><span class=\"line\">                AsynchronousSocketChannel socket = null;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    // Accept the next incoming connection from the server</span><br><span class=\"line\">                    // socket</span><br><span class=\"line\">                    socket = serverSock.accept().get();</span><br><span class=\"line\">                &#125; catch (Exception e) &#123;</span><br><span class=\"line\">                    // We didn&apos;t get a socket</span><br><span class=\"line\">                    countDownConnection();</span><br><span class=\"line\">                    if (running) &#123;</span><br><span class=\"line\">                        // Introduce delay if necessary</span><br><span class=\"line\">                        errorDelay = handleExceptionWithDelay(errorDelay);</span><br><span class=\"line\">                        // re-throw</span><br><span class=\"line\">                        throw e;</span><br><span class=\"line\">                    &#125; else &#123;</span><br><span class=\"line\">                        break;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Configure the socket</span><br><span class=\"line\">                if (running &amp;&amp; !paused) &#123;</span><br><span class=\"line\">                    // setSocketOptions() will hand the socket off to</span><br><span class=\"line\">                    // an appropriate processor if successful</span><br><span class=\"line\">                    if (!setSocketOptions(socket)) &#123;//处理请求！！！！！</span><br><span class=\"line\">                        closeSocket(socket);</span><br><span class=\"line\">                   &#125;</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    closeSocket(socket);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        state = AcceptorState.ENDED;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>接收socket连接请求</p>\n<p>处理请求：setSocketOptions</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected boolean setSocketOptions(SocketChannel socket) &#123;</span><br><span class=\"line\">    // Process the connection</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        //disable blocking, APR style, we are gonna be polling it</span><br><span class=\"line\">        socket.configureBlocking(false);</span><br><span class=\"line\">        Socket sock = socket.socket();</span><br><span class=\"line\">        socketProperties.setProperties(sock);</span><br><span class=\"line\">        NioChannel channel = nioChannels.pop();</span><br><span class=\"line\">        if (channel == null) &#123;</span><br><span class=\"line\">            SocketBufferHandler bufhandler = new SocketBufferHandler(</span><br><span class=\"line\">                    socketProperties.getAppReadBufSize(),</span><br><span class=\"line\">                    socketProperties.getAppWriteBufSize(),</span><br><span class=\"line\">                    socketProperties.getDirectBuffer());</span><br><span class=\"line\">            if (isSSLEnabled()) &#123;</span><br><span class=\"line\">                channel = new SecureNioChannel(socket, bufhandler, selectorPool, this);</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                channel = new NioChannel(socket, bufhandler);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            channel.setIOChannel(socket);</span><br><span class=\"line\">            channel.reset();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //将channer注册进Poller，poller相当于selector</span><br><span class=\"line\">        getPoller0().register(channel);</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//注册过程，创建PollerEvent，将事件注册进Poller</span><br><span class=\"line\">public void register(final NioChannel socket) &#123;</span><br><span class=\"line\">    socket.setPoller(this);</span><br><span class=\"line\">    NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this);</span><br><span class=\"line\">    socket.setSocketWrapper(ka);</span><br><span class=\"line\">    ka.setPoller(this);</span><br><span class=\"line\">    ka.setReadTimeout(getSocketProperties().getSoTimeout());</span><br><span class=\"line\">    ka.setWriteTimeout(getSocketProperties().getSoTimeout());</span><br><span class=\"line\">    ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests());</span><br><span class=\"line\">    ka.setSecure(isSSLEnabled());</span><br><span class=\"line\">    ka.setReadTimeout(getConnectionTimeout());</span><br><span class=\"line\">    ka.setWriteTimeout(getConnectionTimeout());</span><br><span class=\"line\">    PollerEvent r = eventCache.pop();</span><br><span class=\"line\">    ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into.</span><br><span class=\"line\">    if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER);</span><br><span class=\"line\">    else r.reset(socket,ka,OP_REGISTER);</span><br><span class=\"line\">    addEvent(r);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Poller轮询：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void run() &#123;</span><br><span class=\"line\">    // Loop until destroy() is called</span><br><span class=\"line\">    while (true) &#123;</span><br><span class=\"line\">        boolean hasEvents = false;</span><br><span class=\"line\">        Iterator&lt;SelectionKey&gt; iterator =</span><br><span class=\"line\">            keyCount &gt; 0 ? selector.selectedKeys().iterator() : null;</span><br><span class=\"line\">        // Walk through the collection of ready keys and dispatch</span><br><span class=\"line\">        // any active event.</span><br><span class=\"line\">        while (iterator != null &amp;&amp; iterator.hasNext()) &#123;</span><br><span class=\"line\">            SelectionKey sk = iterator.next();</span><br><span class=\"line\">            NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment();</span><br><span class=\"line\">            // Attachment may be null if another thread has called</span><br><span class=\"line\">            // cancelledKey()</span><br><span class=\"line\">            if (attachment == null) &#123;</span><br><span class=\"line\">                iterator.remove();</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                iterator.remove();</span><br><span class=\"line\">                processKey(sk, attachment);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;//while</span><br><span class=\"line\">    &#125;//while</span><br><span class=\"line\">    getStopLatch().countDown();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">1、迭代key并处理processKey</span><br></pre></td></tr></table></figure>\n\n<p>processKey</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void processKey(SelectionKey sk, NioSocketWrapper attachment) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if ( close ) &#123;</span><br><span class=\"line\">            cancelledKey(sk);</span><br><span class=\"line\">        &#125; else if ( sk.isValid() &amp;&amp; attachment != null ) &#123;</span><br><span class=\"line\">            if (sk.isReadable() || sk.isWritable() ) &#123;</span><br><span class=\"line\">                if ( attachment.getSendfileData() != null ) &#123;</span><br><span class=\"line\">                    processSendfile(sk,attachment, false);</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    unreg(sk, attachment, sk.readyOps());</span><br><span class=\"line\">                    boolean closeSocket = false;</span><br><span class=\"line\">                    // Read goes before write</span><br><span class=\"line\">                    if (sk.isReadable()) &#123;</span><br><span class=\"line\">                        if (!processSocket(attachment, SocketEvent.OPEN_READ, true)) &#123;</span><br><span class=\"line\">                            closeSocket = true;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    if (!closeSocket &amp;&amp; sk.isWritable()) &#123;</span><br><span class=\"line\">                        if (!processSocket(attachment, SocketEvent.OPEN_WRITE, true)) &#123;</span><br><span class=\"line\">                            closeSocket = true;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    if (closeSocket) &#123;</span><br><span class=\"line\">                        cancelledKey(sk);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            //invalid key</span><br><span class=\"line\">            cancelledKey(sk);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; catch ( CancelledKeyException ckx ) &#123;</span><br><span class=\"line\">        cancelledKey(sk);</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">        ExceptionUtils.handleThrowable(t);</span><br><span class=\"line\">        log.error(&quot;&quot;,t);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>processSocket</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper,</span><br><span class=\"line\">        SocketEvent event, boolean dispatch) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (socketWrapper == null) &#123;</span><br><span class=\"line\">            return false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        SocketProcessorBase&lt;S&gt; sc = processorCache.pop();</span><br><span class=\"line\">        if (sc == null) &#123;</span><br><span class=\"line\">            sc = createSocketProcessor(socketWrapper, event);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            sc.reset(socketWrapper, event);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Executor executor = getExecutor();</span><br><span class=\"line\">        if (dispatch &amp;&amp; executor != null) &#123;</span><br><span class=\"line\">            executor.execute(sc);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            sc.run();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; catch (RejectedExecutionException ree) &#123;</span><br><span class=\"line\">        getLog().warn(sm.getString(&quot;endpoint.executor.fail&quot;, socketWrapper) , ree);</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">        ExceptionUtils.handleThrowable(t);</span><br><span class=\"line\">        // This means we got an OOM or similar creating a thread, or that</span><br><span class=\"line\">        // the pool and its queue are full</span><br><span class=\"line\">        getLog().error(sm.getString(&quot;endpoint.process.fail&quot;), t);</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>具体执行过程</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected class SocketProcessor extends SocketProcessorBase&lt;NioChannel&gt; &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    protected void doRun() &#123;</span><br><span class=\"line\">        NioChannel socket = socketWrapper.getSocket();</span><br><span class=\"line\">        SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector());</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            int handshake = -1;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                if (key != null) &#123;</span><br><span class=\"line\">                    if (socket.isHandshakeComplete()) &#123;</span><br><span class=\"line\">                        // No TLS handshaking required. Let the handler</span><br><span class=\"line\">                        // process this socket / event combination.</span><br><span class=\"line\">                        handshake = 0;</span><br><span class=\"line\">                    &#125; else if (event == SocketEvent.STOP || event == SocketEvent.DISCONNECT ||</span><br><span class=\"line\">                            event == SocketEvent.ERROR) &#123;</span><br><span class=\"line\">                        // Unable to complete the TLS handshake. Treat it as</span><br><span class=\"line\">                        // if the handshake failed.</span><br><span class=\"line\">                        handshake = -1;</span><br><span class=\"line\">                    &#125; else &#123;</span><br><span class=\"line\">                        handshake = socket.handshake(key.isReadable(), key.isWritable());</span><br><span class=\"line\">                        // The handshake process reads/writes from/to the</span><br><span class=\"line\">                        // socket. status may therefore be OPEN_WRITE once</span><br><span class=\"line\">                        // the handshake completes. However, the handshake</span><br><span class=\"line\">                        // happens when the socket is opened so the status</span><br><span class=\"line\">                        // must always be OPEN_READ after it completes. It</span><br><span class=\"line\">                        // is OK to always set this as it is only used if</span><br><span class=\"line\">                        // the handshake completes.</span><br><span class=\"line\">                        event = SocketEvent.OPEN_READ;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; catch (IOException x) &#123;</span><br><span class=\"line\">                handshake = -1;</span><br><span class=\"line\">                if (log.isDebugEnabled()) log.debug(&quot;Error during SSL handshake&quot;,x);</span><br><span class=\"line\">            &#125; catch (CancelledKeyException ckx) &#123;</span><br><span class=\"line\">                handshake = -1;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (handshake == 0) &#123;</span><br><span class=\"line\">                SocketState state = SocketState.OPEN;</span><br><span class=\"line\">                // Process the request from this socket</span><br><span class=\"line\">                if (event == null) &#123;</span><br><span class=\"line\">                    state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ);</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    state = getHandler().process(socketWrapper, event);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                if (state == SocketState.CLOSED) &#123;</span><br><span class=\"line\">                    close(socket, key);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; else if (handshake == -1 ) &#123;</span><br><span class=\"line\">                getHandler().process(socketWrapper, SocketEvent.CONNECT_FAIL);</span><br><span class=\"line\">                close(socket, key);</span><br><span class=\"line\">            &#125; else if (handshake == SelectionKey.OP_READ)&#123;</span><br><span class=\"line\">                socketWrapper.registerReadInterest();</span><br><span class=\"line\">            &#125; else if (handshake == SelectionKey.OP_WRITE)&#123;</span><br><span class=\"line\">                socketWrapper.registerWriteInterest();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; catch (CancelledKeyException cx) &#123;</span><br><span class=\"line\">            socket.getPoller().cancelledKey(key);</span><br><span class=\"line\">        &#125; catch (VirtualMachineError vme) &#123;</span><br><span class=\"line\">            ExceptionUtils.handleThrowable(vme);</span><br><span class=\"line\">        &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">            log.error(&quot;&quot;, t);</span><br><span class=\"line\">            socket.getPoller().cancelledKey(key);</span><br><span class=\"line\">        &#125; finally &#123;</span><br><span class=\"line\">            socketWrapper = null;</span><br><span class=\"line\">            event = null;</span><br><span class=\"line\">            //return to cache</span><br><span class=\"line\">            if (running &amp;&amp; !paused) &#123;</span><br><span class=\"line\">                processorCache.push(this);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>getHandler().process</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AbstractProtocol</span><br><span class=\"line\">state = processor.process(wrapper, status);</span><br><span class=\"line\">AbstractProtocal类中，获取processor后去执行任务</span><br></pre></td></tr></table></figure>\n\n<p>processor.process—-AbstractProcessorLight</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public SocketState process(SocketWrapperBase&lt;?&gt; socketWrapper, SocketEvent status)</span><br><span class=\"line\">        throws IOException &#123;</span><br><span class=\"line\">    SocketState state = SocketState.CLOSED;</span><br><span class=\"line\">    Iterator&lt;DispatchType&gt; dispatches = null;</span><br><span class=\"line\">    do &#123;</span><br><span class=\"line\">        //判断状态</span><br><span class=\"line\">        &#125; else if (status == SocketEvent.OPEN_READ) &#123;</span><br><span class=\"line\">            state = service(socketWrapper);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; while (state == SocketState.ASYNC_END ||</span><br><span class=\"line\">            dispatches != null &amp;&amp; state != SocketState.CLOSED);</span><br><span class=\"line\"></span><br><span class=\"line\">    return state;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>service —-Http11Processor</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">getAdapter().service(request, response);</span><br></pre></td></tr></table></figure>\n\n<p>adapter.service —- CoyoteAdapter</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Parse and set Catalina and configuration specific</span><br><span class=\"line\">// request parameters</span><br><span class=\"line\">postParseSuccess = postParseRequest(req, request, res, response);</span><br><span class=\"line\">// Calling the container</span><br><span class=\"line\">connector.getService().getContainer().getPipeline().getFirst().invoke(</span><br><span class=\"line\">        request, response);</span><br><span class=\"line\">```        </span><br><span class=\"line\">        </span><br><span class=\"line\">1. 根据请求信息解析, 将对应的Host, Context, Wrapper容器对象封装到request实例中(重点)</span><br><span class=\"line\">2. 调用StandardEngine的pipeline对Request,Response进行处理, StandardHostValve保存在pipeline的first属性中</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">postParseRequest</span><br></pre></td></tr></table></figure>\n\n<p>connector.getService().getMapper().map(serverName, decodedURI,<br>        version, request.getMappingData());</p>\n<pre><code>\n\n# 启动过程总结：\n1. Load阶段已经绑定了端口号\n2. start启动阶段，需要启动轮询线程、创建工作线程、连接池线程\n\n\n\n\n\nhttps://blog.csdn.net/qq_38975553/article/details/103443321\n\n</code></pre>","site":{"data":{}},"excerpt":"<h1 id=\"一、启动过程\"><a href=\"#一、启动过程\" class=\"headerlink\" title=\"一、启动过程\"></a>一、启动过程</h1><p>执行start.sh，实际将执行catalina.sh<br>java命令执行Bootstrap类的main方法，将start作为参数传入<br>Boostrap:</p>","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String args[]) &#123;</span><br><span class=\"line\">    synchronized (daemonLock) &#123;</span><br><span class=\"line\">        Bootstrap daemon = new Bootstrap();</span><br><span class=\"line\">        if (command.equals(&quot;startd&quot;)) &#123;</span><br><span class=\"line\">            args[args.length - 1] = &quot;start&quot;;</span><br><span class=\"line\">            daemon.load(args);</span><br><span class=\"line\">            daemon.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>执行Boostrap的main方法，此时tomcat就在JVM作为一个线程启动了    </p>\n<p>执行start方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void start() throws Exception &#123;</span><br><span class=\"line\">    Method method = catalinaDaemon.getClass().getMethod(&quot;start&quot;, (Class [])null);</span><br><span class=\"line\">    method.invoke(catalinaDaemon, (Object [])null);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>通过反射，执行catlinaDaemon的start方法    </p>\n<h1 id=\"二、start流程\"><a href=\"#二、start流程\" class=\"headerlink\" title=\"二、start流程\"></a>二、start流程</h1><h2 id=\"2-1、Catalina\"><a href=\"#2-1、Catalina\" class=\"headerlink\" title=\"2.1、Catalina:\"></a>2.1、Catalina:</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void start() &#123;</span><br><span class=\"line\">    // Start the new server</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        getServer().start();</span><br><span class=\"line\">    &#125; catch (LifecycleException e) &#123;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>进行服务的初始化</p>\n<h2 id=\"2-2、StandardServer\"><a href=\"#2-2、StandardServer\" class=\"headerlink\" title=\"2.2、StandardServer:\"></a>2.2、StandardServer:</h2><p>实际的server实现是StandardServer</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Start our defined Services</span><br><span class=\"line\">    synchronized (servicesLock) &#123;</span><br><span class=\"line\">        for (int i = 0; i &lt; services.length; i++) &#123;</span><br><span class=\"line\">            services[i].start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从server的启动上看，一个server有多个service</p>\n<h2 id=\"2-3、StandardService\"><a href=\"#2-3、StandardService\" class=\"headerlink\" title=\"2.3、StandardService:\"></a>2.3、StandardService:</h2><p>实际的service实现是StandardService</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    // Start our defined Container first</span><br><span class=\"line\">    if (engine != null) &#123;</span><br><span class=\"line\">        synchronized (engine) &#123;</span><br><span class=\"line\">            engine.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    synchronized (executors) &#123;</span><br><span class=\"line\">        for (Executor executor: executors) &#123;</span><br><span class=\"line\">            executor.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    mapperListener.start();</span><br><span class=\"line\">    // Start our defined Connectors second</span><br><span class=\"line\">    synchronized (connectorsLock) &#123;</span><br><span class=\"line\">        for (Connector connector: connectors) &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                // If it has already failed, don&apos;t try and start it</span><br><span class=\"line\">                if (connector.getState() != LifecycleState.FAILED) &#123;</span><br><span class=\"line\">                    connector.start();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; catch (Exception e) &#123;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>service执行engine的启动。(engine继承Container，所以实际是进行container的初始化)</li>\n<li>然后创建一组线程池。executor是Tomcat自己实现的线程池。【此时会去创建具体的工作线程】</li>\n<li>然后进行连接器的初始化（一组连接器，server.xml中可以配置）</li>\n</ol>\n<h2 id=\"2-4、Executor—StandardThreadExecutor\"><a href=\"#2-4、Executor—StandardThreadExecutor\" class=\"headerlink\" title=\"2.4、Executor—StandardThreadExecutor\"></a>2.4、Executor—StandardThreadExecutor</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    taskqueue = new TaskQueue(maxQueueSize);</span><br><span class=\"line\">    TaskThreadFactory tf = new TaskThreadFactory(namePrefix,daemon,getThreadPriority());</span><br><span class=\"line\">    executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), maxIdleTime, TimeUnit.MILLISECONDS,taskqueue, tf);</span><br><span class=\"line\">    executor.setThreadRenewalDelay(threadRenewalDelay);</span><br><span class=\"line\">    if (prestartminSpareThreads) &#123;</span><br><span class=\"line\">        executor.prestartAllCoreThreads();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    taskqueue.setParent(executor);</span><br><span class=\"line\">    setState(LifecycleState.STARTING);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>创建任务队列</li>\n<li>创建工作线程</li>\n</ol>\n<h2 id=\"2-5、Connector\"><a href=\"#2-5、Connector\" class=\"headerlink\" title=\"2.5、Connector\"></a>2.5、Connector</h2><p>连接器的启动</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void startInternal() throws LifecycleException &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        protocolHandler.start();//启动协议处理器</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n\n<h2 id=\"2-6、protocolHandler-—-gt-AbstractHProtocal\"><a href=\"#2-6、protocolHandler-—-gt-AbstractHProtocal\" class=\"headerlink\" title=\"2.6、protocolHandler —&gt; AbstractHProtocal\"></a>2.6、protocolHandler —&gt; AbstractHProtocal</h2><p>协议处理器的启动。 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void start() throws Exception &#123;</span><br><span class=\"line\">    endpoint.start();//启动端口</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-7、endpoint-—-gt-AbstractEndpoint-—-gt-NIOEndpoint\"><a href=\"#2-7、endpoint-—-gt-AbstractEndpoint-—-gt-NIOEndpoint\" class=\"headerlink\" title=\"2.7、endpoint —&gt; AbstractEndpoint —&gt;  NIOEndpoint\"></a>2.7、endpoint —&gt; AbstractEndpoint —&gt;  NIOEndpoint</h2><p>终端的启动</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public void startInternal() throws Exception &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!running) &#123;</span><br><span class=\"line\">                processorCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,</span><br><span class=\"line\">                socketProperties.getProcessorCache());</span><br><span class=\"line\">        eventCache = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,</span><br><span class=\"line\">                        socketProperties.getEventCache());</span><br><span class=\"line\">        nioChannels = new SynchronizedStack&lt;&gt;(SynchronizedStack.DEFAULT_SIZE,</span><br><span class=\"line\">                socketProperties.getBufferPool());</span><br><span class=\"line\">        // Create worker collection</span><br><span class=\"line\">        if ( getExecutor() == null ) &#123;</span><br><span class=\"line\">            createExecutor();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        initializeConnectionLatch();</span><br><span class=\"line\">        // Start poller threads【轮询线程】</span><br><span class=\"line\">        pollers = new Poller[getPollerThreadCount()];</span><br><span class=\"line\">        for (int i=0; i&lt;pollers.length; i++) &#123;</span><br><span class=\"line\">            pollers[i] = new Poller();</span><br><span class=\"line\">            Thread pollerThread = new Thread(pollers[i], getName() + &quot;-ClientPoller-&quot;+i);</span><br><span class=\"line\">            pollerThread.setPriority(threadPriority);</span><br><span class=\"line\">            pollerThread.setDaemon(true);</span><br><span class=\"line\">            pollerThread.start();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //开启接收线程</span><br><span class=\"line\">        startAcceptorThreads();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>终端的启动，首先创建轮询线程(一般为1个，轮询selector多路复用器)<ul>\n<li>poller是轮训selector的线程</li>\n</ul>\n</li>\n<li>然后启动接收线程【连接池线程数量】</li>\n</ol>\n<p>接收线程：NIOEndpoint.Acceptor</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected class Acceptor extends AbstractEndpoint.Acceptor &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void run() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        int errorDelay = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">        // Loop until we receive a shutdown command</span><br><span class=\"line\">        while (running) &#123;</span><br><span class=\"line\">            state = AcceptorState.RUNNING;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                //if we have reached max connections, wait</span><br><span class=\"line\">                countUpOrAwaitConnection();</span><br><span class=\"line\">                AsynchronousSocketChannel socket = null;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    // Accept the next incoming connection from the server</span><br><span class=\"line\">                    // socket</span><br><span class=\"line\">                    socket = serverSock.accept().get();</span><br><span class=\"line\">                &#125; catch (Exception e) &#123;</span><br><span class=\"line\">                    // We didn&apos;t get a socket</span><br><span class=\"line\">                    countDownConnection();</span><br><span class=\"line\">                    if (running) &#123;</span><br><span class=\"line\">                        // Introduce delay if necessary</span><br><span class=\"line\">                        errorDelay = handleExceptionWithDelay(errorDelay);</span><br><span class=\"line\">                        // re-throw</span><br><span class=\"line\">                        throw e;</span><br><span class=\"line\">                    &#125; else &#123;</span><br><span class=\"line\">                        break;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                // Configure the socket</span><br><span class=\"line\">                if (running &amp;&amp; !paused) &#123;</span><br><span class=\"line\">                    // setSocketOptions() will hand the socket off to</span><br><span class=\"line\">                    // an appropriate processor if successful</span><br><span class=\"line\">                    if (!setSocketOptions(socket)) &#123;//处理请求！！！！！</span><br><span class=\"line\">                        closeSocket(socket);</span><br><span class=\"line\">                   &#125;</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    closeSocket(socket);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        state = AcceptorState.ENDED;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>接收socket连接请求</p>\n<p>处理请求：setSocketOptions</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected boolean setSocketOptions(SocketChannel socket) &#123;</span><br><span class=\"line\">    // Process the connection</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        //disable blocking, APR style, we are gonna be polling it</span><br><span class=\"line\">        socket.configureBlocking(false);</span><br><span class=\"line\">        Socket sock = socket.socket();</span><br><span class=\"line\">        socketProperties.setProperties(sock);</span><br><span class=\"line\">        NioChannel channel = nioChannels.pop();</span><br><span class=\"line\">        if (channel == null) &#123;</span><br><span class=\"line\">            SocketBufferHandler bufhandler = new SocketBufferHandler(</span><br><span class=\"line\">                    socketProperties.getAppReadBufSize(),</span><br><span class=\"line\">                    socketProperties.getAppWriteBufSize(),</span><br><span class=\"line\">                    socketProperties.getDirectBuffer());</span><br><span class=\"line\">            if (isSSLEnabled()) &#123;</span><br><span class=\"line\">                channel = new SecureNioChannel(socket, bufhandler, selectorPool, this);</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                channel = new NioChannel(socket, bufhandler);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            channel.setIOChannel(socket);</span><br><span class=\"line\">            channel.reset();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //将channer注册进Poller，poller相当于selector</span><br><span class=\"line\">        getPoller0().register(channel);</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//注册过程，创建PollerEvent，将事件注册进Poller</span><br><span class=\"line\">public void register(final NioChannel socket) &#123;</span><br><span class=\"line\">    socket.setPoller(this);</span><br><span class=\"line\">    NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this);</span><br><span class=\"line\">    socket.setSocketWrapper(ka);</span><br><span class=\"line\">    ka.setPoller(this);</span><br><span class=\"line\">    ka.setReadTimeout(getSocketProperties().getSoTimeout());</span><br><span class=\"line\">    ka.setWriteTimeout(getSocketProperties().getSoTimeout());</span><br><span class=\"line\">    ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests());</span><br><span class=\"line\">    ka.setSecure(isSSLEnabled());</span><br><span class=\"line\">    ka.setReadTimeout(getConnectionTimeout());</span><br><span class=\"line\">    ka.setWriteTimeout(getConnectionTimeout());</span><br><span class=\"line\">    PollerEvent r = eventCache.pop();</span><br><span class=\"line\">    ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into.</span><br><span class=\"line\">    if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER);</span><br><span class=\"line\">    else r.reset(socket,ka,OP_REGISTER);</span><br><span class=\"line\">    addEvent(r);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Poller轮询：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void run() &#123;</span><br><span class=\"line\">    // Loop until destroy() is called</span><br><span class=\"line\">    while (true) &#123;</span><br><span class=\"line\">        boolean hasEvents = false;</span><br><span class=\"line\">        Iterator&lt;SelectionKey&gt; iterator =</span><br><span class=\"line\">            keyCount &gt; 0 ? selector.selectedKeys().iterator() : null;</span><br><span class=\"line\">        // Walk through the collection of ready keys and dispatch</span><br><span class=\"line\">        // any active event.</span><br><span class=\"line\">        while (iterator != null &amp;&amp; iterator.hasNext()) &#123;</span><br><span class=\"line\">            SelectionKey sk = iterator.next();</span><br><span class=\"line\">            NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment();</span><br><span class=\"line\">            // Attachment may be null if another thread has called</span><br><span class=\"line\">            // cancelledKey()</span><br><span class=\"line\">            if (attachment == null) &#123;</span><br><span class=\"line\">                iterator.remove();</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                iterator.remove();</span><br><span class=\"line\">                processKey(sk, attachment);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;//while</span><br><span class=\"line\">    &#125;//while</span><br><span class=\"line\">    getStopLatch().countDown();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">1、迭代key并处理processKey</span><br></pre></td></tr></table></figure>\n\n<p>processKey</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void processKey(SelectionKey sk, NioSocketWrapper attachment) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if ( close ) &#123;</span><br><span class=\"line\">            cancelledKey(sk);</span><br><span class=\"line\">        &#125; else if ( sk.isValid() &amp;&amp; attachment != null ) &#123;</span><br><span class=\"line\">            if (sk.isReadable() || sk.isWritable() ) &#123;</span><br><span class=\"line\">                if ( attachment.getSendfileData() != null ) &#123;</span><br><span class=\"line\">                    processSendfile(sk,attachment, false);</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    unreg(sk, attachment, sk.readyOps());</span><br><span class=\"line\">                    boolean closeSocket = false;</span><br><span class=\"line\">                    // Read goes before write</span><br><span class=\"line\">                    if (sk.isReadable()) &#123;</span><br><span class=\"line\">                        if (!processSocket(attachment, SocketEvent.OPEN_READ, true)) &#123;</span><br><span class=\"line\">                            closeSocket = true;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    if (!closeSocket &amp;&amp; sk.isWritable()) &#123;</span><br><span class=\"line\">                        if (!processSocket(attachment, SocketEvent.OPEN_WRITE, true)) &#123;</span><br><span class=\"line\">                            closeSocket = true;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    if (closeSocket) &#123;</span><br><span class=\"line\">                        cancelledKey(sk);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            //invalid key</span><br><span class=\"line\">            cancelledKey(sk);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; catch ( CancelledKeyException ckx ) &#123;</span><br><span class=\"line\">        cancelledKey(sk);</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">        ExceptionUtils.handleThrowable(t);</span><br><span class=\"line\">        log.error(&quot;&quot;,t);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>processSocket</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper,</span><br><span class=\"line\">        SocketEvent event, boolean dispatch) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (socketWrapper == null) &#123;</span><br><span class=\"line\">            return false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        SocketProcessorBase&lt;S&gt; sc = processorCache.pop();</span><br><span class=\"line\">        if (sc == null) &#123;</span><br><span class=\"line\">            sc = createSocketProcessor(socketWrapper, event);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            sc.reset(socketWrapper, event);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Executor executor = getExecutor();</span><br><span class=\"line\">        if (dispatch &amp;&amp; executor != null) &#123;</span><br><span class=\"line\">            executor.execute(sc);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            sc.run();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; catch (RejectedExecutionException ree) &#123;</span><br><span class=\"line\">        getLog().warn(sm.getString(&quot;endpoint.executor.fail&quot;, socketWrapper) , ree);</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">        ExceptionUtils.handleThrowable(t);</span><br><span class=\"line\">        // This means we got an OOM or similar creating a thread, or that</span><br><span class=\"line\">        // the pool and its queue are full</span><br><span class=\"line\">        getLog().error(sm.getString(&quot;endpoint.process.fail&quot;), t);</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>具体执行过程</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected class SocketProcessor extends SocketProcessorBase&lt;NioChannel&gt; &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    protected void doRun() &#123;</span><br><span class=\"line\">        NioChannel socket = socketWrapper.getSocket();</span><br><span class=\"line\">        SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector());</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            int handshake = -1;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                if (key != null) &#123;</span><br><span class=\"line\">                    if (socket.isHandshakeComplete()) &#123;</span><br><span class=\"line\">                        // No TLS handshaking required. Let the handler</span><br><span class=\"line\">                        // process this socket / event combination.</span><br><span class=\"line\">                        handshake = 0;</span><br><span class=\"line\">                    &#125; else if (event == SocketEvent.STOP || event == SocketEvent.DISCONNECT ||</span><br><span class=\"line\">                            event == SocketEvent.ERROR) &#123;</span><br><span class=\"line\">                        // Unable to complete the TLS handshake. Treat it as</span><br><span class=\"line\">                        // if the handshake failed.</span><br><span class=\"line\">                        handshake = -1;</span><br><span class=\"line\">                    &#125; else &#123;</span><br><span class=\"line\">                        handshake = socket.handshake(key.isReadable(), key.isWritable());</span><br><span class=\"line\">                        // The handshake process reads/writes from/to the</span><br><span class=\"line\">                        // socket. status may therefore be OPEN_WRITE once</span><br><span class=\"line\">                        // the handshake completes. However, the handshake</span><br><span class=\"line\">                        // happens when the socket is opened so the status</span><br><span class=\"line\">                        // must always be OPEN_READ after it completes. It</span><br><span class=\"line\">                        // is OK to always set this as it is only used if</span><br><span class=\"line\">                        // the handshake completes.</span><br><span class=\"line\">                        event = SocketEvent.OPEN_READ;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; catch (IOException x) &#123;</span><br><span class=\"line\">                handshake = -1;</span><br><span class=\"line\">                if (log.isDebugEnabled()) log.debug(&quot;Error during SSL handshake&quot;,x);</span><br><span class=\"line\">            &#125; catch (CancelledKeyException ckx) &#123;</span><br><span class=\"line\">                handshake = -1;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (handshake == 0) &#123;</span><br><span class=\"line\">                SocketState state = SocketState.OPEN;</span><br><span class=\"line\">                // Process the request from this socket</span><br><span class=\"line\">                if (event == null) &#123;</span><br><span class=\"line\">                    state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ);</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    state = getHandler().process(socketWrapper, event);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                if (state == SocketState.CLOSED) &#123;</span><br><span class=\"line\">                    close(socket, key);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; else if (handshake == -1 ) &#123;</span><br><span class=\"line\">                getHandler().process(socketWrapper, SocketEvent.CONNECT_FAIL);</span><br><span class=\"line\">                close(socket, key);</span><br><span class=\"line\">            &#125; else if (handshake == SelectionKey.OP_READ)&#123;</span><br><span class=\"line\">                socketWrapper.registerReadInterest();</span><br><span class=\"line\">            &#125; else if (handshake == SelectionKey.OP_WRITE)&#123;</span><br><span class=\"line\">                socketWrapper.registerWriteInterest();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; catch (CancelledKeyException cx) &#123;</span><br><span class=\"line\">            socket.getPoller().cancelledKey(key);</span><br><span class=\"line\">        &#125; catch (VirtualMachineError vme) &#123;</span><br><span class=\"line\">            ExceptionUtils.handleThrowable(vme);</span><br><span class=\"line\">        &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">            log.error(&quot;&quot;, t);</span><br><span class=\"line\">            socket.getPoller().cancelledKey(key);</span><br><span class=\"line\">        &#125; finally &#123;</span><br><span class=\"line\">            socketWrapper = null;</span><br><span class=\"line\">            event = null;</span><br><span class=\"line\">            //return to cache</span><br><span class=\"line\">            if (running &amp;&amp; !paused) &#123;</span><br><span class=\"line\">                processorCache.push(this);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>getHandler().process</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AbstractProtocol</span><br><span class=\"line\">state = processor.process(wrapper, status);</span><br><span class=\"line\">AbstractProtocal类中，获取processor后去执行任务</span><br></pre></td></tr></table></figure>\n\n<p>processor.process—-AbstractProcessorLight</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public SocketState process(SocketWrapperBase&lt;?&gt; socketWrapper, SocketEvent status)</span><br><span class=\"line\">        throws IOException &#123;</span><br><span class=\"line\">    SocketState state = SocketState.CLOSED;</span><br><span class=\"line\">    Iterator&lt;DispatchType&gt; dispatches = null;</span><br><span class=\"line\">    do &#123;</span><br><span class=\"line\">        //判断状态</span><br><span class=\"line\">        &#125; else if (status == SocketEvent.OPEN_READ) &#123;</span><br><span class=\"line\">            state = service(socketWrapper);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; while (state == SocketState.ASYNC_END ||</span><br><span class=\"line\">            dispatches != null &amp;&amp; state != SocketState.CLOSED);</span><br><span class=\"line\"></span><br><span class=\"line\">    return state;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>service —-Http11Processor</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">getAdapter().service(request, response);</span><br></pre></td></tr></table></figure>\n\n<p>adapter.service —- CoyoteAdapter</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Parse and set Catalina and configuration specific</span><br><span class=\"line\">// request parameters</span><br><span class=\"line\">postParseSuccess = postParseRequest(req, request, res, response);</span><br><span class=\"line\">// Calling the container</span><br><span class=\"line\">connector.getService().getContainer().getPipeline().getFirst().invoke(</span><br><span class=\"line\">        request, response);</span><br><span class=\"line\">```        </span><br><span class=\"line\">        </span><br><span class=\"line\">1. 根据请求信息解析, 将对应的Host, Context, Wrapper容器对象封装到request实例中(重点)</span><br><span class=\"line\">2. 调用StandardEngine的pipeline对Request,Response进行处理, StandardHostValve保存在pipeline的first属性中</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">postParseRequest</span><br></pre></td></tr></table></figure>\n\n<p>connector.getService().getMapper().map(serverName, decodedURI,<br>        version, request.getMappingData());</p>\n<pre><code>\n\n# 启动过程总结：\n1. Load阶段已经绑定了端口号\n2. start启动阶段，需要启动轮询线程、创建工作线程、连接池线程\n\n\n\n\n\nhttps://blog.csdn.net/qq_38975553/article/details/103443321\n\n</code></pre>"},{"title":"tomcat-netty对比","date":"2020-01-01T03:54:20.000Z","_content":"# 一、Acceptor线程数量对比\n## Tomcat：默认是1，该线程监听客户端连接请求\n```\n    protected class Acceptor extends AbstractEndpoint.Acceptor {\n        ........\n        SocketChannel socket = null;\n        try {\n            // Accept the next incoming connection from the server\n            // socket\n            //接收客户端连接请求，使用acceptor，会阻塞，直到有连接请求\n            socket = serverSock.accept();\n        }\n        ........\n    }\n```\n\n* Acceptor：单线程阻塞监听连接事件，统一处理连接\n* Poller：轮询器（最少2个），内部封装了selector，轮询该selector\n* PollerEvent：事件处理线程队列，将事件（socket）注册进selector内\n* 最后使用线程池去处理请求。\n\n## Netty：\n```\npublic NioServerSocketChannel(ServerSocketChannel channel) {\n    super(null, channel, SelectionKey.OP_ACCEPT);\n    config = new NioServerSocketChannelConfig(this, javaChannel().socket());\n}\n```\nSelectionKey.OP_ACCEPT标志就是监听套接字所感兴趣的事件了\n\n* 使用selector非阻塞模式\n\n[参考博客](https://github.com/fengjiachun/doc/blob/master/netty/Netty%E6%BA%90%E7%A0%81%E7%BB%86%E8%8A%822--bind.md)\n\n\n\n\n","source":"_posts/2020-01-01-tomcat-netty对比.md","raw":"---\ntitle: tomcat-netty对比\ndate: 2020-01-01 11:54:20\ntags: Tomcat netty\n---\n# 一、Acceptor线程数量对比\n## Tomcat：默认是1，该线程监听客户端连接请求\n```\n    protected class Acceptor extends AbstractEndpoint.Acceptor {\n        ........\n        SocketChannel socket = null;\n        try {\n            // Accept the next incoming connection from the server\n            // socket\n            //接收客户端连接请求，使用acceptor，会阻塞，直到有连接请求\n            socket = serverSock.accept();\n        }\n        ........\n    }\n```\n\n* Acceptor：单线程阻塞监听连接事件，统一处理连接\n* Poller：轮询器（最少2个），内部封装了selector，轮询该selector\n* PollerEvent：事件处理线程队列，将事件（socket）注册进selector内\n* 最后使用线程池去处理请求。\n\n## Netty：\n```\npublic NioServerSocketChannel(ServerSocketChannel channel) {\n    super(null, channel, SelectionKey.OP_ACCEPT);\n    config = new NioServerSocketChannelConfig(this, javaChannel().socket());\n}\n```\nSelectionKey.OP_ACCEPT标志就是监听套接字所感兴趣的事件了\n\n* 使用selector非阻塞模式\n\n[参考博客](https://github.com/fengjiachun/doc/blob/master/netty/Netty%E6%BA%90%E7%A0%81%E7%BB%86%E8%8A%822--bind.md)\n\n\n\n\n","slug":"2020-01-01-tomcat-netty对比","published":1,"updated":"2024-10-14T09:38:12.043Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnwl001ta13k667u9rwi","content":"<h1 id=\"一、Acceptor线程数量对比\"><a href=\"#一、Acceptor线程数量对比\" class=\"headerlink\" title=\"一、Acceptor线程数量对比\"></a>一、Acceptor线程数量对比</h1><h2 id=\"Tomcat：默认是1，该线程监听客户端连接请求\"><a href=\"#Tomcat：默认是1，该线程监听客户端连接请求\" class=\"headerlink\" title=\"Tomcat：默认是1，该线程监听客户端连接请求\"></a>Tomcat：默认是1，该线程监听客户端连接请求</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected class Acceptor extends AbstractEndpoint.Acceptor &#123;</span><br><span class=\"line\">    ........</span><br><span class=\"line\">    SocketChannel socket = null;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        // Accept the next incoming connection from the server</span><br><span class=\"line\">        // socket</span><br><span class=\"line\">        //接收客户端连接请求，使用acceptor，会阻塞，直到有连接请求</span><br><span class=\"line\">        socket = serverSock.accept();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ........</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Acceptor：单线程阻塞监听连接事件，统一处理连接</li>\n<li>Poller：轮询器（最少2个），内部封装了selector，轮询该selector</li>\n<li>PollerEvent：事件处理线程队列，将事件（socket）注册进selector内</li>\n<li>最后使用线程池去处理请求。</li>\n</ul>\n<h2 id=\"Netty：\"><a href=\"#Netty：\" class=\"headerlink\" title=\"Netty：\"></a>Netty：</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public NioServerSocketChannel(ServerSocketChannel channel) &#123;</span><br><span class=\"line\">    super(null, channel, SelectionKey.OP_ACCEPT);</span><br><span class=\"line\">    config = new NioServerSocketChannelConfig(this, javaChannel().socket());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>SelectionKey.OP_ACCEPT标志就是监听套接字所感兴趣的事件了</p>\n<ul>\n<li>使用selector非阻塞模式</li>\n</ul>\n<p><a href=\"https://github.com/fengjiachun/doc/blob/master/netty/Netty%E6%BA%90%E7%A0%81%E7%BB%86%E8%8A%822--bind.md\" target=\"_blank\" rel=\"noopener\">参考博客</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、Acceptor线程数量对比\"><a href=\"#一、Acceptor线程数量对比\" class=\"headerlink\" title=\"一、Acceptor线程数量对比\"></a>一、Acceptor线程数量对比</h1><h2 id=\"Tomcat：默认是1，该线程监听客户端连接请求\"><a href=\"#Tomcat：默认是1，该线程监听客户端连接请求\" class=\"headerlink\" title=\"Tomcat：默认是1，该线程监听客户端连接请求\"></a>Tomcat：默认是1，该线程监听客户端连接请求</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected class Acceptor extends AbstractEndpoint.Acceptor &#123;</span><br><span class=\"line\">    ........</span><br><span class=\"line\">    SocketChannel socket = null;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        // Accept the next incoming connection from the server</span><br><span class=\"line\">        // socket</span><br><span class=\"line\">        //接收客户端连接请求，使用acceptor，会阻塞，直到有连接请求</span><br><span class=\"line\">        socket = serverSock.accept();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ........</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Acceptor：单线程阻塞监听连接事件，统一处理连接</li>\n<li>Poller：轮询器（最少2个），内部封装了selector，轮询该selector</li>\n<li>PollerEvent：事件处理线程队列，将事件（socket）注册进selector内</li>\n<li>最后使用线程池去处理请求。</li>\n</ul>\n<h2 id=\"Netty：\"><a href=\"#Netty：\" class=\"headerlink\" title=\"Netty：\"></a>Netty：</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public NioServerSocketChannel(ServerSocketChannel channel) &#123;</span><br><span class=\"line\">    super(null, channel, SelectionKey.OP_ACCEPT);</span><br><span class=\"line\">    config = new NioServerSocketChannelConfig(this, javaChannel().socket());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>SelectionKey.OP_ACCEPT标志就是监听套接字所感兴趣的事件了</p>\n<ul>\n<li>使用selector非阻塞模式</li>\n</ul>\n<p><a href=\"https://github.com/fengjiachun/doc/blob/master/netty/Netty%E6%BA%90%E7%A0%81%E7%BB%86%E8%8A%822--bind.md\" target=\"_blank\" rel=\"noopener\">参考博客</a></p>\n"},{"title":"cpu","date":"2020-04-04T14:56:43.000Z","_content":"# 一、大概布局\n![dmq](2020-04-04-cpu/大概布局.png)\n\n# 二、基本组成\n![dmq](2020-04-04-cpu/基本组成.png)\n\n<!--more-->  \n\n1. PC：程序计数器，记录当前指令地址。\n2. Registers：寄存器，暂时存储数据，种类繁多。\n3. ALU：运算单元。\n4. CU：control unit，控制单元。\n5. MMU：memory management unit，内存控制单元。\n6. Cache：缓存，解决CPU运行速度过快，内存读取速度跟不上的问题。\n\n# 三、CPU缓存\n![dmq](2020-04-04-cpu/CPU缓存.png)\n\n\n# 四、缓存组成\n\n缓存行（cache line）：CPU cache的最小单位，通常64字节。【Java中可存8个long】    \n缓存由多个缓存行组成。\n\n\n# 五、缓存读取\n1、先从缓存读取，l1 -> l2 -> l3   \n2、如果缓存中不存在，则去内存中读取，内存存在，则返回。（从内存读取数据，按块读取，每次读取64字节）   \n3、内存不存在，则触发缺页中断，去磁盘读取数据。（内存按页管理，每页4KB）   \n4、然后读取磁盘，磁盘按块读取。（每次从磁盘读取，都是读取的一页或者是多页）\n\n# 六、缓存问题\n![dmq](2020-04-04-cpu/缓存问题.png)\n\n## 6.1、缓存一致性问题\n例如x,y两个变量同时加入到两个CPU内，在各自CPU内运行，再写入内存导致数据一致性问题。\n\n### 解决方案\n\n> 1、缓存一致性协议：mesi\n>* modify：被修改，其他CPU变成无效\n>* exclusive：只有一个CPU读取独占，另外一个CPU也来读取时变成shared\n>* shared：多个CPU共享\n>* invalid：数据被修改了，当前CPU无效\n\n既然MESI解决了缓存一致性，为什么还需要volatile保证可见性？\n* 因为在MESI的具体实现的中，如果一个变量修改了需要将其他CPU置为invalid，那么需要通知所有的CPU，\n如果其他CPU比较繁忙而返回ack会导致高延迟，所以实现MESI时又引入了store buffer和invalid queue，\n在写侧加入store buffer进行写缓存，写完立即返回；在变量状态需要变更侧加入Invalidate Queue来优化更新。\n\n由于store buffer和Invalidate Queue的存在导致了变量状态的变更不及时，所以需要内存屏障\n\n#### 内存屏障\n>* 读屏障，清空本地的invalidate queue，保证之前的所有load都已经生效；\n>* 写屏障，清空本地的store buffer，使得之前的所有store操作都生效。\n\n> 2、总线锁：效率低\n\n## 6.2、伪共享问题\n例如CPU1只需要读取X，CPU2只需要读取Y，但是两个CPU都读取到了不需要的数据。多个线程读写同一个缓存行的数据而导致的缓存失效，\n相互覆盖导致缓存失效未命中，性能问题。\n\n### 解决方案\n\n> 1、字节填充：保证不同线程变量存在不同的cache line内。\n\n> java6解决方案\n```\npublic class PaddingObject {\n    //实例数据\n    public volatile long value=0L;\n    //填充，为什么只有6个long，因为对象的对象头=8字节\n    public long p1,p2,p3,p4,p5,p6;\n}\n```\n\n> java7解决方案\n```\npublic class AbstractPaddingObject {\n    //填充，为什么只有6个long，因为对象的对象头=8字节\n    public long p1,p2,p3,p4,p5,p6;\n}\n\npublic class PaddingObject extends AbstractPaddingObject{\n    //实例数据\n    public volatile long value=0L;\n}\n因为Java7因为JVM的优化，会将填充代码优化掉，从而又回到了伪共享的问题，\n使用继承来解决这个问题。\n```\n\n> java8解决方案\n```\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.FIELD, ElementType.Type)\npublic @interface Contended {\n    String value() default \"\";\n}\n同时需要开启JVM参数：-XX:-RestrictContended=false\n```\n\n# 七、CPU指令重排\n![dmq](2020-04-04-cpu/CPU指令重排.png)\n\n## 7.1、如何禁止指令重排\n方案：内存屏障\n\n内存屏障的作用：\n* 禁止指令重排序\n* 内存可见\n\n## 7.2、内存屏障的实现\n### 1. CPU硬件实现方式（x86架构下）\n> 内存屏障\n* sfence：强制store屏障之前的指令都先执行完，并且store缓冲区的数据写入到内存。\n* lfence：强制Load屏障之前的指令都先执行完，并且一直等到CPU将Load指令执行完。\n* mfence：mixed屏障，混合屏障，复合了sfence, lfence的功能。\n> lock指令\n* 使用总线锁来实现\n### 2.JVM层面规范\n依赖CPU硬件层面的实现。\n> 4个内存屏障\n* LoadLoad：Load1;LoadLoad;Load2，Load2指令的执行，需要Load1之前的语句区别执行完成。\n* LoadStore：Load1;LoadStore;Store，Store语句的执行，需要Load1语句读取完毕。\n* StoreLoad：Store1;StoreLoad;Load2，Load2语句的执行，需要Store1之前的所有语句执行完成并其他处理器对数据可见。\n* StoreStore：Store1;StoreStore;Store2，Store2指令的执行，需要Store1之前的所有语句执行完成并其他处理器对数据可见。\n> \n\n","source":"_posts/2020-04-04-cpu.md","raw":"---\ntitle: cpu\ndate: 2020-04-04 22:56:43\ntags: Linux CPU\ncategories:\n  - [linux]\n---\n# 一、大概布局\n![dmq](2020-04-04-cpu/大概布局.png)\n\n# 二、基本组成\n![dmq](2020-04-04-cpu/基本组成.png)\n\n<!--more-->  \n\n1. PC：程序计数器，记录当前指令地址。\n2. Registers：寄存器，暂时存储数据，种类繁多。\n3. ALU：运算单元。\n4. CU：control unit，控制单元。\n5. MMU：memory management unit，内存控制单元。\n6. Cache：缓存，解决CPU运行速度过快，内存读取速度跟不上的问题。\n\n# 三、CPU缓存\n![dmq](2020-04-04-cpu/CPU缓存.png)\n\n\n# 四、缓存组成\n\n缓存行（cache line）：CPU cache的最小单位，通常64字节。【Java中可存8个long】    \n缓存由多个缓存行组成。\n\n\n# 五、缓存读取\n1、先从缓存读取，l1 -> l2 -> l3   \n2、如果缓存中不存在，则去内存中读取，内存存在，则返回。（从内存读取数据，按块读取，每次读取64字节）   \n3、内存不存在，则触发缺页中断，去磁盘读取数据。（内存按页管理，每页4KB）   \n4、然后读取磁盘，磁盘按块读取。（每次从磁盘读取，都是读取的一页或者是多页）\n\n# 六、缓存问题\n![dmq](2020-04-04-cpu/缓存问题.png)\n\n## 6.1、缓存一致性问题\n例如x,y两个变量同时加入到两个CPU内，在各自CPU内运行，再写入内存导致数据一致性问题。\n\n### 解决方案\n\n> 1、缓存一致性协议：mesi\n>* modify：被修改，其他CPU变成无效\n>* exclusive：只有一个CPU读取独占，另外一个CPU也来读取时变成shared\n>* shared：多个CPU共享\n>* invalid：数据被修改了，当前CPU无效\n\n既然MESI解决了缓存一致性，为什么还需要volatile保证可见性？\n* 因为在MESI的具体实现的中，如果一个变量修改了需要将其他CPU置为invalid，那么需要通知所有的CPU，\n如果其他CPU比较繁忙而返回ack会导致高延迟，所以实现MESI时又引入了store buffer和invalid queue，\n在写侧加入store buffer进行写缓存，写完立即返回；在变量状态需要变更侧加入Invalidate Queue来优化更新。\n\n由于store buffer和Invalidate Queue的存在导致了变量状态的变更不及时，所以需要内存屏障\n\n#### 内存屏障\n>* 读屏障，清空本地的invalidate queue，保证之前的所有load都已经生效；\n>* 写屏障，清空本地的store buffer，使得之前的所有store操作都生效。\n\n> 2、总线锁：效率低\n\n## 6.2、伪共享问题\n例如CPU1只需要读取X，CPU2只需要读取Y，但是两个CPU都读取到了不需要的数据。多个线程读写同一个缓存行的数据而导致的缓存失效，\n相互覆盖导致缓存失效未命中，性能问题。\n\n### 解决方案\n\n> 1、字节填充：保证不同线程变量存在不同的cache line内。\n\n> java6解决方案\n```\npublic class PaddingObject {\n    //实例数据\n    public volatile long value=0L;\n    //填充，为什么只有6个long，因为对象的对象头=8字节\n    public long p1,p2,p3,p4,p5,p6;\n}\n```\n\n> java7解决方案\n```\npublic class AbstractPaddingObject {\n    //填充，为什么只有6个long，因为对象的对象头=8字节\n    public long p1,p2,p3,p4,p5,p6;\n}\n\npublic class PaddingObject extends AbstractPaddingObject{\n    //实例数据\n    public volatile long value=0L;\n}\n因为Java7因为JVM的优化，会将填充代码优化掉，从而又回到了伪共享的问题，\n使用继承来解决这个问题。\n```\n\n> java8解决方案\n```\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.FIELD, ElementType.Type)\npublic @interface Contended {\n    String value() default \"\";\n}\n同时需要开启JVM参数：-XX:-RestrictContended=false\n```\n\n# 七、CPU指令重排\n![dmq](2020-04-04-cpu/CPU指令重排.png)\n\n## 7.1、如何禁止指令重排\n方案：内存屏障\n\n内存屏障的作用：\n* 禁止指令重排序\n* 内存可见\n\n## 7.2、内存屏障的实现\n### 1. CPU硬件实现方式（x86架构下）\n> 内存屏障\n* sfence：强制store屏障之前的指令都先执行完，并且store缓冲区的数据写入到内存。\n* lfence：强制Load屏障之前的指令都先执行完，并且一直等到CPU将Load指令执行完。\n* mfence：mixed屏障，混合屏障，复合了sfence, lfence的功能。\n> lock指令\n* 使用总线锁来实现\n### 2.JVM层面规范\n依赖CPU硬件层面的实现。\n> 4个内存屏障\n* LoadLoad：Load1;LoadLoad;Load2，Load2指令的执行，需要Load1之前的语句区别执行完成。\n* LoadStore：Load1;LoadStore;Store，Store语句的执行，需要Load1语句读取完毕。\n* StoreLoad：Store1;StoreLoad;Load2，Load2语句的执行，需要Store1之前的所有语句执行完成并其他处理器对数据可见。\n* StoreStore：Store1;StoreStore;Store2，Store2指令的执行，需要Store1之前的所有语句执行完成并其他处理器对数据可见。\n> \n\n","slug":"2020-04-04-cpu","published":1,"updated":"2024-12-09T03:23:43.272Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnwq001va13k9icksg7r","content":"<h1 id=\"一、大概布局\"><a href=\"#一、大概布局\" class=\"headerlink\" title=\"一、大概布局\"></a>一、大概布局</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/%E5%A4%A7%E6%A6%82%E5%B8%83%E5%B1%80.png\" alt=\"dmq\"></p>\n<h1 id=\"二、基本组成\"><a href=\"#二、基本组成\" class=\"headerlink\" title=\"二、基本组成\"></a>二、基本组成</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90.png\" alt=\"dmq\"></p>\n<a id=\"more\"></a>  \n\n<ol>\n<li>PC：程序计数器，记录当前指令地址。</li>\n<li>Registers：寄存器，暂时存储数据，种类繁多。</li>\n<li>ALU：运算单元。</li>\n<li>CU：control unit，控制单元。</li>\n<li>MMU：memory management unit，内存控制单元。</li>\n<li>Cache：缓存，解决CPU运行速度过快，内存读取速度跟不上的问题。</li>\n</ol>\n<h1 id=\"三、CPU缓存\"><a href=\"#三、CPU缓存\" class=\"headerlink\" title=\"三、CPU缓存\"></a>三、CPU缓存</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/CPU%E7%BC%93%E5%AD%98.png\" alt=\"dmq\"></p>\n<h1 id=\"四、缓存组成\"><a href=\"#四、缓存组成\" class=\"headerlink\" title=\"四、缓存组成\"></a>四、缓存组成</h1><p>缓存行（cache line）：CPU cache的最小单位，通常64字节。【Java中可存8个long】<br>缓存由多个缓存行组成。</p>\n<h1 id=\"五、缓存读取\"><a href=\"#五、缓存读取\" class=\"headerlink\" title=\"五、缓存读取\"></a>五、缓存读取</h1><p>1、先从缓存读取，l1 -&gt; l2 -&gt; l3<br>2、如果缓存中不存在，则去内存中读取，内存存在，则返回。（从内存读取数据，按块读取，每次读取64字节）<br>3、内存不存在，则触发缺页中断，去磁盘读取数据。（内存按页管理，每页4KB）<br>4、然后读取磁盘，磁盘按块读取。（每次从磁盘读取，都是读取的一页或者是多页）</p>\n<h1 id=\"六、缓存问题\"><a href=\"#六、缓存问题\" class=\"headerlink\" title=\"六、缓存问题\"></a>六、缓存问题</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98.png\" alt=\"dmq\"></p>\n<h2 id=\"6-1、缓存一致性问题\"><a href=\"#6-1、缓存一致性问题\" class=\"headerlink\" title=\"6.1、缓存一致性问题\"></a>6.1、缓存一致性问题</h2><p>例如x,y两个变量同时加入到两个CPU内，在各自CPU内运行，再写入内存导致数据一致性问题。</p>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><blockquote>\n<p>1、缓存一致性协议：mesi</p>\n<ul>\n<li>modify：被修改，其他CPU变成无效</li>\n<li>exclusive：只有一个CPU读取独占，另外一个CPU也来读取时变成shared</li>\n<li>shared：多个CPU共享</li>\n<li>invalid：数据被修改了，当前CPU无效</li>\n</ul>\n</blockquote>\n<p>既然MESI解决了缓存一致性，为什么还需要volatile保证可见性？</p>\n<ul>\n<li>因为在MESI的具体实现的中，如果一个变量修改了需要将其他CPU置为invalid，那么需要通知所有的CPU，<br>如果其他CPU比较繁忙而返回ack会导致高延迟，所以实现MESI时又引入了store buffer和invalid queue，<br>在写侧加入store buffer进行写缓存，写完立即返回；在变量状态需要变更侧加入Invalidate Queue来优化更新。</li>\n</ul>\n<p>由于store buffer和Invalidate Queue的存在导致了变量状态的变更不及时，所以需要内存屏障</p>\n<h4 id=\"内存屏障\"><a href=\"#内存屏障\" class=\"headerlink\" title=\"内存屏障\"></a>内存屏障</h4><blockquote>\n<ul>\n<li>读屏障，清空本地的invalidate queue，保证之前的所有load都已经生效；</li>\n<li>写屏障，清空本地的store buffer，使得之前的所有store操作都生效。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>2、总线锁：效率低</p>\n</blockquote>\n<h2 id=\"6-2、伪共享问题\"><a href=\"#6-2、伪共享问题\" class=\"headerlink\" title=\"6.2、伪共享问题\"></a>6.2、伪共享问题</h2><p>例如CPU1只需要读取X，CPU2只需要读取Y，但是两个CPU都读取到了不需要的数据。多个线程读写同一个缓存行的数据而导致的缓存失效，<br>相互覆盖导致缓存失效未命中，性能问题。</p>\n<h3 id=\"解决方案-1\"><a href=\"#解决方案-1\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><blockquote>\n<p>1、字节填充：保证不同线程变量存在不同的cache line内。</p>\n</blockquote>\n<blockquote>\n<p>java6解决方案</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class PaddingObject &#123;</span><br><span class=\"line\">    //实例数据</span><br><span class=\"line\">    public volatile long value=0L;</span><br><span class=\"line\">    //填充，为什么只有6个long，因为对象的对象头=8字节</span><br><span class=\"line\">    public long p1,p2,p3,p4,p5,p6;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>java7解决方案</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class AbstractPaddingObject &#123;</span><br><span class=\"line\">    //填充，为什么只有6个long，因为对象的对象头=8字节</span><br><span class=\"line\">    public long p1,p2,p3,p4,p5,p6;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">public class PaddingObject extends AbstractPaddingObject&#123;</span><br><span class=\"line\">    //实例数据</span><br><span class=\"line\">    public volatile long value=0L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">因为Java7因为JVM的优化，会将填充代码优化掉，从而又回到了伪共享的问题，</span><br><span class=\"line\">使用继承来解决这个问题。</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>java8解决方案</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Retention(RetentionPolicy.RUNTIME)</span><br><span class=\"line\">@Target(ElementType.FIELD, ElementType.Type)</span><br><span class=\"line\">public @interface Contended &#123;</span><br><span class=\"line\">    String value() default &quot;&quot;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">同时需要开启JVM参数：-XX:-RestrictContended=false</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"七、CPU指令重排\"><a href=\"#七、CPU指令重排\" class=\"headerlink\" title=\"七、CPU指令重排\"></a>七、CPU指令重排</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/CPU%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92.png\" alt=\"dmq\"></p>\n<h2 id=\"7-1、如何禁止指令重排\"><a href=\"#7-1、如何禁止指令重排\" class=\"headerlink\" title=\"7.1、如何禁止指令重排\"></a>7.1、如何禁止指令重排</h2><p>方案：内存屏障</p>\n<p>内存屏障的作用：</p>\n<ul>\n<li>禁止指令重排序</li>\n<li>内存可见</li>\n</ul>\n<h2 id=\"7-2、内存屏障的实现\"><a href=\"#7-2、内存屏障的实现\" class=\"headerlink\" title=\"7.2、内存屏障的实现\"></a>7.2、内存屏障的实现</h2><h3 id=\"1-CPU硬件实现方式（x86架构下）\"><a href=\"#1-CPU硬件实现方式（x86架构下）\" class=\"headerlink\" title=\"1. CPU硬件实现方式（x86架构下）\"></a>1. CPU硬件实现方式（x86架构下）</h3><blockquote>\n<p>内存屏障</p>\n<ul>\n<li>sfence：强制store屏障之前的指令都先执行完，并且store缓冲区的数据写入到内存。</li>\n<li>lfence：强制Load屏障之前的指令都先执行完，并且一直等到CPU将Load指令执行完。</li>\n<li>mfence：mixed屏障，混合屏障，复合了sfence, lfence的功能。<br>lock指令</li>\n<li>使用总线锁来实现</li>\n</ul>\n</blockquote>\n<h3 id=\"2-JVM层面规范\"><a href=\"#2-JVM层面规范\" class=\"headerlink\" title=\"2.JVM层面规范\"></a>2.JVM层面规范</h3><p>依赖CPU硬件层面的实现。</p>\n<blockquote>\n<p>4个内存屏障</p>\n<ul>\n<li>LoadLoad：Load1;LoadLoad;Load2，Load2指令的执行，需要Load1之前的语句区别执行完成。</li>\n<li>LoadStore：Load1;LoadStore;Store，Store语句的执行，需要Load1语句读取完毕。</li>\n<li>StoreLoad：Store1;StoreLoad;Load2，Load2语句的执行，需要Store1之前的所有语句执行完成并其他处理器对数据可见。</li>\n<li>StoreStore：Store1;StoreStore;Store2，Store2指令的执行，需要Store1之前的所有语句执行完成并其他处理器对数据可见。</li>\n</ul>\n</blockquote>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、大概布局\"><a href=\"#一、大概布局\" class=\"headerlink\" title=\"一、大概布局\"></a>一、大概布局</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/%E5%A4%A7%E6%A6%82%E5%B8%83%E5%B1%80.png\" alt=\"dmq\"></p>\n<h1 id=\"二、基本组成\"><a href=\"#二、基本组成\" class=\"headerlink\" title=\"二、基本组成\"></a>二、基本组成</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90.png\" alt=\"dmq\"></p>","more":"<ol>\n<li>PC：程序计数器，记录当前指令地址。</li>\n<li>Registers：寄存器，暂时存储数据，种类繁多。</li>\n<li>ALU：运算单元。</li>\n<li>CU：control unit，控制单元。</li>\n<li>MMU：memory management unit，内存控制单元。</li>\n<li>Cache：缓存，解决CPU运行速度过快，内存读取速度跟不上的问题。</li>\n</ol>\n<h1 id=\"三、CPU缓存\"><a href=\"#三、CPU缓存\" class=\"headerlink\" title=\"三、CPU缓存\"></a>三、CPU缓存</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/CPU%E7%BC%93%E5%AD%98.png\" alt=\"dmq\"></p>\n<h1 id=\"四、缓存组成\"><a href=\"#四、缓存组成\" class=\"headerlink\" title=\"四、缓存组成\"></a>四、缓存组成</h1><p>缓存行（cache line）：CPU cache的最小单位，通常64字节。【Java中可存8个long】<br>缓存由多个缓存行组成。</p>\n<h1 id=\"五、缓存读取\"><a href=\"#五、缓存读取\" class=\"headerlink\" title=\"五、缓存读取\"></a>五、缓存读取</h1><p>1、先从缓存读取，l1 -&gt; l2 -&gt; l3<br>2、如果缓存中不存在，则去内存中读取，内存存在，则返回。（从内存读取数据，按块读取，每次读取64字节）<br>3、内存不存在，则触发缺页中断，去磁盘读取数据。（内存按页管理，每页4KB）<br>4、然后读取磁盘，磁盘按块读取。（每次从磁盘读取，都是读取的一页或者是多页）</p>\n<h1 id=\"六、缓存问题\"><a href=\"#六、缓存问题\" class=\"headerlink\" title=\"六、缓存问题\"></a>六、缓存问题</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98.png\" alt=\"dmq\"></p>\n<h2 id=\"6-1、缓存一致性问题\"><a href=\"#6-1、缓存一致性问题\" class=\"headerlink\" title=\"6.1、缓存一致性问题\"></a>6.1、缓存一致性问题</h2><p>例如x,y两个变量同时加入到两个CPU内，在各自CPU内运行，再写入内存导致数据一致性问题。</p>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><blockquote>\n<p>1、缓存一致性协议：mesi</p>\n<ul>\n<li>modify：被修改，其他CPU变成无效</li>\n<li>exclusive：只有一个CPU读取独占，另外一个CPU也来读取时变成shared</li>\n<li>shared：多个CPU共享</li>\n<li>invalid：数据被修改了，当前CPU无效</li>\n</ul>\n</blockquote>\n<p>既然MESI解决了缓存一致性，为什么还需要volatile保证可见性？</p>\n<ul>\n<li>因为在MESI的具体实现的中，如果一个变量修改了需要将其他CPU置为invalid，那么需要通知所有的CPU，<br>如果其他CPU比较繁忙而返回ack会导致高延迟，所以实现MESI时又引入了store buffer和invalid queue，<br>在写侧加入store buffer进行写缓存，写完立即返回；在变量状态需要变更侧加入Invalidate Queue来优化更新。</li>\n</ul>\n<p>由于store buffer和Invalidate Queue的存在导致了变量状态的变更不及时，所以需要内存屏障</p>\n<h4 id=\"内存屏障\"><a href=\"#内存屏障\" class=\"headerlink\" title=\"内存屏障\"></a>内存屏障</h4><blockquote>\n<ul>\n<li>读屏障，清空本地的invalidate queue，保证之前的所有load都已经生效；</li>\n<li>写屏障，清空本地的store buffer，使得之前的所有store操作都生效。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>2、总线锁：效率低</p>\n</blockquote>\n<h2 id=\"6-2、伪共享问题\"><a href=\"#6-2、伪共享问题\" class=\"headerlink\" title=\"6.2、伪共享问题\"></a>6.2、伪共享问题</h2><p>例如CPU1只需要读取X，CPU2只需要读取Y，但是两个CPU都读取到了不需要的数据。多个线程读写同一个缓存行的数据而导致的缓存失效，<br>相互覆盖导致缓存失效未命中，性能问题。</p>\n<h3 id=\"解决方案-1\"><a href=\"#解决方案-1\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><blockquote>\n<p>1、字节填充：保证不同线程变量存在不同的cache line内。</p>\n</blockquote>\n<blockquote>\n<p>java6解决方案</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class PaddingObject &#123;</span><br><span class=\"line\">    //实例数据</span><br><span class=\"line\">    public volatile long value=0L;</span><br><span class=\"line\">    //填充，为什么只有6个long，因为对象的对象头=8字节</span><br><span class=\"line\">    public long p1,p2,p3,p4,p5,p6;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>java7解决方案</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class AbstractPaddingObject &#123;</span><br><span class=\"line\">    //填充，为什么只有6个long，因为对象的对象头=8字节</span><br><span class=\"line\">    public long p1,p2,p3,p4,p5,p6;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">public class PaddingObject extends AbstractPaddingObject&#123;</span><br><span class=\"line\">    //实例数据</span><br><span class=\"line\">    public volatile long value=0L;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">因为Java7因为JVM的优化，会将填充代码优化掉，从而又回到了伪共享的问题，</span><br><span class=\"line\">使用继承来解决这个问题。</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>java8解决方案</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Retention(RetentionPolicy.RUNTIME)</span><br><span class=\"line\">@Target(ElementType.FIELD, ElementType.Type)</span><br><span class=\"line\">public @interface Contended &#123;</span><br><span class=\"line\">    String value() default &quot;&quot;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">同时需要开启JVM参数：-XX:-RestrictContended=false</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"七、CPU指令重排\"><a href=\"#七、CPU指令重排\" class=\"headerlink\" title=\"七、CPU指令重排\"></a>七、CPU指令重排</h1><p><img src=\"/2020/04/04/2020-04-04-cpu/CPU%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92.png\" alt=\"dmq\"></p>\n<h2 id=\"7-1、如何禁止指令重排\"><a href=\"#7-1、如何禁止指令重排\" class=\"headerlink\" title=\"7.1、如何禁止指令重排\"></a>7.1、如何禁止指令重排</h2><p>方案：内存屏障</p>\n<p>内存屏障的作用：</p>\n<ul>\n<li>禁止指令重排序</li>\n<li>内存可见</li>\n</ul>\n<h2 id=\"7-2、内存屏障的实现\"><a href=\"#7-2、内存屏障的实现\" class=\"headerlink\" title=\"7.2、内存屏障的实现\"></a>7.2、内存屏障的实现</h2><h3 id=\"1-CPU硬件实现方式（x86架构下）\"><a href=\"#1-CPU硬件实现方式（x86架构下）\" class=\"headerlink\" title=\"1. CPU硬件实现方式（x86架构下）\"></a>1. CPU硬件实现方式（x86架构下）</h3><blockquote>\n<p>内存屏障</p>\n<ul>\n<li>sfence：强制store屏障之前的指令都先执行完，并且store缓冲区的数据写入到内存。</li>\n<li>lfence：强制Load屏障之前的指令都先执行完，并且一直等到CPU将Load指令执行完。</li>\n<li>mfence：mixed屏障，混合屏障，复合了sfence, lfence的功能。<br>lock指令</li>\n<li>使用总线锁来实现</li>\n</ul>\n</blockquote>\n<h3 id=\"2-JVM层面规范\"><a href=\"#2-JVM层面规范\" class=\"headerlink\" title=\"2.JVM层面规范\"></a>2.JVM层面规范</h3><p>依赖CPU硬件层面的实现。</p>\n<blockquote>\n<p>4个内存屏障</p>\n<ul>\n<li>LoadLoad：Load1;LoadLoad;Load2，Load2指令的执行，需要Load1之前的语句区别执行完成。</li>\n<li>LoadStore：Load1;LoadStore;Store，Store语句的执行，需要Load1语句读取完毕。</li>\n<li>StoreLoad：Store1;StoreLoad;Load2，Load2语句的执行，需要Store1之前的所有语句执行完成并其他处理器对数据可见。</li>\n<li>StoreStore：Store1;StoreStore;Store2，Store2指令的执行，需要Store1之前的所有语句执行完成并其他处理器对数据可见。</li>\n</ul>\n</blockquote>"},{"title":"tomcat请求过程","date":"2019-12-22T12:36:02.000Z","_content":"# 一、一个请求的过程\n1. socket 接收到连接请求，Accepter 将socket注册进Poller内。（生成PollerEvent，线程池，处理socket）\n2. poller处理PollerEvent，创建SocketProcessor处理线程，将该处理线程放入Executor线程池内。\n3. 线程执行，创建Processor去处理socket，processor会将socket处理成coyoteRequest.\n4. adapter将coyoteRequest适配成HttpServletRequest\n5. 然后调用管道进行传输，直到StandardWrapperValve\n6. 然后获取到StandardWrapper【StandardWrapper的定义在读取web.xml时已经创建】\n7. StandardWrapper通过servlet名称去反射创建servlet对象。\n8. 然后调用servlet.init方法，进行servlet的初始化工作。\n\n<!--more-->\n\n# 二、如何找到请求的servlet？\n```\npublic void service(org.apache.coyote.Request req, org.apache.coyote.Response res)\n        throws Exception {\n    //将coyoteRequest转换成HttpServletRequest\n    Request request = (Request) req.getNote(ADAPTER_NOTES);\n    Response response = (Response) res.getNote(ADAPTER_NOTES);\n    try {\n        // Parse and set Catalina and configuration specific\n        // request parameters\n        //也就是在此处根据请求信息将制定的Host,Context,Wrapper实例对象封装到request实例中\n        postParseSuccess = postParseRequest(req, request, res, response);\n        // Calling the container\n        //将request和response交给容器处理，最后到wrapper\n        connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);\n```\n\n## 2.1、StandardWrapperValve\n```\npublic final void invoke(Request request, Response response)\n    throws IOException, ServletException {\n    // Initialize local variables we may need\n    boolean unavailable = false;\n    Throwable throwable = null;\n    // This should be a Request attribute...\n    long t1=System.currentTimeMillis();\n    requestCount.incrementAndGet();\n    StandardWrapper wrapper = (StandardWrapper) getContainer();\n    Servlet servlet = null;\n    Context context = (Context) wrapper.getParent();\n    // Allocate a servlet instance to process this request\n    try {\n        if (!unavailable) {\n            //调用wrapper.allocate去创建servlet，除load-on-starup类型的servlet，都是第一次请求来时去创建\n            servlet = wrapper.allocate();\n        }\n    }\n    \n    // 创建过滤链\n    ApplicationFilterChain filterChain =\n        ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);\n    filterChain.doFilter(request.getRequest(),\n        response.getResponse());\n\n```\n## 2.2、StandardWrapper\n具体的servlet包装对象\n```\npublic Servlet allocate() throws ServletException {\n    // If not SingleThreadedModel, return the same instance every time\n    if (!singleThreadModel) {\n        // Load and initialize our instance if necessary\n        if (instance == null || !instanceInitialized) {\n            synchronized (this) {\n                if (instance == null) {\n                    try {\n                        // Note: We don't know if the Servlet implements\n                        // SingleThreadModel until we have loaded it.\n                        instance = loadServlet();\n                        newInstance = true;\n                }\n            }\n        }\n        \n        \npublic synchronized Servlet loadServlet() throws ServletException {\n    Servlet servlet;\n    try {\n        InstanceManager instanceManager = ((StandardContext)getParent()).getInstanceManager();\n        try {\n            //传入servlet名称，然后反射创建对象\n            servlet = (Servlet) instanceManager.newInstance(servletClass);\n        } catch (ClassCastException e) {\n            unavailable(null);\n            // Restore the context ClassLoader\n            throw new ServletException\n                (sm.getString(\"standardWrapper.notServlet\", servletClass), e);\n        } catch (Throwable e) {\n        }\n        //初始化对象\n        initServlet(servlet);\n    } finally {    }\n    return servlet;\n}        \n        \nprivate synchronized void initServlet(Servlet servlet)\n        throws ServletException {\n    // Call the initialization method of this servlet\n    try {\n        //调用具体Servlet的init方法进行实例化\n        servlet.init(facade);\n        }        \n        \n```\n\n\n[参考](https://blog.csdn.net/qq_38975553/article/details/103434423)\n\n\n\n","source":"_posts/2019-12-22-tomcat请求过程.md","raw":"---\ntitle: tomcat请求过程\ndate: 2019-12-22 20:36:02\ntags: Tomcat\n---\n# 一、一个请求的过程\n1. socket 接收到连接请求，Accepter 将socket注册进Poller内。（生成PollerEvent，线程池，处理socket）\n2. poller处理PollerEvent，创建SocketProcessor处理线程，将该处理线程放入Executor线程池内。\n3. 线程执行，创建Processor去处理socket，processor会将socket处理成coyoteRequest.\n4. adapter将coyoteRequest适配成HttpServletRequest\n5. 然后调用管道进行传输，直到StandardWrapperValve\n6. 然后获取到StandardWrapper【StandardWrapper的定义在读取web.xml时已经创建】\n7. StandardWrapper通过servlet名称去反射创建servlet对象。\n8. 然后调用servlet.init方法，进行servlet的初始化工作。\n\n<!--more-->\n\n# 二、如何找到请求的servlet？\n```\npublic void service(org.apache.coyote.Request req, org.apache.coyote.Response res)\n        throws Exception {\n    //将coyoteRequest转换成HttpServletRequest\n    Request request = (Request) req.getNote(ADAPTER_NOTES);\n    Response response = (Response) res.getNote(ADAPTER_NOTES);\n    try {\n        // Parse and set Catalina and configuration specific\n        // request parameters\n        //也就是在此处根据请求信息将制定的Host,Context,Wrapper实例对象封装到request实例中\n        postParseSuccess = postParseRequest(req, request, res, response);\n        // Calling the container\n        //将request和response交给容器处理，最后到wrapper\n        connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);\n```\n\n## 2.1、StandardWrapperValve\n```\npublic final void invoke(Request request, Response response)\n    throws IOException, ServletException {\n    // Initialize local variables we may need\n    boolean unavailable = false;\n    Throwable throwable = null;\n    // This should be a Request attribute...\n    long t1=System.currentTimeMillis();\n    requestCount.incrementAndGet();\n    StandardWrapper wrapper = (StandardWrapper) getContainer();\n    Servlet servlet = null;\n    Context context = (Context) wrapper.getParent();\n    // Allocate a servlet instance to process this request\n    try {\n        if (!unavailable) {\n            //调用wrapper.allocate去创建servlet，除load-on-starup类型的servlet，都是第一次请求来时去创建\n            servlet = wrapper.allocate();\n        }\n    }\n    \n    // 创建过滤链\n    ApplicationFilterChain filterChain =\n        ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);\n    filterChain.doFilter(request.getRequest(),\n        response.getResponse());\n\n```\n## 2.2、StandardWrapper\n具体的servlet包装对象\n```\npublic Servlet allocate() throws ServletException {\n    // If not SingleThreadedModel, return the same instance every time\n    if (!singleThreadModel) {\n        // Load and initialize our instance if necessary\n        if (instance == null || !instanceInitialized) {\n            synchronized (this) {\n                if (instance == null) {\n                    try {\n                        // Note: We don't know if the Servlet implements\n                        // SingleThreadModel until we have loaded it.\n                        instance = loadServlet();\n                        newInstance = true;\n                }\n            }\n        }\n        \n        \npublic synchronized Servlet loadServlet() throws ServletException {\n    Servlet servlet;\n    try {\n        InstanceManager instanceManager = ((StandardContext)getParent()).getInstanceManager();\n        try {\n            //传入servlet名称，然后反射创建对象\n            servlet = (Servlet) instanceManager.newInstance(servletClass);\n        } catch (ClassCastException e) {\n            unavailable(null);\n            // Restore the context ClassLoader\n            throw new ServletException\n                (sm.getString(\"standardWrapper.notServlet\", servletClass), e);\n        } catch (Throwable e) {\n        }\n        //初始化对象\n        initServlet(servlet);\n    } finally {    }\n    return servlet;\n}        \n        \nprivate synchronized void initServlet(Servlet servlet)\n        throws ServletException {\n    // Call the initialization method of this servlet\n    try {\n        //调用具体Servlet的init方法进行实例化\n        servlet.init(facade);\n        }        \n        \n```\n\n\n[参考](https://blog.csdn.net/qq_38975553/article/details/103434423)\n\n\n\n","slug":"2019-12-22-tomcat请求过程","published":1,"updated":"2024-10-14T09:38:12.040Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnwu001za13kexfrmt44","content":"<h1 id=\"一、一个请求的过程\"><a href=\"#一、一个请求的过程\" class=\"headerlink\" title=\"一、一个请求的过程\"></a>一、一个请求的过程</h1><ol>\n<li>socket 接收到连接请求，Accepter 将socket注册进Poller内。（生成PollerEvent，线程池，处理socket）</li>\n<li>poller处理PollerEvent，创建SocketProcessor处理线程，将该处理线程放入Executor线程池内。</li>\n<li>线程执行，创建Processor去处理socket，processor会将socket处理成coyoteRequest.</li>\n<li>adapter将coyoteRequest适配成HttpServletRequest</li>\n<li>然后调用管道进行传输，直到StandardWrapperValve</li>\n<li>然后获取到StandardWrapper【StandardWrapper的定义在读取web.xml时已经创建】</li>\n<li>StandardWrapper通过servlet名称去反射创建servlet对象。</li>\n<li>然后调用servlet.init方法，进行servlet的初始化工作。</li>\n</ol>\n<a id=\"more\"></a>\n\n<h1 id=\"二、如何找到请求的servlet？\"><a href=\"#二、如何找到请求的servlet？\" class=\"headerlink\" title=\"二、如何找到请求的servlet？\"></a>二、如何找到请求的servlet？</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void service(org.apache.coyote.Request req, org.apache.coyote.Response res)</span><br><span class=\"line\">        throws Exception &#123;</span><br><span class=\"line\">    //将coyoteRequest转换成HttpServletRequest</span><br><span class=\"line\">    Request request = (Request) req.getNote(ADAPTER_NOTES);</span><br><span class=\"line\">    Response response = (Response) res.getNote(ADAPTER_NOTES);</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        // Parse and set Catalina and configuration specific</span><br><span class=\"line\">        // request parameters</span><br><span class=\"line\">        //也就是在此处根据请求信息将制定的Host,Context,Wrapper实例对象封装到request实例中</span><br><span class=\"line\">        postParseSuccess = postParseRequest(req, request, res, response);</span><br><span class=\"line\">        // Calling the container</span><br><span class=\"line\">        //将request和response交给容器处理，最后到wrapper</span><br><span class=\"line\">        connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-1、StandardWrapperValve\"><a href=\"#2-1、StandardWrapperValve\" class=\"headerlink\" title=\"2.1、StandardWrapperValve\"></a>2.1、StandardWrapperValve</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public final void invoke(Request request, Response response)</span><br><span class=\"line\">    throws IOException, ServletException &#123;</span><br><span class=\"line\">    // Initialize local variables we may need</span><br><span class=\"line\">    boolean unavailable = false;</span><br><span class=\"line\">    Throwable throwable = null;</span><br><span class=\"line\">    // This should be a Request attribute...</span><br><span class=\"line\">    long t1=System.currentTimeMillis();</span><br><span class=\"line\">    requestCount.incrementAndGet();</span><br><span class=\"line\">    StandardWrapper wrapper = (StandardWrapper) getContainer();</span><br><span class=\"line\">    Servlet servlet = null;</span><br><span class=\"line\">    Context context = (Context) wrapper.getParent();</span><br><span class=\"line\">    // Allocate a servlet instance to process this request</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (!unavailable) &#123;</span><br><span class=\"line\">            //调用wrapper.allocate去创建servlet，除load-on-starup类型的servlet，都是第一次请求来时去创建</span><br><span class=\"line\">            servlet = wrapper.allocate();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // 创建过滤链</span><br><span class=\"line\">    ApplicationFilterChain filterChain =</span><br><span class=\"line\">        ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);</span><br><span class=\"line\">    filterChain.doFilter(request.getRequest(),</span><br><span class=\"line\">        response.getResponse());</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-2、StandardWrapper\"><a href=\"#2-2、StandardWrapper\" class=\"headerlink\" title=\"2.2、StandardWrapper\"></a>2.2、StandardWrapper</h2><p>具体的servlet包装对象</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Servlet allocate() throws ServletException &#123;</span><br><span class=\"line\">    // If not SingleThreadedModel, return the same instance every time</span><br><span class=\"line\">    if (!singleThreadModel) &#123;</span><br><span class=\"line\">        // Load and initialize our instance if necessary</span><br><span class=\"line\">        if (instance == null || !instanceInitialized) &#123;</span><br><span class=\"line\">            synchronized (this) &#123;</span><br><span class=\"line\">                if (instance == null) &#123;</span><br><span class=\"line\">                    try &#123;</span><br><span class=\"line\">                        // Note: We don&apos;t know if the Servlet implements</span><br><span class=\"line\">                        // SingleThreadModel until we have loaded it.</span><br><span class=\"line\">                        instance = loadServlet();</span><br><span class=\"line\">                        newInstance = true;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">public synchronized Servlet loadServlet() throws ServletException &#123;</span><br><span class=\"line\">    Servlet servlet;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        InstanceManager instanceManager = ((StandardContext)getParent()).getInstanceManager();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            //传入servlet名称，然后反射创建对象</span><br><span class=\"line\">            servlet = (Servlet) instanceManager.newInstance(servletClass);</span><br><span class=\"line\">        &#125; catch (ClassCastException e) &#123;</span><br><span class=\"line\">            unavailable(null);</span><br><span class=\"line\">            // Restore the context ClassLoader</span><br><span class=\"line\">            throw new ServletException</span><br><span class=\"line\">                (sm.getString(&quot;standardWrapper.notServlet&quot;, servletClass), e);</span><br><span class=\"line\">        &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //初始化对象</span><br><span class=\"line\">        initServlet(servlet);</span><br><span class=\"line\">    &#125; finally &#123;    &#125;</span><br><span class=\"line\">    return servlet;</span><br><span class=\"line\">&#125;        </span><br><span class=\"line\">        </span><br><span class=\"line\">private synchronized void initServlet(Servlet servlet)</span><br><span class=\"line\">        throws ServletException &#123;</span><br><span class=\"line\">    // Call the initialization method of this servlet</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        //调用具体Servlet的init方法进行实例化</span><br><span class=\"line\">        servlet.init(facade);</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://blog.csdn.net/qq_38975553/article/details/103434423\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、一个请求的过程\"><a href=\"#一、一个请求的过程\" class=\"headerlink\" title=\"一、一个请求的过程\"></a>一、一个请求的过程</h1><ol>\n<li>socket 接收到连接请求，Accepter 将socket注册进Poller内。（生成PollerEvent，线程池，处理socket）</li>\n<li>poller处理PollerEvent，创建SocketProcessor处理线程，将该处理线程放入Executor线程池内。</li>\n<li>线程执行，创建Processor去处理socket，processor会将socket处理成coyoteRequest.</li>\n<li>adapter将coyoteRequest适配成HttpServletRequest</li>\n<li>然后调用管道进行传输，直到StandardWrapperValve</li>\n<li>然后获取到StandardWrapper【StandardWrapper的定义在读取web.xml时已经创建】</li>\n<li>StandardWrapper通过servlet名称去反射创建servlet对象。</li>\n<li>然后调用servlet.init方法，进行servlet的初始化工作。</li>\n</ol>","more":"<h1 id=\"二、如何找到请求的servlet？\"><a href=\"#二、如何找到请求的servlet？\" class=\"headerlink\" title=\"二、如何找到请求的servlet？\"></a>二、如何找到请求的servlet？</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void service(org.apache.coyote.Request req, org.apache.coyote.Response res)</span><br><span class=\"line\">        throws Exception &#123;</span><br><span class=\"line\">    //将coyoteRequest转换成HttpServletRequest</span><br><span class=\"line\">    Request request = (Request) req.getNote(ADAPTER_NOTES);</span><br><span class=\"line\">    Response response = (Response) res.getNote(ADAPTER_NOTES);</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        // Parse and set Catalina and configuration specific</span><br><span class=\"line\">        // request parameters</span><br><span class=\"line\">        //也就是在此处根据请求信息将制定的Host,Context,Wrapper实例对象封装到request实例中</span><br><span class=\"line\">        postParseSuccess = postParseRequest(req, request, res, response);</span><br><span class=\"line\">        // Calling the container</span><br><span class=\"line\">        //将request和response交给容器处理，最后到wrapper</span><br><span class=\"line\">        connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-1、StandardWrapperValve\"><a href=\"#2-1、StandardWrapperValve\" class=\"headerlink\" title=\"2.1、StandardWrapperValve\"></a>2.1、StandardWrapperValve</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public final void invoke(Request request, Response response)</span><br><span class=\"line\">    throws IOException, ServletException &#123;</span><br><span class=\"line\">    // Initialize local variables we may need</span><br><span class=\"line\">    boolean unavailable = false;</span><br><span class=\"line\">    Throwable throwable = null;</span><br><span class=\"line\">    // This should be a Request attribute...</span><br><span class=\"line\">    long t1=System.currentTimeMillis();</span><br><span class=\"line\">    requestCount.incrementAndGet();</span><br><span class=\"line\">    StandardWrapper wrapper = (StandardWrapper) getContainer();</span><br><span class=\"line\">    Servlet servlet = null;</span><br><span class=\"line\">    Context context = (Context) wrapper.getParent();</span><br><span class=\"line\">    // Allocate a servlet instance to process this request</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (!unavailable) &#123;</span><br><span class=\"line\">            //调用wrapper.allocate去创建servlet，除load-on-starup类型的servlet，都是第一次请求来时去创建</span><br><span class=\"line\">            servlet = wrapper.allocate();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // 创建过滤链</span><br><span class=\"line\">    ApplicationFilterChain filterChain =</span><br><span class=\"line\">        ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);</span><br><span class=\"line\">    filterChain.doFilter(request.getRequest(),</span><br><span class=\"line\">        response.getResponse());</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-2、StandardWrapper\"><a href=\"#2-2、StandardWrapper\" class=\"headerlink\" title=\"2.2、StandardWrapper\"></a>2.2、StandardWrapper</h2><p>具体的servlet包装对象</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Servlet allocate() throws ServletException &#123;</span><br><span class=\"line\">    // If not SingleThreadedModel, return the same instance every time</span><br><span class=\"line\">    if (!singleThreadModel) &#123;</span><br><span class=\"line\">        // Load and initialize our instance if necessary</span><br><span class=\"line\">        if (instance == null || !instanceInitialized) &#123;</span><br><span class=\"line\">            synchronized (this) &#123;</span><br><span class=\"line\">                if (instance == null) &#123;</span><br><span class=\"line\">                    try &#123;</span><br><span class=\"line\">                        // Note: We don&apos;t know if the Servlet implements</span><br><span class=\"line\">                        // SingleThreadModel until we have loaded it.</span><br><span class=\"line\">                        instance = loadServlet();</span><br><span class=\"line\">                        newInstance = true;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">public synchronized Servlet loadServlet() throws ServletException &#123;</span><br><span class=\"line\">    Servlet servlet;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        InstanceManager instanceManager = ((StandardContext)getParent()).getInstanceManager();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            //传入servlet名称，然后反射创建对象</span><br><span class=\"line\">            servlet = (Servlet) instanceManager.newInstance(servletClass);</span><br><span class=\"line\">        &#125; catch (ClassCastException e) &#123;</span><br><span class=\"line\">            unavailable(null);</span><br><span class=\"line\">            // Restore the context ClassLoader</span><br><span class=\"line\">            throw new ServletException</span><br><span class=\"line\">                (sm.getString(&quot;standardWrapper.notServlet&quot;, servletClass), e);</span><br><span class=\"line\">        &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //初始化对象</span><br><span class=\"line\">        initServlet(servlet);</span><br><span class=\"line\">    &#125; finally &#123;    &#125;</span><br><span class=\"line\">    return servlet;</span><br><span class=\"line\">&#125;        </span><br><span class=\"line\">        </span><br><span class=\"line\">private synchronized void initServlet(Servlet servlet)</span><br><span class=\"line\">        throws ServletException &#123;</span><br><span class=\"line\">    // Call the initialization method of this servlet</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        //调用具体Servlet的init方法进行实例化</span><br><span class=\"line\">        servlet.init(facade);</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://blog.csdn.net/qq_38975553/article/details/103434423\" target=\"_blank\" rel=\"noopener\">参考</a></p>"},{"title":"linux pagecache","date":"2020-08-08T13:24:46.000Z","_content":"\n## 一、磁盘文件的存储\n\n1. 磁盘的最小存储单元是扇区sector，一个扇区是512个字节\n2. 存储在磁盘的文件系统采用块作为最小的存储单元，1个块大小一般是4KB(1KB, 2KB, 4KB, 8KB)\n3. 磁盘管理器负责处理块到扇区的映射，给定设备号和块号，磁盘管理器可以很方便找到对应的扇区\n\n<!--more-->    \n\n## 二、page cache\n缓存**文件**内容，以page为单位。\n\n## 三、buffer cache\n缓存**硬盘**内容，以块为单位。\n磁盘的最小数据单位为sector（扇区），内核会在磁盘sector上构建一层缓存，他以sector的整数倍力度单位(block)，缓存部分sector数据在内存中\n\n\n## 四、逻辑关系\n\n从linux-2.6.18的内核源码来看，Page Cache和Buffer Cache是一个事物的两种表现：对于一个Page而言，对上，他是某个File的一个Page Cache，而对下，他同样是一个Device上的一组Buffer Cache。\n实际IO操作，都是与page cache交互，不与内存直接交互\n\n*The term, Buffer Cache, is often used for the Page Cache. Linux kernels up to version 2.2 had both a Page Cache as well as a Buffer Cache. As of the 2.4 kernel, these two caches have been combined. Today, there is only one cache, the Page Cache.*\n\n***假设page cache=4K，buffer cache=1k，则一个page cache中有4个buffer cache。（page cache和buffer cache合并后）***\n\n[注意]：这里的Page Cache与Buffer Cache的融合，是针对文件这一层面的Page Cache与Buffer Cache的融合。对于跨层的：File层面的Page Cache和裸设备Buffer Cache，虽然都统一到了基于Page的实现，但File的Page Cache和该文件对应的Block在裸设备层访问的Buffer Cache，这两个是完全独立的Page，这种情况下，一个物理磁盘Block上的数据，仍然对应了Linux内核中的两份Page，一个是通过文件层访问的File的Page Cache(Page Cache)，一个是通过裸设备层访问的Page Cache(Buffer Cache)。\n\n![逻辑关系](2020-04-10-linux-pagecache/27_file_page_device_block.png)\n\n\n## 五、write->系统调用->内核是怎么处理的？\n\n写的时候，内核应该是从用户态进程空间将数据copy至内核态的page cache，此时内核会返回程序写入成功结果，但是数据并没有实际写入硬盘;\n程序可以调用flush方法将数据写入硬盘，或者是等内核自己写入磁盘（例如page cache空间不足时，或者是定时写磁盘）;\n页表，只是一个虚拟地址跟物理地址的一个映射存储容器；\npage cache，是为了解决内存跟硬盘速度问题，是一个缓存容器，以页为单位对文件内容进行缓存;\n在内存中的数据，是怎样的写入硬盘呢？是需要通过CPU呢还是可以使用DMA让内存跟硬盘直接交互\n\n当然，目前 BufferCache 仍然是存在的，因为还存在需要执行的块 IO。因为大多数块都是用来存储文件数据，所以大部分 BufferCache 都指向了 PageCache；但还是有一小部分块并不是文件数据，例如元数据、RawBlock IO，此时还需要通过 BufferCache 来缓存。\n\n\n\n## 六、mmp\n\n用户调用mmap将文件映射到内存时，内核进行一系列的参数检查，然后创建对应的vma，然后给该vma绑定vma_ops。当用户访问到mmap对应的内存时，CPU 会触发page fault，在page fault回调中，将申请pagecache中的匿名页，读取文件到其物理内存中，然后将pagecache中所属的物理页与用户进程的vma进行映射。\n\n***简单点说：就是在用户进程中创建变量vma和物理内存进行映射，而不需要再将数据从page cache再拷贝至用户进程空间。***\n\n\n## 七、read系统调用\n调用open函数时，可以指定是以阻塞方式还是以非阻塞方式打开一个文件描述符。\n\n    阻塞方式打开：\n    int fd = open(\"/dev/tty\", O_RDWR|O_NONBLOCK);\n    非阻塞方式打开：\n    int fd = open(\"/dev/tty\", O_RDWR);\n\n\n**对于网络IO之socket**，默认是阻塞的，即当去read的时候，用户进程会阻塞，由内核去获取数据然后拷贝至用户空间；\n设置成非阻塞时，read时候，用户进程立马得到消息（是否有内容），此时用户进程不是阻塞的，那么如果没有获取数据的话，按一般做法肯定是轮训的询问内核数据是否准备好，会加大内核压力；因此，多路复用就出现了....\n\n\n**对于普通文件IO（IO包下）**，我觉得默认是阻塞的，读一次，就获取多少数据，直到wile循环结束将文件读完...\nJava中IO包下的都是bio，代表是open系统调用是采用默认的阻塞方式，此时进程会阻塞，直到内核将数据从磁盘读到page cache，再从page cache读到用户空间\n\n[Linux Cache VS. Buffer](https://gohalo.me/post/linux-memory-buffer-vs-cache-details.html)\n[Linux内核Page Cache和Buffer Cache关系及演化历史](http://lday.me/2019/09/09/0023_linux_page_cache_and_buffer_cache/)\n[文件IO系统调用内幕](https://lrita.github.io/2019/03/13/the-internal-of-file-syscall/)","source":"_posts/2020-04-10-linux-pagecache.md","raw":"---\ntitle: linux pagecache\ndate: 2020-08-08 21:24:46\ntags: linux pagecache buffercache\ncategories:\n  - [linux]\n---\n\n## 一、磁盘文件的存储\n\n1. 磁盘的最小存储单元是扇区sector，一个扇区是512个字节\n2. 存储在磁盘的文件系统采用块作为最小的存储单元，1个块大小一般是4KB(1KB, 2KB, 4KB, 8KB)\n3. 磁盘管理器负责处理块到扇区的映射，给定设备号和块号，磁盘管理器可以很方便找到对应的扇区\n\n<!--more-->    \n\n## 二、page cache\n缓存**文件**内容，以page为单位。\n\n## 三、buffer cache\n缓存**硬盘**内容，以块为单位。\n磁盘的最小数据单位为sector（扇区），内核会在磁盘sector上构建一层缓存，他以sector的整数倍力度单位(block)，缓存部分sector数据在内存中\n\n\n## 四、逻辑关系\n\n从linux-2.6.18的内核源码来看，Page Cache和Buffer Cache是一个事物的两种表现：对于一个Page而言，对上，他是某个File的一个Page Cache，而对下，他同样是一个Device上的一组Buffer Cache。\n实际IO操作，都是与page cache交互，不与内存直接交互\n\n*The term, Buffer Cache, is often used for the Page Cache. Linux kernels up to version 2.2 had both a Page Cache as well as a Buffer Cache. As of the 2.4 kernel, these two caches have been combined. Today, there is only one cache, the Page Cache.*\n\n***假设page cache=4K，buffer cache=1k，则一个page cache中有4个buffer cache。（page cache和buffer cache合并后）***\n\n[注意]：这里的Page Cache与Buffer Cache的融合，是针对文件这一层面的Page Cache与Buffer Cache的融合。对于跨层的：File层面的Page Cache和裸设备Buffer Cache，虽然都统一到了基于Page的实现，但File的Page Cache和该文件对应的Block在裸设备层访问的Buffer Cache，这两个是完全独立的Page，这种情况下，一个物理磁盘Block上的数据，仍然对应了Linux内核中的两份Page，一个是通过文件层访问的File的Page Cache(Page Cache)，一个是通过裸设备层访问的Page Cache(Buffer Cache)。\n\n![逻辑关系](2020-04-10-linux-pagecache/27_file_page_device_block.png)\n\n\n## 五、write->系统调用->内核是怎么处理的？\n\n写的时候，内核应该是从用户态进程空间将数据copy至内核态的page cache，此时内核会返回程序写入成功结果，但是数据并没有实际写入硬盘;\n程序可以调用flush方法将数据写入硬盘，或者是等内核自己写入磁盘（例如page cache空间不足时，或者是定时写磁盘）;\n页表，只是一个虚拟地址跟物理地址的一个映射存储容器；\npage cache，是为了解决内存跟硬盘速度问题，是一个缓存容器，以页为单位对文件内容进行缓存;\n在内存中的数据，是怎样的写入硬盘呢？是需要通过CPU呢还是可以使用DMA让内存跟硬盘直接交互\n\n当然，目前 BufferCache 仍然是存在的，因为还存在需要执行的块 IO。因为大多数块都是用来存储文件数据，所以大部分 BufferCache 都指向了 PageCache；但还是有一小部分块并不是文件数据，例如元数据、RawBlock IO，此时还需要通过 BufferCache 来缓存。\n\n\n\n## 六、mmp\n\n用户调用mmap将文件映射到内存时，内核进行一系列的参数检查，然后创建对应的vma，然后给该vma绑定vma_ops。当用户访问到mmap对应的内存时，CPU 会触发page fault，在page fault回调中，将申请pagecache中的匿名页，读取文件到其物理内存中，然后将pagecache中所属的物理页与用户进程的vma进行映射。\n\n***简单点说：就是在用户进程中创建变量vma和物理内存进行映射，而不需要再将数据从page cache再拷贝至用户进程空间。***\n\n\n## 七、read系统调用\n调用open函数时，可以指定是以阻塞方式还是以非阻塞方式打开一个文件描述符。\n\n    阻塞方式打开：\n    int fd = open(\"/dev/tty\", O_RDWR|O_NONBLOCK);\n    非阻塞方式打开：\n    int fd = open(\"/dev/tty\", O_RDWR);\n\n\n**对于网络IO之socket**，默认是阻塞的，即当去read的时候，用户进程会阻塞，由内核去获取数据然后拷贝至用户空间；\n设置成非阻塞时，read时候，用户进程立马得到消息（是否有内容），此时用户进程不是阻塞的，那么如果没有获取数据的话，按一般做法肯定是轮训的询问内核数据是否准备好，会加大内核压力；因此，多路复用就出现了....\n\n\n**对于普通文件IO（IO包下）**，我觉得默认是阻塞的，读一次，就获取多少数据，直到wile循环结束将文件读完...\nJava中IO包下的都是bio，代表是open系统调用是采用默认的阻塞方式，此时进程会阻塞，直到内核将数据从磁盘读到page cache，再从page cache读到用户空间\n\n[Linux Cache VS. Buffer](https://gohalo.me/post/linux-memory-buffer-vs-cache-details.html)\n[Linux内核Page Cache和Buffer Cache关系及演化历史](http://lday.me/2019/09/09/0023_linux_page_cache_and_buffer_cache/)\n[文件IO系统调用内幕](https://lrita.github.io/2019/03/13/the-internal-of-file-syscall/)","slug":"2020-04-10-linux-pagecache","published":1,"updated":"2024-12-09T03:23:30.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnwv0022a13k9rajnntq","content":"<h2 id=\"一、磁盘文件的存储\"><a href=\"#一、磁盘文件的存储\" class=\"headerlink\" title=\"一、磁盘文件的存储\"></a>一、磁盘文件的存储</h2><ol>\n<li>磁盘的最小存储单元是扇区sector，一个扇区是512个字节</li>\n<li>存储在磁盘的文件系统采用块作为最小的存储单元，1个块大小一般是4KB(1KB, 2KB, 4KB, 8KB)</li>\n<li>磁盘管理器负责处理块到扇区的映射，给定设备号和块号，磁盘管理器可以很方便找到对应的扇区</li>\n</ol>\n<a id=\"more\"></a>    \n\n<h2 id=\"二、page-cache\"><a href=\"#二、page-cache\" class=\"headerlink\" title=\"二、page cache\"></a>二、page cache</h2><p>缓存<strong>文件</strong>内容，以page为单位。</p>\n<h2 id=\"三、buffer-cache\"><a href=\"#三、buffer-cache\" class=\"headerlink\" title=\"三、buffer cache\"></a>三、buffer cache</h2><p>缓存<strong>硬盘</strong>内容，以块为单位。<br>磁盘的最小数据单位为sector（扇区），内核会在磁盘sector上构建一层缓存，他以sector的整数倍力度单位(block)，缓存部分sector数据在内存中</p>\n<h2 id=\"四、逻辑关系\"><a href=\"#四、逻辑关系\" class=\"headerlink\" title=\"四、逻辑关系\"></a>四、逻辑关系</h2><p>从linux-2.6.18的内核源码来看，Page Cache和Buffer Cache是一个事物的两种表现：对于一个Page而言，对上，他是某个File的一个Page Cache，而对下，他同样是一个Device上的一组Buffer Cache。<br>实际IO操作，都是与page cache交互，不与内存直接交互</p>\n<p><em>The term, Buffer Cache, is often used for the Page Cache. Linux kernels up to version 2.2 had both a Page Cache as well as a Buffer Cache. As of the 2.4 kernel, these two caches have been combined. Today, there is only one cache, the Page Cache.</em></p>\n<p><strong><em>假设page cache=4K，buffer cache=1k，则一个page cache中有4个buffer cache。（page cache和buffer cache合并后）</em></strong></p>\n<p>[注意]：这里的Page Cache与Buffer Cache的融合，是针对文件这一层面的Page Cache与Buffer Cache的融合。对于跨层的：File层面的Page Cache和裸设备Buffer Cache，虽然都统一到了基于Page的实现，但File的Page Cache和该文件对应的Block在裸设备层访问的Buffer Cache，这两个是完全独立的Page，这种情况下，一个物理磁盘Block上的数据，仍然对应了Linux内核中的两份Page，一个是通过文件层访问的File的Page Cache(Page Cache)，一个是通过裸设备层访问的Page Cache(Buffer Cache)。</p>\n<p><img src=\"/2020/08/08/2020-04-10-linux-pagecache/27_file_page_device_block.png\" alt=\"逻辑关系\"></p>\n<h2 id=\"五、write-gt-系统调用-gt-内核是怎么处理的？\"><a href=\"#五、write-gt-系统调用-gt-内核是怎么处理的？\" class=\"headerlink\" title=\"五、write-&gt;系统调用-&gt;内核是怎么处理的？\"></a>五、write-&gt;系统调用-&gt;内核是怎么处理的？</h2><p>写的时候，内核应该是从用户态进程空间将数据copy至内核态的page cache，此时内核会返回程序写入成功结果，但是数据并没有实际写入硬盘;<br>程序可以调用flush方法将数据写入硬盘，或者是等内核自己写入磁盘（例如page cache空间不足时，或者是定时写磁盘）;<br>页表，只是一个虚拟地址跟物理地址的一个映射存储容器；<br>page cache，是为了解决内存跟硬盘速度问题，是一个缓存容器，以页为单位对文件内容进行缓存;<br>在内存中的数据，是怎样的写入硬盘呢？是需要通过CPU呢还是可以使用DMA让内存跟硬盘直接交互</p>\n<p>当然，目前 BufferCache 仍然是存在的，因为还存在需要执行的块 IO。因为大多数块都是用来存储文件数据，所以大部分 BufferCache 都指向了 PageCache；但还是有一小部分块并不是文件数据，例如元数据、RawBlock IO，此时还需要通过 BufferCache 来缓存。</p>\n<h2 id=\"六、mmp\"><a href=\"#六、mmp\" class=\"headerlink\" title=\"六、mmp\"></a>六、mmp</h2><p>用户调用mmap将文件映射到内存时，内核进行一系列的参数检查，然后创建对应的vma，然后给该vma绑定vma_ops。当用户访问到mmap对应的内存时，CPU 会触发page fault，在page fault回调中，将申请pagecache中的匿名页，读取文件到其物理内存中，然后将pagecache中所属的物理页与用户进程的vma进行映射。</p>\n<p><strong><em>简单点说：就是在用户进程中创建变量vma和物理内存进行映射，而不需要再将数据从page cache再拷贝至用户进程空间。</em></strong></p>\n<h2 id=\"七、read系统调用\"><a href=\"#七、read系统调用\" class=\"headerlink\" title=\"七、read系统调用\"></a>七、read系统调用</h2><p>调用open函数时，可以指定是以阻塞方式还是以非阻塞方式打开一个文件描述符。</p>\n<pre><code>阻塞方式打开：\nint fd = open(&quot;/dev/tty&quot;, O_RDWR|O_NONBLOCK);\n非阻塞方式打开：\nint fd = open(&quot;/dev/tty&quot;, O_RDWR);</code></pre><p><strong>对于网络IO之socket</strong>，默认是阻塞的，即当去read的时候，用户进程会阻塞，由内核去获取数据然后拷贝至用户空间；<br>设置成非阻塞时，read时候，用户进程立马得到消息（是否有内容），此时用户进程不是阻塞的，那么如果没有获取数据的话，按一般做法肯定是轮训的询问内核数据是否准备好，会加大内核压力；因此，多路复用就出现了….</p>\n<p><strong>对于普通文件IO（IO包下）</strong>，我觉得默认是阻塞的，读一次，就获取多少数据，直到wile循环结束将文件读完…<br>Java中IO包下的都是bio，代表是open系统调用是采用默认的阻塞方式，此时进程会阻塞，直到内核将数据从磁盘读到page cache，再从page cache读到用户空间</p>\n<p><a href=\"https://gohalo.me/post/linux-memory-buffer-vs-cache-details.html\" target=\"_blank\" rel=\"noopener\">Linux Cache VS. Buffer</a><br><a href=\"http://lday.me/2019/09/09/0023_linux_page_cache_and_buffer_cache/\" target=\"_blank\" rel=\"noopener\">Linux内核Page Cache和Buffer Cache关系及演化历史</a><br><a href=\"https://lrita.github.io/2019/03/13/the-internal-of-file-syscall/\" target=\"_blank\" rel=\"noopener\">文件IO系统调用内幕</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"一、磁盘文件的存储\"><a href=\"#一、磁盘文件的存储\" class=\"headerlink\" title=\"一、磁盘文件的存储\"></a>一、磁盘文件的存储</h2><ol>\n<li>磁盘的最小存储单元是扇区sector，一个扇区是512个字节</li>\n<li>存储在磁盘的文件系统采用块作为最小的存储单元，1个块大小一般是4KB(1KB, 2KB, 4KB, 8KB)</li>\n<li>磁盘管理器负责处理块到扇区的映射，给定设备号和块号，磁盘管理器可以很方便找到对应的扇区</li>\n</ol>","more":"<h2 id=\"二、page-cache\"><a href=\"#二、page-cache\" class=\"headerlink\" title=\"二、page cache\"></a>二、page cache</h2><p>缓存<strong>文件</strong>内容，以page为单位。</p>\n<h2 id=\"三、buffer-cache\"><a href=\"#三、buffer-cache\" class=\"headerlink\" title=\"三、buffer cache\"></a>三、buffer cache</h2><p>缓存<strong>硬盘</strong>内容，以块为单位。<br>磁盘的最小数据单位为sector（扇区），内核会在磁盘sector上构建一层缓存，他以sector的整数倍力度单位(block)，缓存部分sector数据在内存中</p>\n<h2 id=\"四、逻辑关系\"><a href=\"#四、逻辑关系\" class=\"headerlink\" title=\"四、逻辑关系\"></a>四、逻辑关系</h2><p>从linux-2.6.18的内核源码来看，Page Cache和Buffer Cache是一个事物的两种表现：对于一个Page而言，对上，他是某个File的一个Page Cache，而对下，他同样是一个Device上的一组Buffer Cache。<br>实际IO操作，都是与page cache交互，不与内存直接交互</p>\n<p><em>The term, Buffer Cache, is often used for the Page Cache. Linux kernels up to version 2.2 had both a Page Cache as well as a Buffer Cache. As of the 2.4 kernel, these two caches have been combined. Today, there is only one cache, the Page Cache.</em></p>\n<p><strong><em>假设page cache=4K，buffer cache=1k，则一个page cache中有4个buffer cache。（page cache和buffer cache合并后）</em></strong></p>\n<p>[注意]：这里的Page Cache与Buffer Cache的融合，是针对文件这一层面的Page Cache与Buffer Cache的融合。对于跨层的：File层面的Page Cache和裸设备Buffer Cache，虽然都统一到了基于Page的实现，但File的Page Cache和该文件对应的Block在裸设备层访问的Buffer Cache，这两个是完全独立的Page，这种情况下，一个物理磁盘Block上的数据，仍然对应了Linux内核中的两份Page，一个是通过文件层访问的File的Page Cache(Page Cache)，一个是通过裸设备层访问的Page Cache(Buffer Cache)。</p>\n<p><img src=\"/2020/08/08/2020-04-10-linux-pagecache/27_file_page_device_block.png\" alt=\"逻辑关系\"></p>\n<h2 id=\"五、write-gt-系统调用-gt-内核是怎么处理的？\"><a href=\"#五、write-gt-系统调用-gt-内核是怎么处理的？\" class=\"headerlink\" title=\"五、write-&gt;系统调用-&gt;内核是怎么处理的？\"></a>五、write-&gt;系统调用-&gt;内核是怎么处理的？</h2><p>写的时候，内核应该是从用户态进程空间将数据copy至内核态的page cache，此时内核会返回程序写入成功结果，但是数据并没有实际写入硬盘;<br>程序可以调用flush方法将数据写入硬盘，或者是等内核自己写入磁盘（例如page cache空间不足时，或者是定时写磁盘）;<br>页表，只是一个虚拟地址跟物理地址的一个映射存储容器；<br>page cache，是为了解决内存跟硬盘速度问题，是一个缓存容器，以页为单位对文件内容进行缓存;<br>在内存中的数据，是怎样的写入硬盘呢？是需要通过CPU呢还是可以使用DMA让内存跟硬盘直接交互</p>\n<p>当然，目前 BufferCache 仍然是存在的，因为还存在需要执行的块 IO。因为大多数块都是用来存储文件数据，所以大部分 BufferCache 都指向了 PageCache；但还是有一小部分块并不是文件数据，例如元数据、RawBlock IO，此时还需要通过 BufferCache 来缓存。</p>\n<h2 id=\"六、mmp\"><a href=\"#六、mmp\" class=\"headerlink\" title=\"六、mmp\"></a>六、mmp</h2><p>用户调用mmap将文件映射到内存时，内核进行一系列的参数检查，然后创建对应的vma，然后给该vma绑定vma_ops。当用户访问到mmap对应的内存时，CPU 会触发page fault，在page fault回调中，将申请pagecache中的匿名页，读取文件到其物理内存中，然后将pagecache中所属的物理页与用户进程的vma进行映射。</p>\n<p><strong><em>简单点说：就是在用户进程中创建变量vma和物理内存进行映射，而不需要再将数据从page cache再拷贝至用户进程空间。</em></strong></p>\n<h2 id=\"七、read系统调用\"><a href=\"#七、read系统调用\" class=\"headerlink\" title=\"七、read系统调用\"></a>七、read系统调用</h2><p>调用open函数时，可以指定是以阻塞方式还是以非阻塞方式打开一个文件描述符。</p>\n<pre><code>阻塞方式打开：\nint fd = open(&quot;/dev/tty&quot;, O_RDWR|O_NONBLOCK);\n非阻塞方式打开：\nint fd = open(&quot;/dev/tty&quot;, O_RDWR);</code></pre><p><strong>对于网络IO之socket</strong>，默认是阻塞的，即当去read的时候，用户进程会阻塞，由内核去获取数据然后拷贝至用户空间；<br>设置成非阻塞时，read时候，用户进程立马得到消息（是否有内容），此时用户进程不是阻塞的，那么如果没有获取数据的话，按一般做法肯定是轮训的询问内核数据是否准备好，会加大内核压力；因此，多路复用就出现了….</p>\n<p><strong>对于普通文件IO（IO包下）</strong>，我觉得默认是阻塞的，读一次，就获取多少数据，直到wile循环结束将文件读完…<br>Java中IO包下的都是bio，代表是open系统调用是采用默认的阻塞方式，此时进程会阻塞，直到内核将数据从磁盘读到page cache，再从page cache读到用户空间</p>\n<p><a href=\"https://gohalo.me/post/linux-memory-buffer-vs-cache-details.html\" target=\"_blank\" rel=\"noopener\">Linux Cache VS. Buffer</a><br><a href=\"http://lday.me/2019/09/09/0023_linux_page_cache_and_buffer_cache/\" target=\"_blank\" rel=\"noopener\">Linux内核Page Cache和Buffer Cache关系及演化历史</a><br><a href=\"https://lrita.github.io/2019/03/13/the-internal-of-file-syscall/\" target=\"_blank\" rel=\"noopener\">文件IO系统调用内幕</a></p>"},{"title":"Linux-thread","date":"2020-04-09T10:19:15.000Z","_content":"\n# 一、什么是进程，进程和线程的区别\n* 进程：是操作系统进行资源分配的基本单位\n* 线程：是操作系统进行任务执行调度的基本单位\n* 纤程（协程）：运行在用户空间，不与内核进行交互。（不会创建内核进程）\n\n**区别：** 进程和线程在操作系统中都是一个进程，线程共享进程的内存空间，没有独立的内存空间。\n\n进程空间天然独立，不会互相篡改数据，但是对共享数据的操作时，还是需要进行加锁处理；\n\n<!--more-->  \n\n# 二、进程实现\n进程结构、进程创建、thread_info、task_list、虚拟内存、Linux内核架构等内容进行描述\n## 1、进程结构\n进程描述符（PCB=process control block），task_struct是PCB的具体实现。进程的执行，对于CPU来说，也是代码段。\n![task_struct](2020-04-09-Linux-thread/task_struct.png)\n\n代码实现   \n```\nsched.sh文件 \nstruct task_struct { \n    long state; // 进程状态 \n    struct mm_struct *mm; // 虚拟内存结构体 \n    pid_t pid; // 进程号 \n    struct task_struct *parent; // 指向父进程的指针\n    struct list_head children; // 子进程列表 \n    struct fs_struct *fs; // 存放文件系统信息的指针 \n    struct files_struct *files;// 一个数组，包含该进程打开的文件指针 \n};\n\n```\n\n**files：** 每个进程创建时，都会默认填充前三个值：   \n* files[0]：代表标准输入流\n* files[1]：代表标准输出流\n* files[2]：代表标准错误输出流\n\n**理解管道：** 一个进程的输出是另外一个进程的输入\n![task_struct](2020-04-09-Linux-thread/piepline.png)\n\n## 2、进程创建\n### 2.1、内核创建方式\ntask_struct的创建，Linux2.6之后，通过slab分配器动态生成task_struct。\n![task_struct](2020-04-09-Linux-thread/slab.png)\n\n1、高速缓存会被划分为slab。   \n2、task_struct的创建，会先从未满的slab中申请，直到满了才会去空的slab中申请创建。\n### 2.2、对外暴露接口创建方式\nfork()、exec()等函数进行创建\n```\nmain{  \n    pid_t pid;  \n    printf(\"fork!\");\n    pid=fork(); \n    if (pid < 0)  \n        printf(\"error in fork!\");  \n    else if (pid == 0)  \n        printf(\"i am the child process, my process id is %d\\n\",getpid());  \n    else  \n        printf(\"i am the parent process, my process id is %\\/n\",getpid());  \n}\n```\n* fork()：一个父进程会创建一个子进程，子进程共享父进程的内存空间及指针记录。\n* 返回两次结果值，指的是：父进程fork()函数会返回一个值，返回子进程的进程ID；而子进程此时执行节点也是到fork()，\n父子进程会继续往下执行，从而产生返回两个值的现象，本质是两个进程执行得到相应的值。\n\n* 由于在复制时复制了父进程的堆栈段，所以两个进程都停留在fork函数中，等待返回。 \n因此fork函数会返回两次，一次是在父进程中返回，另一次是在子进程中返回，这两次的返回值是不一样的。\n* fork函数返回的值为什么在父子进程中不同。\n“ 其实就相当于链表，进程形成了链表，父进程的fork函数返回的值指向子进程的进程id, 因为子进程没有子进程，所以其fork函数返回的值为0 .\n\n```\nint main(){\n    execl(\"/bin/ls\", \"ls\", \"-l\", NULL);\n    perror(\"execl\");\n    exit(1);\n}\n```\nA进程中调用exec函数族函数，将A进程的代码段替换成了ls程序的代码段，则A进程下的代码则不会执行，也不会返回结果。\n\n\n## 3、thread_info\n快速获取task_struct：  \n* 1、有的硬件系统，有专门的寄存器来存储。\n* 2、寄存器不富余的体系，只能在栈的尾端创建thread_info结构。\n![task_struct](2020-04-09-Linux-thread/thread-info.png)\n\n![task_struct](2020-04-09-Linux-thread/stack.png)\n操作系统，将所有的进程都放入一个双向链表结构的任务列表中（task_list）\n\n## 4、虚拟内存\ntask_struct中的mm_struct结构代表着虚拟内存。\n![task_struct](2020-04-09-Linux-thread/vm.png)\n\n**为什么需要虚拟内存：**  \n1. 多线程环境下，内存空间小，易不足，若想不影响其他进程，则只能将其他进程的内容拷贝至磁盘中持久化，但是会导致耗时增加。\n2. 多线程环境下，若直接使用物理内存，则进程的数据可能被其他进程修改，导致进程运行的不准确。\n\n**为了解决上述问题**，将进程进行隔离，使用了虚拟内存，各进程之间不受影响，使每个进程都能拥有所有的物理内存空间。\n\n### 4.1、虚拟内存实现\n![task_struct](2020-04-09-Linux-thread/vm-实现.png)\n\nLinux为每个进程维护了一个单独的虚拟地址空间，分成内核空间和用户空间。（进程之间空间是天然独立的，互不影响；子进程共享父进程的空间，则会导致子进程数据的相互篡改）\n* 内核空间：高地址空间的1GB，用于运行内核代码和数据和保存进程的相关信息。俗称内核态。\n* 用户空间：低地址空间的3GB，运行用户进程的代码和数据。俗称用户态。\n* 每次内核调用，都会进行空间切换，数据拷贝，这个操作是耗时的。\n* 虚拟内存到物理内存的映射，通过mmu（内存管理单元）操作。\n\n**写时复制：Copy On Write技术实现原理：**   \n```\n1. fork()之后，复制出来的子进程有自己的task_struct结构和pid,  \n2. kernel把父进程中所有的内存页的权限都设为read-only，  \n3. 然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。   \n4. 当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，   \n5. 于是触发页异常中断（page-fault），陷入kernel的一个中断例程。   \n6. 中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份，  \n7. 父进程会对原有的物理空间进行修改，而子进程会使用拷贝后的新物理空间。\n```\n在**fork**函数调用时，父进程和子进程会被内核分配不同的虚拟内存空间，所以从进程的角度看它们访问的是不同的内存：\n* 在虚拟内存空间进行读操作时，内核会将虚拟内存映射到物理内存上，父子进程共享了物理上的内存空间；\n* 当父进程对共享的内存进行修改时，共享的内存会以页为单位进行拷贝，父进程会对原有的物理空间进行修改，而子进程会使用拷贝后的新物理空间；\n* 当子进程对共享的内存进行修改时，子进程会在拷贝后的新物理空间上进行修改，而不会改动原有的物理空间，避免影响父进程的内存空间；\n\n# 五、Linux内核架构\n![internal](2020-04-09-Linux-thread/internal.png)\n进程调度器：process scheduler，持有了task_list，然后管理这些进程链表。维护了一个current指针，指向当前正在执行的进程。  \n**抢占式和非抢占式。**\n\n# 六、进程状态\n* task_running：正在运行或就绪\n* task_intermptible：可中断的休眠，等待资源、信号，一旦满足，由中断变为就绪\n* task_unintermptible：不可中断的休眠，信号无法唤醒，只有当资源满足时可唤醒。\n* task_stoped：进程被停止执行\n* task_traced：表示进程被debugger等进程监视\n\n# 七、中断\nCPU暂停当前线程执行，执行中断请求。\n**中断类型：** \n* 同步中断（软中断）：由CPU控制单元产生，之所以称为同步，因为只有当一条指令执行完成后，才会执行中断指令。\n* 异步中断（硬中断）：由硬件设备产生的中断信号，随机产生。\n\n\n\n#八、缺页\n![缺页](2020-04-09-Linux-thread/缺页.png)\n1. 含义：PTE有晓位=0，虚拟内存中的虚拟页没有被缓存在物理内存中，称为缺页。\n2. 具体表现：malloc()和mmap()函数调用，在分配时只建立的虚拟内存空间（在进程堆中分配），并没有分配虚拟内存对应的物理内存。当进程服务这些虚拟内存时，mmu（内存管理单元）无法解析，将报出page fault错误，缺页中断，然后进程进行空间切换，由用户态切换至内核态，然后由内核处理。\n3. 处理方式：根据缺页类型，CPU判断物理内存中是否有当前所需页帧，如果存在，进行映射；如果不存在，则去磁盘读取保存至内存，再建立映射。\n\n\n","source":"_posts/2020-04-09-Linux-thread.md","raw":"---\ntitle: Linux-thread\ndate: 2020-04-09 18:19:15\ntags: Linux Thread\ncategories: \n  - [linux]\n---\n\n# 一、什么是进程，进程和线程的区别\n* 进程：是操作系统进行资源分配的基本单位\n* 线程：是操作系统进行任务执行调度的基本单位\n* 纤程（协程）：运行在用户空间，不与内核进行交互。（不会创建内核进程）\n\n**区别：** 进程和线程在操作系统中都是一个进程，线程共享进程的内存空间，没有独立的内存空间。\n\n进程空间天然独立，不会互相篡改数据，但是对共享数据的操作时，还是需要进行加锁处理；\n\n<!--more-->  \n\n# 二、进程实现\n进程结构、进程创建、thread_info、task_list、虚拟内存、Linux内核架构等内容进行描述\n## 1、进程结构\n进程描述符（PCB=process control block），task_struct是PCB的具体实现。进程的执行，对于CPU来说，也是代码段。\n![task_struct](2020-04-09-Linux-thread/task_struct.png)\n\n代码实现   \n```\nsched.sh文件 \nstruct task_struct { \n    long state; // 进程状态 \n    struct mm_struct *mm; // 虚拟内存结构体 \n    pid_t pid; // 进程号 \n    struct task_struct *parent; // 指向父进程的指针\n    struct list_head children; // 子进程列表 \n    struct fs_struct *fs; // 存放文件系统信息的指针 \n    struct files_struct *files;// 一个数组，包含该进程打开的文件指针 \n};\n\n```\n\n**files：** 每个进程创建时，都会默认填充前三个值：   \n* files[0]：代表标准输入流\n* files[1]：代表标准输出流\n* files[2]：代表标准错误输出流\n\n**理解管道：** 一个进程的输出是另外一个进程的输入\n![task_struct](2020-04-09-Linux-thread/piepline.png)\n\n## 2、进程创建\n### 2.1、内核创建方式\ntask_struct的创建，Linux2.6之后，通过slab分配器动态生成task_struct。\n![task_struct](2020-04-09-Linux-thread/slab.png)\n\n1、高速缓存会被划分为slab。   \n2、task_struct的创建，会先从未满的slab中申请，直到满了才会去空的slab中申请创建。\n### 2.2、对外暴露接口创建方式\nfork()、exec()等函数进行创建\n```\nmain{  \n    pid_t pid;  \n    printf(\"fork!\");\n    pid=fork(); \n    if (pid < 0)  \n        printf(\"error in fork!\");  \n    else if (pid == 0)  \n        printf(\"i am the child process, my process id is %d\\n\",getpid());  \n    else  \n        printf(\"i am the parent process, my process id is %\\/n\",getpid());  \n}\n```\n* fork()：一个父进程会创建一个子进程，子进程共享父进程的内存空间及指针记录。\n* 返回两次结果值，指的是：父进程fork()函数会返回一个值，返回子进程的进程ID；而子进程此时执行节点也是到fork()，\n父子进程会继续往下执行，从而产生返回两个值的现象，本质是两个进程执行得到相应的值。\n\n* 由于在复制时复制了父进程的堆栈段，所以两个进程都停留在fork函数中，等待返回。 \n因此fork函数会返回两次，一次是在父进程中返回，另一次是在子进程中返回，这两次的返回值是不一样的。\n* fork函数返回的值为什么在父子进程中不同。\n“ 其实就相当于链表，进程形成了链表，父进程的fork函数返回的值指向子进程的进程id, 因为子进程没有子进程，所以其fork函数返回的值为0 .\n\n```\nint main(){\n    execl(\"/bin/ls\", \"ls\", \"-l\", NULL);\n    perror(\"execl\");\n    exit(1);\n}\n```\nA进程中调用exec函数族函数，将A进程的代码段替换成了ls程序的代码段，则A进程下的代码则不会执行，也不会返回结果。\n\n\n## 3、thread_info\n快速获取task_struct：  \n* 1、有的硬件系统，有专门的寄存器来存储。\n* 2、寄存器不富余的体系，只能在栈的尾端创建thread_info结构。\n![task_struct](2020-04-09-Linux-thread/thread-info.png)\n\n![task_struct](2020-04-09-Linux-thread/stack.png)\n操作系统，将所有的进程都放入一个双向链表结构的任务列表中（task_list）\n\n## 4、虚拟内存\ntask_struct中的mm_struct结构代表着虚拟内存。\n![task_struct](2020-04-09-Linux-thread/vm.png)\n\n**为什么需要虚拟内存：**  \n1. 多线程环境下，内存空间小，易不足，若想不影响其他进程，则只能将其他进程的内容拷贝至磁盘中持久化，但是会导致耗时增加。\n2. 多线程环境下，若直接使用物理内存，则进程的数据可能被其他进程修改，导致进程运行的不准确。\n\n**为了解决上述问题**，将进程进行隔离，使用了虚拟内存，各进程之间不受影响，使每个进程都能拥有所有的物理内存空间。\n\n### 4.1、虚拟内存实现\n![task_struct](2020-04-09-Linux-thread/vm-实现.png)\n\nLinux为每个进程维护了一个单独的虚拟地址空间，分成内核空间和用户空间。（进程之间空间是天然独立的，互不影响；子进程共享父进程的空间，则会导致子进程数据的相互篡改）\n* 内核空间：高地址空间的1GB，用于运行内核代码和数据和保存进程的相关信息。俗称内核态。\n* 用户空间：低地址空间的3GB，运行用户进程的代码和数据。俗称用户态。\n* 每次内核调用，都会进行空间切换，数据拷贝，这个操作是耗时的。\n* 虚拟内存到物理内存的映射，通过mmu（内存管理单元）操作。\n\n**写时复制：Copy On Write技术实现原理：**   \n```\n1. fork()之后，复制出来的子进程有自己的task_struct结构和pid,  \n2. kernel把父进程中所有的内存页的权限都设为read-only，  \n3. 然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。   \n4. 当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，   \n5. 于是触发页异常中断（page-fault），陷入kernel的一个中断例程。   \n6. 中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份，  \n7. 父进程会对原有的物理空间进行修改，而子进程会使用拷贝后的新物理空间。\n```\n在**fork**函数调用时，父进程和子进程会被内核分配不同的虚拟内存空间，所以从进程的角度看它们访问的是不同的内存：\n* 在虚拟内存空间进行读操作时，内核会将虚拟内存映射到物理内存上，父子进程共享了物理上的内存空间；\n* 当父进程对共享的内存进行修改时，共享的内存会以页为单位进行拷贝，父进程会对原有的物理空间进行修改，而子进程会使用拷贝后的新物理空间；\n* 当子进程对共享的内存进行修改时，子进程会在拷贝后的新物理空间上进行修改，而不会改动原有的物理空间，避免影响父进程的内存空间；\n\n# 五、Linux内核架构\n![internal](2020-04-09-Linux-thread/internal.png)\n进程调度器：process scheduler，持有了task_list，然后管理这些进程链表。维护了一个current指针，指向当前正在执行的进程。  \n**抢占式和非抢占式。**\n\n# 六、进程状态\n* task_running：正在运行或就绪\n* task_intermptible：可中断的休眠，等待资源、信号，一旦满足，由中断变为就绪\n* task_unintermptible：不可中断的休眠，信号无法唤醒，只有当资源满足时可唤醒。\n* task_stoped：进程被停止执行\n* task_traced：表示进程被debugger等进程监视\n\n# 七、中断\nCPU暂停当前线程执行，执行中断请求。\n**中断类型：** \n* 同步中断（软中断）：由CPU控制单元产生，之所以称为同步，因为只有当一条指令执行完成后，才会执行中断指令。\n* 异步中断（硬中断）：由硬件设备产生的中断信号，随机产生。\n\n\n\n#八、缺页\n![缺页](2020-04-09-Linux-thread/缺页.png)\n1. 含义：PTE有晓位=0，虚拟内存中的虚拟页没有被缓存在物理内存中，称为缺页。\n2. 具体表现：malloc()和mmap()函数调用，在分配时只建立的虚拟内存空间（在进程堆中分配），并没有分配虚拟内存对应的物理内存。当进程服务这些虚拟内存时，mmu（内存管理单元）无法解析，将报出page fault错误，缺页中断，然后进程进行空间切换，由用户态切换至内核态，然后由内核处理。\n3. 处理方式：根据缺页类型，CPU判断物理内存中是否有当前所需页帧，如果存在，进行映射；如果不存在，则去磁盘读取保存至内存，再建立映射。\n\n\n","slug":"2020-04-09-Linux-thread","published":1,"updated":"2024-12-09T03:23:30.958Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnww0025a13ka8vdvw92","content":"<h1 id=\"一、什么是进程，进程和线程的区别\"><a href=\"#一、什么是进程，进程和线程的区别\" class=\"headerlink\" title=\"一、什么是进程，进程和线程的区别\"></a>一、什么是进程，进程和线程的区别</h1><ul>\n<li>进程：是操作系统进行资源分配的基本单位</li>\n<li>线程：是操作系统进行任务执行调度的基本单位</li>\n<li>纤程（协程）：运行在用户空间，不与内核进行交互。（不会创建内核进程）</li>\n</ul>\n<p><strong>区别：</strong> 进程和线程在操作系统中都是一个进程，线程共享进程的内存空间，没有独立的内存空间。</p>\n<p>进程空间天然独立，不会互相篡改数据，但是对共享数据的操作时，还是需要进行加锁处理；</p>\n<a id=\"more\"></a>  \n\n<h1 id=\"二、进程实现\"><a href=\"#二、进程实现\" class=\"headerlink\" title=\"二、进程实现\"></a>二、进程实现</h1><p>进程结构、进程创建、thread_info、task_list、虚拟内存、Linux内核架构等内容进行描述</p>\n<h2 id=\"1、进程结构\"><a href=\"#1、进程结构\" class=\"headerlink\" title=\"1、进程结构\"></a>1、进程结构</h2><p>进程描述符（PCB=process control block），task_struct是PCB的具体实现。进程的执行，对于CPU来说，也是代码段。<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/task_struct.png\" alt=\"task_struct\"></p>\n<p>代码实现   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sched.sh文件 </span><br><span class=\"line\">struct task_struct &#123; </span><br><span class=\"line\">    long state; // 进程状态 </span><br><span class=\"line\">    struct mm_struct *mm; // 虚拟内存结构体 </span><br><span class=\"line\">    pid_t pid; // 进程号 </span><br><span class=\"line\">    struct task_struct *parent; // 指向父进程的指针</span><br><span class=\"line\">    struct list_head children; // 子进程列表 </span><br><span class=\"line\">    struct fs_struct *fs; // 存放文件系统信息的指针 </span><br><span class=\"line\">    struct files_struct *files;// 一个数组，包含该进程打开的文件指针 </span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p><strong>files：</strong> 每个进程创建时，都会默认填充前三个值：   </p>\n<ul>\n<li>files[0]：代表标准输入流</li>\n<li>files[1]：代表标准输出流</li>\n<li>files[2]：代表标准错误输出流</li>\n</ul>\n<p><strong>理解管道：</strong> 一个进程的输出是另外一个进程的输入<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/piepline.png\" alt=\"task_struct\"></p>\n<h2 id=\"2、进程创建\"><a href=\"#2、进程创建\" class=\"headerlink\" title=\"2、进程创建\"></a>2、进程创建</h2><h3 id=\"2-1、内核创建方式\"><a href=\"#2-1、内核创建方式\" class=\"headerlink\" title=\"2.1、内核创建方式\"></a>2.1、内核创建方式</h3><p>task_struct的创建，Linux2.6之后，通过slab分配器动态生成task_struct。<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/slab.png\" alt=\"task_struct\"></p>\n<p>1、高速缓存会被划分为slab。<br>2、task_struct的创建，会先从未满的slab中申请，直到满了才会去空的slab中申请创建。</p>\n<h3 id=\"2-2、对外暴露接口创建方式\"><a href=\"#2-2、对外暴露接口创建方式\" class=\"headerlink\" title=\"2.2、对外暴露接口创建方式\"></a>2.2、对外暴露接口创建方式</h3><p>fork()、exec()等函数进行创建</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main&#123;  </span><br><span class=\"line\">    pid_t pid;  </span><br><span class=\"line\">    printf(&quot;fork!&quot;);</span><br><span class=\"line\">    pid=fork(); </span><br><span class=\"line\">    if (pid &lt; 0)  </span><br><span class=\"line\">        printf(&quot;error in fork!&quot;);  </span><br><span class=\"line\">    else if (pid == 0)  </span><br><span class=\"line\">        printf(&quot;i am the child process, my process id is %d\\n&quot;,getpid());  </span><br><span class=\"line\">    else  </span><br><span class=\"line\">        printf(&quot;i am the parent process, my process id is %\\/n&quot;,getpid());  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>fork()：一个父进程会创建一个子进程，子进程共享父进程的内存空间及指针记录。</p>\n</li>\n<li><p>返回两次结果值，指的是：父进程fork()函数会返回一个值，返回子进程的进程ID；而子进程此时执行节点也是到fork()，<br>父子进程会继续往下执行，从而产生返回两个值的现象，本质是两个进程执行得到相应的值。</p>\n</li>\n<li><p>由于在复制时复制了父进程的堆栈段，所以两个进程都停留在fork函数中，等待返回。<br>因此fork函数会返回两次，一次是在父进程中返回，另一次是在子进程中返回，这两次的返回值是不一样的。</p>\n</li>\n<li><p>fork函数返回的值为什么在父子进程中不同。<br>“ 其实就相当于链表，进程形成了链表，父进程的fork函数返回的值指向子进程的进程id, 因为子进程没有子进程，所以其fork函数返回的值为0 .</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int main()&#123;</span><br><span class=\"line\">    execl(&quot;/bin/ls&quot;, &quot;ls&quot;, &quot;-l&quot;, NULL);</span><br><span class=\"line\">    perror(&quot;execl&quot;);</span><br><span class=\"line\">    exit(1);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>A进程中调用exec函数族函数，将A进程的代码段替换成了ls程序的代码段，则A进程下的代码则不会执行，也不会返回结果。</p>\n<h2 id=\"3、thread-info\"><a href=\"#3、thread-info\" class=\"headerlink\" title=\"3、thread_info\"></a>3、thread_info</h2><p>快速获取task_struct：  </p>\n<ul>\n<li>1、有的硬件系统，有专门的寄存器来存储。</li>\n<li>2、寄存器不富余的体系，只能在栈的尾端创建thread_info结构。<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/thread-info.png\" alt=\"task_struct\"></li>\n</ul>\n<p><img src=\"/2020/04/09/2020-04-09-Linux-thread/stack.png\" alt=\"task_struct\"><br>操作系统，将所有的进程都放入一个双向链表结构的任务列表中（task_list）</p>\n<h2 id=\"4、虚拟内存\"><a href=\"#4、虚拟内存\" class=\"headerlink\" title=\"4、虚拟内存\"></a>4、虚拟内存</h2><p>task_struct中的mm_struct结构代表着虚拟内存。<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/vm.png\" alt=\"task_struct\"></p>\n<p><strong>为什么需要虚拟内存：</strong>  </p>\n<ol>\n<li>多线程环境下，内存空间小，易不足，若想不影响其他进程，则只能将其他进程的内容拷贝至磁盘中持久化，但是会导致耗时增加。</li>\n<li>多线程环境下，若直接使用物理内存，则进程的数据可能被其他进程修改，导致进程运行的不准确。</li>\n</ol>\n<p><strong>为了解决上述问题</strong>，将进程进行隔离，使用了虚拟内存，各进程之间不受影响，使每个进程都能拥有所有的物理内存空间。</p>\n<h3 id=\"4-1、虚拟内存实现\"><a href=\"#4-1、虚拟内存实现\" class=\"headerlink\" title=\"4.1、虚拟内存实现\"></a>4.1、虚拟内存实现</h3><p><img src=\"/2020/04/09/2020-04-09-Linux-thread/vm-%E5%AE%9E%E7%8E%B0.png\" alt=\"task_struct\"></p>\n<p>Linux为每个进程维护了一个单独的虚拟地址空间，分成内核空间和用户空间。（进程之间空间是天然独立的，互不影响；子进程共享父进程的空间，则会导致子进程数据的相互篡改）</p>\n<ul>\n<li>内核空间：高地址空间的1GB，用于运行内核代码和数据和保存进程的相关信息。俗称内核态。</li>\n<li>用户空间：低地址空间的3GB，运行用户进程的代码和数据。俗称用户态。</li>\n<li>每次内核调用，都会进行空间切换，数据拷贝，这个操作是耗时的。</li>\n<li>虚拟内存到物理内存的映射，通过mmu（内存管理单元）操作。</li>\n</ul>\n<p><strong>写时复制：Copy On Write技术实现原理：</strong>   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. fork()之后，复制出来的子进程有自己的task_struct结构和pid,  </span><br><span class=\"line\">2. kernel把父进程中所有的内存页的权限都设为read-only，  </span><br><span class=\"line\">3. 然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。   </span><br><span class=\"line\">4. 当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，   </span><br><span class=\"line\">5. 于是触发页异常中断（page-fault），陷入kernel的一个中断例程。   </span><br><span class=\"line\">6. 中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份，  </span><br><span class=\"line\">7. 父进程会对原有的物理空间进行修改，而子进程会使用拷贝后的新物理空间。</span><br></pre></td></tr></table></figure>\n\n<p>在<strong>fork</strong>函数调用时，父进程和子进程会被内核分配不同的虚拟内存空间，所以从进程的角度看它们访问的是不同的内存：</p>\n<ul>\n<li>在虚拟内存空间进行读操作时，内核会将虚拟内存映射到物理内存上，父子进程共享了物理上的内存空间；</li>\n<li>当父进程对共享的内存进行修改时，共享的内存会以页为单位进行拷贝，父进程会对原有的物理空间进行修改，而子进程会使用拷贝后的新物理空间；</li>\n<li>当子进程对共享的内存进行修改时，子进程会在拷贝后的新物理空间上进行修改，而不会改动原有的物理空间，避免影响父进程的内存空间；</li>\n</ul>\n<h1 id=\"五、Linux内核架构\"><a href=\"#五、Linux内核架构\" class=\"headerlink\" title=\"五、Linux内核架构\"></a>五、Linux内核架构</h1><p><img src=\"/2020/04/09/2020-04-09-Linux-thread/internal.png\" alt=\"internal\"><br>进程调度器：process scheduler，持有了task_list，然后管理这些进程链表。维护了一个current指针，指向当前正在执行的进程。<br><strong>抢占式和非抢占式。</strong></p>\n<h1 id=\"六、进程状态\"><a href=\"#六、进程状态\" class=\"headerlink\" title=\"六、进程状态\"></a>六、进程状态</h1><ul>\n<li>task_running：正在运行或就绪</li>\n<li>task_intermptible：可中断的休眠，等待资源、信号，一旦满足，由中断变为就绪</li>\n<li>task_unintermptible：不可中断的休眠，信号无法唤醒，只有当资源满足时可唤醒。</li>\n<li>task_stoped：进程被停止执行</li>\n<li>task_traced：表示进程被debugger等进程监视</li>\n</ul>\n<h1 id=\"七、中断\"><a href=\"#七、中断\" class=\"headerlink\" title=\"七、中断\"></a>七、中断</h1><p>CPU暂停当前线程执行，执行中断请求。<br><strong>中断类型：</strong> </p>\n<ul>\n<li>同步中断（软中断）：由CPU控制单元产生，之所以称为同步，因为只有当一条指令执行完成后，才会执行中断指令。</li>\n<li>异步中断（硬中断）：由硬件设备产生的中断信号，随机产生。</li>\n</ul>\n<p>#八、缺页<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/%E7%BC%BA%E9%A1%B5.png\" alt=\"缺页\"></p>\n<ol>\n<li>含义：PTE有晓位=0，虚拟内存中的虚拟页没有被缓存在物理内存中，称为缺页。</li>\n<li>具体表现：malloc()和mmap()函数调用，在分配时只建立的虚拟内存空间（在进程堆中分配），并没有分配虚拟内存对应的物理内存。当进程服务这些虚拟内存时，mmu（内存管理单元）无法解析，将报出page fault错误，缺页中断，然后进程进行空间切换，由用户态切换至内核态，然后由内核处理。</li>\n<li>处理方式：根据缺页类型，CPU判断物理内存中是否有当前所需页帧，如果存在，进行映射；如果不存在，则去磁盘读取保存至内存，再建立映射。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、什么是进程，进程和线程的区别\"><a href=\"#一、什么是进程，进程和线程的区别\" class=\"headerlink\" title=\"一、什么是进程，进程和线程的区别\"></a>一、什么是进程，进程和线程的区别</h1><ul>\n<li>进程：是操作系统进行资源分配的基本单位</li>\n<li>线程：是操作系统进行任务执行调度的基本单位</li>\n<li>纤程（协程）：运行在用户空间，不与内核进行交互。（不会创建内核进程）</li>\n</ul>\n<p><strong>区别：</strong> 进程和线程在操作系统中都是一个进程，线程共享进程的内存空间，没有独立的内存空间。</p>\n<p>进程空间天然独立，不会互相篡改数据，但是对共享数据的操作时，还是需要进行加锁处理；</p>","more":"<h1 id=\"二、进程实现\"><a href=\"#二、进程实现\" class=\"headerlink\" title=\"二、进程实现\"></a>二、进程实现</h1><p>进程结构、进程创建、thread_info、task_list、虚拟内存、Linux内核架构等内容进行描述</p>\n<h2 id=\"1、进程结构\"><a href=\"#1、进程结构\" class=\"headerlink\" title=\"1、进程结构\"></a>1、进程结构</h2><p>进程描述符（PCB=process control block），task_struct是PCB的具体实现。进程的执行，对于CPU来说，也是代码段。<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/task_struct.png\" alt=\"task_struct\"></p>\n<p>代码实现   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sched.sh文件 </span><br><span class=\"line\">struct task_struct &#123; </span><br><span class=\"line\">    long state; // 进程状态 </span><br><span class=\"line\">    struct mm_struct *mm; // 虚拟内存结构体 </span><br><span class=\"line\">    pid_t pid; // 进程号 </span><br><span class=\"line\">    struct task_struct *parent; // 指向父进程的指针</span><br><span class=\"line\">    struct list_head children; // 子进程列表 </span><br><span class=\"line\">    struct fs_struct *fs; // 存放文件系统信息的指针 </span><br><span class=\"line\">    struct files_struct *files;// 一个数组，包含该进程打开的文件指针 </span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p><strong>files：</strong> 每个进程创建时，都会默认填充前三个值：   </p>\n<ul>\n<li>files[0]：代表标准输入流</li>\n<li>files[1]：代表标准输出流</li>\n<li>files[2]：代表标准错误输出流</li>\n</ul>\n<p><strong>理解管道：</strong> 一个进程的输出是另外一个进程的输入<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/piepline.png\" alt=\"task_struct\"></p>\n<h2 id=\"2、进程创建\"><a href=\"#2、进程创建\" class=\"headerlink\" title=\"2、进程创建\"></a>2、进程创建</h2><h3 id=\"2-1、内核创建方式\"><a href=\"#2-1、内核创建方式\" class=\"headerlink\" title=\"2.1、内核创建方式\"></a>2.1、内核创建方式</h3><p>task_struct的创建，Linux2.6之后，通过slab分配器动态生成task_struct。<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/slab.png\" alt=\"task_struct\"></p>\n<p>1、高速缓存会被划分为slab。<br>2、task_struct的创建，会先从未满的slab中申请，直到满了才会去空的slab中申请创建。</p>\n<h3 id=\"2-2、对外暴露接口创建方式\"><a href=\"#2-2、对外暴露接口创建方式\" class=\"headerlink\" title=\"2.2、对外暴露接口创建方式\"></a>2.2、对外暴露接口创建方式</h3><p>fork()、exec()等函数进行创建</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main&#123;  </span><br><span class=\"line\">    pid_t pid;  </span><br><span class=\"line\">    printf(&quot;fork!&quot;);</span><br><span class=\"line\">    pid=fork(); </span><br><span class=\"line\">    if (pid &lt; 0)  </span><br><span class=\"line\">        printf(&quot;error in fork!&quot;);  </span><br><span class=\"line\">    else if (pid == 0)  </span><br><span class=\"line\">        printf(&quot;i am the child process, my process id is %d\\n&quot;,getpid());  </span><br><span class=\"line\">    else  </span><br><span class=\"line\">        printf(&quot;i am the parent process, my process id is %\\/n&quot;,getpid());  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>fork()：一个父进程会创建一个子进程，子进程共享父进程的内存空间及指针记录。</p>\n</li>\n<li><p>返回两次结果值，指的是：父进程fork()函数会返回一个值，返回子进程的进程ID；而子进程此时执行节点也是到fork()，<br>父子进程会继续往下执行，从而产生返回两个值的现象，本质是两个进程执行得到相应的值。</p>\n</li>\n<li><p>由于在复制时复制了父进程的堆栈段，所以两个进程都停留在fork函数中，等待返回。<br>因此fork函数会返回两次，一次是在父进程中返回，另一次是在子进程中返回，这两次的返回值是不一样的。</p>\n</li>\n<li><p>fork函数返回的值为什么在父子进程中不同。<br>“ 其实就相当于链表，进程形成了链表，父进程的fork函数返回的值指向子进程的进程id, 因为子进程没有子进程，所以其fork函数返回的值为0 .</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int main()&#123;</span><br><span class=\"line\">    execl(&quot;/bin/ls&quot;, &quot;ls&quot;, &quot;-l&quot;, NULL);</span><br><span class=\"line\">    perror(&quot;execl&quot;);</span><br><span class=\"line\">    exit(1);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>A进程中调用exec函数族函数，将A进程的代码段替换成了ls程序的代码段，则A进程下的代码则不会执行，也不会返回结果。</p>\n<h2 id=\"3、thread-info\"><a href=\"#3、thread-info\" class=\"headerlink\" title=\"3、thread_info\"></a>3、thread_info</h2><p>快速获取task_struct：  </p>\n<ul>\n<li>1、有的硬件系统，有专门的寄存器来存储。</li>\n<li>2、寄存器不富余的体系，只能在栈的尾端创建thread_info结构。<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/thread-info.png\" alt=\"task_struct\"></li>\n</ul>\n<p><img src=\"/2020/04/09/2020-04-09-Linux-thread/stack.png\" alt=\"task_struct\"><br>操作系统，将所有的进程都放入一个双向链表结构的任务列表中（task_list）</p>\n<h2 id=\"4、虚拟内存\"><a href=\"#4、虚拟内存\" class=\"headerlink\" title=\"4、虚拟内存\"></a>4、虚拟内存</h2><p>task_struct中的mm_struct结构代表着虚拟内存。<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/vm.png\" alt=\"task_struct\"></p>\n<p><strong>为什么需要虚拟内存：</strong>  </p>\n<ol>\n<li>多线程环境下，内存空间小，易不足，若想不影响其他进程，则只能将其他进程的内容拷贝至磁盘中持久化，但是会导致耗时增加。</li>\n<li>多线程环境下，若直接使用物理内存，则进程的数据可能被其他进程修改，导致进程运行的不准确。</li>\n</ol>\n<p><strong>为了解决上述问题</strong>，将进程进行隔离，使用了虚拟内存，各进程之间不受影响，使每个进程都能拥有所有的物理内存空间。</p>\n<h3 id=\"4-1、虚拟内存实现\"><a href=\"#4-1、虚拟内存实现\" class=\"headerlink\" title=\"4.1、虚拟内存实现\"></a>4.1、虚拟内存实现</h3><p><img src=\"/2020/04/09/2020-04-09-Linux-thread/vm-%E5%AE%9E%E7%8E%B0.png\" alt=\"task_struct\"></p>\n<p>Linux为每个进程维护了一个单独的虚拟地址空间，分成内核空间和用户空间。（进程之间空间是天然独立的，互不影响；子进程共享父进程的空间，则会导致子进程数据的相互篡改）</p>\n<ul>\n<li>内核空间：高地址空间的1GB，用于运行内核代码和数据和保存进程的相关信息。俗称内核态。</li>\n<li>用户空间：低地址空间的3GB，运行用户进程的代码和数据。俗称用户态。</li>\n<li>每次内核调用，都会进行空间切换，数据拷贝，这个操作是耗时的。</li>\n<li>虚拟内存到物理内存的映射，通过mmu（内存管理单元）操作。</li>\n</ul>\n<p><strong>写时复制：Copy On Write技术实现原理：</strong>   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. fork()之后，复制出来的子进程有自己的task_struct结构和pid,  </span><br><span class=\"line\">2. kernel把父进程中所有的内存页的权限都设为read-only，  </span><br><span class=\"line\">3. 然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。   </span><br><span class=\"line\">4. 当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，   </span><br><span class=\"line\">5. 于是触发页异常中断（page-fault），陷入kernel的一个中断例程。   </span><br><span class=\"line\">6. 中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份，  </span><br><span class=\"line\">7. 父进程会对原有的物理空间进行修改，而子进程会使用拷贝后的新物理空间。</span><br></pre></td></tr></table></figure>\n\n<p>在<strong>fork</strong>函数调用时，父进程和子进程会被内核分配不同的虚拟内存空间，所以从进程的角度看它们访问的是不同的内存：</p>\n<ul>\n<li>在虚拟内存空间进行读操作时，内核会将虚拟内存映射到物理内存上，父子进程共享了物理上的内存空间；</li>\n<li>当父进程对共享的内存进行修改时，共享的内存会以页为单位进行拷贝，父进程会对原有的物理空间进行修改，而子进程会使用拷贝后的新物理空间；</li>\n<li>当子进程对共享的内存进行修改时，子进程会在拷贝后的新物理空间上进行修改，而不会改动原有的物理空间，避免影响父进程的内存空间；</li>\n</ul>\n<h1 id=\"五、Linux内核架构\"><a href=\"#五、Linux内核架构\" class=\"headerlink\" title=\"五、Linux内核架构\"></a>五、Linux内核架构</h1><p><img src=\"/2020/04/09/2020-04-09-Linux-thread/internal.png\" alt=\"internal\"><br>进程调度器：process scheduler，持有了task_list，然后管理这些进程链表。维护了一个current指针，指向当前正在执行的进程。<br><strong>抢占式和非抢占式。</strong></p>\n<h1 id=\"六、进程状态\"><a href=\"#六、进程状态\" class=\"headerlink\" title=\"六、进程状态\"></a>六、进程状态</h1><ul>\n<li>task_running：正在运行或就绪</li>\n<li>task_intermptible：可中断的休眠，等待资源、信号，一旦满足，由中断变为就绪</li>\n<li>task_unintermptible：不可中断的休眠，信号无法唤醒，只有当资源满足时可唤醒。</li>\n<li>task_stoped：进程被停止执行</li>\n<li>task_traced：表示进程被debugger等进程监视</li>\n</ul>\n<h1 id=\"七、中断\"><a href=\"#七、中断\" class=\"headerlink\" title=\"七、中断\"></a>七、中断</h1><p>CPU暂停当前线程执行，执行中断请求。<br><strong>中断类型：</strong> </p>\n<ul>\n<li>同步中断（软中断）：由CPU控制单元产生，之所以称为同步，因为只有当一条指令执行完成后，才会执行中断指令。</li>\n<li>异步中断（硬中断）：由硬件设备产生的中断信号，随机产生。</li>\n</ul>\n<p>#八、缺页<br><img src=\"/2020/04/09/2020-04-09-Linux-thread/%E7%BC%BA%E9%A1%B5.png\" alt=\"缺页\"></p>\n<ol>\n<li>含义：PTE有晓位=0，虚拟内存中的虚拟页没有被缓存在物理内存中，称为缺页。</li>\n<li>具体表现：malloc()和mmap()函数调用，在分配时只建立的虚拟内存空间（在进程堆中分配），并没有分配虚拟内存对应的物理内存。当进程服务这些虚拟内存时，mmu（内存管理单元）无法解析，将报出page fault错误，缺页中断，然后进程进行空间切换，由用户态切换至内核态，然后由内核处理。</li>\n<li>处理方式：根据缺页类型，CPU判断物理内存中是否有当前所需页帧，如果存在，进行映射；如果不存在，则去磁盘读取保存至内存，再建立映射。</li>\n</ol>"},{"title":"ThreadLocal","date":"2020-04-13T08:58:29.000Z","_content":"# 一、背景\n* linux进程之间内存空间独立，互不影响，只有在两个进程访问共享变量时，才需要加锁，例如数据库等。\n* Linux子进程之间共享父进程的内存空间，\n\n例如JVM进程，在Linux系统中，也是一个进程，对应的数据结构：\n![ThreadLocal](2020-04-13-ThreadLocal/jvm-thread-memory.png)\n\n<!--more-->  \n\n* 而jvm线程在Linux中也是一个进程，在未改变原来数据时共享JVM进程的内存空间，若改变了，同一个数据可能会生成多个副本并且值不一致，那么产生的问题就是虚拟空间往物理内存写入时会产生数据不一致的问题，此时则需要加锁等处理保证数据的一致性。\n* 线程数据篡改是怎么产生的？\n    * A、B两个线程，有同一变量的数据副本，当A线程更新了物理内存中的数据，B再去更新，则相当于篡改了A线程的数据，此时缓存一致性协议来保证数据一致性。\n![ThreadLocal](2020-04-13-ThreadLocal/jvm-share.png)\n* 学习中遇到的疑问？\n    * 线程数据既然会被篡改（按linux角度的fork函数而言，fork子线程也会对线程数据进行篡改），那么ThreadLocal是如何做到的？\n    * 理由如下：\n        * 1、Java线程的创建，都是从JVM进程中fork处理的，而不是fork有ThreadLocal的线程。\n        * 2、ThreadLocal只属于当前线程，并且当前线程不会fork出子线程，则不会被其他线程篡改。\n\n# 二、多线程环境下，如何防止自己的变量被其他线程篡改？\n* ThreadLocal的设计目的是为了当前线程拥有自己的变量，并不是为了解决并发或共享变量的问题。\n* ThreadLocal主要作用是做数据隔离，保存到ThreadLocal中的数据只属于当前线程，对于其他线程来说是隔离的。\n\n# 三、实现\n\n```\n//使用方式\npublic static void main(String[] args) {\n    new Thread(new Runnable() {\n        @Override\n        public void run() {\n            ThreadLocal<String> threadLocal1 = new ThreadLocal<>();\n            threadLocal1.set(\"value1\");\n            ThreadLocal<String> threadLocal2 = new ThreadLocal<>();\n            threadLocal2.set(\"value2\");\n            System.out.println(threadLocal1.get());\n            System.out.println(threadLocal2.get());\n        }\n    }).start();\n}\n\n//代码实现\npublic class Thread implements Runnable {\n    //线程属性：threadLocal\n    ThreadLocal.ThreadLocalMap threadLocals = null;   \n}    \npublic class ThreadLocal<T> {\n    //TheadLocal静态内部类ThreadLocalMap，Entry[]数组，而Entry继承了虚引用\n    static class ThreadLocalMap {\n        private Entry[] table;\n        //构造函数\n        ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {\n            table = new Entry[INITIAL_CAPACITY];\n            int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);\n            table[i] = new Entry(firstKey, firstValue);\n            size = 1;\n            setThreshold(INITIAL_CAPACITY);\n        }\n        static class Entry extends WeakReference<ThreadLocal<?>> {\n            Object value;\n            Entry(ThreadLocal<?> k, Object v) {\n                super(k);\n                value = v;\n        }\n        private Entry getEntry(ThreadLocal<?> key) {\n            int i = key.threadLocalHashCode & (table.length - 1);\n            Entry e = table[i];\n            if (e != null && e.get() == key)\n                return e;\n            else\n                return getEntryAfterMiss(key, i, e);\n        }\n    }\n}\n```\n\n\n* ThreadLocal的实现：每个线程拥有一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal本身，value是实际需要存储的对象。也就是说ThreadLocal实际不存储值，只是作为key去ThreadLocalMap中获取value的值。\n* ThreadLocalMap内部是一个数组，Thread指向该数组。Entry的key是ThreadLocal，那么Thread只能有一个相同的ThreadLocal。一个ThreadLocal只能保存一个值。\n![ThreadLocal](2020-04-13-ThreadLocal/threadlocal.png)\n内存示意图：\n![ThreadLocal](2020-04-13-ThreadLocal/threadlocal-memory.png)\n\n1、hash冲突\n* 在插入过程中，根据ThreadLocal对象的hash值，定位到table中的位置i，过程如下：\n    * 1、如果当前位置是空的，那么正好，就初始化一个Entry对象放在位置i上；\n    * 2、不巧，位置i已经有Entry对象了，如果这个Entry对象的key正好是即将设置的key，那么重新设置Entry中的value；\n    * 3、很不巧，位置i的Entry对象，和即将设置的key没关系，那么只能找下一个空位置；\n\n这样的话，在get的时候，也会根据ThreadLocal对象的hash值，定位到table中的位置，然后判断该位置Entry对象中的key是否和get的key一致，如果不一致，就判断下一个位置\n\n2、内存泄漏\n\n* 如果key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。\n* 如果key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。\n\n**ThreadLocalMap内部的Entry[]数组，Entry继承了弱引用，ThreadLocal作为key，Entry弱引用对象指向了ThreadLocal。那么会在下一次GC的时候将弱引用指向的ThreadLocal对象会被回收，此时Entry.key=null，但是还是会有一个强引用指向了value，如果不把value清空，则会导致内存泄漏**\n\nThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。\n\n\n\n\n\n\n","source":"_posts/2020-04-13-ThreadLocal.md","raw":"---\ntitle: ThreadLocal\ndate: 2020-04-13 16:58:29\ntags: jvm\ncategories: \n  - [java, jvm]\n---\n# 一、背景\n* linux进程之间内存空间独立，互不影响，只有在两个进程访问共享变量时，才需要加锁，例如数据库等。\n* Linux子进程之间共享父进程的内存空间，\n\n例如JVM进程，在Linux系统中，也是一个进程，对应的数据结构：\n![ThreadLocal](2020-04-13-ThreadLocal/jvm-thread-memory.png)\n\n<!--more-->  \n\n* 而jvm线程在Linux中也是一个进程，在未改变原来数据时共享JVM进程的内存空间，若改变了，同一个数据可能会生成多个副本并且值不一致，那么产生的问题就是虚拟空间往物理内存写入时会产生数据不一致的问题，此时则需要加锁等处理保证数据的一致性。\n* 线程数据篡改是怎么产生的？\n    * A、B两个线程，有同一变量的数据副本，当A线程更新了物理内存中的数据，B再去更新，则相当于篡改了A线程的数据，此时缓存一致性协议来保证数据一致性。\n![ThreadLocal](2020-04-13-ThreadLocal/jvm-share.png)\n* 学习中遇到的疑问？\n    * 线程数据既然会被篡改（按linux角度的fork函数而言，fork子线程也会对线程数据进行篡改），那么ThreadLocal是如何做到的？\n    * 理由如下：\n        * 1、Java线程的创建，都是从JVM进程中fork处理的，而不是fork有ThreadLocal的线程。\n        * 2、ThreadLocal只属于当前线程，并且当前线程不会fork出子线程，则不会被其他线程篡改。\n\n# 二、多线程环境下，如何防止自己的变量被其他线程篡改？\n* ThreadLocal的设计目的是为了当前线程拥有自己的变量，并不是为了解决并发或共享变量的问题。\n* ThreadLocal主要作用是做数据隔离，保存到ThreadLocal中的数据只属于当前线程，对于其他线程来说是隔离的。\n\n# 三、实现\n\n```\n//使用方式\npublic static void main(String[] args) {\n    new Thread(new Runnable() {\n        @Override\n        public void run() {\n            ThreadLocal<String> threadLocal1 = new ThreadLocal<>();\n            threadLocal1.set(\"value1\");\n            ThreadLocal<String> threadLocal2 = new ThreadLocal<>();\n            threadLocal2.set(\"value2\");\n            System.out.println(threadLocal1.get());\n            System.out.println(threadLocal2.get());\n        }\n    }).start();\n}\n\n//代码实现\npublic class Thread implements Runnable {\n    //线程属性：threadLocal\n    ThreadLocal.ThreadLocalMap threadLocals = null;   \n}    \npublic class ThreadLocal<T> {\n    //TheadLocal静态内部类ThreadLocalMap，Entry[]数组，而Entry继承了虚引用\n    static class ThreadLocalMap {\n        private Entry[] table;\n        //构造函数\n        ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {\n            table = new Entry[INITIAL_CAPACITY];\n            int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);\n            table[i] = new Entry(firstKey, firstValue);\n            size = 1;\n            setThreshold(INITIAL_CAPACITY);\n        }\n        static class Entry extends WeakReference<ThreadLocal<?>> {\n            Object value;\n            Entry(ThreadLocal<?> k, Object v) {\n                super(k);\n                value = v;\n        }\n        private Entry getEntry(ThreadLocal<?> key) {\n            int i = key.threadLocalHashCode & (table.length - 1);\n            Entry e = table[i];\n            if (e != null && e.get() == key)\n                return e;\n            else\n                return getEntryAfterMiss(key, i, e);\n        }\n    }\n}\n```\n\n\n* ThreadLocal的实现：每个线程拥有一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal本身，value是实际需要存储的对象。也就是说ThreadLocal实际不存储值，只是作为key去ThreadLocalMap中获取value的值。\n* ThreadLocalMap内部是一个数组，Thread指向该数组。Entry的key是ThreadLocal，那么Thread只能有一个相同的ThreadLocal。一个ThreadLocal只能保存一个值。\n![ThreadLocal](2020-04-13-ThreadLocal/threadlocal.png)\n内存示意图：\n![ThreadLocal](2020-04-13-ThreadLocal/threadlocal-memory.png)\n\n1、hash冲突\n* 在插入过程中，根据ThreadLocal对象的hash值，定位到table中的位置i，过程如下：\n    * 1、如果当前位置是空的，那么正好，就初始化一个Entry对象放在位置i上；\n    * 2、不巧，位置i已经有Entry对象了，如果这个Entry对象的key正好是即将设置的key，那么重新设置Entry中的value；\n    * 3、很不巧，位置i的Entry对象，和即将设置的key没关系，那么只能找下一个空位置；\n\n这样的话，在get的时候，也会根据ThreadLocal对象的hash值，定位到table中的位置，然后判断该位置Entry对象中的key是否和get的key一致，如果不一致，就判断下一个位置\n\n2、内存泄漏\n\n* 如果key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。\n* 如果key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。\n\n**ThreadLocalMap内部的Entry[]数组，Entry继承了弱引用，ThreadLocal作为key，Entry弱引用对象指向了ThreadLocal。那么会在下一次GC的时候将弱引用指向的ThreadLocal对象会被回收，此时Entry.key=null，但是还是会有一个强引用指向了value，如果不把value清空，则会导致内存泄漏**\n\nThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。\n\n\n\n\n\n\n","slug":"2020-04-13-ThreadLocal","published":1,"updated":"2024-12-09T03:22:02.516Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnwy0027a13k3e9d9101","content":"<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><ul>\n<li>linux进程之间内存空间独立，互不影响，只有在两个进程访问共享变量时，才需要加锁，例如数据库等。</li>\n<li>Linux子进程之间共享父进程的内存空间，</li>\n</ul>\n<p>例如JVM进程，在Linux系统中，也是一个进程，对应的数据结构：<br><img src=\"/2020/04/13/2020-04-13-ThreadLocal/jvm-thread-memory.png\" alt=\"ThreadLocal\"></p>\n<a id=\"more\"></a>  \n\n<ul>\n<li>而jvm线程在Linux中也是一个进程，在未改变原来数据时共享JVM进程的内存空间，若改变了，同一个数据可能会生成多个副本并且值不一致，那么产生的问题就是虚拟空间往物理内存写入时会产生数据不一致的问题，此时则需要加锁等处理保证数据的一致性。</li>\n<li>线程数据篡改是怎么产生的？<ul>\n<li>A、B两个线程，有同一变量的数据副本，当A线程更新了物理内存中的数据，B再去更新，则相当于篡改了A线程的数据，此时缓存一致性协议来保证数据一致性。<br><img src=\"/2020/04/13/2020-04-13-ThreadLocal/jvm-share.png\" alt=\"ThreadLocal\"></li>\n</ul>\n</li>\n<li>学习中遇到的疑问？<ul>\n<li>线程数据既然会被篡改（按linux角度的fork函数而言，fork子线程也会对线程数据进行篡改），那么ThreadLocal是如何做到的？</li>\n<li>理由如下：<ul>\n<li>1、Java线程的创建，都是从JVM进程中fork处理的，而不是fork有ThreadLocal的线程。</li>\n<li>2、ThreadLocal只属于当前线程，并且当前线程不会fork出子线程，则不会被其他线程篡改。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"二、多线程环境下，如何防止自己的变量被其他线程篡改？\"><a href=\"#二、多线程环境下，如何防止自己的变量被其他线程篡改？\" class=\"headerlink\" title=\"二、多线程环境下，如何防止自己的变量被其他线程篡改？\"></a>二、多线程环境下，如何防止自己的变量被其他线程篡改？</h1><ul>\n<li>ThreadLocal的设计目的是为了当前线程拥有自己的变量，并不是为了解决并发或共享变量的问题。</li>\n<li>ThreadLocal主要作用是做数据隔离，保存到ThreadLocal中的数据只属于当前线程，对于其他线程来说是隔离的。</li>\n</ul>\n<h1 id=\"三、实现\"><a href=\"#三、实现\" class=\"headerlink\" title=\"三、实现\"></a>三、实现</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//使用方式</span><br><span class=\"line\">public static void main(String[] args) &#123;</span><br><span class=\"line\">    new Thread(new Runnable() &#123;</span><br><span class=\"line\">        @Override</span><br><span class=\"line\">        public void run() &#123;</span><br><span class=\"line\">            ThreadLocal&lt;String&gt; threadLocal1 = new ThreadLocal&lt;&gt;();</span><br><span class=\"line\">            threadLocal1.set(&quot;value1&quot;);</span><br><span class=\"line\">            ThreadLocal&lt;String&gt; threadLocal2 = new ThreadLocal&lt;&gt;();</span><br><span class=\"line\">            threadLocal2.set(&quot;value2&quot;);</span><br><span class=\"line\">            System.out.println(threadLocal1.get());</span><br><span class=\"line\">            System.out.println(threadLocal2.get());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;).start();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//代码实现</span><br><span class=\"line\">public class Thread implements Runnable &#123;</span><br><span class=\"line\">    //线程属性：threadLocal</span><br><span class=\"line\">    ThreadLocal.ThreadLocalMap threadLocals = null;   </span><br><span class=\"line\">&#125;    </span><br><span class=\"line\">public class ThreadLocal&lt;T&gt; &#123;</span><br><span class=\"line\">    //TheadLocal静态内部类ThreadLocalMap，Entry[]数组，而Entry继承了虚引用</span><br><span class=\"line\">    static class ThreadLocalMap &#123;</span><br><span class=\"line\">        private Entry[] table;</span><br><span class=\"line\">        //构造函数</span><br><span class=\"line\">        ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123;</span><br><span class=\"line\">            table = new Entry[INITIAL_CAPACITY];</span><br><span class=\"line\">            int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);</span><br><span class=\"line\">            table[i] = new Entry(firstKey, firstValue);</span><br><span class=\"line\">            size = 1;</span><br><span class=\"line\">            setThreshold(INITIAL_CAPACITY);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123;</span><br><span class=\"line\">            Object value;</span><br><span class=\"line\">            Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;</span><br><span class=\"line\">                super(k);</span><br><span class=\"line\">                value = v;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123;</span><br><span class=\"line\">            int i = key.threadLocalHashCode &amp; (table.length - 1);</span><br><span class=\"line\">            Entry e = table[i];</span><br><span class=\"line\">            if (e != null &amp;&amp; e.get() == key)</span><br><span class=\"line\">                return e;</span><br><span class=\"line\">            else</span><br><span class=\"line\">                return getEntryAfterMiss(key, i, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>ThreadLocal的实现：每个线程拥有一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal本身，value是实际需要存储的对象。也就是说ThreadLocal实际不存储值，只是作为key去ThreadLocalMap中获取value的值。</li>\n<li>ThreadLocalMap内部是一个数组，Thread指向该数组。Entry的key是ThreadLocal，那么Thread只能有一个相同的ThreadLocal。一个ThreadLocal只能保存一个值。<br><img src=\"/2020/04/13/2020-04-13-ThreadLocal/threadlocal.png\" alt=\"ThreadLocal\"><br>内存示意图：<br><img src=\"/2020/04/13/2020-04-13-ThreadLocal/threadlocal-memory.png\" alt=\"ThreadLocal\"></li>\n</ul>\n<p>1、hash冲突</p>\n<ul>\n<li>在插入过程中，根据ThreadLocal对象的hash值，定位到table中的位置i，过程如下：<ul>\n<li>1、如果当前位置是空的，那么正好，就初始化一个Entry对象放在位置i上；</li>\n<li>2、不巧，位置i已经有Entry对象了，如果这个Entry对象的key正好是即将设置的key，那么重新设置Entry中的value；</li>\n<li>3、很不巧，位置i的Entry对象，和即将设置的key没关系，那么只能找下一个空位置；</li>\n</ul>\n</li>\n</ul>\n<p>这样的话，在get的时候，也会根据ThreadLocal对象的hash值，定位到table中的位置，然后判断该位置Entry对象中的key是否和get的key一致，如果不一致，就判断下一个位置</p>\n<p>2、内存泄漏</p>\n<ul>\n<li>如果key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。</li>\n<li>如果key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。</li>\n</ul>\n<p><strong>ThreadLocalMap内部的Entry[]数组，Entry继承了弱引用，ThreadLocal作为key，Entry弱引用对象指向了ThreadLocal。那么会在下一次GC的时候将弱引用指向的ThreadLocal对象会被回收，此时Entry.key=null，但是还是会有一个强引用指向了value，如果不把value清空，则会导致内存泄漏</strong></p>\n<p>ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><ul>\n<li>linux进程之间内存空间独立，互不影响，只有在两个进程访问共享变量时，才需要加锁，例如数据库等。</li>\n<li>Linux子进程之间共享父进程的内存空间，</li>\n</ul>\n<p>例如JVM进程，在Linux系统中，也是一个进程，对应的数据结构：<br><img src=\"/2020/04/13/2020-04-13-ThreadLocal/jvm-thread-memory.png\" alt=\"ThreadLocal\"></p>","more":"<ul>\n<li>而jvm线程在Linux中也是一个进程，在未改变原来数据时共享JVM进程的内存空间，若改变了，同一个数据可能会生成多个副本并且值不一致，那么产生的问题就是虚拟空间往物理内存写入时会产生数据不一致的问题，此时则需要加锁等处理保证数据的一致性。</li>\n<li>线程数据篡改是怎么产生的？<ul>\n<li>A、B两个线程，有同一变量的数据副本，当A线程更新了物理内存中的数据，B再去更新，则相当于篡改了A线程的数据，此时缓存一致性协议来保证数据一致性。<br><img src=\"/2020/04/13/2020-04-13-ThreadLocal/jvm-share.png\" alt=\"ThreadLocal\"></li>\n</ul>\n</li>\n<li>学习中遇到的疑问？<ul>\n<li>线程数据既然会被篡改（按linux角度的fork函数而言，fork子线程也会对线程数据进行篡改），那么ThreadLocal是如何做到的？</li>\n<li>理由如下：<ul>\n<li>1、Java线程的创建，都是从JVM进程中fork处理的，而不是fork有ThreadLocal的线程。</li>\n<li>2、ThreadLocal只属于当前线程，并且当前线程不会fork出子线程，则不会被其他线程篡改。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"二、多线程环境下，如何防止自己的变量被其他线程篡改？\"><a href=\"#二、多线程环境下，如何防止自己的变量被其他线程篡改？\" class=\"headerlink\" title=\"二、多线程环境下，如何防止自己的变量被其他线程篡改？\"></a>二、多线程环境下，如何防止自己的变量被其他线程篡改？</h1><ul>\n<li>ThreadLocal的设计目的是为了当前线程拥有自己的变量，并不是为了解决并发或共享变量的问题。</li>\n<li>ThreadLocal主要作用是做数据隔离，保存到ThreadLocal中的数据只属于当前线程，对于其他线程来说是隔离的。</li>\n</ul>\n<h1 id=\"三、实现\"><a href=\"#三、实现\" class=\"headerlink\" title=\"三、实现\"></a>三、实现</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//使用方式</span><br><span class=\"line\">public static void main(String[] args) &#123;</span><br><span class=\"line\">    new Thread(new Runnable() &#123;</span><br><span class=\"line\">        @Override</span><br><span class=\"line\">        public void run() &#123;</span><br><span class=\"line\">            ThreadLocal&lt;String&gt; threadLocal1 = new ThreadLocal&lt;&gt;();</span><br><span class=\"line\">            threadLocal1.set(&quot;value1&quot;);</span><br><span class=\"line\">            ThreadLocal&lt;String&gt; threadLocal2 = new ThreadLocal&lt;&gt;();</span><br><span class=\"line\">            threadLocal2.set(&quot;value2&quot;);</span><br><span class=\"line\">            System.out.println(threadLocal1.get());</span><br><span class=\"line\">            System.out.println(threadLocal2.get());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;).start();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//代码实现</span><br><span class=\"line\">public class Thread implements Runnable &#123;</span><br><span class=\"line\">    //线程属性：threadLocal</span><br><span class=\"line\">    ThreadLocal.ThreadLocalMap threadLocals = null;   </span><br><span class=\"line\">&#125;    </span><br><span class=\"line\">public class ThreadLocal&lt;T&gt; &#123;</span><br><span class=\"line\">    //TheadLocal静态内部类ThreadLocalMap，Entry[]数组，而Entry继承了虚引用</span><br><span class=\"line\">    static class ThreadLocalMap &#123;</span><br><span class=\"line\">        private Entry[] table;</span><br><span class=\"line\">        //构造函数</span><br><span class=\"line\">        ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123;</span><br><span class=\"line\">            table = new Entry[INITIAL_CAPACITY];</span><br><span class=\"line\">            int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);</span><br><span class=\"line\">            table[i] = new Entry(firstKey, firstValue);</span><br><span class=\"line\">            size = 1;</span><br><span class=\"line\">            setThreshold(INITIAL_CAPACITY);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123;</span><br><span class=\"line\">            Object value;</span><br><span class=\"line\">            Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;</span><br><span class=\"line\">                super(k);</span><br><span class=\"line\">                value = v;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123;</span><br><span class=\"line\">            int i = key.threadLocalHashCode &amp; (table.length - 1);</span><br><span class=\"line\">            Entry e = table[i];</span><br><span class=\"line\">            if (e != null &amp;&amp; e.get() == key)</span><br><span class=\"line\">                return e;</span><br><span class=\"line\">            else</span><br><span class=\"line\">                return getEntryAfterMiss(key, i, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>ThreadLocal的实现：每个线程拥有一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal本身，value是实际需要存储的对象。也就是说ThreadLocal实际不存储值，只是作为key去ThreadLocalMap中获取value的值。</li>\n<li>ThreadLocalMap内部是一个数组，Thread指向该数组。Entry的key是ThreadLocal，那么Thread只能有一个相同的ThreadLocal。一个ThreadLocal只能保存一个值。<br><img src=\"/2020/04/13/2020-04-13-ThreadLocal/threadlocal.png\" alt=\"ThreadLocal\"><br>内存示意图：<br><img src=\"/2020/04/13/2020-04-13-ThreadLocal/threadlocal-memory.png\" alt=\"ThreadLocal\"></li>\n</ul>\n<p>1、hash冲突</p>\n<ul>\n<li>在插入过程中，根据ThreadLocal对象的hash值，定位到table中的位置i，过程如下：<ul>\n<li>1、如果当前位置是空的，那么正好，就初始化一个Entry对象放在位置i上；</li>\n<li>2、不巧，位置i已经有Entry对象了，如果这个Entry对象的key正好是即将设置的key，那么重新设置Entry中的value；</li>\n<li>3、很不巧，位置i的Entry对象，和即将设置的key没关系，那么只能找下一个空位置；</li>\n</ul>\n</li>\n</ul>\n<p>这样的话，在get的时候，也会根据ThreadLocal对象的hash值，定位到table中的位置，然后判断该位置Entry对象中的key是否和get的key一致，如果不一致，就判断下一个位置</p>\n<p>2、内存泄漏</p>\n<ul>\n<li>如果key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。</li>\n<li>如果key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。</li>\n</ul>\n<p><strong>ThreadLocalMap内部的Entry[]数组，Entry继承了弱引用，ThreadLocal作为key，Entry弱引用对象指向了ThreadLocal。那么会在下一次GC的时候将弱引用指向的ThreadLocal对象会被回收，此时Entry.key=null，但是还是会有一个强引用指向了value，如果不把value清空，则会导致内存泄漏</strong></p>\n<p>ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。</p>"},{"title":"《Java》虚拟机规范","date":"2020-04-11T09:19:31.000Z","_content":"\n### 一、虚拟机规范\n许多人知道类加载机制、JVM内存模型，但他们可能不知道什么是《Java虚拟机规范》。对于Java开发来说，《Java虚拟机规范》才是最为官方、准确的一个文档，了解这个规范可以让我们更深入地理解JVM。我们平常说的JVM其实更多说的是HotSpot（HotSpot是JVM规范的一种实现），但我们常常将HotSpot与JVM等同起来。正因对于JVM规范认识的不足，所以我专门准备一个系列的文章，带着大家读一读JVM规范。\n\n#### 定义与概念:\njava 虚拟机规范详细定义了 JVM 的体系结构、指令集、寄存器集合、类文件格式、内存管理、垃圾回收等诸多方面的内容。它就像是 JVM 的 “宪法”，规定了 JVM 应该如何运行以及如何处理各种情况。\n\n#### 目的和作用：\n- 定义了Java虚拟机的概念模型和整体架构，确保不同的Java虚拟机实现具有一致的行为和功能，使得Java程序能够在不同的平台上具有可移植性。\n\n### 二、Java虚拟机\nJava 虚拟机（Java Virtual Machine，JVM）是一个可以执行 Java 字节码的虚拟机进程。\n\n### 二、关键内容\n打开《Java虚拟机规范》目录，我们可以看到规范分为下面几个部分：\n- 第1章 引言\n- 第2章 Java虚拟机结构\n- 第3章 为Java虚拟机编译\n- 第4章 Class文件格式\n- 第5章 加载、链接与初始化\n- 第6章 Java虚拟机指令集\n- 第7章 操作码助记符\n\n第1章 引言\n\n从第1章的目录可以看出，其主要介绍一些历史以及Java虚拟机的基础知识，还有各章节提要，没有什么难度。略过。\n\n第2章 Java虚拟机结构\n\n第2章介绍了Class文件格式、数据类型、原始类型、引用类型、运行时数据区、栈帧、字节码指令等。\n\n在这一部分中，我们比较熟悉的就是运行时数据区了。其实我们习惯性叫Java虚拟机内存模型或内存结构，但在JVM规范中是叫做运行时数据区的。此外栈帧也是非常重要的一个部分，与方法的调用有关。字节码指令则是更加深层次的知识。\n\n此外，数据类型、原始类型、引用类型等也是基础的知识，但用得相对较少。\n\n第3章 为Java虚拟机编译\n\n这一章从名字可以看出，写的是如何编译Java文件的，将Java文件编译为字节码文件，最终提供给Java虚拟机使用。\n\n我们之前提到Java虚拟机其实就是将字节码文件翻译成机器码，所以这里就是编译器把Java源码编译成字节码。但是到底如何编译呢？\n\n算数运算要怎么编译？\n常量池如何编译？\n方法调用如何编译？\n……\n这一章解决的就是这个问题。\n\n第4章 Class文件格式\n\n前面提到过JVM的输入物料是字节码文件，也就是Class文件，而不是Java文件。也就是说无论是Java语言，还是php语言，只要你能编译出字节码文件，那JVM就能够运行。\n\n那么我们就知道这个Class文件必定是有统一格式的。而这一章节说的内容就是Class文件的格式构成。之前我们写过一个HelloWorld.java文件，将其编译成字节码文件，然后一个字节一个字节地分析其内容。要能分析字节码文件的内容，首先就得弄清楚Class文件的格式。而这一章就是讲解字节码文件格式的。\n\n这一章节也是非常重要的。\n\n第5章 加载、链接与初始化\n\nJava虚拟机规范其实是递进、非常有节奏的。前面第2章讲了JVM的内存结构，之后将如何将源文件（.java）编译成字节码文件（.class）文件，之后将了字节码文件的格式。那么下一步是什么？\n\n下一步就是把字节码文件加载到内存中运行呀！\n\n没错，第5章说的就是这个内容。\n\n首先是加载。《Java虚拟机规范》在这一章中说明了Java虚拟机将如何启动、如何创建、加载类。\n\n其次是链接（包括验证、准备、解析）。首先会验证，字节码文件加载进来了，那么就必须要验证下这个字节码文件是否写对了，不然随便写一个文件就运行，岂不是乱套了。准备是给变量和对象分配内存。校验完数据格式，那么就要针对字节码内容进行解析了，就是读懂这些字节码数据到底要干嘛。这个过程包括了：类与接口解析、字段解析、普通方法解析等等。\n\n之后是初始化。会运行一些初始化的构造方法，用于初始化数据。\n\n最后运行完毕，Java虚拟机退出。\n\n第6章 Java虚拟机指令集\n\n指令集，其实就是一系列指令的集合。例如我们需要给一个局部变量赋予1这个值，即这个动作：int a = 1; 在我们看来，这很简单，但对于机器来说需要很多个动作。\n\n所以Java虚拟机指令集就是将这些常用的动作集中起来，定义成一系列指令，方便我么能使用。","source":"_posts/2020-04-11-java-虚拟机规范.md","raw":"---\ntitle: 《Java》虚拟机规范\ndate: 2020-04-11 17:19:31\ntags: jvm thread\ncategories: \n   - [java, jvm]\n---\n\n### 一、虚拟机规范\n许多人知道类加载机制、JVM内存模型，但他们可能不知道什么是《Java虚拟机规范》。对于Java开发来说，《Java虚拟机规范》才是最为官方、准确的一个文档，了解这个规范可以让我们更深入地理解JVM。我们平常说的JVM其实更多说的是HotSpot（HotSpot是JVM规范的一种实现），但我们常常将HotSpot与JVM等同起来。正因对于JVM规范认识的不足，所以我专门准备一个系列的文章，带着大家读一读JVM规范。\n\n#### 定义与概念:\njava 虚拟机规范详细定义了 JVM 的体系结构、指令集、寄存器集合、类文件格式、内存管理、垃圾回收等诸多方面的内容。它就像是 JVM 的 “宪法”，规定了 JVM 应该如何运行以及如何处理各种情况。\n\n#### 目的和作用：\n- 定义了Java虚拟机的概念模型和整体架构，确保不同的Java虚拟机实现具有一致的行为和功能，使得Java程序能够在不同的平台上具有可移植性。\n\n### 二、Java虚拟机\nJava 虚拟机（Java Virtual Machine，JVM）是一个可以执行 Java 字节码的虚拟机进程。\n\n### 二、关键内容\n打开《Java虚拟机规范》目录，我们可以看到规范分为下面几个部分：\n- 第1章 引言\n- 第2章 Java虚拟机结构\n- 第3章 为Java虚拟机编译\n- 第4章 Class文件格式\n- 第5章 加载、链接与初始化\n- 第6章 Java虚拟机指令集\n- 第7章 操作码助记符\n\n第1章 引言\n\n从第1章的目录可以看出，其主要介绍一些历史以及Java虚拟机的基础知识，还有各章节提要，没有什么难度。略过。\n\n第2章 Java虚拟机结构\n\n第2章介绍了Class文件格式、数据类型、原始类型、引用类型、运行时数据区、栈帧、字节码指令等。\n\n在这一部分中，我们比较熟悉的就是运行时数据区了。其实我们习惯性叫Java虚拟机内存模型或内存结构，但在JVM规范中是叫做运行时数据区的。此外栈帧也是非常重要的一个部分，与方法的调用有关。字节码指令则是更加深层次的知识。\n\n此外，数据类型、原始类型、引用类型等也是基础的知识，但用得相对较少。\n\n第3章 为Java虚拟机编译\n\n这一章从名字可以看出，写的是如何编译Java文件的，将Java文件编译为字节码文件，最终提供给Java虚拟机使用。\n\n我们之前提到Java虚拟机其实就是将字节码文件翻译成机器码，所以这里就是编译器把Java源码编译成字节码。但是到底如何编译呢？\n\n算数运算要怎么编译？\n常量池如何编译？\n方法调用如何编译？\n……\n这一章解决的就是这个问题。\n\n第4章 Class文件格式\n\n前面提到过JVM的输入物料是字节码文件，也就是Class文件，而不是Java文件。也就是说无论是Java语言，还是php语言，只要你能编译出字节码文件，那JVM就能够运行。\n\n那么我们就知道这个Class文件必定是有统一格式的。而这一章节说的内容就是Class文件的格式构成。之前我们写过一个HelloWorld.java文件，将其编译成字节码文件，然后一个字节一个字节地分析其内容。要能分析字节码文件的内容，首先就得弄清楚Class文件的格式。而这一章就是讲解字节码文件格式的。\n\n这一章节也是非常重要的。\n\n第5章 加载、链接与初始化\n\nJava虚拟机规范其实是递进、非常有节奏的。前面第2章讲了JVM的内存结构，之后将如何将源文件（.java）编译成字节码文件（.class）文件，之后将了字节码文件的格式。那么下一步是什么？\n\n下一步就是把字节码文件加载到内存中运行呀！\n\n没错，第5章说的就是这个内容。\n\n首先是加载。《Java虚拟机规范》在这一章中说明了Java虚拟机将如何启动、如何创建、加载类。\n\n其次是链接（包括验证、准备、解析）。首先会验证，字节码文件加载进来了，那么就必须要验证下这个字节码文件是否写对了，不然随便写一个文件就运行，岂不是乱套了。准备是给变量和对象分配内存。校验完数据格式，那么就要针对字节码内容进行解析了，就是读懂这些字节码数据到底要干嘛。这个过程包括了：类与接口解析、字段解析、普通方法解析等等。\n\n之后是初始化。会运行一些初始化的构造方法，用于初始化数据。\n\n最后运行完毕，Java虚拟机退出。\n\n第6章 Java虚拟机指令集\n\n指令集，其实就是一系列指令的集合。例如我们需要给一个局部变量赋予1这个值，即这个动作：int a = 1; 在我们看来，这很简单，但对于机器来说需要很多个动作。\n\n所以Java虚拟机指令集就是将这些常用的动作集中起来，定义成一系列指令，方便我么能使用。","slug":"2020-04-11-java-虚拟机规范","published":1,"updated":"2024-12-09T07:57:30.124Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnwz002aa13kmg6q1zkm","content":"<h3 id=\"一、虚拟机规范\"><a href=\"#一、虚拟机规范\" class=\"headerlink\" title=\"一、虚拟机规范\"></a>一、虚拟机规范</h3><p>许多人知道类加载机制、JVM内存模型，但他们可能不知道什么是《Java虚拟机规范》。对于Java开发来说，《Java虚拟机规范》才是最为官方、准确的一个文档，了解这个规范可以让我们更深入地理解JVM。我们平常说的JVM其实更多说的是HotSpot（HotSpot是JVM规范的一种实现），但我们常常将HotSpot与JVM等同起来。正因对于JVM规范认识的不足，所以我专门准备一个系列的文章，带着大家读一读JVM规范。</p>\n<h4 id=\"定义与概念\"><a href=\"#定义与概念\" class=\"headerlink\" title=\"定义与概念:\"></a>定义与概念:</h4><p>java 虚拟机规范详细定义了 JVM 的体系结构、指令集、寄存器集合、类文件格式、内存管理、垃圾回收等诸多方面的内容。它就像是 JVM 的 “宪法”，规定了 JVM 应该如何运行以及如何处理各种情况。</p>\n<h4 id=\"目的和作用：\"><a href=\"#目的和作用：\" class=\"headerlink\" title=\"目的和作用：\"></a>目的和作用：</h4><ul>\n<li>定义了Java虚拟机的概念模型和整体架构，确保不同的Java虚拟机实现具有一致的行为和功能，使得Java程序能够在不同的平台上具有可移植性。</li>\n</ul>\n<h3 id=\"二、Java虚拟机\"><a href=\"#二、Java虚拟机\" class=\"headerlink\" title=\"二、Java虚拟机\"></a>二、Java虚拟机</h3><p>Java 虚拟机（Java Virtual Machine，JVM）是一个可以执行 Java 字节码的虚拟机进程。</p>\n<h3 id=\"二、关键内容\"><a href=\"#二、关键内容\" class=\"headerlink\" title=\"二、关键内容\"></a>二、关键内容</h3><p>打开《Java虚拟机规范》目录，我们可以看到规范分为下面几个部分：</p>\n<ul>\n<li>第1章 引言</li>\n<li>第2章 Java虚拟机结构</li>\n<li>第3章 为Java虚拟机编译</li>\n<li>第4章 Class文件格式</li>\n<li>第5章 加载、链接与初始化</li>\n<li>第6章 Java虚拟机指令集</li>\n<li>第7章 操作码助记符</li>\n</ul>\n<p>第1章 引言</p>\n<p>从第1章的目录可以看出，其主要介绍一些历史以及Java虚拟机的基础知识，还有各章节提要，没有什么难度。略过。</p>\n<p>第2章 Java虚拟机结构</p>\n<p>第2章介绍了Class文件格式、数据类型、原始类型、引用类型、运行时数据区、栈帧、字节码指令等。</p>\n<p>在这一部分中，我们比较熟悉的就是运行时数据区了。其实我们习惯性叫Java虚拟机内存模型或内存结构，但在JVM规范中是叫做运行时数据区的。此外栈帧也是非常重要的一个部分，与方法的调用有关。字节码指令则是更加深层次的知识。</p>\n<p>此外，数据类型、原始类型、引用类型等也是基础的知识，但用得相对较少。</p>\n<p>第3章 为Java虚拟机编译</p>\n<p>这一章从名字可以看出，写的是如何编译Java文件的，将Java文件编译为字节码文件，最终提供给Java虚拟机使用。</p>\n<p>我们之前提到Java虚拟机其实就是将字节码文件翻译成机器码，所以这里就是编译器把Java源码编译成字节码。但是到底如何编译呢？</p>\n<p>算数运算要怎么编译？<br>常量池如何编译？<br>方法调用如何编译？<br>……<br>这一章解决的就是这个问题。</p>\n<p>第4章 Class文件格式</p>\n<p>前面提到过JVM的输入物料是字节码文件，也就是Class文件，而不是Java文件。也就是说无论是Java语言，还是php语言，只要你能编译出字节码文件，那JVM就能够运行。</p>\n<p>那么我们就知道这个Class文件必定是有统一格式的。而这一章节说的内容就是Class文件的格式构成。之前我们写过一个HelloWorld.java文件，将其编译成字节码文件，然后一个字节一个字节地分析其内容。要能分析字节码文件的内容，首先就得弄清楚Class文件的格式。而这一章就是讲解字节码文件格式的。</p>\n<p>这一章节也是非常重要的。</p>\n<p>第5章 加载、链接与初始化</p>\n<p>Java虚拟机规范其实是递进、非常有节奏的。前面第2章讲了JVM的内存结构，之后将如何将源文件（.java）编译成字节码文件（.class）文件，之后将了字节码文件的格式。那么下一步是什么？</p>\n<p>下一步就是把字节码文件加载到内存中运行呀！</p>\n<p>没错，第5章说的就是这个内容。</p>\n<p>首先是加载。《Java虚拟机规范》在这一章中说明了Java虚拟机将如何启动、如何创建、加载类。</p>\n<p>其次是链接（包括验证、准备、解析）。首先会验证，字节码文件加载进来了，那么就必须要验证下这个字节码文件是否写对了，不然随便写一个文件就运行，岂不是乱套了。准备是给变量和对象分配内存。校验完数据格式，那么就要针对字节码内容进行解析了，就是读懂这些字节码数据到底要干嘛。这个过程包括了：类与接口解析、字段解析、普通方法解析等等。</p>\n<p>之后是初始化。会运行一些初始化的构造方法，用于初始化数据。</p>\n<p>最后运行完毕，Java虚拟机退出。</p>\n<p>第6章 Java虚拟机指令集</p>\n<p>指令集，其实就是一系列指令的集合。例如我们需要给一个局部变量赋予1这个值，即这个动作：int a = 1; 在我们看来，这很简单，但对于机器来说需要很多个动作。</p>\n<p>所以Java虚拟机指令集就是将这些常用的动作集中起来，定义成一系列指令，方便我么能使用。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"一、虚拟机规范\"><a href=\"#一、虚拟机规范\" class=\"headerlink\" title=\"一、虚拟机规范\"></a>一、虚拟机规范</h3><p>许多人知道类加载机制、JVM内存模型，但他们可能不知道什么是《Java虚拟机规范》。对于Java开发来说，《Java虚拟机规范》才是最为官方、准确的一个文档，了解这个规范可以让我们更深入地理解JVM。我们平常说的JVM其实更多说的是HotSpot（HotSpot是JVM规范的一种实现），但我们常常将HotSpot与JVM等同起来。正因对于JVM规范认识的不足，所以我专门准备一个系列的文章，带着大家读一读JVM规范。</p>\n<h4 id=\"定义与概念\"><a href=\"#定义与概念\" class=\"headerlink\" title=\"定义与概念:\"></a>定义与概念:</h4><p>java 虚拟机规范详细定义了 JVM 的体系结构、指令集、寄存器集合、类文件格式、内存管理、垃圾回收等诸多方面的内容。它就像是 JVM 的 “宪法”，规定了 JVM 应该如何运行以及如何处理各种情况。</p>\n<h4 id=\"目的和作用：\"><a href=\"#目的和作用：\" class=\"headerlink\" title=\"目的和作用：\"></a>目的和作用：</h4><ul>\n<li>定义了Java虚拟机的概念模型和整体架构，确保不同的Java虚拟机实现具有一致的行为和功能，使得Java程序能够在不同的平台上具有可移植性。</li>\n</ul>\n<h3 id=\"二、Java虚拟机\"><a href=\"#二、Java虚拟机\" class=\"headerlink\" title=\"二、Java虚拟机\"></a>二、Java虚拟机</h3><p>Java 虚拟机（Java Virtual Machine，JVM）是一个可以执行 Java 字节码的虚拟机进程。</p>\n<h3 id=\"二、关键内容\"><a href=\"#二、关键内容\" class=\"headerlink\" title=\"二、关键内容\"></a>二、关键内容</h3><p>打开《Java虚拟机规范》目录，我们可以看到规范分为下面几个部分：</p>\n<ul>\n<li>第1章 引言</li>\n<li>第2章 Java虚拟机结构</li>\n<li>第3章 为Java虚拟机编译</li>\n<li>第4章 Class文件格式</li>\n<li>第5章 加载、链接与初始化</li>\n<li>第6章 Java虚拟机指令集</li>\n<li>第7章 操作码助记符</li>\n</ul>\n<p>第1章 引言</p>\n<p>从第1章的目录可以看出，其主要介绍一些历史以及Java虚拟机的基础知识，还有各章节提要，没有什么难度。略过。</p>\n<p>第2章 Java虚拟机结构</p>\n<p>第2章介绍了Class文件格式、数据类型、原始类型、引用类型、运行时数据区、栈帧、字节码指令等。</p>\n<p>在这一部分中，我们比较熟悉的就是运行时数据区了。其实我们习惯性叫Java虚拟机内存模型或内存结构，但在JVM规范中是叫做运行时数据区的。此外栈帧也是非常重要的一个部分，与方法的调用有关。字节码指令则是更加深层次的知识。</p>\n<p>此外，数据类型、原始类型、引用类型等也是基础的知识，但用得相对较少。</p>\n<p>第3章 为Java虚拟机编译</p>\n<p>这一章从名字可以看出，写的是如何编译Java文件的，将Java文件编译为字节码文件，最终提供给Java虚拟机使用。</p>\n<p>我们之前提到Java虚拟机其实就是将字节码文件翻译成机器码，所以这里就是编译器把Java源码编译成字节码。但是到底如何编译呢？</p>\n<p>算数运算要怎么编译？<br>常量池如何编译？<br>方法调用如何编译？<br>……<br>这一章解决的就是这个问题。</p>\n<p>第4章 Class文件格式</p>\n<p>前面提到过JVM的输入物料是字节码文件，也就是Class文件，而不是Java文件。也就是说无论是Java语言，还是php语言，只要你能编译出字节码文件，那JVM就能够运行。</p>\n<p>那么我们就知道这个Class文件必定是有统一格式的。而这一章节说的内容就是Class文件的格式构成。之前我们写过一个HelloWorld.java文件，将其编译成字节码文件，然后一个字节一个字节地分析其内容。要能分析字节码文件的内容，首先就得弄清楚Class文件的格式。而这一章就是讲解字节码文件格式的。</p>\n<p>这一章节也是非常重要的。</p>\n<p>第5章 加载、链接与初始化</p>\n<p>Java虚拟机规范其实是递进、非常有节奏的。前面第2章讲了JVM的内存结构，之后将如何将源文件（.java）编译成字节码文件（.class）文件，之后将了字节码文件的格式。那么下一步是什么？</p>\n<p>下一步就是把字节码文件加载到内存中运行呀！</p>\n<p>没错，第5章说的就是这个内容。</p>\n<p>首先是加载。《Java虚拟机规范》在这一章中说明了Java虚拟机将如何启动、如何创建、加载类。</p>\n<p>其次是链接（包括验证、准备、解析）。首先会验证，字节码文件加载进来了，那么就必须要验证下这个字节码文件是否写对了，不然随便写一个文件就运行，岂不是乱套了。准备是给变量和对象分配内存。校验完数据格式，那么就要针对字节码内容进行解析了，就是读懂这些字节码数据到底要干嘛。这个过程包括了：类与接口解析、字段解析、普通方法解析等等。</p>\n<p>之后是初始化。会运行一些初始化的构造方法，用于初始化数据。</p>\n<p>最后运行完毕，Java虚拟机退出。</p>\n<p>第6章 Java虚拟机指令集</p>\n<p>指令集，其实就是一系列指令的集合。例如我们需要给一个局部变量赋予1这个值，即这个动作：int a = 1; 在我们看来，这很简单，但对于机器来说需要很多个动作。</p>\n<p>所以Java虚拟机指令集就是将这些常用的动作集中起来，定义成一系列指令，方便我么能使用。</p>\n"},{"title":"强弱软虚","date":"2020-04-13T08:46:31.000Z","_content":"\n# 一、弱引用\n```java\npublic class WeakReference<T> extends Reference<T> {\n    public WeakReference(T referent) {\n        super(referent);\n    }\n    public WeakReference(T referent, ReferenceQueue<? super T> q) {\n        super(referent, q);\n    }\n}\n```\n* WeakReference(T referent)：referent对象，被弱引用对象指向，会在下一次GC时将referent对象回收，此时WeakReference.get()会返回null。\n* WeakReference(T referent, ReferenceQueue<? super T> q)：当referent对象回收后，会将指向referent的弱引用对象放入队列中。\n\n<!--more-->\n\n使用：\n定义普通类\n```java\npublic class Apple {\n    private String name;\n}\n\n```\n\n定义弱引用类\n```java\npublic class SaladReference extends WeakReference<Apple> {\n    public Salad(Apple apple) {\n        super(apple);\n    }\n}\n\n```\n* SaladReference弱引用对象，将指向Apple对象。\n\n使用\n```java\npublic class Client {\n    public static void main(String[] args) {\n        Salad salad = new Salad(new Apple(\"红富士\"));\n        //通过WeakReference的get()方法获取Apple\n        System.out.println(\"Apple:\" + salad.get());\n        System.gc();\n        try {\n            //休眠一下，在运行的时候加上虚拟机参数-XX:+PrintGCDetails，输出gc信息，确定gc发生了。\n            Thread.sleep(5000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        //如果为空，代表被回收了\n        if (salad.get() == null) {\n            System.out.println(\"clear Apple。\");\n        }\n    }\n}\n```\n* 输出结果：\n```\nApple:Apple{name='红富士'}, hashCode:1846274136\n[GC (System.gc()) [PSYoungGen: 3328K->496K(38400K)] 3328K->504K(125952K), 0.0035102 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] \n[Full GC (System.gc()) [PSYoungGen: 496K->0K(38400K)] [ParOldGen: 8K->359K(87552K)] 504K->359K(125952K), [Metaspace: 2877K->2877K(1056768K)], 0.0067965 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] \nApple： 红富士 finalize。\nclear Apple。\n```\n\n\n\n# 二、强引用\n如果一个对象有强引用，那垃圾回收一定不会回收。\n```\nObject o=new Object();   //  强引用\n```\n当内存空间不足，jvm宁愿抛出OOM错误，也不会回收\n\n# 三、软引用\n被软引用对象引用的实例对象，将在JVM内存不足时进行回收，可用于实现内存敏感的高速缓冲。\n```\nString str=new String(\"abc\");                                     // 强引用\nSoftReference<String> softRef=new SoftReference<String>(str);     // 软引用\n\n```\n软引用和弱引用直接的区别，软引用只有当内存不足时才会去回收；而弱引用会在GC时回收\n\n# 四、虚引用\n顾名思义，形同虚设。如果一个对象仅仅被虚引用对象引用，那该对象随时可以被回收。\n虚引用主要用来跟踪对象被垃圾回收的整个过程活动，虚引用必须和引用队列（ReferenceQueue）联合使用，\n但是它被回收之前，会被放入ReferenceQueue中。注意哦，其它引用是被JVM回收后才被传入ReferenceQueue中的\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/2020-04-13-强弱软虚.md","raw":"---\ntitle: 强弱软虚\ndate: 2020-04-13 16:46:31\ntags: jvm\ncategories:\n  - [java, jvm]\n---\n\n# 一、弱引用\n```java\npublic class WeakReference<T> extends Reference<T> {\n    public WeakReference(T referent) {\n        super(referent);\n    }\n    public WeakReference(T referent, ReferenceQueue<? super T> q) {\n        super(referent, q);\n    }\n}\n```\n* WeakReference(T referent)：referent对象，被弱引用对象指向，会在下一次GC时将referent对象回收，此时WeakReference.get()会返回null。\n* WeakReference(T referent, ReferenceQueue<? super T> q)：当referent对象回收后，会将指向referent的弱引用对象放入队列中。\n\n<!--more-->\n\n使用：\n定义普通类\n```java\npublic class Apple {\n    private String name;\n}\n\n```\n\n定义弱引用类\n```java\npublic class SaladReference extends WeakReference<Apple> {\n    public Salad(Apple apple) {\n        super(apple);\n    }\n}\n\n```\n* SaladReference弱引用对象，将指向Apple对象。\n\n使用\n```java\npublic class Client {\n    public static void main(String[] args) {\n        Salad salad = new Salad(new Apple(\"红富士\"));\n        //通过WeakReference的get()方法获取Apple\n        System.out.println(\"Apple:\" + salad.get());\n        System.gc();\n        try {\n            //休眠一下，在运行的时候加上虚拟机参数-XX:+PrintGCDetails，输出gc信息，确定gc发生了。\n            Thread.sleep(5000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        //如果为空，代表被回收了\n        if (salad.get() == null) {\n            System.out.println(\"clear Apple。\");\n        }\n    }\n}\n```\n* 输出结果：\n```\nApple:Apple{name='红富士'}, hashCode:1846274136\n[GC (System.gc()) [PSYoungGen: 3328K->496K(38400K)] 3328K->504K(125952K), 0.0035102 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] \n[Full GC (System.gc()) [PSYoungGen: 496K->0K(38400K)] [ParOldGen: 8K->359K(87552K)] 504K->359K(125952K), [Metaspace: 2877K->2877K(1056768K)], 0.0067965 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] \nApple： 红富士 finalize。\nclear Apple。\n```\n\n\n\n# 二、强引用\n如果一个对象有强引用，那垃圾回收一定不会回收。\n```\nObject o=new Object();   //  强引用\n```\n当内存空间不足，jvm宁愿抛出OOM错误，也不会回收\n\n# 三、软引用\n被软引用对象引用的实例对象，将在JVM内存不足时进行回收，可用于实现内存敏感的高速缓冲。\n```\nString str=new String(\"abc\");                                     // 强引用\nSoftReference<String> softRef=new SoftReference<String>(str);     // 软引用\n\n```\n软引用和弱引用直接的区别，软引用只有当内存不足时才会去回收；而弱引用会在GC时回收\n\n# 四、虚引用\n顾名思义，形同虚设。如果一个对象仅仅被虚引用对象引用，那该对象随时可以被回收。\n虚引用主要用来跟踪对象被垃圾回收的整个过程活动，虚引用必须和引用队列（ReferenceQueue）联合使用，\n但是它被回收之前，会被放入ReferenceQueue中。注意哦，其它引用是被JVM回收后才被传入ReferenceQueue中的\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"2020-04-13-强弱软虚","published":1,"updated":"2024-12-09T03:22:02.545Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnx1002da13kfpucpy67","content":"<h1 id=\"一、弱引用\"><a href=\"#一、弱引用\" class=\"headerlink\" title=\"一、弱引用\"></a>一、弱引用</h1><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WeakReference</span>&lt;<span class=\"title\">T</span>&gt; <span class=\"keyword\">extends</span> <span class=\"title\">Reference</span>&lt;<span class=\"title\">T</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">WeakReference</span><span class=\"params\">(T referent)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(referent);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">WeakReference</span><span class=\"params\">(T referent, ReferenceQueue&lt;? <span class=\"keyword\">super</span> T&gt; q)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(referent, q);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>WeakReference(T referent)：referent对象，被弱引用对象指向，会在下一次GC时将referent对象回收，此时WeakReference.get()会返回null。</li>\n<li>WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q)：当referent对象回收后，会将指向referent的弱引用对象放入队列中。</li>\n</ul>\n<a id=\"more\"></a>\n\n<p>使用：<br>定义普通类</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Apple</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String name;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>定义弱引用类</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SaladReference</span> <span class=\"keyword\">extends</span> <span class=\"title\">WeakReference</span>&lt;<span class=\"title\">Apple</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Salad</span><span class=\"params\">(Apple apple)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(apple);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>SaladReference弱引用对象，将指向Apple对象。</li>\n</ul>\n<p>使用</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Client</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Salad salad = <span class=\"keyword\">new</span> Salad(<span class=\"keyword\">new</span> Apple(<span class=\"string\">\"红富士\"</span>));</span><br><span class=\"line\">        <span class=\"comment\">//通过WeakReference的get()方法获取Apple</span></span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Apple:\"</span> + salad.get());</span><br><span class=\"line\">        System.gc();</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">//休眠一下，在运行的时候加上虚拟机参数-XX:+PrintGCDetails，输出gc信息，确定gc发生了。</span></span><br><span class=\"line\">            Thread.sleep(<span class=\"number\">5000</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//如果为空，代表被回收了</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (salad.get() == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"clear Apple。\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>输出结果：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Apple:Apple&#123;name=&apos;红富士&apos;&#125;, hashCode:1846274136</span><br><span class=\"line\">[GC (System.gc()) [PSYoungGen: 3328K-&gt;496K(38400K)] 3328K-&gt;504K(125952K), 0.0035102 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] </span><br><span class=\"line\">[Full GC (System.gc()) [PSYoungGen: 496K-&gt;0K(38400K)] [ParOldGen: 8K-&gt;359K(87552K)] 504K-&gt;359K(125952K), [Metaspace: 2877K-&gt;2877K(1056768K)], 0.0067965 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] </span><br><span class=\"line\">Apple： 红富士 finalize。</span><br><span class=\"line\">clear Apple。</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h1 id=\"二、强引用\"><a href=\"#二、强引用\" class=\"headerlink\" title=\"二、强引用\"></a>二、强引用</h1><p>如果一个对象有强引用，那垃圾回收一定不会回收。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Object o=new Object();   //  强引用</span><br></pre></td></tr></table></figure>\n\n<p>当内存空间不足，jvm宁愿抛出OOM错误，也不会回收</p>\n<h1 id=\"三、软引用\"><a href=\"#三、软引用\" class=\"headerlink\" title=\"三、软引用\"></a>三、软引用</h1><p>被软引用对象引用的实例对象，将在JVM内存不足时进行回收，可用于实现内存敏感的高速缓冲。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String str=new String(&quot;abc&quot;);                                     // 强引用</span><br><span class=\"line\">SoftReference&lt;String&gt; softRef=new SoftReference&lt;String&gt;(str);     // 软引用</span><br></pre></td></tr></table></figure>\n\n<p>软引用和弱引用直接的区别，软引用只有当内存不足时才会去回收；而弱引用会在GC时回收</p>\n<h1 id=\"四、虚引用\"><a href=\"#四、虚引用\" class=\"headerlink\" title=\"四、虚引用\"></a>四、虚引用</h1><p>顾名思义，形同虚设。如果一个对象仅仅被虚引用对象引用，那该对象随时可以被回收。<br>虚引用主要用来跟踪对象被垃圾回收的整个过程活动，虚引用必须和引用队列（ReferenceQueue）联合使用，<br>但是它被回收之前，会被放入ReferenceQueue中。注意哦，其它引用是被JVM回收后才被传入ReferenceQueue中的</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、弱引用\"><a href=\"#一、弱引用\" class=\"headerlink\" title=\"一、弱引用\"></a>一、弱引用</h1><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WeakReference</span>&lt;<span class=\"title\">T</span>&gt; <span class=\"keyword\">extends</span> <span class=\"title\">Reference</span>&lt;<span class=\"title\">T</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">WeakReference</span><span class=\"params\">(T referent)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(referent);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">WeakReference</span><span class=\"params\">(T referent, ReferenceQueue&lt;? <span class=\"keyword\">super</span> T&gt; q)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(referent, q);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>WeakReference(T referent)：referent对象，被弱引用对象指向，会在下一次GC时将referent对象回收，此时WeakReference.get()会返回null。</li>\n<li>WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q)：当referent对象回收后，会将指向referent的弱引用对象放入队列中。</li>\n</ul>","more":"<p>使用：<br>定义普通类</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Apple</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String name;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>定义弱引用类</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SaladReference</span> <span class=\"keyword\">extends</span> <span class=\"title\">WeakReference</span>&lt;<span class=\"title\">Apple</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Salad</span><span class=\"params\">(Apple apple)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(apple);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>SaladReference弱引用对象，将指向Apple对象。</li>\n</ul>\n<p>使用</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Client</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Salad salad = <span class=\"keyword\">new</span> Salad(<span class=\"keyword\">new</span> Apple(<span class=\"string\">\"红富士\"</span>));</span><br><span class=\"line\">        <span class=\"comment\">//通过WeakReference的get()方法获取Apple</span></span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Apple:\"</span> + salad.get());</span><br><span class=\"line\">        System.gc();</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">//休眠一下，在运行的时候加上虚拟机参数-XX:+PrintGCDetails，输出gc信息，确定gc发生了。</span></span><br><span class=\"line\">            Thread.sleep(<span class=\"number\">5000</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//如果为空，代表被回收了</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (salad.get() == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"clear Apple。\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>输出结果：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Apple:Apple&#123;name=&apos;红富士&apos;&#125;, hashCode:1846274136</span><br><span class=\"line\">[GC (System.gc()) [PSYoungGen: 3328K-&gt;496K(38400K)] 3328K-&gt;504K(125952K), 0.0035102 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] </span><br><span class=\"line\">[Full GC (System.gc()) [PSYoungGen: 496K-&gt;0K(38400K)] [ParOldGen: 8K-&gt;359K(87552K)] 504K-&gt;359K(125952K), [Metaspace: 2877K-&gt;2877K(1056768K)], 0.0067965 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] </span><br><span class=\"line\">Apple： 红富士 finalize。</span><br><span class=\"line\">clear Apple。</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<h1 id=\"二、强引用\"><a href=\"#二、强引用\" class=\"headerlink\" title=\"二、强引用\"></a>二、强引用</h1><p>如果一个对象有强引用，那垃圾回收一定不会回收。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Object o=new Object();   //  强引用</span><br></pre></td></tr></table></figure>\n\n<p>当内存空间不足，jvm宁愿抛出OOM错误，也不会回收</p>\n<h1 id=\"三、软引用\"><a href=\"#三、软引用\" class=\"headerlink\" title=\"三、软引用\"></a>三、软引用</h1><p>被软引用对象引用的实例对象，将在JVM内存不足时进行回收，可用于实现内存敏感的高速缓冲。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String str=new String(&quot;abc&quot;);                                     // 强引用</span><br><span class=\"line\">SoftReference&lt;String&gt; softRef=new SoftReference&lt;String&gt;(str);     // 软引用</span><br></pre></td></tr></table></figure>\n\n<p>软引用和弱引用直接的区别，软引用只有当内存不足时才会去回收；而弱引用会在GC时回收</p>\n<h1 id=\"四、虚引用\"><a href=\"#四、虚引用\" class=\"headerlink\" title=\"四、虚引用\"></a>四、虚引用</h1><p>顾名思义，形同虚设。如果一个对象仅仅被虚引用对象引用，那该对象随时可以被回收。<br>虚引用主要用来跟踪对象被垃圾回收的整个过程活动，虚引用必须和引用队列（ReferenceQueue）联合使用，<br>但是它被回收之前，会被放入ReferenceQueue中。注意哦，其它引用是被JVM回收后才被传入ReferenceQueue中的</p>"},{"title":"线程池","date":"2020-04-12T13:07:15.000Z","_content":"* 面试问题1：Java的线程池说一下，各个参数的作用，如何进行的?\n* 面试问题2：按线程池内部机制，当提交新任务时，有哪些异常要考虑。\n* 面试问题3：线程池都有哪几种工作队列？\n* 面试问题4：使用无界队列的线程池会导致内存飙升吗？\n* 面试问题5：说说几种常见的线程池及使用场景?\n\n# 一、常见的创建线程池方式有以下几种：\n1. Executors.newCachedThreadPool()：无限线程池。\n2. Executors.newFixedThreadPool(nThreads)：创建固定大小的线程池。\n3. Executors.newSingleThreadExecutor()：创建单个线程的线程池。\n\n<!--more-->  \n\n# 二、具体实现\n```\npublic static ExecutorService newCachedThreadPool() {\n    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                  60L, TimeUnit.SECONDS,\n                                  new SynchronousQueue<Runnable>());\n}\n```\n底层实现，都是采用了ThreadPoolExecutor对象进行线程池的实例化。\n\n```\nThreadPoolExecutor(\n    int corePoolSize, \n    int maximumPoolSize, \n    long keepAliveTime, \n    TimeUnit unit, \n    BlockingQueue<Runnable> workQueue, \n    RejectedExecutionHandler handler) \n```\n\n这几个核心参数的作用：\n* corePoolSize 为线程池的基本大小。\n* maximumPoolSize 为线程池最大线程大小。\n* keepAliveTime 和 unit 则是线程空闲后的存活时间。\n* workQueue 用于存放任务的阻塞队列。\n* handler 当队列和最大线程池都满了之后的饱和策略。\n\n\n# 三、线程池执行流程\n![线程池](2020-04-12-线程池/线程池.png)\n\n# 四、四种拒绝策略\n\n1. AbortPolicy(抛出一个异常，默认的)\n2. DiscardPolicy(直接丢弃任务)\n3. DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池）\n4. CallerRunsPolicy（交给调用线程池的线程进行处理)\n\n\n# 五、线程池的工作队列\n\n* ArrayBlockingQueue：（有界队列）用数组实现的有界阻塞队列，按FIFO排序量。\n* LinkedBlockingQueue：（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序量，不设置容量则是无界的，吞吐量大于ArrayBlockingQueue\n* DelayQueue：（延迟队列）\n* PriorityBlockingQueue：（优先级队列）（小根堆）\n* SynchronousQueue：（同步队列）\n    * 内部使用CAS操作：特别之处在于它内部没有容器，一个生产线程，当它生产产品（即put的时候），如果当前没有人想要消费产品(即当前没有线程执行take)，此生产线程必须阻塞，等待一个消费线程调用take操作，take操作将会唤醒该生产线程，同时消费线程会获取生产线程的产品（即数据传递），这样的一个过程称为一次配对过程(当然也可以先take后put,原理是一样的)\n\n# 六、几种常见的线程池\n* newFixedThreadPool (固定数目线程的线程池)：采用无界队列，可能导致内存飙升及OOM，适用于执行长期的任务\n* newCachedThreadPool(可缓存线程的线程池)\n* newSingleThreadExecutor(单线程的线程池)\n* newScheduledThreadPool(定时及周期执行的线程池)\n\n```\nnewFixedThreadPool\npublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) { \n    return new ThreadPoolExecutor(nThreads, \n                                    nThreads, \n                                    0L, \n                                    TimeUnit.MILLISECONDS, \n                                    new LinkedBlockingQueue<Runnable>(), threadFactory); \n}\n```\n1、采用无界队列，任务的执行时间比较长(比如设置了10秒)，会导致队列的任务越积越多，\n    导致机器内存使用不停飙升， 最终导致OOM。\n\n```\nnewCachedThreadPool\npublic static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) { \n    return new ThreadPoolExecutor(0, \n                                Integer.MAX_VALUE, \n                                60L, \n                                TimeUnit.SECONDS, \n                                new SynchronousQueue<Runnable>(), \n                                threadFactory); \n}\n```\n1、线程个数无界\n\n```\nnewSingleThreadExecutor\npublic static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) { return new FinalizableDelegatedExecutorService (\n    new ThreadPoolExecutor(1, \n                            1, \n                            0L, \n                            TimeUnit.MILLISECONDS, \n                            new LinkedBlockingQueue<Runnable>(), \n                            threadFactory)); \n}\n```\n1、核心线程数=1\n2、最大线程数=1\n3、适用于串行执行任务的场景，一个任务一个任务地执行\n\n```\nnewScheduledThreadPool\npublic ScheduledThreadPoolExecutor(int corePoolSize) { \n    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); \n}\n```\n\n# 七、线程池状态\n![线程池状态](2020-04-12-线程池/线程池状态.png)\n1. RUNNING：运行状态，能够接收新任务，并处理已添加的任务。\n2. SHUTDOWN：不接收新任务，但是已有任务继续执行。\n3. STOP：不接收新任务，不处理已添加的任务，并会中断正在执行的任务。\n4. TIDYING：最终做到队列中的任务为空。\n5. TERMINATED：终止状态。\n\n# 八、execute()和submit()方法的区别\n1. execute()：提交不需要返回结果的任务。\n2. submit()：提交需要返回结果的任务。\n\n\n# 九、细讲ScheduledThreadPoolExecutor使用与实现\n\n## 9.1、实际开发当中，经常会遇到计划任务类的需求：\n* 订单15分钟内未支付自动关闭\n* 每隔1个小时对前1小时内的支付账单做对账检查\n* 每日凌晨2点对前一日的订单数据汇总处理\n\n## 9.2、提供4个调度方法：\n* schedule(Runnable command, long delay, TimeUnit unit)\n    * 延迟特定时间后执行指定任务，无返回结果 \n* schedule(Callable<V> callable, long delay, TimeUnit unit)\n    * 延迟特定时间后执行指定任务，有返回结果\n* scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)\n    * 延迟初始时间后执行指定任务，之后周期性执行指定任务\n* scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)\n    * 延迟初始时间后执行指定任务，之后按固定时间间隔执行任务\n\n\n![线程池状态](2020-04-12-线程池/定时任务.png)\n## 9.3、数据结构\n![线程池状态](2020-04-12-线程池/定时任务-数据结构.png)\n\nDelayedWorkQueue结构\n![线程池状态](2020-04-12-线程池/DelayedWorkQueue.png)\n\n# 10、线程池的动态扩容\n1. TheadPoolExecute.setCorePoolSize(newSize)\n    1. 若新值 > 旧值，则会创建线程去消费队列\n    2. 若新值 < 旧值，则会在线程执行完成空闲(idle)时，进行线程回收","source":"_posts/2020-04-12-线程池.md","raw":"---\ntitle: 线程池\ndate: 2020-04-12 21:07:15\ntags: jvm ThreadPoll\ncategories:\n  - [java, 线程池]\n---\n* 面试问题1：Java的线程池说一下，各个参数的作用，如何进行的?\n* 面试问题2：按线程池内部机制，当提交新任务时，有哪些异常要考虑。\n* 面试问题3：线程池都有哪几种工作队列？\n* 面试问题4：使用无界队列的线程池会导致内存飙升吗？\n* 面试问题5：说说几种常见的线程池及使用场景?\n\n# 一、常见的创建线程池方式有以下几种：\n1. Executors.newCachedThreadPool()：无限线程池。\n2. Executors.newFixedThreadPool(nThreads)：创建固定大小的线程池。\n3. Executors.newSingleThreadExecutor()：创建单个线程的线程池。\n\n<!--more-->  \n\n# 二、具体实现\n```\npublic static ExecutorService newCachedThreadPool() {\n    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                  60L, TimeUnit.SECONDS,\n                                  new SynchronousQueue<Runnable>());\n}\n```\n底层实现，都是采用了ThreadPoolExecutor对象进行线程池的实例化。\n\n```\nThreadPoolExecutor(\n    int corePoolSize, \n    int maximumPoolSize, \n    long keepAliveTime, \n    TimeUnit unit, \n    BlockingQueue<Runnable> workQueue, \n    RejectedExecutionHandler handler) \n```\n\n这几个核心参数的作用：\n* corePoolSize 为线程池的基本大小。\n* maximumPoolSize 为线程池最大线程大小。\n* keepAliveTime 和 unit 则是线程空闲后的存活时间。\n* workQueue 用于存放任务的阻塞队列。\n* handler 当队列和最大线程池都满了之后的饱和策略。\n\n\n# 三、线程池执行流程\n![线程池](2020-04-12-线程池/线程池.png)\n\n# 四、四种拒绝策略\n\n1. AbortPolicy(抛出一个异常，默认的)\n2. DiscardPolicy(直接丢弃任务)\n3. DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池）\n4. CallerRunsPolicy（交给调用线程池的线程进行处理)\n\n\n# 五、线程池的工作队列\n\n* ArrayBlockingQueue：（有界队列）用数组实现的有界阻塞队列，按FIFO排序量。\n* LinkedBlockingQueue：（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序量，不设置容量则是无界的，吞吐量大于ArrayBlockingQueue\n* DelayQueue：（延迟队列）\n* PriorityBlockingQueue：（优先级队列）（小根堆）\n* SynchronousQueue：（同步队列）\n    * 内部使用CAS操作：特别之处在于它内部没有容器，一个生产线程，当它生产产品（即put的时候），如果当前没有人想要消费产品(即当前没有线程执行take)，此生产线程必须阻塞，等待一个消费线程调用take操作，take操作将会唤醒该生产线程，同时消费线程会获取生产线程的产品（即数据传递），这样的一个过程称为一次配对过程(当然也可以先take后put,原理是一样的)\n\n# 六、几种常见的线程池\n* newFixedThreadPool (固定数目线程的线程池)：采用无界队列，可能导致内存飙升及OOM，适用于执行长期的任务\n* newCachedThreadPool(可缓存线程的线程池)\n* newSingleThreadExecutor(单线程的线程池)\n* newScheduledThreadPool(定时及周期执行的线程池)\n\n```\nnewFixedThreadPool\npublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) { \n    return new ThreadPoolExecutor(nThreads, \n                                    nThreads, \n                                    0L, \n                                    TimeUnit.MILLISECONDS, \n                                    new LinkedBlockingQueue<Runnable>(), threadFactory); \n}\n```\n1、采用无界队列，任务的执行时间比较长(比如设置了10秒)，会导致队列的任务越积越多，\n    导致机器内存使用不停飙升， 最终导致OOM。\n\n```\nnewCachedThreadPool\npublic static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) { \n    return new ThreadPoolExecutor(0, \n                                Integer.MAX_VALUE, \n                                60L, \n                                TimeUnit.SECONDS, \n                                new SynchronousQueue<Runnable>(), \n                                threadFactory); \n}\n```\n1、线程个数无界\n\n```\nnewSingleThreadExecutor\npublic static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) { return new FinalizableDelegatedExecutorService (\n    new ThreadPoolExecutor(1, \n                            1, \n                            0L, \n                            TimeUnit.MILLISECONDS, \n                            new LinkedBlockingQueue<Runnable>(), \n                            threadFactory)); \n}\n```\n1、核心线程数=1\n2、最大线程数=1\n3、适用于串行执行任务的场景，一个任务一个任务地执行\n\n```\nnewScheduledThreadPool\npublic ScheduledThreadPoolExecutor(int corePoolSize) { \n    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); \n}\n```\n\n# 七、线程池状态\n![线程池状态](2020-04-12-线程池/线程池状态.png)\n1. RUNNING：运行状态，能够接收新任务，并处理已添加的任务。\n2. SHUTDOWN：不接收新任务，但是已有任务继续执行。\n3. STOP：不接收新任务，不处理已添加的任务，并会中断正在执行的任务。\n4. TIDYING：最终做到队列中的任务为空。\n5. TERMINATED：终止状态。\n\n# 八、execute()和submit()方法的区别\n1. execute()：提交不需要返回结果的任务。\n2. submit()：提交需要返回结果的任务。\n\n\n# 九、细讲ScheduledThreadPoolExecutor使用与实现\n\n## 9.1、实际开发当中，经常会遇到计划任务类的需求：\n* 订单15分钟内未支付自动关闭\n* 每隔1个小时对前1小时内的支付账单做对账检查\n* 每日凌晨2点对前一日的订单数据汇总处理\n\n## 9.2、提供4个调度方法：\n* schedule(Runnable command, long delay, TimeUnit unit)\n    * 延迟特定时间后执行指定任务，无返回结果 \n* schedule(Callable<V> callable, long delay, TimeUnit unit)\n    * 延迟特定时间后执行指定任务，有返回结果\n* scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)\n    * 延迟初始时间后执行指定任务，之后周期性执行指定任务\n* scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)\n    * 延迟初始时间后执行指定任务，之后按固定时间间隔执行任务\n\n\n![线程池状态](2020-04-12-线程池/定时任务.png)\n## 9.3、数据结构\n![线程池状态](2020-04-12-线程池/定时任务-数据结构.png)\n\nDelayedWorkQueue结构\n![线程池状态](2020-04-12-线程池/DelayedWorkQueue.png)\n\n# 10、线程池的动态扩容\n1. TheadPoolExecute.setCorePoolSize(newSize)\n    1. 若新值 > 旧值，则会创建线程去消费队列\n    2. 若新值 < 旧值，则会在线程执行完成空闲(idle)时，进行线程回收","slug":"2020-04-12-线程池","published":1,"updated":"2024-12-09T03:22:02.665Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnx3002fa13k1dzolbyj","content":"<ul>\n<li>面试问题1：Java的线程池说一下，各个参数的作用，如何进行的?</li>\n<li>面试问题2：按线程池内部机制，当提交新任务时，有哪些异常要考虑。</li>\n<li>面试问题3：线程池都有哪几种工作队列？</li>\n<li>面试问题4：使用无界队列的线程池会导致内存飙升吗？</li>\n<li>面试问题5：说说几种常见的线程池及使用场景?</li>\n</ul>\n<h1 id=\"一、常见的创建线程池方式有以下几种：\"><a href=\"#一、常见的创建线程池方式有以下几种：\" class=\"headerlink\" title=\"一、常见的创建线程池方式有以下几种：\"></a>一、常见的创建线程池方式有以下几种：</h1><ol>\n<li>Executors.newCachedThreadPool()：无限线程池。</li>\n<li>Executors.newFixedThreadPool(nThreads)：创建固定大小的线程池。</li>\n<li>Executors.newSingleThreadExecutor()：创建单个线程的线程池。</li>\n</ol>\n<a id=\"more\"></a>  \n\n<h1 id=\"二、具体实现\"><a href=\"#二、具体实现\" class=\"headerlink\" title=\"二、具体实现\"></a>二、具体实现</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static ExecutorService newCachedThreadPool() &#123;</span><br><span class=\"line\">    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,</span><br><span class=\"line\">                                  60L, TimeUnit.SECONDS,</span><br><span class=\"line\">                                  new SynchronousQueue&lt;Runnable&gt;());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>底层实现，都是采用了ThreadPoolExecutor对象进行线程池的实例化。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ThreadPoolExecutor(</span><br><span class=\"line\">    int corePoolSize, </span><br><span class=\"line\">    int maximumPoolSize, </span><br><span class=\"line\">    long keepAliveTime, </span><br><span class=\"line\">    TimeUnit unit, </span><br><span class=\"line\">    BlockingQueue&lt;Runnable&gt; workQueue, </span><br><span class=\"line\">    RejectedExecutionHandler handler)</span><br></pre></td></tr></table></figure>\n\n<p>这几个核心参数的作用：</p>\n<ul>\n<li>corePoolSize 为线程池的基本大小。</li>\n<li>maximumPoolSize 为线程池最大线程大小。</li>\n<li>keepAliveTime 和 unit 则是线程空闲后的存活时间。</li>\n<li>workQueue 用于存放任务的阻塞队列。</li>\n<li>handler 当队列和最大线程池都满了之后的饱和策略。</li>\n</ul>\n<h1 id=\"三、线程池执行流程\"><a href=\"#三、线程池执行流程\" class=\"headerlink\" title=\"三、线程池执行流程\"></a>三、线程池执行流程</h1><p><img src=\"/2020/04/12/2020-04-12-线程池/%E7%BA%BF%E7%A8%8B%E6%B1%A0.png\" alt=\"线程池\"></p>\n<h1 id=\"四、四种拒绝策略\"><a href=\"#四、四种拒绝策略\" class=\"headerlink\" title=\"四、四种拒绝策略\"></a>四、四种拒绝策略</h1><ol>\n<li>AbortPolicy(抛出一个异常，默认的)</li>\n<li>DiscardPolicy(直接丢弃任务)</li>\n<li>DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池）</li>\n<li>CallerRunsPolicy（交给调用线程池的线程进行处理)</li>\n</ol>\n<h1 id=\"五、线程池的工作队列\"><a href=\"#五、线程池的工作队列\" class=\"headerlink\" title=\"五、线程池的工作队列\"></a>五、线程池的工作队列</h1><ul>\n<li>ArrayBlockingQueue：（有界队列）用数组实现的有界阻塞队列，按FIFO排序量。</li>\n<li>LinkedBlockingQueue：（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序量，不设置容量则是无界的，吞吐量大于ArrayBlockingQueue</li>\n<li>DelayQueue：（延迟队列）</li>\n<li>PriorityBlockingQueue：（优先级队列）（小根堆）</li>\n<li>SynchronousQueue：（同步队列）<ul>\n<li>内部使用CAS操作：特别之处在于它内部没有容器，一个生产线程，当它生产产品（即put的时候），如果当前没有人想要消费产品(即当前没有线程执行take)，此生产线程必须阻塞，等待一个消费线程调用take操作，take操作将会唤醒该生产线程，同时消费线程会获取生产线程的产品（即数据传递），这样的一个过程称为一次配对过程(当然也可以先take后put,原理是一样的)</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"六、几种常见的线程池\"><a href=\"#六、几种常见的线程池\" class=\"headerlink\" title=\"六、几种常见的线程池\"></a>六、几种常见的线程池</h1><ul>\n<li>newFixedThreadPool (固定数目线程的线程池)：采用无界队列，可能导致内存飙升及OOM，适用于执行长期的任务</li>\n<li>newCachedThreadPool(可缓存线程的线程池)</li>\n<li>newSingleThreadExecutor(单线程的线程池)</li>\n<li>newScheduledThreadPool(定时及周期执行的线程池)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">newFixedThreadPool</span><br><span class=\"line\">public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; </span><br><span class=\"line\">    return new ThreadPoolExecutor(nThreads, </span><br><span class=\"line\">                                    nThreads, </span><br><span class=\"line\">                                    0L, </span><br><span class=\"line\">                                    TimeUnit.MILLISECONDS, </span><br><span class=\"line\">                                    new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1、采用无界队列，任务的执行时间比较长(比如设置了10秒)，会导致队列的任务越积越多，<br>    导致机器内存使用不停飙升， 最终导致OOM。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">newCachedThreadPool</span><br><span class=\"line\">public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; </span><br><span class=\"line\">    return new ThreadPoolExecutor(0, </span><br><span class=\"line\">                                Integer.MAX_VALUE, </span><br><span class=\"line\">                                60L, </span><br><span class=\"line\">                                TimeUnit.SECONDS, </span><br><span class=\"line\">                                new SynchronousQueue&lt;Runnable&gt;(), </span><br><span class=\"line\">                                threadFactory); </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1、线程个数无界</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">newSingleThreadExecutor</span><br><span class=\"line\">public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (</span><br><span class=\"line\">    new ThreadPoolExecutor(1, </span><br><span class=\"line\">                            1, </span><br><span class=\"line\">                            0L, </span><br><span class=\"line\">                            TimeUnit.MILLISECONDS, </span><br><span class=\"line\">                            new LinkedBlockingQueue&lt;Runnable&gt;(), </span><br><span class=\"line\">                            threadFactory)); </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1、核心线程数=1<br>2、最大线程数=1<br>3、适用于串行执行任务的场景，一个任务一个任务地执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">newScheduledThreadPool</span><br><span class=\"line\">public ScheduledThreadPoolExecutor(int corePoolSize) &#123; </span><br><span class=\"line\">    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"七、线程池状态\"><a href=\"#七、线程池状态\" class=\"headerlink\" title=\"七、线程池状态\"></a>七、线程池状态</h1><p><img src=\"/2020/04/12/2020-04-12-线程池/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%8A%B6%E6%80%81.png\" alt=\"线程池状态\"></p>\n<ol>\n<li>RUNNING：运行状态，能够接收新任务，并处理已添加的任务。</li>\n<li>SHUTDOWN：不接收新任务，但是已有任务继续执行。</li>\n<li>STOP：不接收新任务，不处理已添加的任务，并会中断正在执行的任务。</li>\n<li>TIDYING：最终做到队列中的任务为空。</li>\n<li>TERMINATED：终止状态。</li>\n</ol>\n<h1 id=\"八、execute-和submit-方法的区别\"><a href=\"#八、execute-和submit-方法的区别\" class=\"headerlink\" title=\"八、execute()和submit()方法的区别\"></a>八、execute()和submit()方法的区别</h1><ol>\n<li>execute()：提交不需要返回结果的任务。</li>\n<li>submit()：提交需要返回结果的任务。</li>\n</ol>\n<h1 id=\"九、细讲ScheduledThreadPoolExecutor使用与实现\"><a href=\"#九、细讲ScheduledThreadPoolExecutor使用与实现\" class=\"headerlink\" title=\"九、细讲ScheduledThreadPoolExecutor使用与实现\"></a>九、细讲ScheduledThreadPoolExecutor使用与实现</h1><h2 id=\"9-1、实际开发当中，经常会遇到计划任务类的需求：\"><a href=\"#9-1、实际开发当中，经常会遇到计划任务类的需求：\" class=\"headerlink\" title=\"9.1、实际开发当中，经常会遇到计划任务类的需求：\"></a>9.1、实际开发当中，经常会遇到计划任务类的需求：</h2><ul>\n<li>订单15分钟内未支付自动关闭</li>\n<li>每隔1个小时对前1小时内的支付账单做对账检查</li>\n<li>每日凌晨2点对前一日的订单数据汇总处理</li>\n</ul>\n<h2 id=\"9-2、提供4个调度方法：\"><a href=\"#9-2、提供4个调度方法：\" class=\"headerlink\" title=\"9.2、提供4个调度方法：\"></a>9.2、提供4个调度方法：</h2><ul>\n<li>schedule(Runnable command, long delay, TimeUnit unit)<ul>\n<li>延迟特定时间后执行指定任务，无返回结果 </li>\n</ul>\n</li>\n<li>schedule(Callable<v> callable, long delay, TimeUnit unit)<ul>\n<li>延迟特定时间后执行指定任务，有返回结果</li>\n</ul>\n</v></li>\n<li>scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)<ul>\n<li>延迟初始时间后执行指定任务，之后周期性执行指定任务</li>\n</ul>\n</li>\n<li>scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)<ul>\n<li>延迟初始时间后执行指定任务，之后按固定时间间隔执行任务</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/04/12/2020-04-12-线程池/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.png\" alt=\"线程池状态\"></p>\n<h2 id=\"9-3、数据结构\"><a href=\"#9-3、数据结构\" class=\"headerlink\" title=\"9.3、数据结构\"></a>9.3、数据结构</h2><p><img src=\"/2020/04/12/2020-04-12-线程池/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png\" alt=\"线程池状态\"></p>\n<p>DelayedWorkQueue结构<br><img src=\"/2020/04/12/2020-04-12-线程池/DelayedWorkQueue.png\" alt=\"线程池状态\"></p>\n<h1 id=\"10、线程池的动态扩容\"><a href=\"#10、线程池的动态扩容\" class=\"headerlink\" title=\"10、线程池的动态扩容\"></a>10、线程池的动态扩容</h1><ol>\n<li>TheadPoolExecute.setCorePoolSize(newSize)<ol>\n<li>若新值 &gt; 旧值，则会创建线程去消费队列</li>\n<li>若新值 &lt; 旧值，则会在线程执行完成空闲(idle)时，进行线程回收</li>\n</ol>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<ul>\n<li>面试问题1：Java的线程池说一下，各个参数的作用，如何进行的?</li>\n<li>面试问题2：按线程池内部机制，当提交新任务时，有哪些异常要考虑。</li>\n<li>面试问题3：线程池都有哪几种工作队列？</li>\n<li>面试问题4：使用无界队列的线程池会导致内存飙升吗？</li>\n<li>面试问题5：说说几种常见的线程池及使用场景?</li>\n</ul>\n<h1 id=\"一、常见的创建线程池方式有以下几种：\"><a href=\"#一、常见的创建线程池方式有以下几种：\" class=\"headerlink\" title=\"一、常见的创建线程池方式有以下几种：\"></a>一、常见的创建线程池方式有以下几种：</h1><ol>\n<li>Executors.newCachedThreadPool()：无限线程池。</li>\n<li>Executors.newFixedThreadPool(nThreads)：创建固定大小的线程池。</li>\n<li>Executors.newSingleThreadExecutor()：创建单个线程的线程池。</li>\n</ol>","more":"<h1 id=\"二、具体实现\"><a href=\"#二、具体实现\" class=\"headerlink\" title=\"二、具体实现\"></a>二、具体实现</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static ExecutorService newCachedThreadPool() &#123;</span><br><span class=\"line\">    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,</span><br><span class=\"line\">                                  60L, TimeUnit.SECONDS,</span><br><span class=\"line\">                                  new SynchronousQueue&lt;Runnable&gt;());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>底层实现，都是采用了ThreadPoolExecutor对象进行线程池的实例化。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ThreadPoolExecutor(</span><br><span class=\"line\">    int corePoolSize, </span><br><span class=\"line\">    int maximumPoolSize, </span><br><span class=\"line\">    long keepAliveTime, </span><br><span class=\"line\">    TimeUnit unit, </span><br><span class=\"line\">    BlockingQueue&lt;Runnable&gt; workQueue, </span><br><span class=\"line\">    RejectedExecutionHandler handler)</span><br></pre></td></tr></table></figure>\n\n<p>这几个核心参数的作用：</p>\n<ul>\n<li>corePoolSize 为线程池的基本大小。</li>\n<li>maximumPoolSize 为线程池最大线程大小。</li>\n<li>keepAliveTime 和 unit 则是线程空闲后的存活时间。</li>\n<li>workQueue 用于存放任务的阻塞队列。</li>\n<li>handler 当队列和最大线程池都满了之后的饱和策略。</li>\n</ul>\n<h1 id=\"三、线程池执行流程\"><a href=\"#三、线程池执行流程\" class=\"headerlink\" title=\"三、线程池执行流程\"></a>三、线程池执行流程</h1><p><img src=\"/2020/04/12/2020-04-12-线程池/%E7%BA%BF%E7%A8%8B%E6%B1%A0.png\" alt=\"线程池\"></p>\n<h1 id=\"四、四种拒绝策略\"><a href=\"#四、四种拒绝策略\" class=\"headerlink\" title=\"四、四种拒绝策略\"></a>四、四种拒绝策略</h1><ol>\n<li>AbortPolicy(抛出一个异常，默认的)</li>\n<li>DiscardPolicy(直接丢弃任务)</li>\n<li>DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池）</li>\n<li>CallerRunsPolicy（交给调用线程池的线程进行处理)</li>\n</ol>\n<h1 id=\"五、线程池的工作队列\"><a href=\"#五、线程池的工作队列\" class=\"headerlink\" title=\"五、线程池的工作队列\"></a>五、线程池的工作队列</h1><ul>\n<li>ArrayBlockingQueue：（有界队列）用数组实现的有界阻塞队列，按FIFO排序量。</li>\n<li>LinkedBlockingQueue：（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序量，不设置容量则是无界的，吞吐量大于ArrayBlockingQueue</li>\n<li>DelayQueue：（延迟队列）</li>\n<li>PriorityBlockingQueue：（优先级队列）（小根堆）</li>\n<li>SynchronousQueue：（同步队列）<ul>\n<li>内部使用CAS操作：特别之处在于它内部没有容器，一个生产线程，当它生产产品（即put的时候），如果当前没有人想要消费产品(即当前没有线程执行take)，此生产线程必须阻塞，等待一个消费线程调用take操作，take操作将会唤醒该生产线程，同时消费线程会获取生产线程的产品（即数据传递），这样的一个过程称为一次配对过程(当然也可以先take后put,原理是一样的)</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"六、几种常见的线程池\"><a href=\"#六、几种常见的线程池\" class=\"headerlink\" title=\"六、几种常见的线程池\"></a>六、几种常见的线程池</h1><ul>\n<li>newFixedThreadPool (固定数目线程的线程池)：采用无界队列，可能导致内存飙升及OOM，适用于执行长期的任务</li>\n<li>newCachedThreadPool(可缓存线程的线程池)</li>\n<li>newSingleThreadExecutor(单线程的线程池)</li>\n<li>newScheduledThreadPool(定时及周期执行的线程池)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">newFixedThreadPool</span><br><span class=\"line\">public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; </span><br><span class=\"line\">    return new ThreadPoolExecutor(nThreads, </span><br><span class=\"line\">                                    nThreads, </span><br><span class=\"line\">                                    0L, </span><br><span class=\"line\">                                    TimeUnit.MILLISECONDS, </span><br><span class=\"line\">                                    new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1、采用无界队列，任务的执行时间比较长(比如设置了10秒)，会导致队列的任务越积越多，<br>    导致机器内存使用不停飙升， 最终导致OOM。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">newCachedThreadPool</span><br><span class=\"line\">public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; </span><br><span class=\"line\">    return new ThreadPoolExecutor(0, </span><br><span class=\"line\">                                Integer.MAX_VALUE, </span><br><span class=\"line\">                                60L, </span><br><span class=\"line\">                                TimeUnit.SECONDS, </span><br><span class=\"line\">                                new SynchronousQueue&lt;Runnable&gt;(), </span><br><span class=\"line\">                                threadFactory); </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1、线程个数无界</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">newSingleThreadExecutor</span><br><span class=\"line\">public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (</span><br><span class=\"line\">    new ThreadPoolExecutor(1, </span><br><span class=\"line\">                            1, </span><br><span class=\"line\">                            0L, </span><br><span class=\"line\">                            TimeUnit.MILLISECONDS, </span><br><span class=\"line\">                            new LinkedBlockingQueue&lt;Runnable&gt;(), </span><br><span class=\"line\">                            threadFactory)); </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>1、核心线程数=1<br>2、最大线程数=1<br>3、适用于串行执行任务的场景，一个任务一个任务地执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">newScheduledThreadPool</span><br><span class=\"line\">public ScheduledThreadPoolExecutor(int corePoolSize) &#123; </span><br><span class=\"line\">    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"七、线程池状态\"><a href=\"#七、线程池状态\" class=\"headerlink\" title=\"七、线程池状态\"></a>七、线程池状态</h1><p><img src=\"/2020/04/12/2020-04-12-线程池/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%8A%B6%E6%80%81.png\" alt=\"线程池状态\"></p>\n<ol>\n<li>RUNNING：运行状态，能够接收新任务，并处理已添加的任务。</li>\n<li>SHUTDOWN：不接收新任务，但是已有任务继续执行。</li>\n<li>STOP：不接收新任务，不处理已添加的任务，并会中断正在执行的任务。</li>\n<li>TIDYING：最终做到队列中的任务为空。</li>\n<li>TERMINATED：终止状态。</li>\n</ol>\n<h1 id=\"八、execute-和submit-方法的区别\"><a href=\"#八、execute-和submit-方法的区别\" class=\"headerlink\" title=\"八、execute()和submit()方法的区别\"></a>八、execute()和submit()方法的区别</h1><ol>\n<li>execute()：提交不需要返回结果的任务。</li>\n<li>submit()：提交需要返回结果的任务。</li>\n</ol>\n<h1 id=\"九、细讲ScheduledThreadPoolExecutor使用与实现\"><a href=\"#九、细讲ScheduledThreadPoolExecutor使用与实现\" class=\"headerlink\" title=\"九、细讲ScheduledThreadPoolExecutor使用与实现\"></a>九、细讲ScheduledThreadPoolExecutor使用与实现</h1><h2 id=\"9-1、实际开发当中，经常会遇到计划任务类的需求：\"><a href=\"#9-1、实际开发当中，经常会遇到计划任务类的需求：\" class=\"headerlink\" title=\"9.1、实际开发当中，经常会遇到计划任务类的需求：\"></a>9.1、实际开发当中，经常会遇到计划任务类的需求：</h2><ul>\n<li>订单15分钟内未支付自动关闭</li>\n<li>每隔1个小时对前1小时内的支付账单做对账检查</li>\n<li>每日凌晨2点对前一日的订单数据汇总处理</li>\n</ul>\n<h2 id=\"9-2、提供4个调度方法：\"><a href=\"#9-2、提供4个调度方法：\" class=\"headerlink\" title=\"9.2、提供4个调度方法：\"></a>9.2、提供4个调度方法：</h2><ul>\n<li>schedule(Runnable command, long delay, TimeUnit unit)<ul>\n<li>延迟特定时间后执行指定任务，无返回结果 </li>\n</ul>\n</li>\n<li>schedule(Callable<v> callable, long delay, TimeUnit unit)<ul>\n<li>延迟特定时间后执行指定任务，有返回结果</li>\n</ul>\n</v></li>\n<li>scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)<ul>\n<li>延迟初始时间后执行指定任务，之后周期性执行指定任务</li>\n</ul>\n</li>\n<li>scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)<ul>\n<li>延迟初始时间后执行指定任务，之后按固定时间间隔执行任务</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/04/12/2020-04-12-线程池/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.png\" alt=\"线程池状态\"></p>\n<h2 id=\"9-3、数据结构\"><a href=\"#9-3、数据结构\" class=\"headerlink\" title=\"9.3、数据结构\"></a>9.3、数据结构</h2><p><img src=\"/2020/04/12/2020-04-12-线程池/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png\" alt=\"线程池状态\"></p>\n<p>DelayedWorkQueue结构<br><img src=\"/2020/04/12/2020-04-12-线程池/DelayedWorkQueue.png\" alt=\"线程池状态\"></p>\n<h1 id=\"10、线程池的动态扩容\"><a href=\"#10、线程池的动态扩容\" class=\"headerlink\" title=\"10、线程池的动态扩容\"></a>10、线程池的动态扩容</h1><ol>\n<li>TheadPoolExecute.setCorePoolSize(newSize)<ol>\n<li>若新值 &gt; 旧值，则会创建线程去消费队列</li>\n<li>若新值 &lt; 旧值，则会在线程执行完成空闲(idle)时，进行线程回收</li>\n</ol>\n</li>\n</ol>"},{"title":"JMM","date":"2020-05-10T10:14:36.000Z","_content":"\n# 一、什么是虚拟机规范\n定义Java虚拟机实现的一些基本要求。\n\n# 二、虚拟机结构\n从Class文件结构、数据类型、运行时数据区等方面进行了定义，具体实现未定义。\n\n![jmm](2020-05-10-JMM/jmm.png)\n\n<!--more-->  \n\n# 三、运行时数据区\n> PC寄存器、Java虚拟机栈、Java本地方法栈、Java堆、方法区、运行时常量池\n\n## 1、PC寄存器\n线程独有，每个线程都有自己的PC寄存器，如果方法不是native的，则保存的是当前所执行字节码的地址。\n## 2、Java虚拟机栈\n线程独有，每个线程对应一个虚拟机栈，栈和线程同时创建，用于存储栈桢。    \n用于存储局部变量和过程结果的地方。   \n* 可能发生的异常：\n    * 如果线程请求的栈容量超过栈允许的最大容量，则抛出StackOverflowError异常\n    * 如果栈允许动态扩展，而此时无法获取更多内存；或者是新的线程创建无法获取内存，此时都会抛出OutOfMemoryError异常\n## 3、Java本地方法栈\n线程独有，线程创建时会创建一个对应的本地方法栈。（虚拟机可不实现本地方法栈）   \n来native方法的执行（支持除Java语音编写）。\n* 可能发生的异常：\n    * 如果线程请求的栈容量超过栈允许的最大容量，则抛出StackOverflowError异常\n    * 如果栈允许动态扩展，而此时无法获取更多内存；或者是新的线程创建无法获取内存，此时都会抛出OutOfMemoryError异常\n## 4、Java堆\n线程共享，用于存储类实例和数组对象。      \n虚拟机规范并未指定具体实现方式及内存管理，方案可自己定义（如垃圾收集，内存管理）   \n* 可能发生的异常：\n    * 如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常\n## 5、方法区\n线程共享，用于存储类的结构信息，例如运行时常量池、字段和方法数据，构造函数和普通方法的字节码数据。     \n方法区在虚拟机启动的时候被创建。虚拟机规范中定义为可垃圾回收或者是不回收。   \n* 可能发生的异常：\n    * 如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常\n### 5.1、运行时常量池\n线程共享，每一个运行时常量池都分配在方法区中。类或接口加载到内存中，就会创建运行时常量池。   \n是类或接口的常量池的运行时表现形式。   \n它包括了若干种不同的常量：从编译期可知的数值字面量到必须运行 期解析后才能获得的方法或字段引用。\n* 可能发生的异常：\n    * 如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常\n\nclass文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池\n用于存放编译期生成的各种字面量和符号引用\n    \n    字面量：文本字符串、声明为final的常量值\n    符号引用：\n        1. 类和接口的全限定名\n        2. 字段的名称和描述符\n        3. 方法的名称和描述符\n\n\nJDK7将字符串常量池、字符引用、静态变量移动到了堆中，运行时常量池还在方法区内。     \njdk8方法区的实现使用metaspace元空间代替，运行时常量池在元空间内，元空间被放在了直接内存内。     \n\n# 四、栈桢\n每一个方法执行都会创建一个栈桢，方法执行完就释放。栈桢存储在虚拟机栈上。\n* 结构：\n    * 局部变量表\n    * 操作数栈\n    * 指向类运行时常量池的引用\n* 作用：\n    * 存储数据和部分过程结果的数据结构，同时也用来处理动态链接、方法返回值和异常分派\n\n## 4.1、局部变量表\n栈桢中的一组变量列表，长度编译期间确定，并存储在类或接口的二进制表之中。\nlong和double需要两个变量来存储，其他的都只需要一个变量。\n变量表中的第0个位置存储的是调用该方法所对应实例对象的引用（this关键字，其他的参数从1位置开始）\n## 4.2、操作数栈\n栈桢中的一个后进先出的栈，长度编译期间确定，并存储在类或接口的二进制表之中。\n从局部变量表中或实例对象中获取数据，通过指令入栈出栈，计算并出栈入栈。在方法调用时，用来存储入参及返回结果。\n## 4.3、引用\n指向类运行时常量池的引用来实现动态链接。\nClass文件里边，用符号引用来描述方法调用或访问其他成员变量。\n动态链接就是为了将符号引用转换成直接引用。\n\n\n\n","source":"_posts/2020-05-10-JMM.md","raw":"---\ntitle: JMM\ndate: 2020-05-10 18:14:36\ntags: jvm JMM Java\ncategories:\n  - [java, jmm]\n---\n\n# 一、什么是虚拟机规范\n定义Java虚拟机实现的一些基本要求。\n\n# 二、虚拟机结构\n从Class文件结构、数据类型、运行时数据区等方面进行了定义，具体实现未定义。\n\n![jmm](2020-05-10-JMM/jmm.png)\n\n<!--more-->  \n\n# 三、运行时数据区\n> PC寄存器、Java虚拟机栈、Java本地方法栈、Java堆、方法区、运行时常量池\n\n## 1、PC寄存器\n线程独有，每个线程都有自己的PC寄存器，如果方法不是native的，则保存的是当前所执行字节码的地址。\n## 2、Java虚拟机栈\n线程独有，每个线程对应一个虚拟机栈，栈和线程同时创建，用于存储栈桢。    \n用于存储局部变量和过程结果的地方。   \n* 可能发生的异常：\n    * 如果线程请求的栈容量超过栈允许的最大容量，则抛出StackOverflowError异常\n    * 如果栈允许动态扩展，而此时无法获取更多内存；或者是新的线程创建无法获取内存，此时都会抛出OutOfMemoryError异常\n## 3、Java本地方法栈\n线程独有，线程创建时会创建一个对应的本地方法栈。（虚拟机可不实现本地方法栈）   \n来native方法的执行（支持除Java语音编写）。\n* 可能发生的异常：\n    * 如果线程请求的栈容量超过栈允许的最大容量，则抛出StackOverflowError异常\n    * 如果栈允许动态扩展，而此时无法获取更多内存；或者是新的线程创建无法获取内存，此时都会抛出OutOfMemoryError异常\n## 4、Java堆\n线程共享，用于存储类实例和数组对象。      \n虚拟机规范并未指定具体实现方式及内存管理，方案可自己定义（如垃圾收集，内存管理）   \n* 可能发生的异常：\n    * 如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常\n## 5、方法区\n线程共享，用于存储类的结构信息，例如运行时常量池、字段和方法数据，构造函数和普通方法的字节码数据。     \n方法区在虚拟机启动的时候被创建。虚拟机规范中定义为可垃圾回收或者是不回收。   \n* 可能发生的异常：\n    * 如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常\n### 5.1、运行时常量池\n线程共享，每一个运行时常量池都分配在方法区中。类或接口加载到内存中，就会创建运行时常量池。   \n是类或接口的常量池的运行时表现形式。   \n它包括了若干种不同的常量：从编译期可知的数值字面量到必须运行 期解析后才能获得的方法或字段引用。\n* 可能发生的异常：\n    * 如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常\n\nclass文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池\n用于存放编译期生成的各种字面量和符号引用\n    \n    字面量：文本字符串、声明为final的常量值\n    符号引用：\n        1. 类和接口的全限定名\n        2. 字段的名称和描述符\n        3. 方法的名称和描述符\n\n\nJDK7将字符串常量池、字符引用、静态变量移动到了堆中，运行时常量池还在方法区内。     \njdk8方法区的实现使用metaspace元空间代替，运行时常量池在元空间内，元空间被放在了直接内存内。     \n\n# 四、栈桢\n每一个方法执行都会创建一个栈桢，方法执行完就释放。栈桢存储在虚拟机栈上。\n* 结构：\n    * 局部变量表\n    * 操作数栈\n    * 指向类运行时常量池的引用\n* 作用：\n    * 存储数据和部分过程结果的数据结构，同时也用来处理动态链接、方法返回值和异常分派\n\n## 4.1、局部变量表\n栈桢中的一组变量列表，长度编译期间确定，并存储在类或接口的二进制表之中。\nlong和double需要两个变量来存储，其他的都只需要一个变量。\n变量表中的第0个位置存储的是调用该方法所对应实例对象的引用（this关键字，其他的参数从1位置开始）\n## 4.2、操作数栈\n栈桢中的一个后进先出的栈，长度编译期间确定，并存储在类或接口的二进制表之中。\n从局部变量表中或实例对象中获取数据，通过指令入栈出栈，计算并出栈入栈。在方法调用时，用来存储入参及返回结果。\n## 4.3、引用\n指向类运行时常量池的引用来实现动态链接。\nClass文件里边，用符号引用来描述方法调用或访问其他成员变量。\n动态链接就是为了将符号引用转换成直接引用。\n\n\n\n","slug":"2020-05-10-JMM","published":1,"updated":"2024-12-09T03:22:02.628Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnx4002ha13krmhlilge","content":"<h1 id=\"一、什么是虚拟机规范\"><a href=\"#一、什么是虚拟机规范\" class=\"headerlink\" title=\"一、什么是虚拟机规范\"></a>一、什么是虚拟机规范</h1><p>定义Java虚拟机实现的一些基本要求。</p>\n<h1 id=\"二、虚拟机结构\"><a href=\"#二、虚拟机结构\" class=\"headerlink\" title=\"二、虚拟机结构\"></a>二、虚拟机结构</h1><p>从Class文件结构、数据类型、运行时数据区等方面进行了定义，具体实现未定义。</p>\n<p><img src=\"/2020/05/10/2020-05-10-JMM/jmm.png\" alt=\"jmm\"></p>\n<a id=\"more\"></a>  \n\n<h1 id=\"三、运行时数据区\"><a href=\"#三、运行时数据区\" class=\"headerlink\" title=\"三、运行时数据区\"></a>三、运行时数据区</h1><blockquote>\n<p>PC寄存器、Java虚拟机栈、Java本地方法栈、Java堆、方法区、运行时常量池</p>\n</blockquote>\n<h2 id=\"1、PC寄存器\"><a href=\"#1、PC寄存器\" class=\"headerlink\" title=\"1、PC寄存器\"></a>1、PC寄存器</h2><p>线程独有，每个线程都有自己的PC寄存器，如果方法不是native的，则保存的是当前所执行字节码的地址。</p>\n<h2 id=\"2、Java虚拟机栈\"><a href=\"#2、Java虚拟机栈\" class=\"headerlink\" title=\"2、Java虚拟机栈\"></a>2、Java虚拟机栈</h2><p>线程独有，每个线程对应一个虚拟机栈，栈和线程同时创建，用于存储栈桢。<br>用于存储局部变量和过程结果的地方。   </p>\n<ul>\n<li>可能发生的异常：<ul>\n<li>如果线程请求的栈容量超过栈允许的最大容量，则抛出StackOverflowError异常</li>\n<li>如果栈允许动态扩展，而此时无法获取更多内存；或者是新的线程创建无法获取内存，此时都会抛出OutOfMemoryError异常<h2 id=\"3、Java本地方法栈\"><a href=\"#3、Java本地方法栈\" class=\"headerlink\" title=\"3、Java本地方法栈\"></a>3、Java本地方法栈</h2>线程独有，线程创建时会创建一个对应的本地方法栈。（虚拟机可不实现本地方法栈）<br>来native方法的执行（支持除Java语音编写）。</li>\n</ul>\n</li>\n<li>可能发生的异常：<ul>\n<li>如果线程请求的栈容量超过栈允许的最大容量，则抛出StackOverflowError异常</li>\n<li>如果栈允许动态扩展，而此时无法获取更多内存；或者是新的线程创建无法获取内存，此时都会抛出OutOfMemoryError异常<h2 id=\"4、Java堆\"><a href=\"#4、Java堆\" class=\"headerlink\" title=\"4、Java堆\"></a>4、Java堆</h2>线程共享，用于存储类实例和数组对象。<br>虚拟机规范并未指定具体实现方式及内存管理，方案可自己定义（如垃圾收集，内存管理）   </li>\n</ul>\n</li>\n<li>可能发生的异常：<ul>\n<li>如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常<h2 id=\"5、方法区\"><a href=\"#5、方法区\" class=\"headerlink\" title=\"5、方法区\"></a>5、方法区</h2>线程共享，用于存储类的结构信息，例如运行时常量池、字段和方法数据，构造函数和普通方法的字节码数据。<br>方法区在虚拟机启动的时候被创建。虚拟机规范中定义为可垃圾回收或者是不回收。   </li>\n</ul>\n</li>\n<li>可能发生的异常：<ul>\n<li>如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常<h3 id=\"5-1、运行时常量池\"><a href=\"#5-1、运行时常量池\" class=\"headerlink\" title=\"5.1、运行时常量池\"></a>5.1、运行时常量池</h3>线程共享，每一个运行时常量池都分配在方法区中。类或接口加载到内存中，就会创建运行时常量池。<br>是类或接口的常量池的运行时表现形式。<br>它包括了若干种不同的常量：从编译期可知的数值字面量到必须运行 期解析后才能获得的方法或字段引用。</li>\n</ul>\n</li>\n<li>可能发生的异常：<ul>\n<li>如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常</li>\n</ul>\n</li>\n</ul>\n<p>class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池<br>用于存放编译期生成的各种字面量和符号引用</p>\n<pre><code>字面量：文本字符串、声明为final的常量值\n符号引用：\n    1. 类和接口的全限定名\n    2. 字段的名称和描述符\n    3. 方法的名称和描述符</code></pre><p>JDK7将字符串常量池、字符引用、静态变量移动到了堆中，运行时常量池还在方法区内。<br>jdk8方法区的实现使用metaspace元空间代替，运行时常量池在元空间内，元空间被放在了直接内存内。     </p>\n<h1 id=\"四、栈桢\"><a href=\"#四、栈桢\" class=\"headerlink\" title=\"四、栈桢\"></a>四、栈桢</h1><p>每一个方法执行都会创建一个栈桢，方法执行完就释放。栈桢存储在虚拟机栈上。</p>\n<ul>\n<li>结构：<ul>\n<li>局部变量表</li>\n<li>操作数栈</li>\n<li>指向类运行时常量池的引用</li>\n</ul>\n</li>\n<li>作用：<ul>\n<li>存储数据和部分过程结果的数据结构，同时也用来处理动态链接、方法返回值和异常分派</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-1、局部变量表\"><a href=\"#4-1、局部变量表\" class=\"headerlink\" title=\"4.1、局部变量表\"></a>4.1、局部变量表</h2><p>栈桢中的一组变量列表，长度编译期间确定，并存储在类或接口的二进制表之中。<br>long和double需要两个变量来存储，其他的都只需要一个变量。<br>变量表中的第0个位置存储的是调用该方法所对应实例对象的引用（this关键字，其他的参数从1位置开始）</p>\n<h2 id=\"4-2、操作数栈\"><a href=\"#4-2、操作数栈\" class=\"headerlink\" title=\"4.2、操作数栈\"></a>4.2、操作数栈</h2><p>栈桢中的一个后进先出的栈，长度编译期间确定，并存储在类或接口的二进制表之中。<br>从局部变量表中或实例对象中获取数据，通过指令入栈出栈，计算并出栈入栈。在方法调用时，用来存储入参及返回结果。</p>\n<h2 id=\"4-3、引用\"><a href=\"#4-3、引用\" class=\"headerlink\" title=\"4.3、引用\"></a>4.3、引用</h2><p>指向类运行时常量池的引用来实现动态链接。<br>Class文件里边，用符号引用来描述方法调用或访问其他成员变量。<br>动态链接就是为了将符号引用转换成直接引用。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、什么是虚拟机规范\"><a href=\"#一、什么是虚拟机规范\" class=\"headerlink\" title=\"一、什么是虚拟机规范\"></a>一、什么是虚拟机规范</h1><p>定义Java虚拟机实现的一些基本要求。</p>\n<h1 id=\"二、虚拟机结构\"><a href=\"#二、虚拟机结构\" class=\"headerlink\" title=\"二、虚拟机结构\"></a>二、虚拟机结构</h1><p>从Class文件结构、数据类型、运行时数据区等方面进行了定义，具体实现未定义。</p>\n<p><img src=\"/2020/05/10/2020-05-10-JMM/jmm.png\" alt=\"jmm\"></p>","more":"<h1 id=\"三、运行时数据区\"><a href=\"#三、运行时数据区\" class=\"headerlink\" title=\"三、运行时数据区\"></a>三、运行时数据区</h1><blockquote>\n<p>PC寄存器、Java虚拟机栈、Java本地方法栈、Java堆、方法区、运行时常量池</p>\n</blockquote>\n<h2 id=\"1、PC寄存器\"><a href=\"#1、PC寄存器\" class=\"headerlink\" title=\"1、PC寄存器\"></a>1、PC寄存器</h2><p>线程独有，每个线程都有自己的PC寄存器，如果方法不是native的，则保存的是当前所执行字节码的地址。</p>\n<h2 id=\"2、Java虚拟机栈\"><a href=\"#2、Java虚拟机栈\" class=\"headerlink\" title=\"2、Java虚拟机栈\"></a>2、Java虚拟机栈</h2><p>线程独有，每个线程对应一个虚拟机栈，栈和线程同时创建，用于存储栈桢。<br>用于存储局部变量和过程结果的地方。   </p>\n<ul>\n<li>可能发生的异常：<ul>\n<li>如果线程请求的栈容量超过栈允许的最大容量，则抛出StackOverflowError异常</li>\n<li>如果栈允许动态扩展，而此时无法获取更多内存；或者是新的线程创建无法获取内存，此时都会抛出OutOfMemoryError异常<h2 id=\"3、Java本地方法栈\"><a href=\"#3、Java本地方法栈\" class=\"headerlink\" title=\"3、Java本地方法栈\"></a>3、Java本地方法栈</h2>线程独有，线程创建时会创建一个对应的本地方法栈。（虚拟机可不实现本地方法栈）<br>来native方法的执行（支持除Java语音编写）。</li>\n</ul>\n</li>\n<li>可能发生的异常：<ul>\n<li>如果线程请求的栈容量超过栈允许的最大容量，则抛出StackOverflowError异常</li>\n<li>如果栈允许动态扩展，而此时无法获取更多内存；或者是新的线程创建无法获取内存，此时都会抛出OutOfMemoryError异常<h2 id=\"4、Java堆\"><a href=\"#4、Java堆\" class=\"headerlink\" title=\"4、Java堆\"></a>4、Java堆</h2>线程共享，用于存储类实例和数组对象。<br>虚拟机规范并未指定具体实现方式及内存管理，方案可自己定义（如垃圾收集，内存管理）   </li>\n</ul>\n</li>\n<li>可能发生的异常：<ul>\n<li>如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常<h2 id=\"5、方法区\"><a href=\"#5、方法区\" class=\"headerlink\" title=\"5、方法区\"></a>5、方法区</h2>线程共享，用于存储类的结构信息，例如运行时常量池、字段和方法数据，构造函数和普通方法的字节码数据。<br>方法区在虚拟机启动的时候被创建。虚拟机规范中定义为可垃圾回收或者是不回收。   </li>\n</ul>\n</li>\n<li>可能发生的异常：<ul>\n<li>如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常<h3 id=\"5-1、运行时常量池\"><a href=\"#5-1、运行时常量池\" class=\"headerlink\" title=\"5.1、运行时常量池\"></a>5.1、运行时常量池</h3>线程共享，每一个运行时常量池都分配在方法区中。类或接口加载到内存中，就会创建运行时常量池。<br>是类或接口的常量池的运行时表现形式。<br>它包括了若干种不同的常量：从编译期可知的数值字面量到必须运行 期解析后才能获得的方法或字段引用。</li>\n</ul>\n</li>\n<li>可能发生的异常：<ul>\n<li>如果实际需要的容量超过堆的最大容量，则抛出OutOfMemoryError异常</li>\n</ul>\n</li>\n</ul>\n<p>class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池<br>用于存放编译期生成的各种字面量和符号引用</p>\n<pre><code>字面量：文本字符串、声明为final的常量值\n符号引用：\n    1. 类和接口的全限定名\n    2. 字段的名称和描述符\n    3. 方法的名称和描述符</code></pre><p>JDK7将字符串常量池、字符引用、静态变量移动到了堆中，运行时常量池还在方法区内。<br>jdk8方法区的实现使用metaspace元空间代替，运行时常量池在元空间内，元空间被放在了直接内存内。     </p>\n<h1 id=\"四、栈桢\"><a href=\"#四、栈桢\" class=\"headerlink\" title=\"四、栈桢\"></a>四、栈桢</h1><p>每一个方法执行都会创建一个栈桢，方法执行完就释放。栈桢存储在虚拟机栈上。</p>\n<ul>\n<li>结构：<ul>\n<li>局部变量表</li>\n<li>操作数栈</li>\n<li>指向类运行时常量池的引用</li>\n</ul>\n</li>\n<li>作用：<ul>\n<li>存储数据和部分过程结果的数据结构，同时也用来处理动态链接、方法返回值和异常分派</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"4-1、局部变量表\"><a href=\"#4-1、局部变量表\" class=\"headerlink\" title=\"4.1、局部变量表\"></a>4.1、局部变量表</h2><p>栈桢中的一组变量列表，长度编译期间确定，并存储在类或接口的二进制表之中。<br>long和double需要两个变量来存储，其他的都只需要一个变量。<br>变量表中的第0个位置存储的是调用该方法所对应实例对象的引用（this关键字，其他的参数从1位置开始）</p>\n<h2 id=\"4-2、操作数栈\"><a href=\"#4-2、操作数栈\" class=\"headerlink\" title=\"4.2、操作数栈\"></a>4.2、操作数栈</h2><p>栈桢中的一个后进先出的栈，长度编译期间确定，并存储在类或接口的二进制表之中。<br>从局部变量表中或实例对象中获取数据，通过指令入栈出栈，计算并出栈入栈。在方法调用时，用来存储入参及返回结果。</p>\n<h2 id=\"4-3、引用\"><a href=\"#4-3、引用\" class=\"headerlink\" title=\"4.3、引用\"></a>4.3、引用</h2><p>指向类运行时常量池的引用来实现动态链接。<br>Class文件里边，用符号引用来描述方法调用或访问其他成员变量。<br>动态链接就是为了将符号引用转换成直接引用。</p>"},{"title":"零拷贝","date":"2020-05-07T13:36:43.000Z","_content":"# 一、什么是零拷贝？\n减少数据的拷贝。\n\n\n# 二、前提知识\n## 1、Linux进程的虚拟空间\nLinux进程的虚拟空间，分成内核空间和用户空间，数据进入进程的过程，是从磁盘拷贝至内核，然后从内核空间拷贝至用户空间。\n![基本方式](2020-05-07-零拷贝/基本方式.png)\nread、write两个系统调用的过程，从磁盘将数据读入内核空间，然后从内核空间拷贝至用户空间，过程复杂。\n* 4次数据拷贝，速率低下。\n\n<!--more-->  \n\n## 2、DMA拷贝\nDirect Memory Access，直接内存操作。   \n传统数据的传输：使用CPU，CPU负责数据的拷贝传输。\n![基本方式](2020-05-07-零拷贝/DMA.png)\n优化数据传输：DMA，专门进行数据传输的硬件\n![基本方式](2020-05-07-零拷贝/DMA-优化.png)\n优势：解放CPU\n\n\n\n# 三、零拷贝的实现\n减少系统调用，减少态的切换。\n* mmap\n* sendfile\n* sendfile + DMA\n\n## 1、mmap\n用户空间会和内核空间行程一个映射，这样就不需要将数据从内核态拷贝至用户态，从而减少一次拷贝。    \n**映射原理：**\n* 就是在用户进程中创建变量vma和物理内存进行映射，而不需要再将数据从page cache再拷贝至用户进程空间\n![mmap](2020-05-07-零拷贝/mmp.png)\n* 4次上下文切换，3次拷贝。\n## 2、sendfile\n```\ninclude <sys/socket.h>\nssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);\n```\n\n它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。\n它可以替代前面的**read()**和**write()**这两个系统调用，这样就可以减少一次系统调用\n![sendfile](2020-05-07-零拷贝/sendfile.png)\n* 2次上下文切换，3次拷贝\n\n## 3、sendfile + DMA\nsendfile减少内核空间的CPU拷贝\n![sendfile_dma](2020-05-07-零拷贝/sendfile_DMA.png)\n\n\n# 四、Java中的零拷贝\n* java NIO的零拷贝实现是基于mmap+write方式\n* FileChannel的map方法产生的MappedByteBuffer FileChannel提供了map()方法，\n该方法可以在一个打开的文件和MappedByteBuffer之间建立一个虚拟内存映射，MappedByteBuffer继承于ByteBuffer；\n该缓冲器的内存是一个文件的内存映射区域。map方法底层是通过mmap实现的，因此将文件内存从磁盘读取到内核缓冲区后，用户空间和内核空间共享该缓冲区。用法如下\n\n\n## 4.1、从JMM看堆外内存\n![JMM](2020-05-07-零拷贝/jmm.png)\n直接内存：就是基于mmap+write方式实现的零拷贝\n* 永久代主要存放以下数据：\n    * JVM internal representation of classes and their metadata\n    * Class statics\n    * Interned strings\n    * 运行时常量池\n        \n* 从 JDK7 开始，JDK 开发者们就有消灭永久代的打算了。有部分数据移到永久代之外了：\n    * Symbols => native memory\n    * Interned strings => Java Heap\n    * Class statics => Java Heap\n    * 运行时常量池，还是存放在方法区内\n* 到了 JDK8，这个工作终于完成了，彻底废弃了 PermGen，Metaspace 取而代之。\n    * 运行时常量池，也移到了metaspace内\n\n### 1、内存分类 \n* 堆内内存： on-heap memory  \n    * java虚拟机运行时区域堆内存（HeapByteBuffer）。 \n    \n* 堆外内存：off-heap memory\n    * 除java堆之外的所有其他运行时数据区域，包括程序计数器，java虚拟机栈，本地 方法栈，方法区（元数据区），\n    运行时常量池，直接内存（DirectByteBuffer）。\n\n### 2、如何申请直接内存 \n1. Unsafe.allocateMemory(long var1) \n2. ByteBuffer.allocateDirect(int capacity) \n3. native方法\n\n### 3、源码解析\n![直接内存](2020-05-07-零拷贝/直接内存.png)\n* DirectByteBuffer：直接内存对象，还归属JVM管理，在堆中。（冰山对象）\n* 构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，堆外内存也会被释放\n\n### 4、申请&回收\n* 申请\n    * 通过C的malloc来进行分配\n        * 如果内存不够？Bits.reserveMemory(size, cap) \n        * 首先尝试tryReserveMemory，这个方法会释放已经被JVM回收的DirectByteBuffer对象所引用的堆外内存。\n        * 如果内存依旧不够，则会尝试System.gc()，产生full GC\n        * 如果上面的操作都失败并且重试9次，则抛出OOM异常\n\n* 回收\n    * Cleaner是PhantomReference的子类，并通过自身的next和prev字段维护的一个双向链表。\n    * PhantomReference的作用在于跟踪垃圾回收过程，并不会对对象的垃圾回收过程造成任何的影响。\n    * 所以cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); 用于对当前构造的DirectByteBuffer对象的垃圾回收过程进行跟踪。\n    * 当DirectByteBuffer对象从pending状态 ——> enqueue状态时，会触发Cleaner的clean()，而Cleaner的clean()的方法会实现通过unsafe对堆外内存的释放。\n\n![JMM](2020-05-07-零拷贝/直接内存回收和分配.png)\n\n\n\n\n[参考](https://www.jianshu.com/p/007052ee3773)","source":"_posts/2020-05-07-零拷贝.md","raw":"---\ntitle: 零拷贝\ndate: 2020-05-07 21:36:43\ntags:\n---\n# 一、什么是零拷贝？\n减少数据的拷贝。\n\n\n# 二、前提知识\n## 1、Linux进程的虚拟空间\nLinux进程的虚拟空间，分成内核空间和用户空间，数据进入进程的过程，是从磁盘拷贝至内核，然后从内核空间拷贝至用户空间。\n![基本方式](2020-05-07-零拷贝/基本方式.png)\nread、write两个系统调用的过程，从磁盘将数据读入内核空间，然后从内核空间拷贝至用户空间，过程复杂。\n* 4次数据拷贝，速率低下。\n\n<!--more-->  \n\n## 2、DMA拷贝\nDirect Memory Access，直接内存操作。   \n传统数据的传输：使用CPU，CPU负责数据的拷贝传输。\n![基本方式](2020-05-07-零拷贝/DMA.png)\n优化数据传输：DMA，专门进行数据传输的硬件\n![基本方式](2020-05-07-零拷贝/DMA-优化.png)\n优势：解放CPU\n\n\n\n# 三、零拷贝的实现\n减少系统调用，减少态的切换。\n* mmap\n* sendfile\n* sendfile + DMA\n\n## 1、mmap\n用户空间会和内核空间行程一个映射，这样就不需要将数据从内核态拷贝至用户态，从而减少一次拷贝。    \n**映射原理：**\n* 就是在用户进程中创建变量vma和物理内存进行映射，而不需要再将数据从page cache再拷贝至用户进程空间\n![mmap](2020-05-07-零拷贝/mmp.png)\n* 4次上下文切换，3次拷贝。\n## 2、sendfile\n```\ninclude <sys/socket.h>\nssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);\n```\n\n它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。\n它可以替代前面的**read()**和**write()**这两个系统调用，这样就可以减少一次系统调用\n![sendfile](2020-05-07-零拷贝/sendfile.png)\n* 2次上下文切换，3次拷贝\n\n## 3、sendfile + DMA\nsendfile减少内核空间的CPU拷贝\n![sendfile_dma](2020-05-07-零拷贝/sendfile_DMA.png)\n\n\n# 四、Java中的零拷贝\n* java NIO的零拷贝实现是基于mmap+write方式\n* FileChannel的map方法产生的MappedByteBuffer FileChannel提供了map()方法，\n该方法可以在一个打开的文件和MappedByteBuffer之间建立一个虚拟内存映射，MappedByteBuffer继承于ByteBuffer；\n该缓冲器的内存是一个文件的内存映射区域。map方法底层是通过mmap实现的，因此将文件内存从磁盘读取到内核缓冲区后，用户空间和内核空间共享该缓冲区。用法如下\n\n\n## 4.1、从JMM看堆外内存\n![JMM](2020-05-07-零拷贝/jmm.png)\n直接内存：就是基于mmap+write方式实现的零拷贝\n* 永久代主要存放以下数据：\n    * JVM internal representation of classes and their metadata\n    * Class statics\n    * Interned strings\n    * 运行时常量池\n        \n* 从 JDK7 开始，JDK 开发者们就有消灭永久代的打算了。有部分数据移到永久代之外了：\n    * Symbols => native memory\n    * Interned strings => Java Heap\n    * Class statics => Java Heap\n    * 运行时常量池，还是存放在方法区内\n* 到了 JDK8，这个工作终于完成了，彻底废弃了 PermGen，Metaspace 取而代之。\n    * 运行时常量池，也移到了metaspace内\n\n### 1、内存分类 \n* 堆内内存： on-heap memory  \n    * java虚拟机运行时区域堆内存（HeapByteBuffer）。 \n    \n* 堆外内存：off-heap memory\n    * 除java堆之外的所有其他运行时数据区域，包括程序计数器，java虚拟机栈，本地 方法栈，方法区（元数据区），\n    运行时常量池，直接内存（DirectByteBuffer）。\n\n### 2、如何申请直接内存 \n1. Unsafe.allocateMemory(long var1) \n2. ByteBuffer.allocateDirect(int capacity) \n3. native方法\n\n### 3、源码解析\n![直接内存](2020-05-07-零拷贝/直接内存.png)\n* DirectByteBuffer：直接内存对象，还归属JVM管理，在堆中。（冰山对象）\n* 构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，堆外内存也会被释放\n\n### 4、申请&回收\n* 申请\n    * 通过C的malloc来进行分配\n        * 如果内存不够？Bits.reserveMemory(size, cap) \n        * 首先尝试tryReserveMemory，这个方法会释放已经被JVM回收的DirectByteBuffer对象所引用的堆外内存。\n        * 如果内存依旧不够，则会尝试System.gc()，产生full GC\n        * 如果上面的操作都失败并且重试9次，则抛出OOM异常\n\n* 回收\n    * Cleaner是PhantomReference的子类，并通过自身的next和prev字段维护的一个双向链表。\n    * PhantomReference的作用在于跟踪垃圾回收过程，并不会对对象的垃圾回收过程造成任何的影响。\n    * 所以cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); 用于对当前构造的DirectByteBuffer对象的垃圾回收过程进行跟踪。\n    * 当DirectByteBuffer对象从pending状态 ——> enqueue状态时，会触发Cleaner的clean()，而Cleaner的clean()的方法会实现通过unsafe对堆外内存的释放。\n\n![JMM](2020-05-07-零拷贝/直接内存回收和分配.png)\n\n\n\n\n[参考](https://www.jianshu.com/p/007052ee3773)","slug":"2020-05-07-零拷贝","published":1,"updated":"2024-10-14T09:38:12.218Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnx7002la13k391oce55","content":"<h1 id=\"一、什么是零拷贝？\"><a href=\"#一、什么是零拷贝？\" class=\"headerlink\" title=\"一、什么是零拷贝？\"></a>一、什么是零拷贝？</h1><p>减少数据的拷贝。</p>\n<h1 id=\"二、前提知识\"><a href=\"#二、前提知识\" class=\"headerlink\" title=\"二、前提知识\"></a>二、前提知识</h1><h2 id=\"1、Linux进程的虚拟空间\"><a href=\"#1、Linux进程的虚拟空间\" class=\"headerlink\" title=\"1、Linux进程的虚拟空间\"></a>1、Linux进程的虚拟空间</h2><p>Linux进程的虚拟空间，分成内核空间和用户空间，数据进入进程的过程，是从磁盘拷贝至内核，然后从内核空间拷贝至用户空间。<br><img src=\"/2020/05/07/2020-05-07-零拷贝/%E5%9F%BA%E6%9C%AC%E6%96%B9%E5%BC%8F.png\" alt=\"基本方式\"><br>read、write两个系统调用的过程，从磁盘将数据读入内核空间，然后从内核空间拷贝至用户空间，过程复杂。</p>\n<ul>\n<li>4次数据拷贝，速率低下。</li>\n</ul>\n<a id=\"more\"></a>  \n\n<h2 id=\"2、DMA拷贝\"><a href=\"#2、DMA拷贝\" class=\"headerlink\" title=\"2、DMA拷贝\"></a>2、DMA拷贝</h2><p>Direct Memory Access，直接内存操作。<br>传统数据的传输：使用CPU，CPU负责数据的拷贝传输。<br><img src=\"/2020/05/07/2020-05-07-零拷贝/DMA.png\" alt=\"基本方式\"><br>优化数据传输：DMA，专门进行数据传输的硬件<br><img src=\"/2020/05/07/2020-05-07-零拷贝/DMA-%E4%BC%98%E5%8C%96.png\" alt=\"基本方式\"><br>优势：解放CPU</p>\n<h1 id=\"三、零拷贝的实现\"><a href=\"#三、零拷贝的实现\" class=\"headerlink\" title=\"三、零拷贝的实现\"></a>三、零拷贝的实现</h1><p>减少系统调用，减少态的切换。</p>\n<ul>\n<li>mmap</li>\n<li>sendfile</li>\n<li>sendfile + DMA</li>\n</ul>\n<h2 id=\"1、mmap\"><a href=\"#1、mmap\" class=\"headerlink\" title=\"1、mmap\"></a>1、mmap</h2><p>用户空间会和内核空间行程一个映射，这样就不需要将数据从内核态拷贝至用户态，从而减少一次拷贝。<br><strong>映射原理：</strong></p>\n<ul>\n<li>就是在用户进程中创建变量vma和物理内存进行映射，而不需要再将数据从page cache再拷贝至用户进程空间<br><img src=\"/2020/05/07/2020-05-07-零拷贝/mmp.png\" alt=\"mmap\"></li>\n<li>4次上下文切换，3次拷贝。<h2 id=\"2、sendfile\"><a href=\"#2、sendfile\" class=\"headerlink\" title=\"2、sendfile\"></a>2、sendfile</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include &lt;sys/socket.h&gt;</span><br><span class=\"line\">ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。<br>它可以替代前面的<strong>read()</strong>和<strong>write()</strong>这两个系统调用，这样就可以减少一次系统调用<br><img src=\"/2020/05/07/2020-05-07-零拷贝/sendfile.png\" alt=\"sendfile\"></p>\n<ul>\n<li>2次上下文切换，3次拷贝</li>\n</ul>\n<h2 id=\"3、sendfile-DMA\"><a href=\"#3、sendfile-DMA\" class=\"headerlink\" title=\"3、sendfile + DMA\"></a>3、sendfile + DMA</h2><p>sendfile减少内核空间的CPU拷贝<br><img src=\"/2020/05/07/2020-05-07-零拷贝/sendfile_DMA.png\" alt=\"sendfile_dma\"></p>\n<h1 id=\"四、Java中的零拷贝\"><a href=\"#四、Java中的零拷贝\" class=\"headerlink\" title=\"四、Java中的零拷贝\"></a>四、Java中的零拷贝</h1><ul>\n<li>java NIO的零拷贝实现是基于mmap+write方式</li>\n<li>FileChannel的map方法产生的MappedByteBuffer FileChannel提供了map()方法，<br>该方法可以在一个打开的文件和MappedByteBuffer之间建立一个虚拟内存映射，MappedByteBuffer继承于ByteBuffer；<br>该缓冲器的内存是一个文件的内存映射区域。map方法底层是通过mmap实现的，因此将文件内存从磁盘读取到内核缓冲区后，用户空间和内核空间共享该缓冲区。用法如下</li>\n</ul>\n<h2 id=\"4-1、从JMM看堆外内存\"><a href=\"#4-1、从JMM看堆外内存\" class=\"headerlink\" title=\"4.1、从JMM看堆外内存\"></a>4.1、从JMM看堆外内存</h2><p><img src=\"/2020/05/07/2020-05-07-零拷贝/jmm.png\" alt=\"JMM\"><br>直接内存：就是基于mmap+write方式实现的零拷贝</p>\n<ul>\n<li><p>永久代主要存放以下数据：</p>\n<ul>\n<li>JVM internal representation of classes and their metadata</li>\n<li>Class statics</li>\n<li>Interned strings</li>\n<li>运行时常量池</li>\n</ul>\n</li>\n<li><p>从 JDK7 开始，JDK 开发者们就有消灭永久代的打算了。有部分数据移到永久代之外了：</p>\n<ul>\n<li>Symbols =&gt; native memory</li>\n<li>Interned strings =&gt; Java Heap</li>\n<li>Class statics =&gt; Java Heap</li>\n<li>运行时常量池，还是存放在方法区内</li>\n</ul>\n</li>\n<li><p>到了 JDK8，这个工作终于完成了，彻底废弃了 PermGen，Metaspace 取而代之。</p>\n<ul>\n<li>运行时常量池，也移到了metaspace内</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1、内存分类\"><a href=\"#1、内存分类\" class=\"headerlink\" title=\"1、内存分类\"></a>1、内存分类</h3><ul>\n<li><p>堆内内存： on-heap memory  </p>\n<ul>\n<li>java虚拟机运行时区域堆内存（HeapByteBuffer）。 </li>\n</ul>\n</li>\n<li><p>堆外内存：off-heap memory</p>\n<ul>\n<li>除java堆之外的所有其他运行时数据区域，包括程序计数器，java虚拟机栈，本地 方法栈，方法区（元数据区），<br>运行时常量池，直接内存（DirectByteBuffer）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2、如何申请直接内存\"><a href=\"#2、如何申请直接内存\" class=\"headerlink\" title=\"2、如何申请直接内存\"></a>2、如何申请直接内存</h3><ol>\n<li>Unsafe.allocateMemory(long var1) </li>\n<li>ByteBuffer.allocateDirect(int capacity) </li>\n<li>native方法</li>\n</ol>\n<h3 id=\"3、源码解析\"><a href=\"#3、源码解析\" class=\"headerlink\" title=\"3、源码解析\"></a>3、源码解析</h3><p><img src=\"/2020/05/07/2020-05-07-零拷贝/%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98.png\" alt=\"直接内存\"></p>\n<ul>\n<li>DirectByteBuffer：直接内存对象，还归属JVM管理，在堆中。（冰山对象）</li>\n<li>构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，堆外内存也会被释放</li>\n</ul>\n<h3 id=\"4、申请-amp-回收\"><a href=\"#4、申请-amp-回收\" class=\"headerlink\" title=\"4、申请&amp;回收\"></a>4、申请&amp;回收</h3><ul>\n<li><p>申请</p>\n<ul>\n<li>通过C的malloc来进行分配<ul>\n<li>如果内存不够？Bits.reserveMemory(size, cap) </li>\n<li>首先尝试tryReserveMemory，这个方法会释放已经被JVM回收的DirectByteBuffer对象所引用的堆外内存。</li>\n<li>如果内存依旧不够，则会尝试System.gc()，产生full GC</li>\n<li>如果上面的操作都失败并且重试9次，则抛出OOM异常</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>回收</p>\n<ul>\n<li>Cleaner是PhantomReference的子类，并通过自身的next和prev字段维护的一个双向链表。</li>\n<li>PhantomReference的作用在于跟踪垃圾回收过程，并不会对对象的垃圾回收过程造成任何的影响。</li>\n<li>所以cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); 用于对当前构造的DirectByteBuffer对象的垃圾回收过程进行跟踪。</li>\n<li>当DirectByteBuffer对象从pending状态 ——&gt; enqueue状态时，会触发Cleaner的clean()，而Cleaner的clean()的方法会实现通过unsafe对堆外内存的释放。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/05/07/2020-05-07-零拷贝/%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E5%92%8C%E5%88%86%E9%85%8D.png\" alt=\"JMM\"></p>\n<p><a href=\"https://www.jianshu.com/p/007052ee3773\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、什么是零拷贝？\"><a href=\"#一、什么是零拷贝？\" class=\"headerlink\" title=\"一、什么是零拷贝？\"></a>一、什么是零拷贝？</h1><p>减少数据的拷贝。</p>\n<h1 id=\"二、前提知识\"><a href=\"#二、前提知识\" class=\"headerlink\" title=\"二、前提知识\"></a>二、前提知识</h1><h2 id=\"1、Linux进程的虚拟空间\"><a href=\"#1、Linux进程的虚拟空间\" class=\"headerlink\" title=\"1、Linux进程的虚拟空间\"></a>1、Linux进程的虚拟空间</h2><p>Linux进程的虚拟空间，分成内核空间和用户空间，数据进入进程的过程，是从磁盘拷贝至内核，然后从内核空间拷贝至用户空间。<br><img src=\"/2020/05/07/2020-05-07-零拷贝/%E5%9F%BA%E6%9C%AC%E6%96%B9%E5%BC%8F.png\" alt=\"基本方式\"><br>read、write两个系统调用的过程，从磁盘将数据读入内核空间，然后从内核空间拷贝至用户空间，过程复杂。</p>\n<ul>\n<li>4次数据拷贝，速率低下。</li>\n</ul>","more":"<h2 id=\"2、DMA拷贝\"><a href=\"#2、DMA拷贝\" class=\"headerlink\" title=\"2、DMA拷贝\"></a>2、DMA拷贝</h2><p>Direct Memory Access，直接内存操作。<br>传统数据的传输：使用CPU，CPU负责数据的拷贝传输。<br><img src=\"/2020/05/07/2020-05-07-零拷贝/DMA.png\" alt=\"基本方式\"><br>优化数据传输：DMA，专门进行数据传输的硬件<br><img src=\"/2020/05/07/2020-05-07-零拷贝/DMA-%E4%BC%98%E5%8C%96.png\" alt=\"基本方式\"><br>优势：解放CPU</p>\n<h1 id=\"三、零拷贝的实现\"><a href=\"#三、零拷贝的实现\" class=\"headerlink\" title=\"三、零拷贝的实现\"></a>三、零拷贝的实现</h1><p>减少系统调用，减少态的切换。</p>\n<ul>\n<li>mmap</li>\n<li>sendfile</li>\n<li>sendfile + DMA</li>\n</ul>\n<h2 id=\"1、mmap\"><a href=\"#1、mmap\" class=\"headerlink\" title=\"1、mmap\"></a>1、mmap</h2><p>用户空间会和内核空间行程一个映射，这样就不需要将数据从内核态拷贝至用户态，从而减少一次拷贝。<br><strong>映射原理：</strong></p>\n<ul>\n<li>就是在用户进程中创建变量vma和物理内存进行映射，而不需要再将数据从page cache再拷贝至用户进程空间<br><img src=\"/2020/05/07/2020-05-07-零拷贝/mmp.png\" alt=\"mmap\"></li>\n<li>4次上下文切换，3次拷贝。<h2 id=\"2、sendfile\"><a href=\"#2、sendfile\" class=\"headerlink\" title=\"2、sendfile\"></a>2、sendfile</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include &lt;sys/socket.h&gt;</span><br><span class=\"line\">ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。<br>它可以替代前面的<strong>read()</strong>和<strong>write()</strong>这两个系统调用，这样就可以减少一次系统调用<br><img src=\"/2020/05/07/2020-05-07-零拷贝/sendfile.png\" alt=\"sendfile\"></p>\n<ul>\n<li>2次上下文切换，3次拷贝</li>\n</ul>\n<h2 id=\"3、sendfile-DMA\"><a href=\"#3、sendfile-DMA\" class=\"headerlink\" title=\"3、sendfile + DMA\"></a>3、sendfile + DMA</h2><p>sendfile减少内核空间的CPU拷贝<br><img src=\"/2020/05/07/2020-05-07-零拷贝/sendfile_DMA.png\" alt=\"sendfile_dma\"></p>\n<h1 id=\"四、Java中的零拷贝\"><a href=\"#四、Java中的零拷贝\" class=\"headerlink\" title=\"四、Java中的零拷贝\"></a>四、Java中的零拷贝</h1><ul>\n<li>java NIO的零拷贝实现是基于mmap+write方式</li>\n<li>FileChannel的map方法产生的MappedByteBuffer FileChannel提供了map()方法，<br>该方法可以在一个打开的文件和MappedByteBuffer之间建立一个虚拟内存映射，MappedByteBuffer继承于ByteBuffer；<br>该缓冲器的内存是一个文件的内存映射区域。map方法底层是通过mmap实现的，因此将文件内存从磁盘读取到内核缓冲区后，用户空间和内核空间共享该缓冲区。用法如下</li>\n</ul>\n<h2 id=\"4-1、从JMM看堆外内存\"><a href=\"#4-1、从JMM看堆外内存\" class=\"headerlink\" title=\"4.1、从JMM看堆外内存\"></a>4.1、从JMM看堆外内存</h2><p><img src=\"/2020/05/07/2020-05-07-零拷贝/jmm.png\" alt=\"JMM\"><br>直接内存：就是基于mmap+write方式实现的零拷贝</p>\n<ul>\n<li><p>永久代主要存放以下数据：</p>\n<ul>\n<li>JVM internal representation of classes and their metadata</li>\n<li>Class statics</li>\n<li>Interned strings</li>\n<li>运行时常量池</li>\n</ul>\n</li>\n<li><p>从 JDK7 开始，JDK 开发者们就有消灭永久代的打算了。有部分数据移到永久代之外了：</p>\n<ul>\n<li>Symbols =&gt; native memory</li>\n<li>Interned strings =&gt; Java Heap</li>\n<li>Class statics =&gt; Java Heap</li>\n<li>运行时常量池，还是存放在方法区内</li>\n</ul>\n</li>\n<li><p>到了 JDK8，这个工作终于完成了，彻底废弃了 PermGen，Metaspace 取而代之。</p>\n<ul>\n<li>运行时常量池，也移到了metaspace内</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1、内存分类\"><a href=\"#1、内存分类\" class=\"headerlink\" title=\"1、内存分类\"></a>1、内存分类</h3><ul>\n<li><p>堆内内存： on-heap memory  </p>\n<ul>\n<li>java虚拟机运行时区域堆内存（HeapByteBuffer）。 </li>\n</ul>\n</li>\n<li><p>堆外内存：off-heap memory</p>\n<ul>\n<li>除java堆之外的所有其他运行时数据区域，包括程序计数器，java虚拟机栈，本地 方法栈，方法区（元数据区），<br>运行时常量池，直接内存（DirectByteBuffer）。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2、如何申请直接内存\"><a href=\"#2、如何申请直接内存\" class=\"headerlink\" title=\"2、如何申请直接内存\"></a>2、如何申请直接内存</h3><ol>\n<li>Unsafe.allocateMemory(long var1) </li>\n<li>ByteBuffer.allocateDirect(int capacity) </li>\n<li>native方法</li>\n</ol>\n<h3 id=\"3、源码解析\"><a href=\"#3、源码解析\" class=\"headerlink\" title=\"3、源码解析\"></a>3、源码解析</h3><p><img src=\"/2020/05/07/2020-05-07-零拷贝/%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98.png\" alt=\"直接内存\"></p>\n<ul>\n<li>DirectByteBuffer：直接内存对象，还归属JVM管理，在堆中。（冰山对象）</li>\n<li>构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，堆外内存也会被释放</li>\n</ul>\n<h3 id=\"4、申请-amp-回收\"><a href=\"#4、申请-amp-回收\" class=\"headerlink\" title=\"4、申请&amp;回收\"></a>4、申请&amp;回收</h3><ul>\n<li><p>申请</p>\n<ul>\n<li>通过C的malloc来进行分配<ul>\n<li>如果内存不够？Bits.reserveMemory(size, cap) </li>\n<li>首先尝试tryReserveMemory，这个方法会释放已经被JVM回收的DirectByteBuffer对象所引用的堆外内存。</li>\n<li>如果内存依旧不够，则会尝试System.gc()，产生full GC</li>\n<li>如果上面的操作都失败并且重试9次，则抛出OOM异常</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>回收</p>\n<ul>\n<li>Cleaner是PhantomReference的子类，并通过自身的next和prev字段维护的一个双向链表。</li>\n<li>PhantomReference的作用在于跟踪垃圾回收过程，并不会对对象的垃圾回收过程造成任何的影响。</li>\n<li>所以cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); 用于对当前构造的DirectByteBuffer对象的垃圾回收过程进行跟踪。</li>\n<li>当DirectByteBuffer对象从pending状态 ——&gt; enqueue状态时，会触发Cleaner的clean()，而Cleaner的clean()的方法会实现通过unsafe对堆外内存的释放。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/05/07/2020-05-07-零拷贝/%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E5%92%8C%E5%88%86%E9%85%8D.png\" alt=\"JMM\"></p>\n<p><a href=\"https://www.jianshu.com/p/007052ee3773\" target=\"_blank\" rel=\"noopener\">参考</a></p>"},{"title":"枚举","date":"2020-05-14T13:36:33.000Z","_content":"\n# 一、什么是枚举\n一种特殊的类类型，但是比类类型多了一些约束。\n\n#二、实现原理\n```java\npublic enum EnumSingleBest {\n    INSTANCE;\n}\n```\n\n\n经过编译器编译后\n```\npublic final class com.single.EnumSingleBest extends java.lang.Enum<com.single.EnumSingleBest> {\n  public static final com.single.EnumSingleBest INSTANCE;\n  public static com.single.EnumSingleBest[] values();\n  public static com.single.EnumSingleBest valueOf(java.lang.String);\n  static {};\n}\n```\n* 枚举类编译后生成继承Enum抽象类的final类。\n* 内部有静态不可变的实例对象。\n","source":"_posts/2020-05-14-枚举.md","raw":"---\ntitle: 枚举\ndate: 2020-05-14 21:36:33\ntags: Enum java\ncategories:\n  - [java]\n---\n\n# 一、什么是枚举\n一种特殊的类类型，但是比类类型多了一些约束。\n\n#二、实现原理\n```java\npublic enum EnumSingleBest {\n    INSTANCE;\n}\n```\n\n\n经过编译器编译后\n```\npublic final class com.single.EnumSingleBest extends java.lang.Enum<com.single.EnumSingleBest> {\n  public static final com.single.EnumSingleBest INSTANCE;\n  public static com.single.EnumSingleBest[] values();\n  public static com.single.EnumSingleBest valueOf(java.lang.String);\n  static {};\n}\n```\n* 枚举类编译后生成继承Enum抽象类的final类。\n* 内部有静态不可变的实例对象。\n","slug":"2020-05-14-枚举","published":1,"updated":"2024-12-09T03:22:02.525Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnx8002oa13kegip255g","content":"<h1 id=\"一、什么是枚举\"><a href=\"#一、什么是枚举\" class=\"headerlink\" title=\"一、什么是枚举\"></a>一、什么是枚举</h1><p>一种特殊的类类型，但是比类类型多了一些约束。</p>\n<p>#二、实现原理</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">enum</span> EnumSingleBest &#123;</span><br><span class=\"line\">    INSTANCE;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>经过编译器编译后</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public final class com.single.EnumSingleBest extends java.lang.Enum&lt;com.single.EnumSingleBest&gt; &#123;</span><br><span class=\"line\">  public static final com.single.EnumSingleBest INSTANCE;</span><br><span class=\"line\">  public static com.single.EnumSingleBest[] values();</span><br><span class=\"line\">  public static com.single.EnumSingleBest valueOf(java.lang.String);</span><br><span class=\"line\">  static &#123;&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>枚举类编译后生成继承Enum抽象类的final类。</li>\n<li>内部有静态不可变的实例对象。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、什么是枚举\"><a href=\"#一、什么是枚举\" class=\"headerlink\" title=\"一、什么是枚举\"></a>一、什么是枚举</h1><p>一种特殊的类类型，但是比类类型多了一些约束。</p>\n<p>#二、实现原理</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">enum</span> EnumSingleBest &#123;</span><br><span class=\"line\">    INSTANCE;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>经过编译器编译后</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public final class com.single.EnumSingleBest extends java.lang.Enum&lt;com.single.EnumSingleBest&gt; &#123;</span><br><span class=\"line\">  public static final com.single.EnumSingleBest INSTANCE;</span><br><span class=\"line\">  public static com.single.EnumSingleBest[] values();</span><br><span class=\"line\">  public static com.single.EnumSingleBest valueOf(java.lang.String);</span><br><span class=\"line\">  static &#123;&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>枚举类编译后生成继承Enum抽象类的final类。</li>\n<li>内部有静态不可变的实例对象。</li>\n</ul>\n"},{"title":"单例","date":"2020-05-13T11:50:03.000Z","_content":"#一、什么是单例\n单例，就是保证一个类的实例对象只存在一个\n#二、创建对象方法\nnew，反射，克隆，反序列化\n\n#三、破坏单例\n什么是破坏单例？就是让一个类存在多个实例对象   \n**如何破坏：**\n1. 单例的首要条件是构造函数私有化。那么new方式行不通。\n2. 克隆，需要实现cloneable接口。要达到单例效果，就不能实现这个类。\n3. 序列化：需要实现Serializable接口\n```\npublic class Test {  \n    public static void main(String[] args) throws Exception {  \n        //序列化  \n        Singleton instance1 = Singleton.getInstance();  \n        ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(\"tempFile\"));  \n        objectOutputStream.writeObject(instance1);  \n        //反序列化  \n        File file = new File(\"tempFile\");  \n        ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(file));  \n        Singleton instance2 = (Singleton) objectInputStream.readObject();  \n        System.out.println(instance1 == instance2); //false，代表不是同一个对象\n    }  \n}\n```\n<!--more-->  \n\n* 总结：通过反射，可以破坏单例。【底层实现原理还是使用反射】\n* 防止序列化破坏单例：在单例类中实现readResolve方法\n```\n//在单例类中实现readResolve方法\npublic class Singleton implements Serializable {  \n    private Singleton() {  \n    }  \n    private static class SingletonInstance {  \n        private static final Singleton INSTANCE = new Singleton();  \n   }   \n    public static Singleton getInstance() {  \n        return SingletonInstance.INSTANCE;  \n   }  \n    private Object readResolve() {  \n        return SingletonInstance.INSTANCE;  \n   }  \n}\n```\n4. 反射\n```\npublic class Test {  \n    public static void main(String[] args) throws Exception {  \n      Singleton instance1 = Singleton.getInstance();  \n      //通过反射创建对象  \n      Class<Singleton> singletonClass = Singleton.class;  \n      Constructor<Singleton> constructor = singletonClass.getDeclaredConstructor(); \n      //暴力破解私有构造器------开启后才能反射创建对象\n      constructor.setAccessible(true);  \n      Singleton instance2 = constructor.newInstance();   \n     System.out.println(instance1 == instance2);  //返回false\n  }  \n}\n```\n* 总结：反射可以破坏单例\n* 防止反射破坏序列化：修改构造器，通过构造器判断（饥汉模式无法实现）\n```\npublic class Singleton {\n    private static volatile Singleton instance ;\n    private Singleton(){\n        //构造器判断\n        if(instance != null){\n            throw new RuntimeException(\"不允许反射调用构造器\");\n        }\n    }\n    public static Singleton getInstance(){\n    }\n}\n```\n\n总结：要想实现不被破坏的单例，需要通过构造函数判断+实现readResolve方法。\n#四、最佳方式\n枚举\n```\npublic enum EnumSingleton {\n    INSTANCE; \n    public EnumSingleton getInstance(){ \n         return INSTANCE;\n    }\n}\n```\n避免反射破坏单例：\n使用反射会抛出异常\n```\njava.lang.NoSuchMethodException: com.jvm.SingleEnum.<init>()\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getDeclaredConstructor(Class.java:2178)\n\tat com.jvm.SingleEnumTest.main(SingleEnumTest.java:16)\n```\n原因\n```\nprotected Enum(String name, int ordinal) {\n    this.name = name;\n    this.ordinal = ordinal;\n}\n```\n枚举类的构造函数有参，无法通过子类的构造函数进行\n\n\n并且Constructor.newInstance进行了枚举判断，如果是枚举则抛出异常。\n\n* 避免反序列化破坏单例：\n    * 每个枚举对象都有一个唯一的name属性。序列化只是将name属性序列化，在反序列化的时候，通过创建一个Map(key,value)，搭建起name和与之对应的对象之间的联系，然后通过索引key来获得枚举对象。\n\n# 五、懒汉饥汉\n\n```java\npublic class safeLazyInitialization {\n    private static Instance instance;\n    public synchronized static Instance getInstance(){\n        if(instance ==null)\n            instance = new Instance();       \n        return instance;\n    }\n}\n```\n方法上添加synchronized方法，会导致性能较差，可以实现单例。\n\n优化一\n```java\npublic class DoubleCheckedLocking {                     //1\n    private static Instance instance;                   //2\n    public  static Instance getInstance(){              //3\n        if(instance ==null) {                           //4:第一次检查\n            synchronized (DoubleCheckedLocking.class) { //5：加锁\n                if (instance == null)                   //6：第二次检查\n                    instance = new Instance();          //7：问题的根源处在这里\n            }                                           //8\n        }                                               //9\n        return instance;                                //10\n    }                                                   //11\n}\n```\n不对方法进行加锁，对Class对象进行加锁。但是也会出现问题。\n* 指令代码\n```\nmemory=allocate();        //1:分配对象的内存空间\nctorInstance(memory);     //2:初始化对象\ninstance = memory;          //3:设置instance指向刚分配的内存地址\n```\n* 指令重排序后\n```\nmemory=allocate();        //1:分配对象的内存空间\ninstance = memory;          //3:设置instance指向刚分配的内存地址\nctorInstance(memory);     //2:初始化对象\n```\n* 问题根源\n    * 线程1执行到第7行时，因为指令重排序，instance!=null，但是对象未进行初始化，对象信息都是初始值。\n    * 线程2此时执行第4行，instance!=null，此时返回instance，因为未初始化，属性值将是初始值有问题。\n* 为什么需要双重校验呢？\n    * 第一层校验，提高效率\n    * 如果A、B两个线程，A进入了synchronized同步代码块，此时B通过了136行的校验，阻塞在同步代码块\n    * 如果没有第二层校验，那么A创建完释放锁，B进入同步代码块，没有判断的话也会创建实例，从而导致问题。\n    \n优化二\n```java\npublic class DoubleCheckedLocking {                     //1\n  private static volatile Instance instance;                   //2\n  public  static Instance getInstance(){              //3\n      if(instance ==null) {                           //4:第一次检查\n          synchronized (DoubleCheckedLocking.class) { //5：加锁\n              if (instance == null)                   //6：第二次检查\n                  instance = new Instance();          //7：问题的根源处在这里\n          }                                           //8\n      }                                               //9\n      return instance;                                //10\n  }                                                   //11\n}\n```  \nvolatile防止指令重排序。","source":"_posts/2020-05-13-单例.md","raw":"---\ntitle: 单例\ndate: 2020-05-13 19:50:03\ntags:\ncategories:\n  - [java]\n---\n#一、什么是单例\n单例，就是保证一个类的实例对象只存在一个\n#二、创建对象方法\nnew，反射，克隆，反序列化\n\n#三、破坏单例\n什么是破坏单例？就是让一个类存在多个实例对象   \n**如何破坏：**\n1. 单例的首要条件是构造函数私有化。那么new方式行不通。\n2. 克隆，需要实现cloneable接口。要达到单例效果，就不能实现这个类。\n3. 序列化：需要实现Serializable接口\n```\npublic class Test {  \n    public static void main(String[] args) throws Exception {  \n        //序列化  \n        Singleton instance1 = Singleton.getInstance();  \n        ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(\"tempFile\"));  \n        objectOutputStream.writeObject(instance1);  \n        //反序列化  \n        File file = new File(\"tempFile\");  \n        ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(file));  \n        Singleton instance2 = (Singleton) objectInputStream.readObject();  \n        System.out.println(instance1 == instance2); //false，代表不是同一个对象\n    }  \n}\n```\n<!--more-->  \n\n* 总结：通过反射，可以破坏单例。【底层实现原理还是使用反射】\n* 防止序列化破坏单例：在单例类中实现readResolve方法\n```\n//在单例类中实现readResolve方法\npublic class Singleton implements Serializable {  \n    private Singleton() {  \n    }  \n    private static class SingletonInstance {  \n        private static final Singleton INSTANCE = new Singleton();  \n   }   \n    public static Singleton getInstance() {  \n        return SingletonInstance.INSTANCE;  \n   }  \n    private Object readResolve() {  \n        return SingletonInstance.INSTANCE;  \n   }  \n}\n```\n4. 反射\n```\npublic class Test {  \n    public static void main(String[] args) throws Exception {  \n      Singleton instance1 = Singleton.getInstance();  \n      //通过反射创建对象  \n      Class<Singleton> singletonClass = Singleton.class;  \n      Constructor<Singleton> constructor = singletonClass.getDeclaredConstructor(); \n      //暴力破解私有构造器------开启后才能反射创建对象\n      constructor.setAccessible(true);  \n      Singleton instance2 = constructor.newInstance();   \n     System.out.println(instance1 == instance2);  //返回false\n  }  \n}\n```\n* 总结：反射可以破坏单例\n* 防止反射破坏序列化：修改构造器，通过构造器判断（饥汉模式无法实现）\n```\npublic class Singleton {\n    private static volatile Singleton instance ;\n    private Singleton(){\n        //构造器判断\n        if(instance != null){\n            throw new RuntimeException(\"不允许反射调用构造器\");\n        }\n    }\n    public static Singleton getInstance(){\n    }\n}\n```\n\n总结：要想实现不被破坏的单例，需要通过构造函数判断+实现readResolve方法。\n#四、最佳方式\n枚举\n```\npublic enum EnumSingleton {\n    INSTANCE; \n    public EnumSingleton getInstance(){ \n         return INSTANCE;\n    }\n}\n```\n避免反射破坏单例：\n使用反射会抛出异常\n```\njava.lang.NoSuchMethodException: com.jvm.SingleEnum.<init>()\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getDeclaredConstructor(Class.java:2178)\n\tat com.jvm.SingleEnumTest.main(SingleEnumTest.java:16)\n```\n原因\n```\nprotected Enum(String name, int ordinal) {\n    this.name = name;\n    this.ordinal = ordinal;\n}\n```\n枚举类的构造函数有参，无法通过子类的构造函数进行\n\n\n并且Constructor.newInstance进行了枚举判断，如果是枚举则抛出异常。\n\n* 避免反序列化破坏单例：\n    * 每个枚举对象都有一个唯一的name属性。序列化只是将name属性序列化，在反序列化的时候，通过创建一个Map(key,value)，搭建起name和与之对应的对象之间的联系，然后通过索引key来获得枚举对象。\n\n# 五、懒汉饥汉\n\n```java\npublic class safeLazyInitialization {\n    private static Instance instance;\n    public synchronized static Instance getInstance(){\n        if(instance ==null)\n            instance = new Instance();       \n        return instance;\n    }\n}\n```\n方法上添加synchronized方法，会导致性能较差，可以实现单例。\n\n优化一\n```java\npublic class DoubleCheckedLocking {                     //1\n    private static Instance instance;                   //2\n    public  static Instance getInstance(){              //3\n        if(instance ==null) {                           //4:第一次检查\n            synchronized (DoubleCheckedLocking.class) { //5：加锁\n                if (instance == null)                   //6：第二次检查\n                    instance = new Instance();          //7：问题的根源处在这里\n            }                                           //8\n        }                                               //9\n        return instance;                                //10\n    }                                                   //11\n}\n```\n不对方法进行加锁，对Class对象进行加锁。但是也会出现问题。\n* 指令代码\n```\nmemory=allocate();        //1:分配对象的内存空间\nctorInstance(memory);     //2:初始化对象\ninstance = memory;          //3:设置instance指向刚分配的内存地址\n```\n* 指令重排序后\n```\nmemory=allocate();        //1:分配对象的内存空间\ninstance = memory;          //3:设置instance指向刚分配的内存地址\nctorInstance(memory);     //2:初始化对象\n```\n* 问题根源\n    * 线程1执行到第7行时，因为指令重排序，instance!=null，但是对象未进行初始化，对象信息都是初始值。\n    * 线程2此时执行第4行，instance!=null，此时返回instance，因为未初始化，属性值将是初始值有问题。\n* 为什么需要双重校验呢？\n    * 第一层校验，提高效率\n    * 如果A、B两个线程，A进入了synchronized同步代码块，此时B通过了136行的校验，阻塞在同步代码块\n    * 如果没有第二层校验，那么A创建完释放锁，B进入同步代码块，没有判断的话也会创建实例，从而导致问题。\n    \n优化二\n```java\npublic class DoubleCheckedLocking {                     //1\n  private static volatile Instance instance;                   //2\n  public  static Instance getInstance(){              //3\n      if(instance ==null) {                           //4:第一次检查\n          synchronized (DoubleCheckedLocking.class) { //5：加锁\n              if (instance == null)                   //6：第二次检查\n                  instance = new Instance();          //7：问题的根源处在这里\n          }                                           //8\n      }                                               //9\n      return instance;                                //10\n  }                                                   //11\n}\n```  \nvolatile防止指令重排序。","slug":"2020-05-13-单例","published":1,"updated":"2024-12-09T03:22:02.648Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnx9002ra13kuatmivm2","content":"<p>#一、什么是单例<br>单例，就是保证一个类的实例对象只存在一个</p>\n<p>#二、创建对象方法<br>new，反射，克隆，反序列化</p>\n<p>#三、破坏单例<br>什么是破坏单例？就是让一个类存在多个实例对象<br><strong>如何破坏：</strong></p>\n<ol>\n<li>单例的首要条件是构造函数私有化。那么new方式行不通。</li>\n<li>克隆，需要实现cloneable接口。要达到单例效果，就不能实现这个类。</li>\n<li>序列化：需要实现Serializable接口<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class Test &#123;  </span><br><span class=\"line\">    public static void main(String[] args) throws Exception &#123;  </span><br><span class=\"line\">        //序列化  </span><br><span class=\"line\">        Singleton instance1 = Singleton.getInstance();  </span><br><span class=\"line\">        ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(&quot;tempFile&quot;));  </span><br><span class=\"line\">        objectOutputStream.writeObject(instance1);  </span><br><span class=\"line\">        //反序列化  </span><br><span class=\"line\">        File file = new File(&quot;tempFile&quot;);  </span><br><span class=\"line\">        ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(file));  </span><br><span class=\"line\">        Singleton instance2 = (Singleton) objectInputStream.readObject();  </span><br><span class=\"line\">        System.out.println(instance1 == instance2); //false，代表不是同一个对象</span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<a id=\"more\"></a>  \n\n<ul>\n<li>总结：通过反射，可以破坏单例。【底层实现原理还是使用反射】</li>\n<li>防止序列化破坏单例：在单例类中实现readResolve方法<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//在单例类中实现readResolve方法</span><br><span class=\"line\">public class Singleton implements Serializable &#123;  </span><br><span class=\"line\">    private Singleton() &#123;  </span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">    private static class SingletonInstance &#123;  </span><br><span class=\"line\">        private static final Singleton INSTANCE = new Singleton();  </span><br><span class=\"line\">   &#125;   </span><br><span class=\"line\">    public static Singleton getInstance() &#123;  </span><br><span class=\"line\">        return SingletonInstance.INSTANCE;  </span><br><span class=\"line\">   &#125;  </span><br><span class=\"line\">    private Object readResolve() &#123;  </span><br><span class=\"line\">        return SingletonInstance.INSTANCE;  </span><br><span class=\"line\">   &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol start=\"4\">\n<li>反射<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class Test &#123;  </span><br><span class=\"line\">    public static void main(String[] args) throws Exception &#123;  </span><br><span class=\"line\">      Singleton instance1 = Singleton.getInstance();  </span><br><span class=\"line\">      //通过反射创建对象  </span><br><span class=\"line\">      Class&lt;Singleton&gt; singletonClass = Singleton.class;  </span><br><span class=\"line\">      Constructor&lt;Singleton&gt; constructor = singletonClass.getDeclaredConstructor(); </span><br><span class=\"line\">      //暴力破解私有构造器------开启后才能反射创建对象</span><br><span class=\"line\">      constructor.setAccessible(true);  </span><br><span class=\"line\">      Singleton instance2 = constructor.newInstance();   </span><br><span class=\"line\">     System.out.println(instance1 == instance2);  //返回false</span><br><span class=\"line\">  &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ul>\n<li>总结：反射可以破坏单例</li>\n<li>防止反射破坏序列化：修改构造器，通过构造器判断（饥汉模式无法实现）<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class Singleton &#123;</span><br><span class=\"line\">    private static volatile Singleton instance ;</span><br><span class=\"line\">    private Singleton()&#123;</span><br><span class=\"line\">        //构造器判断</span><br><span class=\"line\">        if(instance != null)&#123;</span><br><span class=\"line\">            throw new RuntimeException(&quot;不允许反射调用构造器&quot;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    public static Singleton getInstance()&#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>总结：要想实现不被破坏的单例，需要通过构造函数判断+实现readResolve方法。</p>\n<p>#四、最佳方式<br>枚举</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public enum EnumSingleton &#123;</span><br><span class=\"line\">    INSTANCE; </span><br><span class=\"line\">    public EnumSingleton getInstance()&#123; </span><br><span class=\"line\">         return INSTANCE;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>避免反射破坏单例：<br>使用反射会抛出异常</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">java.lang.NoSuchMethodException: com.jvm.SingleEnum.&lt;init&gt;()</span><br><span class=\"line\">\tat java.lang.Class.getConstructor0(Class.java:3082)</span><br><span class=\"line\">\tat java.lang.Class.getDeclaredConstructor(Class.java:2178)</span><br><span class=\"line\">\tat com.jvm.SingleEnumTest.main(SingleEnumTest.java:16)</span><br></pre></td></tr></table></figure>\n\n<p>原因</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected Enum(String name, int ordinal) &#123;</span><br><span class=\"line\">    this.name = name;</span><br><span class=\"line\">    this.ordinal = ordinal;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>枚举类的构造函数有参，无法通过子类的构造函数进行</p>\n<p>并且Constructor.newInstance进行了枚举判断，如果是枚举则抛出异常。</p>\n<ul>\n<li>避免反序列化破坏单例：<ul>\n<li>每个枚举对象都有一个唯一的name属性。序列化只是将name属性序列化，在反序列化的时候，通过创建一个Map(key,value)，搭建起name和与之对应的对象之间的联系，然后通过索引key来获得枚举对象。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"五、懒汉饥汉\"><a href=\"#五、懒汉饥汉\" class=\"headerlink\" title=\"五、懒汉饥汉\"></a>五、懒汉饥汉</h1><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">safeLazyInitialization</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Instance instance;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> <span class=\"keyword\">static</span> Instance <span class=\"title\">getInstance</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(instance ==<span class=\"keyword\">null</span>)</span><br><span class=\"line\">            instance = <span class=\"keyword\">new</span> Instance();       </span><br><span class=\"line\">        <span class=\"keyword\">return</span> instance;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>方法上添加synchronized方法，会导致性能较差，可以实现单例。</p>\n<p>优化一</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DoubleCheckedLocking</span> </span>&#123;                     <span class=\"comment\">//1</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Instance instance;                   <span class=\"comment\">//2</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span>  <span class=\"keyword\">static</span> Instance <span class=\"title\">getInstance</span><span class=\"params\">()</span></span>&#123;              <span class=\"comment\">//3</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(instance ==<span class=\"keyword\">null</span>) &#123;                           <span class=\"comment\">//4:第一次检查</span></span><br><span class=\"line\">            <span class=\"keyword\">synchronized</span> (DoubleCheckedLocking<span class=\"class\">.<span class=\"keyword\">class</span>) </span>&#123; <span class=\"comment\">//5：加锁</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (instance == <span class=\"keyword\">null</span>)                   <span class=\"comment\">//6：第二次检查</span></span><br><span class=\"line\">                    instance = <span class=\"keyword\">new</span> Instance();          <span class=\"comment\">//7：问题的根源处在这里</span></span><br><span class=\"line\">            &#125;                                           <span class=\"comment\">//8</span></span><br><span class=\"line\">        &#125;                                               <span class=\"comment\">//9</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> instance;                                <span class=\"comment\">//10</span></span><br><span class=\"line\">    &#125;                                                   <span class=\"comment\">//11</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>不对方法进行加锁，对Class对象进行加锁。但是也会出现问题。</p>\n<ul>\n<li><p>指令代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">memory=allocate();        //1:分配对象的内存空间</span><br><span class=\"line\">ctorInstance(memory);     //2:初始化对象</span><br><span class=\"line\">instance = memory;          //3:设置instance指向刚分配的内存地址</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指令重排序后</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">memory=allocate();        //1:分配对象的内存空间</span><br><span class=\"line\">instance = memory;          //3:设置instance指向刚分配的内存地址</span><br><span class=\"line\">ctorInstance(memory);     //2:初始化对象</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>问题根源</p>\n<ul>\n<li>线程1执行到第7行时，因为指令重排序，instance!=null，但是对象未进行初始化，对象信息都是初始值。</li>\n<li>线程2此时执行第4行，instance!=null，此时返回instance，因为未初始化，属性值将是初始值有问题。</li>\n</ul>\n</li>\n<li><p>为什么需要双重校验呢？</p>\n<ul>\n<li>第一层校验，提高效率</li>\n<li>如果A、B两个线程，A进入了synchronized同步代码块，此时B通过了136行的校验，阻塞在同步代码块</li>\n<li>如果没有第二层校验，那么A创建完释放锁，B进入同步代码块，没有判断的话也会创建实例，从而导致问题。</li>\n</ul>\n</li>\n</ul>\n<p>优化二</p>\n<pre><code class=\"java\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DoubleCheckedLocking</span> </span>{                     <span class=\"comment\">//1</span>\n  <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">volatile</span> Instance instance;                   <span class=\"comment\">//2</span>\n  <span class=\"function\"><span class=\"keyword\">public</span>  <span class=\"keyword\">static</span> Instance <span class=\"title\">getInstance</span><span class=\"params\">()</span></span>{              <span class=\"comment\">//3</span>\n      <span class=\"keyword\">if</span>(instance ==<span class=\"keyword\">null</span>) {                           <span class=\"comment\">//4:第一次检查</span>\n          <span class=\"keyword\">synchronized</span> (DoubleCheckedLocking<span class=\"class\">.<span class=\"keyword\">class</span>) </span>{ <span class=\"comment\">//5：加锁</span>\n              <span class=\"keyword\">if</span> (instance == <span class=\"keyword\">null</span>)                   <span class=\"comment\">//6：第二次检查</span>\n                  instance = <span class=\"keyword\">new</span> Instance();          <span class=\"comment\">//7：问题的根源处在这里</span>\n          }                                           <span class=\"comment\">//8</span>\n      }                                               <span class=\"comment\">//9</span>\n      <span class=\"keyword\">return</span> instance;                                <span class=\"comment\">//10</span>\n  }                                                   <span class=\"comment\">//11</span>\n}</code></pre>\n<p>volatile防止指令重排序。</p>\n","site":{"data":{}},"excerpt":"<p>#一、什么是单例<br>单例，就是保证一个类的实例对象只存在一个</p>\n<p>#二、创建对象方法<br>new，反射，克隆，反序列化</p>\n<p>#三、破坏单例<br>什么是破坏单例？就是让一个类存在多个实例对象<br><strong>如何破坏：</strong></p>\n<ol>\n<li>单例的首要条件是构造函数私有化。那么new方式行不通。</li>\n<li>克隆，需要实现cloneable接口。要达到单例效果，就不能实现这个类。</li>\n<li>序列化：需要实现Serializable接口<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class Test &#123;  </span><br><span class=\"line\">    public static void main(String[] args) throws Exception &#123;  </span><br><span class=\"line\">        //序列化  </span><br><span class=\"line\">        Singleton instance1 = Singleton.getInstance();  </span><br><span class=\"line\">        ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(&quot;tempFile&quot;));  </span><br><span class=\"line\">        objectOutputStream.writeObject(instance1);  </span><br><span class=\"line\">        //反序列化  </span><br><span class=\"line\">        File file = new File(&quot;tempFile&quot;);  </span><br><span class=\"line\">        ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(file));  </span><br><span class=\"line\">        Singleton instance2 = (Singleton) objectInputStream.readObject();  </span><br><span class=\"line\">        System.out.println(instance1 == instance2); //false，代表不是同一个对象</span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>","more":"<ul>\n<li>总结：通过反射，可以破坏单例。【底层实现原理还是使用反射】</li>\n<li>防止序列化破坏单例：在单例类中实现readResolve方法<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//在单例类中实现readResolve方法</span><br><span class=\"line\">public class Singleton implements Serializable &#123;  </span><br><span class=\"line\">    private Singleton() &#123;  </span><br><span class=\"line\">    &#125;  </span><br><span class=\"line\">    private static class SingletonInstance &#123;  </span><br><span class=\"line\">        private static final Singleton INSTANCE = new Singleton();  </span><br><span class=\"line\">   &#125;   </span><br><span class=\"line\">    public static Singleton getInstance() &#123;  </span><br><span class=\"line\">        return SingletonInstance.INSTANCE;  </span><br><span class=\"line\">   &#125;  </span><br><span class=\"line\">    private Object readResolve() &#123;  </span><br><span class=\"line\">        return SingletonInstance.INSTANCE;  </span><br><span class=\"line\">   &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol start=\"4\">\n<li>反射<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class Test &#123;  </span><br><span class=\"line\">    public static void main(String[] args) throws Exception &#123;  </span><br><span class=\"line\">      Singleton instance1 = Singleton.getInstance();  </span><br><span class=\"line\">      //通过反射创建对象  </span><br><span class=\"line\">      Class&lt;Singleton&gt; singletonClass = Singleton.class;  </span><br><span class=\"line\">      Constructor&lt;Singleton&gt; constructor = singletonClass.getDeclaredConstructor(); </span><br><span class=\"line\">      //暴力破解私有构造器------开启后才能反射创建对象</span><br><span class=\"line\">      constructor.setAccessible(true);  </span><br><span class=\"line\">      Singleton instance2 = constructor.newInstance();   </span><br><span class=\"line\">     System.out.println(instance1 == instance2);  //返回false</span><br><span class=\"line\">  &#125;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ul>\n<li>总结：反射可以破坏单例</li>\n<li>防止反射破坏序列化：修改构造器，通过构造器判断（饥汉模式无法实现）<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class Singleton &#123;</span><br><span class=\"line\">    private static volatile Singleton instance ;</span><br><span class=\"line\">    private Singleton()&#123;</span><br><span class=\"line\">        //构造器判断</span><br><span class=\"line\">        if(instance != null)&#123;</span><br><span class=\"line\">            throw new RuntimeException(&quot;不允许反射调用构造器&quot;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    public static Singleton getInstance()&#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>总结：要想实现不被破坏的单例，需要通过构造函数判断+实现readResolve方法。</p>\n<p>#四、最佳方式<br>枚举</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public enum EnumSingleton &#123;</span><br><span class=\"line\">    INSTANCE; </span><br><span class=\"line\">    public EnumSingleton getInstance()&#123; </span><br><span class=\"line\">         return INSTANCE;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>避免反射破坏单例：<br>使用反射会抛出异常</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">java.lang.NoSuchMethodException: com.jvm.SingleEnum.&lt;init&gt;()</span><br><span class=\"line\">\tat java.lang.Class.getConstructor0(Class.java:3082)</span><br><span class=\"line\">\tat java.lang.Class.getDeclaredConstructor(Class.java:2178)</span><br><span class=\"line\">\tat com.jvm.SingleEnumTest.main(SingleEnumTest.java:16)</span><br></pre></td></tr></table></figure>\n\n<p>原因</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected Enum(String name, int ordinal) &#123;</span><br><span class=\"line\">    this.name = name;</span><br><span class=\"line\">    this.ordinal = ordinal;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>枚举类的构造函数有参，无法通过子类的构造函数进行</p>\n<p>并且Constructor.newInstance进行了枚举判断，如果是枚举则抛出异常。</p>\n<ul>\n<li>避免反序列化破坏单例：<ul>\n<li>每个枚举对象都有一个唯一的name属性。序列化只是将name属性序列化，在反序列化的时候，通过创建一个Map(key,value)，搭建起name和与之对应的对象之间的联系，然后通过索引key来获得枚举对象。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"五、懒汉饥汉\"><a href=\"#五、懒汉饥汉\" class=\"headerlink\" title=\"五、懒汉饥汉\"></a>五、懒汉饥汉</h1><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">safeLazyInitialization</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Instance instance;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> <span class=\"keyword\">static</span> Instance <span class=\"title\">getInstance</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(instance ==<span class=\"keyword\">null</span>)</span><br><span class=\"line\">            instance = <span class=\"keyword\">new</span> Instance();       </span><br><span class=\"line\">        <span class=\"keyword\">return</span> instance;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>方法上添加synchronized方法，会导致性能较差，可以实现单例。</p>\n<p>优化一</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DoubleCheckedLocking</span> </span>&#123;                     <span class=\"comment\">//1</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Instance instance;                   <span class=\"comment\">//2</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span>  <span class=\"keyword\">static</span> Instance <span class=\"title\">getInstance</span><span class=\"params\">()</span></span>&#123;              <span class=\"comment\">//3</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(instance ==<span class=\"keyword\">null</span>) &#123;                           <span class=\"comment\">//4:第一次检查</span></span><br><span class=\"line\">            <span class=\"keyword\">synchronized</span> (DoubleCheckedLocking<span class=\"class\">.<span class=\"keyword\">class</span>) </span>&#123; <span class=\"comment\">//5：加锁</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (instance == <span class=\"keyword\">null</span>)                   <span class=\"comment\">//6：第二次检查</span></span><br><span class=\"line\">                    instance = <span class=\"keyword\">new</span> Instance();          <span class=\"comment\">//7：问题的根源处在这里</span></span><br><span class=\"line\">            &#125;                                           <span class=\"comment\">//8</span></span><br><span class=\"line\">        &#125;                                               <span class=\"comment\">//9</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> instance;                                <span class=\"comment\">//10</span></span><br><span class=\"line\">    &#125;                                                   <span class=\"comment\">//11</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>不对方法进行加锁，对Class对象进行加锁。但是也会出现问题。</p>\n<ul>\n<li><p>指令代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">memory=allocate();        //1:分配对象的内存空间</span><br><span class=\"line\">ctorInstance(memory);     //2:初始化对象</span><br><span class=\"line\">instance = memory;          //3:设置instance指向刚分配的内存地址</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指令重排序后</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">memory=allocate();        //1:分配对象的内存空间</span><br><span class=\"line\">instance = memory;          //3:设置instance指向刚分配的内存地址</span><br><span class=\"line\">ctorInstance(memory);     //2:初始化对象</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>问题根源</p>\n<ul>\n<li>线程1执行到第7行时，因为指令重排序，instance!=null，但是对象未进行初始化，对象信息都是初始值。</li>\n<li>线程2此时执行第4行，instance!=null，此时返回instance，因为未初始化，属性值将是初始值有问题。</li>\n</ul>\n</li>\n<li><p>为什么需要双重校验呢？</p>\n<ul>\n<li>第一层校验，提高效率</li>\n<li>如果A、B两个线程，A进入了synchronized同步代码块，此时B通过了136行的校验，阻塞在同步代码块</li>\n<li>如果没有第二层校验，那么A创建完释放锁，B进入同步代码块，没有判断的话也会创建实例，从而导致问题。</li>\n</ul>\n</li>\n</ul>\n<p>优化二</p>\n<pre><code class=\"java\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DoubleCheckedLocking</span> </span>{                     <span class=\"comment\">//1</span>\n  <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">volatile</span> Instance instance;                   <span class=\"comment\">//2</span>\n  <span class=\"function\"><span class=\"keyword\">public</span>  <span class=\"keyword\">static</span> Instance <span class=\"title\">getInstance</span><span class=\"params\">()</span></span>{              <span class=\"comment\">//3</span>\n      <span class=\"keyword\">if</span>(instance ==<span class=\"keyword\">null</span>) {                           <span class=\"comment\">//4:第一次检查</span>\n          <span class=\"keyword\">synchronized</span> (DoubleCheckedLocking<span class=\"class\">.<span class=\"keyword\">class</span>) </span>{ <span class=\"comment\">//5：加锁</span>\n              <span class=\"keyword\">if</span> (instance == <span class=\"keyword\">null</span>)                   <span class=\"comment\">//6：第二次检查</span>\n                  instance = <span class=\"keyword\">new</span> Instance();          <span class=\"comment\">//7：问题的根源处在这里</span>\n          }                                           <span class=\"comment\">//8</span>\n      }                                               <span class=\"comment\">//9</span>\n      <span class=\"keyword\">return</span> instance;                                <span class=\"comment\">//10</span>\n  }                                                   <span class=\"comment\">//11</span>\n}</code></pre>\n<p>volatile防止指令重排序。</p>"},{"title":"类加载","date":"2020-05-11T10:42:33.000Z","_content":"\n\n# 一、类的加载过程\n从类加载顺序、类加载器等方面进行讲解\n![类加载过程](2020-05-11-类加载/类加载过程.png)\n# 二、类加载顺序\n加载 -> 验证 -> 准备 -> 解析 -> 初始化\n\n加载：\n将字节码文件加载至内存。\n\n验证：\n验证字节码文件是否符合JVM规范\n\n准备：\n对类或接口的**静态变量分配空间，并默认初始值**。此时不会执行任何字节码指令。\n因为在初始化阶段，会调用显式的初始化器来初始化。\n\n解析：\n根据运行时常量池中的符号引用转化成直接引用\n解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。\n\n初始化：\n在准备阶段，已经按系统要求对静态变量分配空间和初始值，初始化过程**调用(clinit)类初始化器**\n\n一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。\n\n\n<!--more-->  \n\n## 2.1、clinit详解\nJava类加载的初始化过程，编译器会按语句在源文件出现的位置，依次自动收集类中的所有类变量的赋值动作和静态代码块，\n然后**合并产生clinit方法**；如果类中没有静态语句和静态代码块，则可以不生成。\n\n并且 clinit() 不需要显式调用父类（接口除外，接口不需要调用父接口的初始化方法，只有使用到父接口中的静态变量时才需要调用）的初始化方法 clinit()，虚拟机会保证在子类的 clinit() 方法执行之前，父类的 clinit() 方法已经执行完毕。\n\n> 虚拟机首先执行的是类加载初始化过程中的 <clinit>() 方法，也就是静态变量赋值以及静态代码块中的代码，如果 <clinit>() 方法中触发了对象的初始化，也就是 <init>() 方法，那么会进入执行 <init>() 方法，执行 <init>() 方法完成之后，再回来继续执行 <clinit>() 方法。\n\n# 三、类是生命周期\n![类生命周期](2020-05-11-类加载/类生命周期.png)\n\n\n\n# 四、热加载\n1. 实现自己的类加载器。\n2. 从自己的类加载器中加载要热加载的类。\n3. 不断轮训要热加载的类 class 文件是否有更新。\n4. 如果有更新，重新加载。\n\n> 如何判断文件是否更新?\n\n我们需要判断 class 是否进行了更新，所以我们需要记录 class 类的修改时间，以及对应的类信息。\n所以编译一个类用来记录某个类对应的某个类加载器以及上次加载的 class 的修改时间。\n\n在实现思路里，我们知道轮训检查 class 文件是不是被更新过，所以每次调用要热加载的类时，我们都要进行检查类是否被更新然后决定要不要重新加载。为了方便这步的获取操作，可以使用一个简单的工厂模式进行封装。\n\n\n# 五、双亲委派机制\nClass.loadClass()方法，内部实现了双亲委派机制。\n* 重写loadClass()方法进行定义自己的类加载器（可能会破坏双亲委派）\n* 如果不想打破双亲委派，则重写findClass()方法","source":"_posts/2020-05-11-类加载.md","raw":"---\ntitle: 类加载\ndate: 2020-05-11 18:42:33\ntags:\ncategories:\n  - [java]\n---\n\n\n# 一、类的加载过程\n从类加载顺序、类加载器等方面进行讲解\n![类加载过程](2020-05-11-类加载/类加载过程.png)\n# 二、类加载顺序\n加载 -> 验证 -> 准备 -> 解析 -> 初始化\n\n加载：\n将字节码文件加载至内存。\n\n验证：\n验证字节码文件是否符合JVM规范\n\n准备：\n对类或接口的**静态变量分配空间，并默认初始值**。此时不会执行任何字节码指令。\n因为在初始化阶段，会调用显式的初始化器来初始化。\n\n解析：\n根据运行时常量池中的符号引用转化成直接引用\n解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。\n\n初始化：\n在准备阶段，已经按系统要求对静态变量分配空间和初始值，初始化过程**调用(clinit)类初始化器**\n\n一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。\n\n\n<!--more-->  \n\n## 2.1、clinit详解\nJava类加载的初始化过程，编译器会按语句在源文件出现的位置，依次自动收集类中的所有类变量的赋值动作和静态代码块，\n然后**合并产生clinit方法**；如果类中没有静态语句和静态代码块，则可以不生成。\n\n并且 clinit() 不需要显式调用父类（接口除外，接口不需要调用父接口的初始化方法，只有使用到父接口中的静态变量时才需要调用）的初始化方法 clinit()，虚拟机会保证在子类的 clinit() 方法执行之前，父类的 clinit() 方法已经执行完毕。\n\n> 虚拟机首先执行的是类加载初始化过程中的 <clinit>() 方法，也就是静态变量赋值以及静态代码块中的代码，如果 <clinit>() 方法中触发了对象的初始化，也就是 <init>() 方法，那么会进入执行 <init>() 方法，执行 <init>() 方法完成之后，再回来继续执行 <clinit>() 方法。\n\n# 三、类是生命周期\n![类生命周期](2020-05-11-类加载/类生命周期.png)\n\n\n\n# 四、热加载\n1. 实现自己的类加载器。\n2. 从自己的类加载器中加载要热加载的类。\n3. 不断轮训要热加载的类 class 文件是否有更新。\n4. 如果有更新，重新加载。\n\n> 如何判断文件是否更新?\n\n我们需要判断 class 是否进行了更新，所以我们需要记录 class 类的修改时间，以及对应的类信息。\n所以编译一个类用来记录某个类对应的某个类加载器以及上次加载的 class 的修改时间。\n\n在实现思路里，我们知道轮训检查 class 文件是不是被更新过，所以每次调用要热加载的类时，我们都要进行检查类是否被更新然后决定要不要重新加载。为了方便这步的获取操作，可以使用一个简单的工厂模式进行封装。\n\n\n# 五、双亲委派机制\nClass.loadClass()方法，内部实现了双亲委派机制。\n* 重写loadClass()方法进行定义自己的类加载器（可能会破坏双亲委派）\n* 如果不想打破双亲委派，则重写findClass()方法","slug":"2020-05-11-类加载","published":1,"updated":"2024-12-09T03:22:02.617Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxb002va13ku9v9lnms","content":"<h1 id=\"一、类的加载过程\"><a href=\"#一、类的加载过程\" class=\"headerlink\" title=\"一、类的加载过程\"></a>一、类的加载过程</h1><p>从类加载顺序、类加载器等方面进行讲解<br><img src=\"/2020/05/11/2020-05-11-类加载/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B.png\" alt=\"类加载过程\"></p>\n<h1 id=\"二、类加载顺序\"><a href=\"#二、类加载顺序\" class=\"headerlink\" title=\"二、类加载顺序\"></a>二、类加载顺序</h1><p>加载 -&gt; 验证 -&gt; 准备 -&gt; 解析 -&gt; 初始化</p>\n<p>加载：<br>将字节码文件加载至内存。</p>\n<p>验证：<br>验证字节码文件是否符合JVM规范</p>\n<p>准备：<br>对类或接口的<strong>静态变量分配空间，并默认初始值</strong>。此时不会执行任何字节码指令。<br>因为在初始化阶段，会调用显式的初始化器来初始化。</p>\n<p>解析：<br>根据运行时常量池中的符号引用转化成直接引用<br>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。</p>\n<p>初始化：<br>在准备阶段，已经按系统要求对静态变量分配空间和初始值，初始化过程<strong>调用(clinit)类初始化器</strong></p>\n<p>一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。</p>\n<a id=\"more\"></a>  \n\n<h2 id=\"2-1、clinit详解\"><a href=\"#2-1、clinit详解\" class=\"headerlink\" title=\"2.1、clinit详解\"></a>2.1、clinit详解</h2><p>Java类加载的初始化过程，编译器会按语句在源文件出现的位置，依次自动收集类中的所有类变量的赋值动作和静态代码块，<br>然后<strong>合并产生clinit方法</strong>；如果类中没有静态语句和静态代码块，则可以不生成。</p>\n<p>并且 clinit() 不需要显式调用父类（接口除外，接口不需要调用父接口的初始化方法，只有使用到父接口中的静态变量时才需要调用）的初始化方法 clinit()，虚拟机会保证在子类的 clinit() 方法执行之前，父类的 clinit() 方法已经执行完毕。</p>\n<blockquote>\n<p>虚拟机首先执行的是类加载初始化过程中的 <clinit>() 方法，也就是静态变量赋值以及静态代码块中的代码，如果 <clinit>() 方法中触发了对象的初始化，也就是 <init>() 方法，那么会进入执行 <init>() 方法，执行 <init>() 方法完成之后，再回来继续执行 <clinit>() 方法。</clinit></init></init></init></clinit></clinit></p>\n</blockquote>\n<h1 id=\"三、类是生命周期\"><a href=\"#三、类是生命周期\" class=\"headerlink\" title=\"三、类是生命周期\"></a>三、类是生命周期</h1><p><img src=\"/2020/05/11/2020-05-11-类加载/%E7%B1%BB%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png\" alt=\"类生命周期\"></p>\n<h1 id=\"四、热加载\"><a href=\"#四、热加载\" class=\"headerlink\" title=\"四、热加载\"></a>四、热加载</h1><ol>\n<li>实现自己的类加载器。</li>\n<li>从自己的类加载器中加载要热加载的类。</li>\n<li>不断轮训要热加载的类 class 文件是否有更新。</li>\n<li>如果有更新，重新加载。</li>\n</ol>\n<blockquote>\n<p>如何判断文件是否更新?</p>\n</blockquote>\n<p>我们需要判断 class 是否进行了更新，所以我们需要记录 class 类的修改时间，以及对应的类信息。<br>所以编译一个类用来记录某个类对应的某个类加载器以及上次加载的 class 的修改时间。</p>\n<p>在实现思路里，我们知道轮训检查 class 文件是不是被更新过，所以每次调用要热加载的类时，我们都要进行检查类是否被更新然后决定要不要重新加载。为了方便这步的获取操作，可以使用一个简单的工厂模式进行封装。</p>\n<h1 id=\"五、双亲委派机制\"><a href=\"#五、双亲委派机制\" class=\"headerlink\" title=\"五、双亲委派机制\"></a>五、双亲委派机制</h1><p>Class.loadClass()方法，内部实现了双亲委派机制。</p>\n<ul>\n<li>重写loadClass()方法进行定义自己的类加载器（可能会破坏双亲委派）</li>\n<li>如果不想打破双亲委派，则重写findClass()方法</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、类的加载过程\"><a href=\"#一、类的加载过程\" class=\"headerlink\" title=\"一、类的加载过程\"></a>一、类的加载过程</h1><p>从类加载顺序、类加载器等方面进行讲解<br><img src=\"/2020/05/11/2020-05-11-类加载/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B.png\" alt=\"类加载过程\"></p>\n<h1 id=\"二、类加载顺序\"><a href=\"#二、类加载顺序\" class=\"headerlink\" title=\"二、类加载顺序\"></a>二、类加载顺序</h1><p>加载 -&gt; 验证 -&gt; 准备 -&gt; 解析 -&gt; 初始化</p>\n<p>加载：<br>将字节码文件加载至内存。</p>\n<p>验证：<br>验证字节码文件是否符合JVM规范</p>\n<p>准备：<br>对类或接口的<strong>静态变量分配空间，并默认初始值</strong>。此时不会执行任何字节码指令。<br>因为在初始化阶段，会调用显式的初始化器来初始化。</p>\n<p>解析：<br>根据运行时常量池中的符号引用转化成直接引用<br>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。</p>\n<p>初始化：<br>在准备阶段，已经按系统要求对静态变量分配空间和初始值，初始化过程<strong>调用(clinit)类初始化器</strong></p>\n<p>一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。</p>","more":"<h2 id=\"2-1、clinit详解\"><a href=\"#2-1、clinit详解\" class=\"headerlink\" title=\"2.1、clinit详解\"></a>2.1、clinit详解</h2><p>Java类加载的初始化过程，编译器会按语句在源文件出现的位置，依次自动收集类中的所有类变量的赋值动作和静态代码块，<br>然后<strong>合并产生clinit方法</strong>；如果类中没有静态语句和静态代码块，则可以不生成。</p>\n<p>并且 clinit() 不需要显式调用父类（接口除外，接口不需要调用父接口的初始化方法，只有使用到父接口中的静态变量时才需要调用）的初始化方法 clinit()，虚拟机会保证在子类的 clinit() 方法执行之前，父类的 clinit() 方法已经执行完毕。</p>\n<blockquote>\n<p>虚拟机首先执行的是类加载初始化过程中的 <clinit>() 方法，也就是静态变量赋值以及静态代码块中的代码，如果 <clinit>() 方法中触发了对象的初始化，也就是 <init>() 方法，那么会进入执行 <init>() 方法，执行 <init>() 方法完成之后，再回来继续执行 <clinit>() 方法。</clinit></init></init></init></clinit></clinit></p>\n</blockquote>\n<h1 id=\"三、类是生命周期\"><a href=\"#三、类是生命周期\" class=\"headerlink\" title=\"三、类是生命周期\"></a>三、类是生命周期</h1><p><img src=\"/2020/05/11/2020-05-11-类加载/%E7%B1%BB%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png\" alt=\"类生命周期\"></p>\n<h1 id=\"四、热加载\"><a href=\"#四、热加载\" class=\"headerlink\" title=\"四、热加载\"></a>四、热加载</h1><ol>\n<li>实现自己的类加载器。</li>\n<li>从自己的类加载器中加载要热加载的类。</li>\n<li>不断轮训要热加载的类 class 文件是否有更新。</li>\n<li>如果有更新，重新加载。</li>\n</ol>\n<blockquote>\n<p>如何判断文件是否更新?</p>\n</blockquote>\n<p>我们需要判断 class 是否进行了更新，所以我们需要记录 class 类的修改时间，以及对应的类信息。<br>所以编译一个类用来记录某个类对应的某个类加载器以及上次加载的 class 的修改时间。</p>\n<p>在实现思路里，我们知道轮训检查 class 文件是不是被更新过，所以每次调用要热加载的类时，我们都要进行检查类是否被更新然后决定要不要重新加载。为了方便这步的获取操作，可以使用一个简单的工厂模式进行封装。</p>\n<h1 id=\"五、双亲委派机制\"><a href=\"#五、双亲委派机制\" class=\"headerlink\" title=\"五、双亲委派机制\"></a>五、双亲委派机制</h1><p>Class.loadClass()方法，内部实现了双亲委派机制。</p>\n<ul>\n<li>重写loadClass()方法进行定义自己的类加载器（可能会破坏双亲委派）</li>\n<li>如果不想打破双亲委派，则重写findClass()方法</li>\n</ul>"},{"title":"泛型","date":"2020-05-15T13:38:56.000Z","_content":"# 一、什么是泛型\n什么是泛型，泛型的实现方式，泛型的问题\n# 二、泛型\nJDK1.5带入的新特性，提供了编译时类型安全检测机制。  \n编译期间就可以进行类型的检测，防止运行时出现问题。  \n\n# 三、使用方式\n```\nList<Integer> list = new ArrayList<>();\n\nlist.add(12);\n//这里直接添加会报错\nlist.add(\"a\");\nClass<? extends List> clazz = list.getClass();\nMethod add = clazz.getDeclaredMethod(\"add\", Object.class);\n//但是通过反射添加，是可以的\nadd.invoke(list, \"kl\");\n\nSystem.out.println(list)\n```\nT，E，K，V，？等来表示泛型   \n泛型类、泛型接口、泛型方法\n<!--more-->  \n# 四、实现方式\n**类型擦除：**在编译期间，所有的类型信息都将擦除。\n```\npublic class Test {\n    public static void main(String[] args) {\n        ArrayList<String> list1 = new ArrayList<String>();\n        list1.add(\"abc\");\n        ArrayList<Integer> list2 = new ArrayList<Integer>();\n        list2.add(123);\n        System.out.println(list1.getClass() == list2.getClass());\n    }\n}\n```\n程序输出结果：true   \n**说明：** 类型擦除后，list1和list2在jvm中的数据类型是一致的，String和integer都被擦除了，保留了原始类型。\n\n* 原始类型：类型擦除后，最后在字节码中类型变量的真正类型。\n* 类型擦除，并使用其限定类型（无限定类型的用Object）替换。\n\n\n[参考](https://www.cnblogs.com/wuqinglong/p/9456193.html)","source":"_posts/2020-05-15-泛型.md","raw":"---\ntitle: 泛型\ndate: 2020-05-15 21:38:56\ntags:\ncategories:\n  - [java]\n---\n# 一、什么是泛型\n什么是泛型，泛型的实现方式，泛型的问题\n# 二、泛型\nJDK1.5带入的新特性，提供了编译时类型安全检测机制。  \n编译期间就可以进行类型的检测，防止运行时出现问题。  \n\n# 三、使用方式\n```\nList<Integer> list = new ArrayList<>();\n\nlist.add(12);\n//这里直接添加会报错\nlist.add(\"a\");\nClass<? extends List> clazz = list.getClass();\nMethod add = clazz.getDeclaredMethod(\"add\", Object.class);\n//但是通过反射添加，是可以的\nadd.invoke(list, \"kl\");\n\nSystem.out.println(list)\n```\nT，E，K，V，？等来表示泛型   \n泛型类、泛型接口、泛型方法\n<!--more-->  \n# 四、实现方式\n**类型擦除：**在编译期间，所有的类型信息都将擦除。\n```\npublic class Test {\n    public static void main(String[] args) {\n        ArrayList<String> list1 = new ArrayList<String>();\n        list1.add(\"abc\");\n        ArrayList<Integer> list2 = new ArrayList<Integer>();\n        list2.add(123);\n        System.out.println(list1.getClass() == list2.getClass());\n    }\n}\n```\n程序输出结果：true   \n**说明：** 类型擦除后，list1和list2在jvm中的数据类型是一致的，String和integer都被擦除了，保留了原始类型。\n\n* 原始类型：类型擦除后，最后在字节码中类型变量的真正类型。\n* 类型擦除，并使用其限定类型（无限定类型的用Object）替换。\n\n\n[参考](https://www.cnblogs.com/wuqinglong/p/9456193.html)","slug":"2020-05-15-泛型","published":1,"updated":"2024-12-09T03:22:02.658Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxc002ya13kalnvsyh1","content":"<h1 id=\"一、什么是泛型\"><a href=\"#一、什么是泛型\" class=\"headerlink\" title=\"一、什么是泛型\"></a>一、什么是泛型</h1><p>什么是泛型，泛型的实现方式，泛型的问题</p>\n<h1 id=\"二、泛型\"><a href=\"#二、泛型\" class=\"headerlink\" title=\"二、泛型\"></a>二、泛型</h1><p>JDK1.5带入的新特性，提供了编译时类型安全检测机制。<br>编译期间就可以进行类型的检测，防止运行时出现问题。  </p>\n<h1 id=\"三、使用方式\"><a href=\"#三、使用方式\" class=\"headerlink\" title=\"三、使用方式\"></a>三、使用方式</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Integer&gt; list = new ArrayList&lt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">list.add(12);</span><br><span class=\"line\">//这里直接添加会报错</span><br><span class=\"line\">list.add(&quot;a&quot;);</span><br><span class=\"line\">Class&lt;? extends List&gt; clazz = list.getClass();</span><br><span class=\"line\">Method add = clazz.getDeclaredMethod(&quot;add&quot;, Object.class);</span><br><span class=\"line\">//但是通过反射添加，是可以的</span><br><span class=\"line\">add.invoke(list, &quot;kl&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">System.out.println(list)</span><br></pre></td></tr></table></figure>\n\n<p>T，E，K，V，？等来表示泛型<br>泛型类、泛型接口、泛型方法</p>\n<a id=\"more\"></a>  \n<h1 id=\"四、实现方式\"><a href=\"#四、实现方式\" class=\"headerlink\" title=\"四、实现方式\"></a>四、实现方式</h1><p><strong>类型擦除：</strong>在编译期间，所有的类型信息都将擦除。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class Test &#123;</span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;();</span><br><span class=\"line\">        list1.add(&quot;abc&quot;);</span><br><span class=\"line\">        ArrayList&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">        list2.add(123);</span><br><span class=\"line\">        System.out.println(list1.getClass() == list2.getClass());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>程序输出结果：true<br><strong>说明：</strong> 类型擦除后，list1和list2在jvm中的数据类型是一致的，String和integer都被擦除了，保留了原始类型。</p>\n<ul>\n<li>原始类型：类型擦除后，最后在字节码中类型变量的真正类型。</li>\n<li>类型擦除，并使用其限定类型（无限定类型的用Object）替换。</li>\n</ul>\n<p><a href=\"https://www.cnblogs.com/wuqinglong/p/9456193.html\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、什么是泛型\"><a href=\"#一、什么是泛型\" class=\"headerlink\" title=\"一、什么是泛型\"></a>一、什么是泛型</h1><p>什么是泛型，泛型的实现方式，泛型的问题</p>\n<h1 id=\"二、泛型\"><a href=\"#二、泛型\" class=\"headerlink\" title=\"二、泛型\"></a>二、泛型</h1><p>JDK1.5带入的新特性，提供了编译时类型安全检测机制。<br>编译期间就可以进行类型的检测，防止运行时出现问题。  </p>\n<h1 id=\"三、使用方式\"><a href=\"#三、使用方式\" class=\"headerlink\" title=\"三、使用方式\"></a>三、使用方式</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Integer&gt; list = new ArrayList&lt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">list.add(12);</span><br><span class=\"line\">//这里直接添加会报错</span><br><span class=\"line\">list.add(&quot;a&quot;);</span><br><span class=\"line\">Class&lt;? extends List&gt; clazz = list.getClass();</span><br><span class=\"line\">Method add = clazz.getDeclaredMethod(&quot;add&quot;, Object.class);</span><br><span class=\"line\">//但是通过反射添加，是可以的</span><br><span class=\"line\">add.invoke(list, &quot;kl&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">System.out.println(list)</span><br></pre></td></tr></table></figure>\n\n<p>T，E，K，V，？等来表示泛型<br>泛型类、泛型接口、泛型方法</p>","more":"<h1 id=\"四、实现方式\"><a href=\"#四、实现方式\" class=\"headerlink\" title=\"四、实现方式\"></a>四、实现方式</h1><p><strong>类型擦除：</strong>在编译期间，所有的类型信息都将擦除。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class Test &#123;</span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;();</span><br><span class=\"line\">        list1.add(&quot;abc&quot;);</span><br><span class=\"line\">        ArrayList&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">        list2.add(123);</span><br><span class=\"line\">        System.out.println(list1.getClass() == list2.getClass());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>程序输出结果：true<br><strong>说明：</strong> 类型擦除后，list1和list2在jvm中的数据类型是一致的，String和integer都被擦除了，保留了原始类型。</p>\n<ul>\n<li>原始类型：类型擦除后，最后在字节码中类型变量的真正类型。</li>\n<li>类型擦除，并使用其限定类型（无限定类型的用Object）替换。</li>\n</ul>\n<p><a href=\"https://www.cnblogs.com/wuqinglong/p/9456193.html\" target=\"_blank\" rel=\"noopener\">参考</a></p>"},{"title":"es","date":"2020-06-01T12:34:59.000Z","_content":"\n\n# 一、时间问题\n将一个时间字符按不同时区来解释，得到的data数据是不同的\n```\nString timeStr = \"2017-8-24 11:17:10\"; // 字面时间\nSimpleDateFormat bjSdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\nbjSdf.setTimeZone(TimeZone.getTimeZone(\"Asia/Shanghai\"));\nDate bjDate = bjSdf.parse(timeStr);  // 解析\nSystem.out.println(\"字面时间: \" + timeStr +\",按北京时间来解释:\" + bjSdf.format(bjDate) + \", \" + bjDate.getTime());\n \nSimpleDateFormat tokyoSdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");  // 东京\ntokyoSdf.setTimeZone(TimeZone.getTimeZone(\"Asia/Tokyo\"));  // 设置东京时区\nDate tokyoDate = tokyoSdf.parse(timeStr); // 解析\nSystem.out.println(\"字面时间: \" + timeStr +\",按东京时间来解释:\"  + tokyoSdf.format(tokyoDate) + \", \" + tokyoDate.getTime());\n```\n输出为：   \n* 字面时间: 2017-8-24 11:17:10,按北京时间来解释:2017-08-24 11:17:10, 1503544630000\n* 字面时间: 2017-8-24 11:17:10,按东京时间来解释:2017-08-24 11:17:10, 1503541030000\n\n一个字符串时间，按不同时区解析，得到的毫秒数是不一样的。  \nES中默认时区是UTC，如果北京时间2017-8-23 11:17:10存入es中，那么会按UTC时区解析，那么实际存储到ES中的时间是会小8小时的，然后再把毫秒数按北京时区解析，自然就少了8小时。这就是ES的时区问题。\n\n<!--more-->  \n\n# 二、架构\n集群架构：多个节点，主从架构。\n![集群架构](2020-06-01-es/集群架构.png)\n数据逻辑结构：\n![数据逻辑结构](2020-06-01-es/数据逻辑结构.png)\n存储目录结构图：\n![存储目录结构图](2020-06-01-es/存储目录结构图.png)\n1. index包含多个shard。\n2. primary shard的数量在创建索引的时候就固定了，因为索引时，需要按照primary shard的数量为文档做路由（默认使用文档的_id属性取哈希值做路由，也可以通过routing指定使用其他文档字段取哈希值做路由）。replica shard的数量可以随时修改。\n3. primary shard不能和自己的replica shard放在同一个节点上（否则节点宕机，primary shard和副本都丢失，起不到容错的作用），但是可以和其他primary shard的replica shard放在同一个节点上。\n\n\n## 分片：shard\n1. 什么是分片？\n    * 索引数据过大时，单机无法存储，对索引数据进行切割，索引可以确定切割几片，切成的每一块就叫切片。\n    * 然后为了切片的高可用，然后采用了副本的方式，每个切片可以确定副本的数量，副本不能和主分片存储在同一台机器。\n\n\n# 三、选举\n## 1、ES是如何实现Master选举的\n1. 对所有可以成为master的节点(node.master:true)根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master，否则重新选举一直到满足上述条件。\n    * 补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。\n    \n## 2、脑裂如何避免\n 当集群master候选数量不少于3个时，可以通过设置最少投票数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题。当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。\n\n\n\n# 四、倒排索引\n## 1. 什么是倒排索引？\n![倒排索引](2020-06-01-es/倒排索引.png)\n记录的是单词存在的文档ID列表。\n\n### 倒排索引组成\n倒排文件 + 单词词典\n![倒排索引组成](2020-06-01-es/倒排索引组成.png)\n1. 单词词典（Term Dictionary）：搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。\n    * 如何快速定位单词呢？使用什么数据类型？\n    * 方式1：数组+ 链表\n    * 方式2：B或B+树\n2. 倒排列表(PostingList)：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息及频率（作关联性算分），每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。\n3. 倒排文件(Inverted File)：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。\n\n## 2. 正排索引\n![正排索引](2020-06-01-es/正排索引.png)\n用ID建立索引，保存ID所对应的文档内容等数据。\n\n\n\n\n# 五、Elasticsearch写人数据的过程 \n## 1、Elasticsearch写人数据的过程\n1. 客户端选择一个node发送请求过去，这个node就是coordinating node（协调节点）\n2. coordinating node，对document进行路由，将请求转发给对应的node（有primary shard）\n3. 实际的node上的primary shard处理请求，然后将数据同步到replica node\n4. coordinating node，如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端\n\n## 2、Elasticsearch写数据的底层原理\n 1. 数据先写入到buffer里面，在buffer里面的数据时搜索不到的，同时将数据写入到translog日志文件之中\n 2. 如果buffer快满了，或是一段时间之后，就会将buffer数据refresh到一个新的OS cache之中，然后每隔1秒，就会将OS cache的数据写入到segment file之中，\n 但是如果每一秒钟没有新的数据到buffer之中，就会创建一个新的空的segment file，只要buffer中的数据被refresh到OS cache之中，就代表这个数据可以被搜索到了。\n 当然可以通过restful api 和Java api，手动的执行一次refresh操作，就是手动的将buffer中的数据刷入到OS cache之中，让数据立马搜索到，只要数据被输入到OS cache之中，buffer的内容就会被清空了。\n 同时进行的是，数据到shard之后，就会将数据写入到translog之中，每隔5秒将translog之中的数据持久化到磁盘之中\n 3. 重复以上的操作，每次一条数据写入buffer，同时会写入一条日志到translog日志文件之中去，这个translog文件会不断的变大，当达到一定的程度之后，就会触发commit操作。\n 4. 将一个commit point写入到磁盘文件，里面标识着这个commit point 对应的所有segment file\n 5. 强行将OS cache 之中的数据都fsync到磁盘文件中去。\n    * 解释：translog的作用：在执行commit之前，所有的而数据都是停留在buffer或OS cache之中，无论buffer或OS cache都是内存，一旦这台机器死了，内存的数据就会丢失，所以需要将数据对应的操作写入一个专门的日志问价之中，一旦机器出现宕机，再次重启的时候，es会主动的读取translog之中的日志文件的数据，恢复到内存buffer和OS cache之中。\n 6. 将现有的translog文件进行清空，然后在重新启动一个translog，此时commit就算是成功了，默认的是每隔30分钟进行一次commit，但是如果translog的文件过大，也会触发commit，整个commit过程就叫做一个flush操作，我们也可以通过ES API,手动执行flush操作，手动将OS cache 的数据fsync到磁盘上面去，记录一个commit point，清空translog文件\n    * 补充：其实translog的数据也是先写入到OS cache之中的，默认每隔5秒之中将数据刷新到硬盘中去，也就是说，可能有5秒的数据仅仅停留在buffer或者translog文件的OS cache中，如果此时机器挂了，会丢失5秒的数据，但是这样的性能比较好，我们也可以将每次的操作都必须是直接fsync到磁盘，但是性能会比较差。\n 7. 如果时删除操作，commit的时候会产生一个.del文件，里面讲某个doc标记为delete状态，那么搜索的时候，会根据.del文件的状态，就知道那个文件被删除了。\n 8. 如果时更新操作，就是讲原来的doc标识为delete状态，然后重新写入一条数据即可。\n 9. buffer每次更新一次，就会产生一个segment file 文件，所以在默认情况之下，就会产生很多的segment file 文件，将会定期执行merge操作\n 10. 每次merge的时候，就会将多个segment file 文件进行合并为一个，同时将标记为delete的文件进行删除，然后将新的segment file 文件写入到磁盘，这里会写一个commit point，标识所有的新的segment file，然后打开新的segment file供搜索使用。\n\n总之，segment的四个核心概念，refresh，flush，translog、merge\n\n### 总结：\n1. 和MySQL类似，日志先行，先将数据写入到日志文件。\n2. 而后是写入磁盘，将缓冲数据写入刷入磁盘。（有个顺序，先刷入os cache，再有os决定什么时候刷入磁盘；或者强制刷入flush）\n3. 然后是日志文件的刷入磁盘，和缓冲数据是一样的。\n4. 每插入一条数据，都会生成一个segment文件，需要对segment文件进行merge操作。\n\n# 六、Elasticsearch读取数据的过程 \n## 1、Elasticsearch读取数据的过程\n1. 客户端发送请求到任意⼀个node，成为coordinate node\n2. coordinate node对document进⾏路由，将请求转发到对应的node，此时会使⽤round-robin随机\n轮询算法，在primary shard以及其所有replica中随机选择⼀个，让读请求负载均衡\n3. 接收请求的node返回document给coordinate node\n4. coordinate node返回document给客户端\n    1. 写⼊document时，每个document会⾃动分配⼀个全局唯⼀的id即doc id，同时也是根据doc id进 ⾏hash路由到对应的primary shard上。也可以⼿动指定doc id，⽐如⽤订单id，⽤户id。\n    2. 读取document时，你可以通过doc id来查询，然后会根据doc id进⾏hash，判断出来当时把doc\nid分配到了哪个shard上⾯去，从那个shard去查询\n\n* 这里的读，是指读某个具体的数据。\n### 总结\n1. 根据具体的数据，可以具体的路由到具体的node\n2. 然后读取node的分片，从分片中获取数据\n\n## 2、Elasticsearch搜索数据过程\n1. 客户端发送一个请求给coordinate node\n2. 协调节点将搜索的请求转发给所有的shard对应的primary shard 或replica shard\n3. query phase：每一个shard 将自己搜索的结果（其实也就是一些唯一标识），返回给协调节点，有协调节点进行数据的合并，排序，分页等操作，产出最后的结果\n4. fetch phase ，接着由协调节点，根据唯一标识去各个节点进行拉去数据，最总返回给客户端\n\n* 搜索，指的是用某些分词去获取所有的数据\n### 总结\n1. 根据请求，找到任意一个集群节点node（作为协调节点）\n2. 然后将请求分发给所有的分片。\n2. 聚合后返回结果。\n\n[ES参考](https://segmentfault.com/a/1190000015256970)\n\n\n\n\n\n\n","source":"_posts/2020-06-01-es.md","raw":"---\ntitle: es\ndate: 2020-06-01 20:34:59\ntags: es\ncategories: ES\n---\n\n\n# 一、时间问题\n将一个时间字符按不同时区来解释，得到的data数据是不同的\n```\nString timeStr = \"2017-8-24 11:17:10\"; // 字面时间\nSimpleDateFormat bjSdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\nbjSdf.setTimeZone(TimeZone.getTimeZone(\"Asia/Shanghai\"));\nDate bjDate = bjSdf.parse(timeStr);  // 解析\nSystem.out.println(\"字面时间: \" + timeStr +\",按北京时间来解释:\" + bjSdf.format(bjDate) + \", \" + bjDate.getTime());\n \nSimpleDateFormat tokyoSdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");  // 东京\ntokyoSdf.setTimeZone(TimeZone.getTimeZone(\"Asia/Tokyo\"));  // 设置东京时区\nDate tokyoDate = tokyoSdf.parse(timeStr); // 解析\nSystem.out.println(\"字面时间: \" + timeStr +\",按东京时间来解释:\"  + tokyoSdf.format(tokyoDate) + \", \" + tokyoDate.getTime());\n```\n输出为：   \n* 字面时间: 2017-8-24 11:17:10,按北京时间来解释:2017-08-24 11:17:10, 1503544630000\n* 字面时间: 2017-8-24 11:17:10,按东京时间来解释:2017-08-24 11:17:10, 1503541030000\n\n一个字符串时间，按不同时区解析，得到的毫秒数是不一样的。  \nES中默认时区是UTC，如果北京时间2017-8-23 11:17:10存入es中，那么会按UTC时区解析，那么实际存储到ES中的时间是会小8小时的，然后再把毫秒数按北京时区解析，自然就少了8小时。这就是ES的时区问题。\n\n<!--more-->  \n\n# 二、架构\n集群架构：多个节点，主从架构。\n![集群架构](2020-06-01-es/集群架构.png)\n数据逻辑结构：\n![数据逻辑结构](2020-06-01-es/数据逻辑结构.png)\n存储目录结构图：\n![存储目录结构图](2020-06-01-es/存储目录结构图.png)\n1. index包含多个shard。\n2. primary shard的数量在创建索引的时候就固定了，因为索引时，需要按照primary shard的数量为文档做路由（默认使用文档的_id属性取哈希值做路由，也可以通过routing指定使用其他文档字段取哈希值做路由）。replica shard的数量可以随时修改。\n3. primary shard不能和自己的replica shard放在同一个节点上（否则节点宕机，primary shard和副本都丢失，起不到容错的作用），但是可以和其他primary shard的replica shard放在同一个节点上。\n\n\n## 分片：shard\n1. 什么是分片？\n    * 索引数据过大时，单机无法存储，对索引数据进行切割，索引可以确定切割几片，切成的每一块就叫切片。\n    * 然后为了切片的高可用，然后采用了副本的方式，每个切片可以确定副本的数量，副本不能和主分片存储在同一台机器。\n\n\n# 三、选举\n## 1、ES是如何实现Master选举的\n1. 对所有可以成为master的节点(node.master:true)根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master，否则重新选举一直到满足上述条件。\n    * 补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。\n    \n## 2、脑裂如何避免\n 当集群master候选数量不少于3个时，可以通过设置最少投票数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题。当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。\n\n\n\n# 四、倒排索引\n## 1. 什么是倒排索引？\n![倒排索引](2020-06-01-es/倒排索引.png)\n记录的是单词存在的文档ID列表。\n\n### 倒排索引组成\n倒排文件 + 单词词典\n![倒排索引组成](2020-06-01-es/倒排索引组成.png)\n1. 单词词典（Term Dictionary）：搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。\n    * 如何快速定位单词呢？使用什么数据类型？\n    * 方式1：数组+ 链表\n    * 方式2：B或B+树\n2. 倒排列表(PostingList)：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息及频率（作关联性算分），每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。\n3. 倒排文件(Inverted File)：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。\n\n## 2. 正排索引\n![正排索引](2020-06-01-es/正排索引.png)\n用ID建立索引，保存ID所对应的文档内容等数据。\n\n\n\n\n# 五、Elasticsearch写人数据的过程 \n## 1、Elasticsearch写人数据的过程\n1. 客户端选择一个node发送请求过去，这个node就是coordinating node（协调节点）\n2. coordinating node，对document进行路由，将请求转发给对应的node（有primary shard）\n3. 实际的node上的primary shard处理请求，然后将数据同步到replica node\n4. coordinating node，如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端\n\n## 2、Elasticsearch写数据的底层原理\n 1. 数据先写入到buffer里面，在buffer里面的数据时搜索不到的，同时将数据写入到translog日志文件之中\n 2. 如果buffer快满了，或是一段时间之后，就会将buffer数据refresh到一个新的OS cache之中，然后每隔1秒，就会将OS cache的数据写入到segment file之中，\n 但是如果每一秒钟没有新的数据到buffer之中，就会创建一个新的空的segment file，只要buffer中的数据被refresh到OS cache之中，就代表这个数据可以被搜索到了。\n 当然可以通过restful api 和Java api，手动的执行一次refresh操作，就是手动的将buffer中的数据刷入到OS cache之中，让数据立马搜索到，只要数据被输入到OS cache之中，buffer的内容就会被清空了。\n 同时进行的是，数据到shard之后，就会将数据写入到translog之中，每隔5秒将translog之中的数据持久化到磁盘之中\n 3. 重复以上的操作，每次一条数据写入buffer，同时会写入一条日志到translog日志文件之中去，这个translog文件会不断的变大，当达到一定的程度之后，就会触发commit操作。\n 4. 将一个commit point写入到磁盘文件，里面标识着这个commit point 对应的所有segment file\n 5. 强行将OS cache 之中的数据都fsync到磁盘文件中去。\n    * 解释：translog的作用：在执行commit之前，所有的而数据都是停留在buffer或OS cache之中，无论buffer或OS cache都是内存，一旦这台机器死了，内存的数据就会丢失，所以需要将数据对应的操作写入一个专门的日志问价之中，一旦机器出现宕机，再次重启的时候，es会主动的读取translog之中的日志文件的数据，恢复到内存buffer和OS cache之中。\n 6. 将现有的translog文件进行清空，然后在重新启动一个translog，此时commit就算是成功了，默认的是每隔30分钟进行一次commit，但是如果translog的文件过大，也会触发commit，整个commit过程就叫做一个flush操作，我们也可以通过ES API,手动执行flush操作，手动将OS cache 的数据fsync到磁盘上面去，记录一个commit point，清空translog文件\n    * 补充：其实translog的数据也是先写入到OS cache之中的，默认每隔5秒之中将数据刷新到硬盘中去，也就是说，可能有5秒的数据仅仅停留在buffer或者translog文件的OS cache中，如果此时机器挂了，会丢失5秒的数据，但是这样的性能比较好，我们也可以将每次的操作都必须是直接fsync到磁盘，但是性能会比较差。\n 7. 如果时删除操作，commit的时候会产生一个.del文件，里面讲某个doc标记为delete状态，那么搜索的时候，会根据.del文件的状态，就知道那个文件被删除了。\n 8. 如果时更新操作，就是讲原来的doc标识为delete状态，然后重新写入一条数据即可。\n 9. buffer每次更新一次，就会产生一个segment file 文件，所以在默认情况之下，就会产生很多的segment file 文件，将会定期执行merge操作\n 10. 每次merge的时候，就会将多个segment file 文件进行合并为一个，同时将标记为delete的文件进行删除，然后将新的segment file 文件写入到磁盘，这里会写一个commit point，标识所有的新的segment file，然后打开新的segment file供搜索使用。\n\n总之，segment的四个核心概念，refresh，flush，translog、merge\n\n### 总结：\n1. 和MySQL类似，日志先行，先将数据写入到日志文件。\n2. 而后是写入磁盘，将缓冲数据写入刷入磁盘。（有个顺序，先刷入os cache，再有os决定什么时候刷入磁盘；或者强制刷入flush）\n3. 然后是日志文件的刷入磁盘，和缓冲数据是一样的。\n4. 每插入一条数据，都会生成一个segment文件，需要对segment文件进行merge操作。\n\n# 六、Elasticsearch读取数据的过程 \n## 1、Elasticsearch读取数据的过程\n1. 客户端发送请求到任意⼀个node，成为coordinate node\n2. coordinate node对document进⾏路由，将请求转发到对应的node，此时会使⽤round-robin随机\n轮询算法，在primary shard以及其所有replica中随机选择⼀个，让读请求负载均衡\n3. 接收请求的node返回document给coordinate node\n4. coordinate node返回document给客户端\n    1. 写⼊document时，每个document会⾃动分配⼀个全局唯⼀的id即doc id，同时也是根据doc id进 ⾏hash路由到对应的primary shard上。也可以⼿动指定doc id，⽐如⽤订单id，⽤户id。\n    2. 读取document时，你可以通过doc id来查询，然后会根据doc id进⾏hash，判断出来当时把doc\nid分配到了哪个shard上⾯去，从那个shard去查询\n\n* 这里的读，是指读某个具体的数据。\n### 总结\n1. 根据具体的数据，可以具体的路由到具体的node\n2. 然后读取node的分片，从分片中获取数据\n\n## 2、Elasticsearch搜索数据过程\n1. 客户端发送一个请求给coordinate node\n2. 协调节点将搜索的请求转发给所有的shard对应的primary shard 或replica shard\n3. query phase：每一个shard 将自己搜索的结果（其实也就是一些唯一标识），返回给协调节点，有协调节点进行数据的合并，排序，分页等操作，产出最后的结果\n4. fetch phase ，接着由协调节点，根据唯一标识去各个节点进行拉去数据，最总返回给客户端\n\n* 搜索，指的是用某些分词去获取所有的数据\n### 总结\n1. 根据请求，找到任意一个集群节点node（作为协调节点）\n2. 然后将请求分发给所有的分片。\n2. 聚合后返回结果。\n\n[ES参考](https://segmentfault.com/a/1190000015256970)\n\n\n\n\n\n\n","slug":"2020-06-01-es","published":1,"updated":"2024-10-14T09:38:12.303Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxf0032a13k3zyubj0u","content":"<h1 id=\"一、时间问题\"><a href=\"#一、时间问题\" class=\"headerlink\" title=\"一、时间问题\"></a>一、时间问题</h1><p>将一个时间字符按不同时区来解释，得到的data数据是不同的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String timeStr = &quot;2017-8-24 11:17:10&quot;; // 字面时间</span><br><span class=\"line\">SimpleDateFormat bjSdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);</span><br><span class=\"line\">bjSdf.setTimeZone(TimeZone.getTimeZone(&quot;Asia/Shanghai&quot;));</span><br><span class=\"line\">Date bjDate = bjSdf.parse(timeStr);  // 解析</span><br><span class=\"line\">System.out.println(&quot;字面时间: &quot; + timeStr +&quot;,按北京时间来解释:&quot; + bjSdf.format(bjDate) + &quot;, &quot; + bjDate.getTime());</span><br><span class=\"line\"> </span><br><span class=\"line\">SimpleDateFormat tokyoSdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);  // 东京</span><br><span class=\"line\">tokyoSdf.setTimeZone(TimeZone.getTimeZone(&quot;Asia/Tokyo&quot;));  // 设置东京时区</span><br><span class=\"line\">Date tokyoDate = tokyoSdf.parse(timeStr); // 解析</span><br><span class=\"line\">System.out.println(&quot;字面时间: &quot; + timeStr +&quot;,按东京时间来解释:&quot;  + tokyoSdf.format(tokyoDate) + &quot;, &quot; + tokyoDate.getTime());</span><br></pre></td></tr></table></figure>\n\n<p>输出为：   </p>\n<ul>\n<li>字面时间: 2017-8-24 11:17:10,按北京时间来解释:2017-08-24 11:17:10, 1503544630000</li>\n<li>字面时间: 2017-8-24 11:17:10,按东京时间来解释:2017-08-24 11:17:10, 1503541030000</li>\n</ul>\n<p>一个字符串时间，按不同时区解析，得到的毫秒数是不一样的。<br>ES中默认时区是UTC，如果北京时间2017-8-23 11:17:10存入es中，那么会按UTC时区解析，那么实际存储到ES中的时间是会小8小时的，然后再把毫秒数按北京时区解析，自然就少了8小时。这就是ES的时区问题。</p>\n<a id=\"more\"></a>  \n\n<h1 id=\"二、架构\"><a href=\"#二、架构\" class=\"headerlink\" title=\"二、架构\"></a>二、架构</h1><p>集群架构：多个节点，主从架构。<br><img src=\"/2020/06/01/2020-06-01-es/%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.png\" alt=\"集群架构\"><br>数据逻辑结构：<br><img src=\"/2020/06/01/2020-06-01-es/%E6%95%B0%E6%8D%AE%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84.png\" alt=\"数据逻辑结构\"><br>存储目录结构图：<br><img src=\"/2020/06/01/2020-06-01-es/%E5%AD%98%E5%82%A8%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%9B%BE.png\" alt=\"存储目录结构图\"></p>\n<ol>\n<li>index包含多个shard。</li>\n<li>primary shard的数量在创建索引的时候就固定了，因为索引时，需要按照primary shard的数量为文档做路由（默认使用文档的_id属性取哈希值做路由，也可以通过routing指定使用其他文档字段取哈希值做路由）。replica shard的数量可以随时修改。</li>\n<li>primary shard不能和自己的replica shard放在同一个节点上（否则节点宕机，primary shard和副本都丢失，起不到容错的作用），但是可以和其他primary shard的replica shard放在同一个节点上。</li>\n</ol>\n<h2 id=\"分片：shard\"><a href=\"#分片：shard\" class=\"headerlink\" title=\"分片：shard\"></a>分片：shard</h2><ol>\n<li>什么是分片？<ul>\n<li>索引数据过大时，单机无法存储，对索引数据进行切割，索引可以确定切割几片，切成的每一块就叫切片。</li>\n<li>然后为了切片的高可用，然后采用了副本的方式，每个切片可以确定副本的数量，副本不能和主分片存储在同一台机器。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"三、选举\"><a href=\"#三、选举\" class=\"headerlink\" title=\"三、选举\"></a>三、选举</h1><h2 id=\"1、ES是如何实现Master选举的\"><a href=\"#1、ES是如何实现Master选举的\" class=\"headerlink\" title=\"1、ES是如何实现Master选举的\"></a>1、ES是如何实现Master选举的</h2><ol>\n<li>对所有可以成为master的节点(node.master:true)根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master，否则重新选举一直到满足上述条件。<ul>\n<li>补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"2、脑裂如何避免\"><a href=\"#2、脑裂如何避免\" class=\"headerlink\" title=\"2、脑裂如何避免\"></a>2、脑裂如何避免</h2><p> 当集群master候选数量不少于3个时，可以通过设置最少投票数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题。当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。</p>\n<h1 id=\"四、倒排索引\"><a href=\"#四、倒排索引\" class=\"headerlink\" title=\"四、倒排索引\"></a>四、倒排索引</h1><h2 id=\"1-什么是倒排索引？\"><a href=\"#1-什么是倒排索引？\" class=\"headerlink\" title=\"1. 什么是倒排索引？\"></a>1. 什么是倒排索引？</h2><p><img src=\"/2020/06/01/2020-06-01-es/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.png\" alt=\"倒排索引\"><br>记录的是单词存在的文档ID列表。</p>\n<h3 id=\"倒排索引组成\"><a href=\"#倒排索引组成\" class=\"headerlink\" title=\"倒排索引组成\"></a>倒排索引组成</h3><p>倒排文件 + 单词词典<br><img src=\"/2020/06/01/2020-06-01-es/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E7%BB%84%E6%88%90.png\" alt=\"倒排索引组成\"></p>\n<ol>\n<li>单词词典（Term Dictionary）：搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。<ul>\n<li>如何快速定位单词呢？使用什么数据类型？</li>\n<li>方式1：数组+ 链表</li>\n<li>方式2：B或B+树</li>\n</ul>\n</li>\n<li>倒排列表(PostingList)：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息及频率（作关联性算分），每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。</li>\n<li>倒排文件(Inverted File)：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。</li>\n</ol>\n<h2 id=\"2-正排索引\"><a href=\"#2-正排索引\" class=\"headerlink\" title=\"2. 正排索引\"></a>2. 正排索引</h2><p><img src=\"/2020/06/01/2020-06-01-es/%E6%AD%A3%E6%8E%92%E7%B4%A2%E5%BC%95.png\" alt=\"正排索引\"><br>用ID建立索引，保存ID所对应的文档内容等数据。</p>\n<h1 id=\"五、Elasticsearch写人数据的过程\"><a href=\"#五、Elasticsearch写人数据的过程\" class=\"headerlink\" title=\"五、Elasticsearch写人数据的过程\"></a>五、Elasticsearch写人数据的过程</h1><h2 id=\"1、Elasticsearch写人数据的过程\"><a href=\"#1、Elasticsearch写人数据的过程\" class=\"headerlink\" title=\"1、Elasticsearch写人数据的过程\"></a>1、Elasticsearch写人数据的过程</h2><ol>\n<li>客户端选择一个node发送请求过去，这个node就是coordinating node（协调节点）</li>\n<li>coordinating node，对document进行路由，将请求转发给对应的node（有primary shard）</li>\n<li>实际的node上的primary shard处理请求，然后将数据同步到replica node</li>\n<li>coordinating node，如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端</li>\n</ol>\n<h2 id=\"2、Elasticsearch写数据的底层原理\"><a href=\"#2、Elasticsearch写数据的底层原理\" class=\"headerlink\" title=\"2、Elasticsearch写数据的底层原理\"></a>2、Elasticsearch写数据的底层原理</h2><ol>\n<li>数据先写入到buffer里面，在buffer里面的数据时搜索不到的，同时将数据写入到translog日志文件之中</li>\n<li>如果buffer快满了，或是一段时间之后，就会将buffer数据refresh到一个新的OS cache之中，然后每隔1秒，就会将OS cache的数据写入到segment file之中，<br>但是如果每一秒钟没有新的数据到buffer之中，就会创建一个新的空的segment file，只要buffer中的数据被refresh到OS cache之中，就代表这个数据可以被搜索到了。<br>当然可以通过restful api 和Java api，手动的执行一次refresh操作，就是手动的将buffer中的数据刷入到OS cache之中，让数据立马搜索到，只要数据被输入到OS cache之中，buffer的内容就会被清空了。<br>同时进行的是，数据到shard之后，就会将数据写入到translog之中，每隔5秒将translog之中的数据持久化到磁盘之中</li>\n<li>重复以上的操作，每次一条数据写入buffer，同时会写入一条日志到translog日志文件之中去，这个translog文件会不断的变大，当达到一定的程度之后，就会触发commit操作。</li>\n<li>将一个commit point写入到磁盘文件，里面标识着这个commit point 对应的所有segment file</li>\n<li>强行将OS cache 之中的数据都fsync到磁盘文件中去。<ul>\n<li>解释：translog的作用：在执行commit之前，所有的而数据都是停留在buffer或OS cache之中，无论buffer或OS cache都是内存，一旦这台机器死了，内存的数据就会丢失，所以需要将数据对应的操作写入一个专门的日志问价之中，一旦机器出现宕机，再次重启的时候，es会主动的读取translog之中的日志文件的数据，恢复到内存buffer和OS cache之中。</li>\n</ul>\n</li>\n<li>将现有的translog文件进行清空，然后在重新启动一个translog，此时commit就算是成功了，默认的是每隔30分钟进行一次commit，但是如果translog的文件过大，也会触发commit，整个commit过程就叫做一个flush操作，我们也可以通过ES API,手动执行flush操作，手动将OS cache 的数据fsync到磁盘上面去，记录一个commit point，清空translog文件<ul>\n<li>补充：其实translog的数据也是先写入到OS cache之中的，默认每隔5秒之中将数据刷新到硬盘中去，也就是说，可能有5秒的数据仅仅停留在buffer或者translog文件的OS cache中，如果此时机器挂了，会丢失5秒的数据，但是这样的性能比较好，我们也可以将每次的操作都必须是直接fsync到磁盘，但是性能会比较差。</li>\n</ul>\n</li>\n<li>如果时删除操作，commit的时候会产生一个.del文件，里面讲某个doc标记为delete状态，那么搜索的时候，会根据.del文件的状态，就知道那个文件被删除了。</li>\n<li>如果时更新操作，就是讲原来的doc标识为delete状态，然后重新写入一条数据即可。</li>\n<li>buffer每次更新一次，就会产生一个segment file 文件，所以在默认情况之下，就会产生很多的segment file 文件，将会定期执行merge操作</li>\n<li>每次merge的时候，就会将多个segment file 文件进行合并为一个，同时将标记为delete的文件进行删除，然后将新的segment file 文件写入到磁盘，这里会写一个commit point，标识所有的新的segment file，然后打开新的segment file供搜索使用。</li>\n</ol>\n<p>总之，segment的四个核心概念，refresh，flush，translog、merge</p>\n<h3 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h3><ol>\n<li>和MySQL类似，日志先行，先将数据写入到日志文件。</li>\n<li>而后是写入磁盘，将缓冲数据写入刷入磁盘。（有个顺序，先刷入os cache，再有os决定什么时候刷入磁盘；或者强制刷入flush）</li>\n<li>然后是日志文件的刷入磁盘，和缓冲数据是一样的。</li>\n<li>每插入一条数据，都会生成一个segment文件，需要对segment文件进行merge操作。</li>\n</ol>\n<h1 id=\"六、Elasticsearch读取数据的过程\"><a href=\"#六、Elasticsearch读取数据的过程\" class=\"headerlink\" title=\"六、Elasticsearch读取数据的过程\"></a>六、Elasticsearch读取数据的过程</h1><h2 id=\"1、Elasticsearch读取数据的过程\"><a href=\"#1、Elasticsearch读取数据的过程\" class=\"headerlink\" title=\"1、Elasticsearch读取数据的过程\"></a>1、Elasticsearch读取数据的过程</h2><ol>\n<li>客户端发送请求到任意⼀个node，成为coordinate node</li>\n<li>coordinate node对document进⾏路由，将请求转发到对应的node，此时会使⽤round-robin随机<br>轮询算法，在primary shard以及其所有replica中随机选择⼀个，让读请求负载均衡</li>\n<li>接收请求的node返回document给coordinate node</li>\n<li>coordinate node返回document给客户端<ol>\n<li>写⼊document时，每个document会⾃动分配⼀个全局唯⼀的id即doc id，同时也是根据doc id进 ⾏hash路由到对应的primary shard上。也可以⼿动指定doc id，⽐如⽤订单id，⽤户id。</li>\n<li>读取document时，你可以通过doc id来查询，然后会根据doc id进⾏hash，判断出来当时把doc<br>id分配到了哪个shard上⾯去，从那个shard去查询</li>\n</ol>\n</li>\n</ol>\n<ul>\n<li>这里的读，是指读某个具体的数据。<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3></li>\n</ul>\n<ol>\n<li>根据具体的数据，可以具体的路由到具体的node</li>\n<li>然后读取node的分片，从分片中获取数据</li>\n</ol>\n<h2 id=\"2、Elasticsearch搜索数据过程\"><a href=\"#2、Elasticsearch搜索数据过程\" class=\"headerlink\" title=\"2、Elasticsearch搜索数据过程\"></a>2、Elasticsearch搜索数据过程</h2><ol>\n<li>客户端发送一个请求给coordinate node</li>\n<li>协调节点将搜索的请求转发给所有的shard对应的primary shard 或replica shard</li>\n<li>query phase：每一个shard 将自己搜索的结果（其实也就是一些唯一标识），返回给协调节点，有协调节点进行数据的合并，排序，分页等操作，产出最后的结果</li>\n<li>fetch phase ，接着由协调节点，根据唯一标识去各个节点进行拉去数据，最总返回给客户端</li>\n</ol>\n<ul>\n<li>搜索，指的是用某些分词去获取所有的数据<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h3></li>\n</ul>\n<ol>\n<li>根据请求，找到任意一个集群节点node（作为协调节点）</li>\n<li>然后将请求分发给所有的分片。</li>\n<li>聚合后返回结果。</li>\n</ol>\n<p><a href=\"https://segmentfault.com/a/1190000015256970\" target=\"_blank\" rel=\"noopener\">ES参考</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、时间问题\"><a href=\"#一、时间问题\" class=\"headerlink\" title=\"一、时间问题\"></a>一、时间问题</h1><p>将一个时间字符按不同时区来解释，得到的data数据是不同的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String timeStr = &quot;2017-8-24 11:17:10&quot;; // 字面时间</span><br><span class=\"line\">SimpleDateFormat bjSdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);</span><br><span class=\"line\">bjSdf.setTimeZone(TimeZone.getTimeZone(&quot;Asia/Shanghai&quot;));</span><br><span class=\"line\">Date bjDate = bjSdf.parse(timeStr);  // 解析</span><br><span class=\"line\">System.out.println(&quot;字面时间: &quot; + timeStr +&quot;,按北京时间来解释:&quot; + bjSdf.format(bjDate) + &quot;, &quot; + bjDate.getTime());</span><br><span class=\"line\"> </span><br><span class=\"line\">SimpleDateFormat tokyoSdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);  // 东京</span><br><span class=\"line\">tokyoSdf.setTimeZone(TimeZone.getTimeZone(&quot;Asia/Tokyo&quot;));  // 设置东京时区</span><br><span class=\"line\">Date tokyoDate = tokyoSdf.parse(timeStr); // 解析</span><br><span class=\"line\">System.out.println(&quot;字面时间: &quot; + timeStr +&quot;,按东京时间来解释:&quot;  + tokyoSdf.format(tokyoDate) + &quot;, &quot; + tokyoDate.getTime());</span><br></pre></td></tr></table></figure>\n\n<p>输出为：   </p>\n<ul>\n<li>字面时间: 2017-8-24 11:17:10,按北京时间来解释:2017-08-24 11:17:10, 1503544630000</li>\n<li>字面时间: 2017-8-24 11:17:10,按东京时间来解释:2017-08-24 11:17:10, 1503541030000</li>\n</ul>\n<p>一个字符串时间，按不同时区解析，得到的毫秒数是不一样的。<br>ES中默认时区是UTC，如果北京时间2017-8-23 11:17:10存入es中，那么会按UTC时区解析，那么实际存储到ES中的时间是会小8小时的，然后再把毫秒数按北京时区解析，自然就少了8小时。这就是ES的时区问题。</p>","more":"<h1 id=\"二、架构\"><a href=\"#二、架构\" class=\"headerlink\" title=\"二、架构\"></a>二、架构</h1><p>集群架构：多个节点，主从架构。<br><img src=\"/2020/06/01/2020-06-01-es/%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84.png\" alt=\"集群架构\"><br>数据逻辑结构：<br><img src=\"/2020/06/01/2020-06-01-es/%E6%95%B0%E6%8D%AE%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84.png\" alt=\"数据逻辑结构\"><br>存储目录结构图：<br><img src=\"/2020/06/01/2020-06-01-es/%E5%AD%98%E5%82%A8%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%9B%BE.png\" alt=\"存储目录结构图\"></p>\n<ol>\n<li>index包含多个shard。</li>\n<li>primary shard的数量在创建索引的时候就固定了，因为索引时，需要按照primary shard的数量为文档做路由（默认使用文档的_id属性取哈希值做路由，也可以通过routing指定使用其他文档字段取哈希值做路由）。replica shard的数量可以随时修改。</li>\n<li>primary shard不能和自己的replica shard放在同一个节点上（否则节点宕机，primary shard和副本都丢失，起不到容错的作用），但是可以和其他primary shard的replica shard放在同一个节点上。</li>\n</ol>\n<h2 id=\"分片：shard\"><a href=\"#分片：shard\" class=\"headerlink\" title=\"分片：shard\"></a>分片：shard</h2><ol>\n<li>什么是分片？<ul>\n<li>索引数据过大时，单机无法存储，对索引数据进行切割，索引可以确定切割几片，切成的每一块就叫切片。</li>\n<li>然后为了切片的高可用，然后采用了副本的方式，每个切片可以确定副本的数量，副本不能和主分片存储在同一台机器。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"三、选举\"><a href=\"#三、选举\" class=\"headerlink\" title=\"三、选举\"></a>三、选举</h1><h2 id=\"1、ES是如何实现Master选举的\"><a href=\"#1、ES是如何实现Master选举的\" class=\"headerlink\" title=\"1、ES是如何实现Master选举的\"></a>1、ES是如何实现Master选举的</h2><ol>\n<li>对所有可以成为master的节点(node.master:true)根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master，否则重新选举一直到满足上述条件。<ul>\n<li>补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"2、脑裂如何避免\"><a href=\"#2、脑裂如何避免\" class=\"headerlink\" title=\"2、脑裂如何避免\"></a>2、脑裂如何避免</h2><p> 当集群master候选数量不少于3个时，可以通过设置最少投票数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题。当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。</p>\n<h1 id=\"四、倒排索引\"><a href=\"#四、倒排索引\" class=\"headerlink\" title=\"四、倒排索引\"></a>四、倒排索引</h1><h2 id=\"1-什么是倒排索引？\"><a href=\"#1-什么是倒排索引？\" class=\"headerlink\" title=\"1. 什么是倒排索引？\"></a>1. 什么是倒排索引？</h2><p><img src=\"/2020/06/01/2020-06-01-es/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.png\" alt=\"倒排索引\"><br>记录的是单词存在的文档ID列表。</p>\n<h3 id=\"倒排索引组成\"><a href=\"#倒排索引组成\" class=\"headerlink\" title=\"倒排索引组成\"></a>倒排索引组成</h3><p>倒排文件 + 单词词典<br><img src=\"/2020/06/01/2020-06-01-es/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E7%BB%84%E6%88%90.png\" alt=\"倒排索引组成\"></p>\n<ol>\n<li>单词词典（Term Dictionary）：搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。<ul>\n<li>如何快速定位单词呢？使用什么数据类型？</li>\n<li>方式1：数组+ 链表</li>\n<li>方式2：B或B+树</li>\n</ul>\n</li>\n<li>倒排列表(PostingList)：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息及频率（作关联性算分），每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。</li>\n<li>倒排文件(Inverted File)：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。</li>\n</ol>\n<h2 id=\"2-正排索引\"><a href=\"#2-正排索引\" class=\"headerlink\" title=\"2. 正排索引\"></a>2. 正排索引</h2><p><img src=\"/2020/06/01/2020-06-01-es/%E6%AD%A3%E6%8E%92%E7%B4%A2%E5%BC%95.png\" alt=\"正排索引\"><br>用ID建立索引，保存ID所对应的文档内容等数据。</p>\n<h1 id=\"五、Elasticsearch写人数据的过程\"><a href=\"#五、Elasticsearch写人数据的过程\" class=\"headerlink\" title=\"五、Elasticsearch写人数据的过程\"></a>五、Elasticsearch写人数据的过程</h1><h2 id=\"1、Elasticsearch写人数据的过程\"><a href=\"#1、Elasticsearch写人数据的过程\" class=\"headerlink\" title=\"1、Elasticsearch写人数据的过程\"></a>1、Elasticsearch写人数据的过程</h2><ol>\n<li>客户端选择一个node发送请求过去，这个node就是coordinating node（协调节点）</li>\n<li>coordinating node，对document进行路由，将请求转发给对应的node（有primary shard）</li>\n<li>实际的node上的primary shard处理请求，然后将数据同步到replica node</li>\n<li>coordinating node，如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端</li>\n</ol>\n<h2 id=\"2、Elasticsearch写数据的底层原理\"><a href=\"#2、Elasticsearch写数据的底层原理\" class=\"headerlink\" title=\"2、Elasticsearch写数据的底层原理\"></a>2、Elasticsearch写数据的底层原理</h2><ol>\n<li>数据先写入到buffer里面，在buffer里面的数据时搜索不到的，同时将数据写入到translog日志文件之中</li>\n<li>如果buffer快满了，或是一段时间之后，就会将buffer数据refresh到一个新的OS cache之中，然后每隔1秒，就会将OS cache的数据写入到segment file之中，<br>但是如果每一秒钟没有新的数据到buffer之中，就会创建一个新的空的segment file，只要buffer中的数据被refresh到OS cache之中，就代表这个数据可以被搜索到了。<br>当然可以通过restful api 和Java api，手动的执行一次refresh操作，就是手动的将buffer中的数据刷入到OS cache之中，让数据立马搜索到，只要数据被输入到OS cache之中，buffer的内容就会被清空了。<br>同时进行的是，数据到shard之后，就会将数据写入到translog之中，每隔5秒将translog之中的数据持久化到磁盘之中</li>\n<li>重复以上的操作，每次一条数据写入buffer，同时会写入一条日志到translog日志文件之中去，这个translog文件会不断的变大，当达到一定的程度之后，就会触发commit操作。</li>\n<li>将一个commit point写入到磁盘文件，里面标识着这个commit point 对应的所有segment file</li>\n<li>强行将OS cache 之中的数据都fsync到磁盘文件中去。<ul>\n<li>解释：translog的作用：在执行commit之前，所有的而数据都是停留在buffer或OS cache之中，无论buffer或OS cache都是内存，一旦这台机器死了，内存的数据就会丢失，所以需要将数据对应的操作写入一个专门的日志问价之中，一旦机器出现宕机，再次重启的时候，es会主动的读取translog之中的日志文件的数据，恢复到内存buffer和OS cache之中。</li>\n</ul>\n</li>\n<li>将现有的translog文件进行清空，然后在重新启动一个translog，此时commit就算是成功了，默认的是每隔30分钟进行一次commit，但是如果translog的文件过大，也会触发commit，整个commit过程就叫做一个flush操作，我们也可以通过ES API,手动执行flush操作，手动将OS cache 的数据fsync到磁盘上面去，记录一个commit point，清空translog文件<ul>\n<li>补充：其实translog的数据也是先写入到OS cache之中的，默认每隔5秒之中将数据刷新到硬盘中去，也就是说，可能有5秒的数据仅仅停留在buffer或者translog文件的OS cache中，如果此时机器挂了，会丢失5秒的数据，但是这样的性能比较好，我们也可以将每次的操作都必须是直接fsync到磁盘，但是性能会比较差。</li>\n</ul>\n</li>\n<li>如果时删除操作，commit的时候会产生一个.del文件，里面讲某个doc标记为delete状态，那么搜索的时候，会根据.del文件的状态，就知道那个文件被删除了。</li>\n<li>如果时更新操作，就是讲原来的doc标识为delete状态，然后重新写入一条数据即可。</li>\n<li>buffer每次更新一次，就会产生一个segment file 文件，所以在默认情况之下，就会产生很多的segment file 文件，将会定期执行merge操作</li>\n<li>每次merge的时候，就会将多个segment file 文件进行合并为一个，同时将标记为delete的文件进行删除，然后将新的segment file 文件写入到磁盘，这里会写一个commit point，标识所有的新的segment file，然后打开新的segment file供搜索使用。</li>\n</ol>\n<p>总之，segment的四个核心概念，refresh，flush，translog、merge</p>\n<h3 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h3><ol>\n<li>和MySQL类似，日志先行，先将数据写入到日志文件。</li>\n<li>而后是写入磁盘，将缓冲数据写入刷入磁盘。（有个顺序，先刷入os cache，再有os决定什么时候刷入磁盘；或者强制刷入flush）</li>\n<li>然后是日志文件的刷入磁盘，和缓冲数据是一样的。</li>\n<li>每插入一条数据，都会生成一个segment文件，需要对segment文件进行merge操作。</li>\n</ol>\n<h1 id=\"六、Elasticsearch读取数据的过程\"><a href=\"#六、Elasticsearch读取数据的过程\" class=\"headerlink\" title=\"六、Elasticsearch读取数据的过程\"></a>六、Elasticsearch读取数据的过程</h1><h2 id=\"1、Elasticsearch读取数据的过程\"><a href=\"#1、Elasticsearch读取数据的过程\" class=\"headerlink\" title=\"1、Elasticsearch读取数据的过程\"></a>1、Elasticsearch读取数据的过程</h2><ol>\n<li>客户端发送请求到任意⼀个node，成为coordinate node</li>\n<li>coordinate node对document进⾏路由，将请求转发到对应的node，此时会使⽤round-robin随机<br>轮询算法，在primary shard以及其所有replica中随机选择⼀个，让读请求负载均衡</li>\n<li>接收请求的node返回document给coordinate node</li>\n<li>coordinate node返回document给客户端<ol>\n<li>写⼊document时，每个document会⾃动分配⼀个全局唯⼀的id即doc id，同时也是根据doc id进 ⾏hash路由到对应的primary shard上。也可以⼿动指定doc id，⽐如⽤订单id，⽤户id。</li>\n<li>读取document时，你可以通过doc id来查询，然后会根据doc id进⾏hash，判断出来当时把doc<br>id分配到了哪个shard上⾯去，从那个shard去查询</li>\n</ol>\n</li>\n</ol>\n<ul>\n<li>这里的读，是指读某个具体的数据。<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3></li>\n</ul>\n<ol>\n<li>根据具体的数据，可以具体的路由到具体的node</li>\n<li>然后读取node的分片，从分片中获取数据</li>\n</ol>\n<h2 id=\"2、Elasticsearch搜索数据过程\"><a href=\"#2、Elasticsearch搜索数据过程\" class=\"headerlink\" title=\"2、Elasticsearch搜索数据过程\"></a>2、Elasticsearch搜索数据过程</h2><ol>\n<li>客户端发送一个请求给coordinate node</li>\n<li>协调节点将搜索的请求转发给所有的shard对应的primary shard 或replica shard</li>\n<li>query phase：每一个shard 将自己搜索的结果（其实也就是一些唯一标识），返回给协调节点，有协调节点进行数据的合并，排序，分页等操作，产出最后的结果</li>\n<li>fetch phase ，接着由协调节点，根据唯一标识去各个节点进行拉去数据，最总返回给客户端</li>\n</ol>\n<ul>\n<li>搜索，指的是用某些分词去获取所有的数据<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h3></li>\n</ul>\n<ol>\n<li>根据请求，找到任意一个集群节点node（作为协调节点）</li>\n<li>然后将请求分发给所有的分片。</li>\n<li>聚合后返回结果。</li>\n</ol>\n<p><a href=\"https://segmentfault.com/a/1190000015256970\" target=\"_blank\" rel=\"noopener\">ES参考</a></p>"},{"title":"volatile","date":"2020-04-06T07:05:38.000Z","_content":"\n# 一、volatile\n1. 保证变量可见性。\n2. 禁止指令重排序。\n\n# 二、如何实现\n从三个层面解析。   \n1. 字节码层面\n2. JVM层面\n3. CPU层面（汇编语言）\n\n<!--more-->  \n\n## 2.1、字节码层面\n![dmq](2020-04-06-volatile/volatile字节码.png)\n\n使用volatile关键字修饰的实例变量，会使用ACC_VOLATILE修饰。\n\n## 2.2、JVM层面\nc/c++中的volatile关键字，用来修饰变量，通常用于语言级别的 memory barrier。  \nvolatile是一种类型修饰符，被volatile声明的变量表示随时可能发生变化，每次使用时，都必须从变量i对应的内存地址读取，编译器对操作该变量的代码不再进行优化\n\n![volatile](2020-04-06-volatile/volatile-jvm.png)\n\n\n## 2.3、汇编语言层面\n![volatile](2020-04-06-volatile/volatile汇编代码.png)\n\nidea：查看汇编指令代码，在执行的VM参数中添加以下值：\n```\n-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*VolatileTest.main\n```\n\n生成lock指令，lock指令会锁住总线，阻止其他CPU通过总线访问内存。\n\n[volatile实现内存可见性分析：字节码版本](https://blog.csdn.net/m15517986455/article/details/83273723)\n\n\n# 三、总结\n## 3.1、如何保证禁止指令重排？\n* 编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。\n* 指令级并行的重排序：如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n* 内存系统的重排序：\n\n1. volatile会添加编译器屏障，防止编译器优化导致的指令重排，JMM定义的如下：\n    * storestore\n    * storeload\n    * loadload\n    * loadstore\n2. 指令级的重排序\n    * lfence：读屏障，清空invalidate queue，强制读取cache中的值，lfence之前的读操作一定在lfence之前完成\n    * sfence：写屏障，会将store buffer中的修改写入到cache中，sfence之前的写操作一点在sfence之前完成，使其他CPU可见\n    * mfence：同时刷新store buffer和 invalidate queue     \n\n## 3.2、如何保证内存可见？\n\n1. 写操作时，lock指令锁住总线，修改内存中的值。\n2. 修改完以后，通过MESI协议保证数据一致性\n    * MESI协议：定义了四种状态，独占->共享->修改->无效，当修改了数据时回写缓存，同时通知其他CPU该缓存无效，所以其他CPU需要重新从主存中读取最新内容，以此达到可见性，修改值的CPU需要等待其他CPU返回ack。\n    * MESI实现：MESI的实现，按理论实现的话效率过低，从而通过store buffer来提高运行效率。\n        * store buffer：在CPU和缓存之间CPU0修改并回写时，直接返回成功，不需要等到其他CPU返回invalidate ack，解决MESI协议的强一致性问题，提升性能。具体实现是：cpu0写入到store buffer后，继续往下执行，然后通知其他CPU值失效返回ack，此时CPU0会从cache中获取而不是store buffer，此处导致数据不一致，执行顺序也乱序；\n        * Invalidate queue：在缓存和内存之间在收到invalidate消息后立马返回ack，实际并没有将cache中的数据清除，从而导致了数据不一致。\n\n* **StoreBuffer和InvalidateQueue结构**\n![volatile](2020-04-06-volatile/cache_sync.png)\n\nStoreBuffer和InvalidateQueue结构的引入，会引起数据不一致的问题，如何解决呢？\n* 内存屏障（指令级）\n    * smp_wmb(StoreStore)：执行后需等待 Store Buffer 中的写入变更 flush 完全到缓存后，后续的写操作才能继续执行，保证执行前后的写操作对其他 CPU 而言是顺序执行的；\n    * smp_rmb(LoadLoad)：执行后需等待 Invalidate Queue 完全应用到缓存后，后续的读操作才能继续执行，保证执行前后的读操作对其他 CPU 而言是顺序执行的；\n\n[happens-before](https://zhuanlan.zhihu.com/p/126275344)","source":"_posts/2020-04-06-volatile.md","raw":"---\ntitle: volatile\ndate: 2020-04-06 15:05:38\ntags: jvm\ncategories: \n   - [java, jvm]\n---\n\n# 一、volatile\n1. 保证变量可见性。\n2. 禁止指令重排序。\n\n# 二、如何实现\n从三个层面解析。   \n1. 字节码层面\n2. JVM层面\n3. CPU层面（汇编语言）\n\n<!--more-->  \n\n## 2.1、字节码层面\n![dmq](2020-04-06-volatile/volatile字节码.png)\n\n使用volatile关键字修饰的实例变量，会使用ACC_VOLATILE修饰。\n\n## 2.2、JVM层面\nc/c++中的volatile关键字，用来修饰变量，通常用于语言级别的 memory barrier。  \nvolatile是一种类型修饰符，被volatile声明的变量表示随时可能发生变化，每次使用时，都必须从变量i对应的内存地址读取，编译器对操作该变量的代码不再进行优化\n\n![volatile](2020-04-06-volatile/volatile-jvm.png)\n\n\n## 2.3、汇编语言层面\n![volatile](2020-04-06-volatile/volatile汇编代码.png)\n\nidea：查看汇编指令代码，在执行的VM参数中添加以下值：\n```\n-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*VolatileTest.main\n```\n\n生成lock指令，lock指令会锁住总线，阻止其他CPU通过总线访问内存。\n\n[volatile实现内存可见性分析：字节码版本](https://blog.csdn.net/m15517986455/article/details/83273723)\n\n\n# 三、总结\n## 3.1、如何保证禁止指令重排？\n* 编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。\n* 指令级并行的重排序：如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n* 内存系统的重排序：\n\n1. volatile会添加编译器屏障，防止编译器优化导致的指令重排，JMM定义的如下：\n    * storestore\n    * storeload\n    * loadload\n    * loadstore\n2. 指令级的重排序\n    * lfence：读屏障，清空invalidate queue，强制读取cache中的值，lfence之前的读操作一定在lfence之前完成\n    * sfence：写屏障，会将store buffer中的修改写入到cache中，sfence之前的写操作一点在sfence之前完成，使其他CPU可见\n    * mfence：同时刷新store buffer和 invalidate queue     \n\n## 3.2、如何保证内存可见？\n\n1. 写操作时，lock指令锁住总线，修改内存中的值。\n2. 修改完以后，通过MESI协议保证数据一致性\n    * MESI协议：定义了四种状态，独占->共享->修改->无效，当修改了数据时回写缓存，同时通知其他CPU该缓存无效，所以其他CPU需要重新从主存中读取最新内容，以此达到可见性，修改值的CPU需要等待其他CPU返回ack。\n    * MESI实现：MESI的实现，按理论实现的话效率过低，从而通过store buffer来提高运行效率。\n        * store buffer：在CPU和缓存之间CPU0修改并回写时，直接返回成功，不需要等到其他CPU返回invalidate ack，解决MESI协议的强一致性问题，提升性能。具体实现是：cpu0写入到store buffer后，继续往下执行，然后通知其他CPU值失效返回ack，此时CPU0会从cache中获取而不是store buffer，此处导致数据不一致，执行顺序也乱序；\n        * Invalidate queue：在缓存和内存之间在收到invalidate消息后立马返回ack，实际并没有将cache中的数据清除，从而导致了数据不一致。\n\n* **StoreBuffer和InvalidateQueue结构**\n![volatile](2020-04-06-volatile/cache_sync.png)\n\nStoreBuffer和InvalidateQueue结构的引入，会引起数据不一致的问题，如何解决呢？\n* 内存屏障（指令级）\n    * smp_wmb(StoreStore)：执行后需等待 Store Buffer 中的写入变更 flush 完全到缓存后，后续的写操作才能继续执行，保证执行前后的写操作对其他 CPU 而言是顺序执行的；\n    * smp_rmb(LoadLoad)：执行后需等待 Invalidate Queue 完全应用到缓存后，后续的读操作才能继续执行，保证执行前后的读操作对其他 CPU 而言是顺序执行的；\n\n[happens-before](https://zhuanlan.zhihu.com/p/126275344)","slug":"2020-04-06-volatile","published":1,"updated":"2024-12-09T03:22:02.693Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxg0035a13ku97w4boz","content":"<h1 id=\"一、volatile\"><a href=\"#一、volatile\" class=\"headerlink\" title=\"一、volatile\"></a>一、volatile</h1><ol>\n<li>保证变量可见性。</li>\n<li>禁止指令重排序。</li>\n</ol>\n<h1 id=\"二、如何实现\"><a href=\"#二、如何实现\" class=\"headerlink\" title=\"二、如何实现\"></a>二、如何实现</h1><p>从三个层面解析。   </p>\n<ol>\n<li>字节码层面</li>\n<li>JVM层面</li>\n<li>CPU层面（汇编语言）</li>\n</ol>\n<a id=\"more\"></a>  \n\n<h2 id=\"2-1、字节码层面\"><a href=\"#2-1、字节码层面\" class=\"headerlink\" title=\"2.1、字节码层面\"></a>2.1、字节码层面</h2><p><img src=\"/2020/04/06/2020-04-06-volatile/volatile%E5%AD%97%E8%8A%82%E7%A0%81.png\" alt=\"dmq\"></p>\n<p>使用volatile关键字修饰的实例变量，会使用ACC_VOLATILE修饰。</p>\n<h2 id=\"2-2、JVM层面\"><a href=\"#2-2、JVM层面\" class=\"headerlink\" title=\"2.2、JVM层面\"></a>2.2、JVM层面</h2><p>c/c++中的volatile关键字，用来修饰变量，通常用于语言级别的 memory barrier。<br>volatile是一种类型修饰符，被volatile声明的变量表示随时可能发生变化，每次使用时，都必须从变量i对应的内存地址读取，编译器对操作该变量的代码不再进行优化</p>\n<p><img src=\"/2020/04/06/2020-04-06-volatile/volatile-jvm.png\" alt=\"volatile\"></p>\n<h2 id=\"2-3、汇编语言层面\"><a href=\"#2-3、汇编语言层面\" class=\"headerlink\" title=\"2.3、汇编语言层面\"></a>2.3、汇编语言层面</h2><p><img src=\"/2020/04/06/2020-04-06-volatile/volatile%E6%B1%87%E7%BC%96%E4%BB%A3%E7%A0%81.png\" alt=\"volatile\"></p>\n<p>idea：查看汇编指令代码，在执行的VM参数中添加以下值：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*VolatileTest.main</span><br></pre></td></tr></table></figure>\n\n<p>生成lock指令，lock指令会锁住总线，阻止其他CPU通过总线访问内存。</p>\n<p><a href=\"https://blog.csdn.net/m15517986455/article/details/83273723\" target=\"_blank\" rel=\"noopener\">volatile实现内存可见性分析：字节码版本</a></p>\n<h1 id=\"三、总结\"><a href=\"#三、总结\" class=\"headerlink\" title=\"三、总结\"></a>三、总结</h1><h2 id=\"3-1、如何保证禁止指令重排？\"><a href=\"#3-1、如何保证禁止指令重排？\" class=\"headerlink\" title=\"3.1、如何保证禁止指令重排？\"></a>3.1、如何保证禁止指令重排？</h2><ul>\n<li>编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</li>\n<li>指令级并行的重排序：如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</li>\n<li>内存系统的重排序：</li>\n</ul>\n<ol>\n<li>volatile会添加编译器屏障，防止编译器优化导致的指令重排，JMM定义的如下：<ul>\n<li>storestore</li>\n<li>storeload</li>\n<li>loadload</li>\n<li>loadstore</li>\n</ul>\n</li>\n<li>指令级的重排序<ul>\n<li>lfence：读屏障，清空invalidate queue，强制读取cache中的值，lfence之前的读操作一定在lfence之前完成</li>\n<li>sfence：写屏障，会将store buffer中的修改写入到cache中，sfence之前的写操作一点在sfence之前完成，使其他CPU可见</li>\n<li>mfence：同时刷新store buffer和 invalidate queue     </li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-2、如何保证内存可见？\"><a href=\"#3-2、如何保证内存可见？\" class=\"headerlink\" title=\"3.2、如何保证内存可见？\"></a>3.2、如何保证内存可见？</h2><ol>\n<li>写操作时，lock指令锁住总线，修改内存中的值。</li>\n<li>修改完以后，通过MESI协议保证数据一致性<ul>\n<li>MESI协议：定义了四种状态，独占-&gt;共享-&gt;修改-&gt;无效，当修改了数据时回写缓存，同时通知其他CPU该缓存无效，所以其他CPU需要重新从主存中读取最新内容，以此达到可见性，修改值的CPU需要等待其他CPU返回ack。</li>\n<li>MESI实现：MESI的实现，按理论实现的话效率过低，从而通过store buffer来提高运行效率。<ul>\n<li>store buffer：在CPU和缓存之间CPU0修改并回写时，直接返回成功，不需要等到其他CPU返回invalidate ack，解决MESI协议的强一致性问题，提升性能。具体实现是：cpu0写入到store buffer后，继续往下执行，然后通知其他CPU值失效返回ack，此时CPU0会从cache中获取而不是store buffer，此处导致数据不一致，执行顺序也乱序；</li>\n<li>Invalidate queue：在缓存和内存之间在收到invalidate消息后立马返回ack，实际并没有将cache中的数据清除，从而导致了数据不一致。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li><strong>StoreBuffer和InvalidateQueue结构</strong><br><img src=\"/2020/04/06/2020-04-06-volatile/cache_sync.png\" alt=\"volatile\"></li>\n</ul>\n<p>StoreBuffer和InvalidateQueue结构的引入，会引起数据不一致的问题，如何解决呢？</p>\n<ul>\n<li>内存屏障（指令级）<ul>\n<li>smp_wmb(StoreStore)：执行后需等待 Store Buffer 中的写入变更 flush 完全到缓存后，后续的写操作才能继续执行，保证执行前后的写操作对其他 CPU 而言是顺序执行的；</li>\n<li>smp_rmb(LoadLoad)：执行后需等待 Invalidate Queue 完全应用到缓存后，后续的读操作才能继续执行，保证执行前后的读操作对其他 CPU 而言是顺序执行的；</li>\n</ul>\n</li>\n</ul>\n<p><a href=\"https://zhuanlan.zhihu.com/p/126275344\" target=\"_blank\" rel=\"noopener\">happens-before</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、volatile\"><a href=\"#一、volatile\" class=\"headerlink\" title=\"一、volatile\"></a>一、volatile</h1><ol>\n<li>保证变量可见性。</li>\n<li>禁止指令重排序。</li>\n</ol>\n<h1 id=\"二、如何实现\"><a href=\"#二、如何实现\" class=\"headerlink\" title=\"二、如何实现\"></a>二、如何实现</h1><p>从三个层面解析。   </p>\n<ol>\n<li>字节码层面</li>\n<li>JVM层面</li>\n<li>CPU层面（汇编语言）</li>\n</ol>","more":"<h2 id=\"2-1、字节码层面\"><a href=\"#2-1、字节码层面\" class=\"headerlink\" title=\"2.1、字节码层面\"></a>2.1、字节码层面</h2><p><img src=\"/2020/04/06/2020-04-06-volatile/volatile%E5%AD%97%E8%8A%82%E7%A0%81.png\" alt=\"dmq\"></p>\n<p>使用volatile关键字修饰的实例变量，会使用ACC_VOLATILE修饰。</p>\n<h2 id=\"2-2、JVM层面\"><a href=\"#2-2、JVM层面\" class=\"headerlink\" title=\"2.2、JVM层面\"></a>2.2、JVM层面</h2><p>c/c++中的volatile关键字，用来修饰变量，通常用于语言级别的 memory barrier。<br>volatile是一种类型修饰符，被volatile声明的变量表示随时可能发生变化，每次使用时，都必须从变量i对应的内存地址读取，编译器对操作该变量的代码不再进行优化</p>\n<p><img src=\"/2020/04/06/2020-04-06-volatile/volatile-jvm.png\" alt=\"volatile\"></p>\n<h2 id=\"2-3、汇编语言层面\"><a href=\"#2-3、汇编语言层面\" class=\"headerlink\" title=\"2.3、汇编语言层面\"></a>2.3、汇编语言层面</h2><p><img src=\"/2020/04/06/2020-04-06-volatile/volatile%E6%B1%87%E7%BC%96%E4%BB%A3%E7%A0%81.png\" alt=\"volatile\"></p>\n<p>idea：查看汇编指令代码，在执行的VM参数中添加以下值：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*VolatileTest.main</span><br></pre></td></tr></table></figure>\n\n<p>生成lock指令，lock指令会锁住总线，阻止其他CPU通过总线访问内存。</p>\n<p><a href=\"https://blog.csdn.net/m15517986455/article/details/83273723\" target=\"_blank\" rel=\"noopener\">volatile实现内存可见性分析：字节码版本</a></p>\n<h1 id=\"三、总结\"><a href=\"#三、总结\" class=\"headerlink\" title=\"三、总结\"></a>三、总结</h1><h2 id=\"3-1、如何保证禁止指令重排？\"><a href=\"#3-1、如何保证禁止指令重排？\" class=\"headerlink\" title=\"3.1、如何保证禁止指令重排？\"></a>3.1、如何保证禁止指令重排？</h2><ul>\n<li>编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</li>\n<li>指令级并行的重排序：如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</li>\n<li>内存系统的重排序：</li>\n</ul>\n<ol>\n<li>volatile会添加编译器屏障，防止编译器优化导致的指令重排，JMM定义的如下：<ul>\n<li>storestore</li>\n<li>storeload</li>\n<li>loadload</li>\n<li>loadstore</li>\n</ul>\n</li>\n<li>指令级的重排序<ul>\n<li>lfence：读屏障，清空invalidate queue，强制读取cache中的值，lfence之前的读操作一定在lfence之前完成</li>\n<li>sfence：写屏障，会将store buffer中的修改写入到cache中，sfence之前的写操作一点在sfence之前完成，使其他CPU可见</li>\n<li>mfence：同时刷新store buffer和 invalidate queue     </li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-2、如何保证内存可见？\"><a href=\"#3-2、如何保证内存可见？\" class=\"headerlink\" title=\"3.2、如何保证内存可见？\"></a>3.2、如何保证内存可见？</h2><ol>\n<li>写操作时，lock指令锁住总线，修改内存中的值。</li>\n<li>修改完以后，通过MESI协议保证数据一致性<ul>\n<li>MESI协议：定义了四种状态，独占-&gt;共享-&gt;修改-&gt;无效，当修改了数据时回写缓存，同时通知其他CPU该缓存无效，所以其他CPU需要重新从主存中读取最新内容，以此达到可见性，修改值的CPU需要等待其他CPU返回ack。</li>\n<li>MESI实现：MESI的实现，按理论实现的话效率过低，从而通过store buffer来提高运行效率。<ul>\n<li>store buffer：在CPU和缓存之间CPU0修改并回写时，直接返回成功，不需要等到其他CPU返回invalidate ack，解决MESI协议的强一致性问题，提升性能。具体实现是：cpu0写入到store buffer后，继续往下执行，然后通知其他CPU值失效返回ack，此时CPU0会从cache中获取而不是store buffer，此处导致数据不一致，执行顺序也乱序；</li>\n<li>Invalidate queue：在缓存和内存之间在收到invalidate消息后立马返回ack，实际并没有将cache中的数据清除，从而导致了数据不一致。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li><strong>StoreBuffer和InvalidateQueue结构</strong><br><img src=\"/2020/04/06/2020-04-06-volatile/cache_sync.png\" alt=\"volatile\"></li>\n</ul>\n<p>StoreBuffer和InvalidateQueue结构的引入，会引起数据不一致的问题，如何解决呢？</p>\n<ul>\n<li>内存屏障（指令级）<ul>\n<li>smp_wmb(StoreStore)：执行后需等待 Store Buffer 中的写入变更 flush 完全到缓存后，后续的写操作才能继续执行，保证执行前后的写操作对其他 CPU 而言是顺序执行的；</li>\n<li>smp_rmb(LoadLoad)：执行后需等待 Invalidate Queue 完全应用到缓存后，后续的读操作才能继续执行，保证执行前后的读操作对其他 CPU 而言是顺序执行的；</li>\n</ul>\n</li>\n</ul>\n<p><a href=\"https://zhuanlan.zhihu.com/p/126275344\" target=\"_blank\" rel=\"noopener\">happens-before</a></p>"},{"title":"分布式主键ID","date":"2020-06-14T09:03:49.000Z","_content":"\n\n# 一、UUID\n1. 生成规则：\n    * 基于时间戳&时钟序列生成\n    * 基于名字空间/名字的散列值 (MD5/SHA1) 生成\n    * 基于随机数生成\n2. 优点\n    * 无需网络，单机自行生成\n    * 速度快，QPS高（支持100ns级并发）\n    * 使用简单\n    * 不会泄漏商业机密\n3. 缺点\n    * 可读性差\n    * 占用空间太多(16个字节)\n    * 影响数据库的性能,\n\n<!--more-->  \n\n# 二、数据库自增\n数据库自增ID可能是大家最熟悉的一种唯一ID生成方式，其具有使用简单，满足基本需求，天然有序的优点，但也有缺陷：\n并发性不好\n数据库写压力大\n数据库故障后不可使用\n存在数量泄露风险\n因此这里给出两种优化方案。\n1. 数据库水平拆分，设置不同的初始值和相同的步长\n![数据库水平拆分ID](2020-06-14-分布式主键ID/数据库水平拆分ID.png)\n如图所示，可保证每台数据库生成的ID是不冲突的，但这种固定步长的方式也会带来扩容的问题，很容易想到当扩容时会出现无ID初始值可分的窘境，解决方案有：\n根据扩容考虑决定步长\n增加其他位标记区分扩容\n这其实都是在需求与方案间的权衡，根据需求来选择最适合的方式。\n2. 批量生成一批ID\n如果要使用单台机器做ID生成，避免固定步长带来的扩容问题，可以每次批量生成一批ID给不同的机器去慢慢消费，这样数据库的压力也会减小到N分之一，且故障后可坚持一段时间。\n![数据库批量生成分配](2020-06-14-分布式主键ID/数据库批量生成分配.png)\n如图所示，但这种做法的缺点是服务器重启、单点故障会造成ID不连续。还是那句话，没有最好的方案，只有最适合的方案。\n\n\n# 三、雪花算法\n定义一个64bit的数，对指定机器 & 同一时刻 & 某一并发序列，是唯一的，其极限QPS约为400w/s。其格式为：\n![雪花算法](2020-06-14-分布式主键ID/雪花算法.png)\n这个就是原生的雪花算法分配\n* 41bit时间戳：这里采用的就是当前系统的具体时间，单位为毫秒\n* 10bit工作机器ID（workerId）：每台机器分配一个id，这样可以标示不同的机器，但是上限为1024，标示一个集群某个业务最多部署的机器个数上限\n* 12bit序列号（自增域）：表示在某一毫秒下，这个自增域最大可以分配的bit个数，在当前这种配置下，每一毫秒可以分配2^12个数据，也就是说QPS可以到 409.6 w/s。\n\n## 3.1、存在的问题\n时间回拨问题：由于机器的时间是动态的调整的，有可能会出现时间跑到之前几毫秒，如果这个时候获取到了这种时间，则会出现数据重复\n机器id分配及回收问题：目前机器id需要每台机器不一样，这样的方式分配需要有方案进行处理，同时也要考虑，如果改机器宕机了，对应的workerId分配后的回收问题\n机器id上限：机器id是固定的bit，那么也就是对应的机器个数是有上限的，在有些业务场景下，需要所有机器共享同一个业务空间，那么10bit表示的1024台机器是不够的。\n业内方案\n业内的方案中对以上三个问题有这么几种处理，但是都没有彻底解决，我们这里表述下\n### 1.时间回拨问题：\n采用直接抛异常方式：这种很不友好，太粗暴\n采用等待跟上次时间的一段范围：这种算是简单解决，可以接受，但是如果等待一段时间后再出现回拨，则抛异常，可接受，但是不算彻底解决\n### 2.机器id分配及回收：\n采用zookeeper的顺序节点分配：解决了分配，回收可采用zookeeper临时节点回收，但是临时节点不可靠，存在无故消失问题，因此也不可靠\n采用DB中插入数据作为节点值：解决了分配，没有解决回收\n### 3.机器id上限\n该问题在业内都没有处理，也就是说如果采用雪花算法，则必定会存在该问题，但是该问题也只有需要大量的业务机器共享的场景才会出现，这种情况，采用客户端双Buffer+DB这种非雪花算法的方案也未尝不可。\nhttps://cloud.tencent.com/developer/news/678423\n\n# 四、Redis\nRedis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。\n```\n127.0.0.1:6379> set seq_id 1     // 初始化自增ID为1\nOK\n127.0.0.1:6379> incr seq_id      // 增加1，并返回递增后的数值\n(integer) 2\n```\n用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF\nRDB会定时打一个快照进行持久化，假如连续自增但redis没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。\nAOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长。\n\n\n\n","source":"_posts/2020-06-14-分布式主键ID.md","raw":"---\ntitle: 分布式主键ID\ndate: 2020-06-14 17:03:49\ntags: snowflake UUID\n---\n\n\n# 一、UUID\n1. 生成规则：\n    * 基于时间戳&时钟序列生成\n    * 基于名字空间/名字的散列值 (MD5/SHA1) 生成\n    * 基于随机数生成\n2. 优点\n    * 无需网络，单机自行生成\n    * 速度快，QPS高（支持100ns级并发）\n    * 使用简单\n    * 不会泄漏商业机密\n3. 缺点\n    * 可读性差\n    * 占用空间太多(16个字节)\n    * 影响数据库的性能,\n\n<!--more-->  \n\n# 二、数据库自增\n数据库自增ID可能是大家最熟悉的一种唯一ID生成方式，其具有使用简单，满足基本需求，天然有序的优点，但也有缺陷：\n并发性不好\n数据库写压力大\n数据库故障后不可使用\n存在数量泄露风险\n因此这里给出两种优化方案。\n1. 数据库水平拆分，设置不同的初始值和相同的步长\n![数据库水平拆分ID](2020-06-14-分布式主键ID/数据库水平拆分ID.png)\n如图所示，可保证每台数据库生成的ID是不冲突的，但这种固定步长的方式也会带来扩容的问题，很容易想到当扩容时会出现无ID初始值可分的窘境，解决方案有：\n根据扩容考虑决定步长\n增加其他位标记区分扩容\n这其实都是在需求与方案间的权衡，根据需求来选择最适合的方式。\n2. 批量生成一批ID\n如果要使用单台机器做ID生成，避免固定步长带来的扩容问题，可以每次批量生成一批ID给不同的机器去慢慢消费，这样数据库的压力也会减小到N分之一，且故障后可坚持一段时间。\n![数据库批量生成分配](2020-06-14-分布式主键ID/数据库批量生成分配.png)\n如图所示，但这种做法的缺点是服务器重启、单点故障会造成ID不连续。还是那句话，没有最好的方案，只有最适合的方案。\n\n\n# 三、雪花算法\n定义一个64bit的数，对指定机器 & 同一时刻 & 某一并发序列，是唯一的，其极限QPS约为400w/s。其格式为：\n![雪花算法](2020-06-14-分布式主键ID/雪花算法.png)\n这个就是原生的雪花算法分配\n* 41bit时间戳：这里采用的就是当前系统的具体时间，单位为毫秒\n* 10bit工作机器ID（workerId）：每台机器分配一个id，这样可以标示不同的机器，但是上限为1024，标示一个集群某个业务最多部署的机器个数上限\n* 12bit序列号（自增域）：表示在某一毫秒下，这个自增域最大可以分配的bit个数，在当前这种配置下，每一毫秒可以分配2^12个数据，也就是说QPS可以到 409.6 w/s。\n\n## 3.1、存在的问题\n时间回拨问题：由于机器的时间是动态的调整的，有可能会出现时间跑到之前几毫秒，如果这个时候获取到了这种时间，则会出现数据重复\n机器id分配及回收问题：目前机器id需要每台机器不一样，这样的方式分配需要有方案进行处理，同时也要考虑，如果改机器宕机了，对应的workerId分配后的回收问题\n机器id上限：机器id是固定的bit，那么也就是对应的机器个数是有上限的，在有些业务场景下，需要所有机器共享同一个业务空间，那么10bit表示的1024台机器是不够的。\n业内方案\n业内的方案中对以上三个问题有这么几种处理，但是都没有彻底解决，我们这里表述下\n### 1.时间回拨问题：\n采用直接抛异常方式：这种很不友好，太粗暴\n采用等待跟上次时间的一段范围：这种算是简单解决，可以接受，但是如果等待一段时间后再出现回拨，则抛异常，可接受，但是不算彻底解决\n### 2.机器id分配及回收：\n采用zookeeper的顺序节点分配：解决了分配，回收可采用zookeeper临时节点回收，但是临时节点不可靠，存在无故消失问题，因此也不可靠\n采用DB中插入数据作为节点值：解决了分配，没有解决回收\n### 3.机器id上限\n该问题在业内都没有处理，也就是说如果采用雪花算法，则必定会存在该问题，但是该问题也只有需要大量的业务机器共享的场景才会出现，这种情况，采用客户端双Buffer+DB这种非雪花算法的方案也未尝不可。\nhttps://cloud.tencent.com/developer/news/678423\n\n# 四、Redis\nRedis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。\n```\n127.0.0.1:6379> set seq_id 1     // 初始化自增ID为1\nOK\n127.0.0.1:6379> incr seq_id      // 增加1，并返回递增后的数值\n(integer) 2\n```\n用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF\nRDB会定时打一个快照进行持久化，假如连续自增但redis没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。\nAOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长。\n\n\n\n","slug":"2020-06-14-分布式主键ID","published":1,"updated":"2024-10-14T09:38:12.312Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxi0039a13k9uc1irbh","content":"<h1 id=\"一、UUID\"><a href=\"#一、UUID\" class=\"headerlink\" title=\"一、UUID\"></a>一、UUID</h1><ol>\n<li>生成规则：<ul>\n<li>基于时间戳&amp;时钟序列生成</li>\n<li>基于名字空间/名字的散列值 (MD5/SHA1) 生成</li>\n<li>基于随机数生成</li>\n</ul>\n</li>\n<li>优点<ul>\n<li>无需网络，单机自行生成</li>\n<li>速度快，QPS高（支持100ns级并发）</li>\n<li>使用简单</li>\n<li>不会泄漏商业机密</li>\n</ul>\n</li>\n<li>缺点<ul>\n<li>可读性差</li>\n<li>占用空间太多(16个字节)</li>\n<li>影响数据库的性能,</li>\n</ul>\n</li>\n</ol>\n<a id=\"more\"></a>  \n\n<h1 id=\"二、数据库自增\"><a href=\"#二、数据库自增\" class=\"headerlink\" title=\"二、数据库自增\"></a>二、数据库自增</h1><p>数据库自增ID可能是大家最熟悉的一种唯一ID生成方式，其具有使用简单，满足基本需求，天然有序的优点，但也有缺陷：<br>并发性不好<br>数据库写压力大<br>数据库故障后不可使用<br>存在数量泄露风险<br>因此这里给出两种优化方案。</p>\n<ol>\n<li>数据库水平拆分，设置不同的初始值和相同的步长<br><img src=\"/2020/06/14/2020-06-14-分布式主键ID/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%B0%B4%E5%B9%B3%E6%8B%86%E5%88%86ID.png\" alt=\"数据库水平拆分ID\"><br>如图所示，可保证每台数据库生成的ID是不冲突的，但这种固定步长的方式也会带来扩容的问题，很容易想到当扩容时会出现无ID初始值可分的窘境，解决方案有：<br>根据扩容考虑决定步长<br>增加其他位标记区分扩容<br>这其实都是在需求与方案间的权衡，根据需求来选择最适合的方式。</li>\n<li>批量生成一批ID<br>如果要使用单台机器做ID生成，避免固定步长带来的扩容问题，可以每次批量生成一批ID给不同的机器去慢慢消费，这样数据库的压力也会减小到N分之一，且故障后可坚持一段时间。<br><img src=\"/2020/06/14/2020-06-14-分布式主键ID/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%B9%E9%87%8F%E7%94%9F%E6%88%90%E5%88%86%E9%85%8D.png\" alt=\"数据库批量生成分配\"><br>如图所示，但这种做法的缺点是服务器重启、单点故障会造成ID不连续。还是那句话，没有最好的方案，只有最适合的方案。</li>\n</ol>\n<h1 id=\"三、雪花算法\"><a href=\"#三、雪花算法\" class=\"headerlink\" title=\"三、雪花算法\"></a>三、雪花算法</h1><p>定义一个64bit的数，对指定机器 &amp; 同一时刻 &amp; 某一并发序列，是唯一的，其极限QPS约为400w/s。其格式为：<br><img src=\"/2020/06/14/2020-06-14-分布式主键ID/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95.png\" alt=\"雪花算法\"><br>这个就是原生的雪花算法分配</p>\n<ul>\n<li>41bit时间戳：这里采用的就是当前系统的具体时间，单位为毫秒</li>\n<li>10bit工作机器ID（workerId）：每台机器分配一个id，这样可以标示不同的机器，但是上限为1024，标示一个集群某个业务最多部署的机器个数上限</li>\n<li>12bit序列号（自增域）：表示在某一毫秒下，这个自增域最大可以分配的bit个数，在当前这种配置下，每一毫秒可以分配2^12个数据，也就是说QPS可以到 409.6 w/s。</li>\n</ul>\n<h2 id=\"3-1、存在的问题\"><a href=\"#3-1、存在的问题\" class=\"headerlink\" title=\"3.1、存在的问题\"></a>3.1、存在的问题</h2><p>时间回拨问题：由于机器的时间是动态的调整的，有可能会出现时间跑到之前几毫秒，如果这个时候获取到了这种时间，则会出现数据重复<br>机器id分配及回收问题：目前机器id需要每台机器不一样，这样的方式分配需要有方案进行处理，同时也要考虑，如果改机器宕机了，对应的workerId分配后的回收问题<br>机器id上限：机器id是固定的bit，那么也就是对应的机器个数是有上限的，在有些业务场景下，需要所有机器共享同一个业务空间，那么10bit表示的1024台机器是不够的。<br>业内方案<br>业内的方案中对以上三个问题有这么几种处理，但是都没有彻底解决，我们这里表述下</p>\n<h3 id=\"1-时间回拨问题：\"><a href=\"#1-时间回拨问题：\" class=\"headerlink\" title=\"1.时间回拨问题：\"></a>1.时间回拨问题：</h3><p>采用直接抛异常方式：这种很不友好，太粗暴<br>采用等待跟上次时间的一段范围：这种算是简单解决，可以接受，但是如果等待一段时间后再出现回拨，则抛异常，可接受，但是不算彻底解决</p>\n<h3 id=\"2-机器id分配及回收：\"><a href=\"#2-机器id分配及回收：\" class=\"headerlink\" title=\"2.机器id分配及回收：\"></a>2.机器id分配及回收：</h3><p>采用zookeeper的顺序节点分配：解决了分配，回收可采用zookeeper临时节点回收，但是临时节点不可靠，存在无故消失问题，因此也不可靠<br>采用DB中插入数据作为节点值：解决了分配，没有解决回收</p>\n<h3 id=\"3-机器id上限\"><a href=\"#3-机器id上限\" class=\"headerlink\" title=\"3.机器id上限\"></a>3.机器id上限</h3><p>该问题在业内都没有处理，也就是说如果采用雪花算法，则必定会存在该问题，但是该问题也只有需要大量的业务机器共享的场景才会出现，这种情况，采用客户端双Buffer+DB这种非雪花算法的方案也未尝不可。<br><a href=\"https://cloud.tencent.com/developer/news/678423\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/developer/news/678423</a></p>\n<h1 id=\"四、Redis\"><a href=\"#四、Redis\" class=\"headerlink\" title=\"四、Redis\"></a>四、Redis</h1><p>Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; set seq_id 1     // 初始化自增ID为1</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6379&gt; incr seq_id      // 增加1，并返回递增后的数值</span><br><span class=\"line\">(integer) 2</span><br></pre></td></tr></table></figure>\n\n<p>用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF<br>RDB会定时打一个快照进行持久化，假如连续自增但redis没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。<br>AOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、UUID\"><a href=\"#一、UUID\" class=\"headerlink\" title=\"一、UUID\"></a>一、UUID</h1><ol>\n<li>生成规则：<ul>\n<li>基于时间戳&amp;时钟序列生成</li>\n<li>基于名字空间/名字的散列值 (MD5/SHA1) 生成</li>\n<li>基于随机数生成</li>\n</ul>\n</li>\n<li>优点<ul>\n<li>无需网络，单机自行生成</li>\n<li>速度快，QPS高（支持100ns级并发）</li>\n<li>使用简单</li>\n<li>不会泄漏商业机密</li>\n</ul>\n</li>\n<li>缺点<ul>\n<li>可读性差</li>\n<li>占用空间太多(16个字节)</li>\n<li>影响数据库的性能,</li>\n</ul>\n</li>\n</ol>","more":"<h1 id=\"二、数据库自增\"><a href=\"#二、数据库自增\" class=\"headerlink\" title=\"二、数据库自增\"></a>二、数据库自增</h1><p>数据库自增ID可能是大家最熟悉的一种唯一ID生成方式，其具有使用简单，满足基本需求，天然有序的优点，但也有缺陷：<br>并发性不好<br>数据库写压力大<br>数据库故障后不可使用<br>存在数量泄露风险<br>因此这里给出两种优化方案。</p>\n<ol>\n<li>数据库水平拆分，设置不同的初始值和相同的步长<br><img src=\"/2020/06/14/2020-06-14-分布式主键ID/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%B0%B4%E5%B9%B3%E6%8B%86%E5%88%86ID.png\" alt=\"数据库水平拆分ID\"><br>如图所示，可保证每台数据库生成的ID是不冲突的，但这种固定步长的方式也会带来扩容的问题，很容易想到当扩容时会出现无ID初始值可分的窘境，解决方案有：<br>根据扩容考虑决定步长<br>增加其他位标记区分扩容<br>这其实都是在需求与方案间的权衡，根据需求来选择最适合的方式。</li>\n<li>批量生成一批ID<br>如果要使用单台机器做ID生成，避免固定步长带来的扩容问题，可以每次批量生成一批ID给不同的机器去慢慢消费，这样数据库的压力也会减小到N分之一，且故障后可坚持一段时间。<br><img src=\"/2020/06/14/2020-06-14-分布式主键ID/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%B9%E9%87%8F%E7%94%9F%E6%88%90%E5%88%86%E9%85%8D.png\" alt=\"数据库批量生成分配\"><br>如图所示，但这种做法的缺点是服务器重启、单点故障会造成ID不连续。还是那句话，没有最好的方案，只有最适合的方案。</li>\n</ol>\n<h1 id=\"三、雪花算法\"><a href=\"#三、雪花算法\" class=\"headerlink\" title=\"三、雪花算法\"></a>三、雪花算法</h1><p>定义一个64bit的数，对指定机器 &amp; 同一时刻 &amp; 某一并发序列，是唯一的，其极限QPS约为400w/s。其格式为：<br><img src=\"/2020/06/14/2020-06-14-分布式主键ID/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95.png\" alt=\"雪花算法\"><br>这个就是原生的雪花算法分配</p>\n<ul>\n<li>41bit时间戳：这里采用的就是当前系统的具体时间，单位为毫秒</li>\n<li>10bit工作机器ID（workerId）：每台机器分配一个id，这样可以标示不同的机器，但是上限为1024，标示一个集群某个业务最多部署的机器个数上限</li>\n<li>12bit序列号（自增域）：表示在某一毫秒下，这个自增域最大可以分配的bit个数，在当前这种配置下，每一毫秒可以分配2^12个数据，也就是说QPS可以到 409.6 w/s。</li>\n</ul>\n<h2 id=\"3-1、存在的问题\"><a href=\"#3-1、存在的问题\" class=\"headerlink\" title=\"3.1、存在的问题\"></a>3.1、存在的问题</h2><p>时间回拨问题：由于机器的时间是动态的调整的，有可能会出现时间跑到之前几毫秒，如果这个时候获取到了这种时间，则会出现数据重复<br>机器id分配及回收问题：目前机器id需要每台机器不一样，这样的方式分配需要有方案进行处理，同时也要考虑，如果改机器宕机了，对应的workerId分配后的回收问题<br>机器id上限：机器id是固定的bit，那么也就是对应的机器个数是有上限的，在有些业务场景下，需要所有机器共享同一个业务空间，那么10bit表示的1024台机器是不够的。<br>业内方案<br>业内的方案中对以上三个问题有这么几种处理，但是都没有彻底解决，我们这里表述下</p>\n<h3 id=\"1-时间回拨问题：\"><a href=\"#1-时间回拨问题：\" class=\"headerlink\" title=\"1.时间回拨问题：\"></a>1.时间回拨问题：</h3><p>采用直接抛异常方式：这种很不友好，太粗暴<br>采用等待跟上次时间的一段范围：这种算是简单解决，可以接受，但是如果等待一段时间后再出现回拨，则抛异常，可接受，但是不算彻底解决</p>\n<h3 id=\"2-机器id分配及回收：\"><a href=\"#2-机器id分配及回收：\" class=\"headerlink\" title=\"2.机器id分配及回收：\"></a>2.机器id分配及回收：</h3><p>采用zookeeper的顺序节点分配：解决了分配，回收可采用zookeeper临时节点回收，但是临时节点不可靠，存在无故消失问题，因此也不可靠<br>采用DB中插入数据作为节点值：解决了分配，没有解决回收</p>\n<h3 id=\"3-机器id上限\"><a href=\"#3-机器id上限\" class=\"headerlink\" title=\"3.机器id上限\"></a>3.机器id上限</h3><p>该问题在业内都没有处理，也就是说如果采用雪花算法，则必定会存在该问题，但是该问题也只有需要大量的业务机器共享的场景才会出现，这种情况，采用客户端双Buffer+DB这种非雪花算法的方案也未尝不可。<br><a href=\"https://cloud.tencent.com/developer/news/678423\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/developer/news/678423</a></p>\n<h1 id=\"四、Redis\"><a href=\"#四、Redis\" class=\"headerlink\" title=\"四、Redis\"></a>四、Redis</h1><p>Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; set seq_id 1     // 初始化自增ID为1</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6379&gt; incr seq_id      // 增加1，并返回递增后的数值</span><br><span class=\"line\">(integer) 2</span><br></pre></td></tr></table></figure>\n\n<p>用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF<br>RDB会定时打一个快照进行持久化，假如连续自增但redis没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。<br>AOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长。</p>"},{"title":"java对象","date":"2020-05-16T12:29:04.000Z","_content":"# 一、讲讲对象\n从对象结构、对象创建过程、锁升级过程说明\n# 二、对象结构\n* 对象=对象头+实例数据+数据填充\n* 对象头=markword+classpointer+数组大小\n* markword=hashcode+GC年龄+锁标识+偏向锁标识\n32bit虚拟机:\n![对象头](2020-05-16-java对象/对象头.png)\n\n25bit的hashcode，4bit的GC年龄(0-15岁)，1bit的偏向锁标识，2bit的锁标志位（4种状态） = 32bit\n\n<!--more-->  \n\n# 三、锁升级\n从锁的种类，锁的定义等方面进行讲述。\n* 无锁：对象默认进来是没有锁的\n* 偏向锁：\n    1. 锁产生背景：同步代码块，通过经验验证，一般同时只有一个线程使用，从而竞争较少。\n    2. 锁实现原理：对象头的markwork中记录当前线程的ID，表示偏向该线程。\n    3. 锁升级过程：当线程执行同步代码块，判断对象是否有锁，无锁的话，对象头的markword中记录当前线程的ID（CAS操作），\n           表示偏向该线程。线程进入代码块，只需要判断对象的是否偏向该线程（首先判断偏向锁标识，再判断markword中存储的线程ID）。\n    4. 锁释放：线程不会主动释放锁，只有当其他线程竞争时，才会继续锁的升级。       \n* 轻量级锁：\n    1. 锁产生背景：不阻塞线程，通过自旋的方式，提升性能。\n    2. 锁实现原理：从线程栈桢中创建Lock Record空间，然后将对象的markword复制到Lock record空间，然后通过CAS操作\n    将对象的markword更新为指向Lock record的指针，Lock record的owner指向了markword。\n    3. 锁升级过程：当线程自旋超过一定次数时，或者是超过2个线程竞争资源，都会升级成重量级锁。    \n    \n    * 优点：竞争时，只需要让现场自旋尝试去获取锁，而不需要阻塞线程。\n    * 缺点：自旋，适合执行时间短，自旋时间长容易消耗CPU资源。    \n\n\n* 重量级锁：\n1、锁实现原理：通过对象的monitor锁，而monitor锁依赖操作系统的MutexLock（互斥锁）\n    将markword的值替换成指向MutexLock的指针\n2、monitor锁实现原理:\n    1. 每个对象都有监视器\n    2. 字节码指令：monitorEnter和monitorExit\n    3. c++实现ObjectMonitor，以下为重要属性\n        * _owner：监视器持有者\n        * _entryList：存放处于blocked状态的线程列表，多个线程同时访问进来会进入这个集合\n        * _waitSet：当持有monitor的线程调用wait()方法时，该线程会释放monitor，_owner变量恢复成null，_count会减1，该线程进入_waitSet并等待唤醒。\n        * _recursions：锁的重入次数   \n        * _count：用来记录当前线程拥有锁的次数  \n       \n    * 缺点：依赖操作系统的锁，会阻塞线程，唤醒和阻塞都需要用户态和内核态的切换       \n\n\n# 四、对象内存分配\n\n* 对象头\n```\n32bit JVM (8字节)\n    mark word: 32bit\n        在对象未被锁定的状态：25bit hashcode + 4bit 对象分代年龄 + 2bit存储锁标志位 + 1bit 固定为0\n    类型指针：32bit\n    \n64bit JVM (16字节)\n\n    mark word: 64bit\n    类型指针：64bit\n    \n数组长度（Array Length）\n    如果对象是一个数组，那么对象头还需要有额外的空间用于存储数组的长度。\n    这部分数据的长度也随着JVM架构的不同而不同：32位的JVM上，长度为32位；64位JVM则为64位。\n    64位JVM如果开启+UseCompressedOops选项，该区域长度也将由64位压缩至32位。\n```\n* 实例数据\n```\n基本类型与引用类型\n    boolean             1\n    byte                1\n    shot                2\n    char                2\n    int                 4\n    float               4\n    long                8   \n    double              8\n```\n* 栗子\n```\nClass A {\n    int i;\n    byte b;\n    String str;\n}\n```\n![内存分配](2020-05-16-java对象/内存分配.png)\n# 五、对象的继承\n![对象继承](2020-05-16-java对象/对象继承.png)\n\n这个程序执行的基本流程是：\n\n1. 虚拟机加载Test类，提取类信息到方法区；\n\n2. 通过保存在方法去的字节码，虚拟机开始执行main方法，main函数入栈；\n\n3. 执行Student s = new Student();给student实例对象分配堆空间。又因为实现自己要先实现父类，所以，虚拟机加载person类到方法区，并在堆中为父类成员变量在子类空间中初始化。然后加载student类到方法区，为子类的成员变量分配空间并初始化。\n\n4. 接下来两条语句为成员变量赋值，由于name跟age是从父类继承而来，会被保存在子类父对象中，所以就根据引用变量s持有的引用找到堆中的对象(子类对象)，然后给name跟age赋值。\n\n5. 调用say()方法，通过引用变量s持有的引用找到堆中的实例对象，通过实例对象持有的本类在方法区的引用，找到本类的类型信息，定位到say()方法。say()方法入栈。开始执行say()方法中的字节码。\n\n6. say()方法执行完毕，say方法出栈，程序回到main方法，main方法执行完毕出栈，主线程消亡，虚拟机实例消亡，程序结束。\n\n总结：相同的方法会被重写，变量没有重写之说，如果子类声明了跟父类一样的变量，那意味着子类将有两个相同名称的变量。一个存放在子类实例对象中，一个存放在父类子对象中。父类的private变量，也会被继承并且初始化在子类父对象中，只不过对外不可见。\n\n\n\n","source":"_posts/2020-05-16-java对象.md","raw":"---\ntitle: java对象\ndate: 2020-05-16 20:29:04\ntags: jvm java\ncategories: \n    - [java, jvm, 对象]\n---\n# 一、讲讲对象\n从对象结构、对象创建过程、锁升级过程说明\n# 二、对象结构\n* 对象=对象头+实例数据+数据填充\n* 对象头=markword+classpointer+数组大小\n* markword=hashcode+GC年龄+锁标识+偏向锁标识\n32bit虚拟机:\n![对象头](2020-05-16-java对象/对象头.png)\n\n25bit的hashcode，4bit的GC年龄(0-15岁)，1bit的偏向锁标识，2bit的锁标志位（4种状态） = 32bit\n\n<!--more-->  \n\n# 三、锁升级\n从锁的种类，锁的定义等方面进行讲述。\n* 无锁：对象默认进来是没有锁的\n* 偏向锁：\n    1. 锁产生背景：同步代码块，通过经验验证，一般同时只有一个线程使用，从而竞争较少。\n    2. 锁实现原理：对象头的markwork中记录当前线程的ID，表示偏向该线程。\n    3. 锁升级过程：当线程执行同步代码块，判断对象是否有锁，无锁的话，对象头的markword中记录当前线程的ID（CAS操作），\n           表示偏向该线程。线程进入代码块，只需要判断对象的是否偏向该线程（首先判断偏向锁标识，再判断markword中存储的线程ID）。\n    4. 锁释放：线程不会主动释放锁，只有当其他线程竞争时，才会继续锁的升级。       \n* 轻量级锁：\n    1. 锁产生背景：不阻塞线程，通过自旋的方式，提升性能。\n    2. 锁实现原理：从线程栈桢中创建Lock Record空间，然后将对象的markword复制到Lock record空间，然后通过CAS操作\n    将对象的markword更新为指向Lock record的指针，Lock record的owner指向了markword。\n    3. 锁升级过程：当线程自旋超过一定次数时，或者是超过2个线程竞争资源，都会升级成重量级锁。    \n    \n    * 优点：竞争时，只需要让现场自旋尝试去获取锁，而不需要阻塞线程。\n    * 缺点：自旋，适合执行时间短，自旋时间长容易消耗CPU资源。    \n\n\n* 重量级锁：\n1、锁实现原理：通过对象的monitor锁，而monitor锁依赖操作系统的MutexLock（互斥锁）\n    将markword的值替换成指向MutexLock的指针\n2、monitor锁实现原理:\n    1. 每个对象都有监视器\n    2. 字节码指令：monitorEnter和monitorExit\n    3. c++实现ObjectMonitor，以下为重要属性\n        * _owner：监视器持有者\n        * _entryList：存放处于blocked状态的线程列表，多个线程同时访问进来会进入这个集合\n        * _waitSet：当持有monitor的线程调用wait()方法时，该线程会释放monitor，_owner变量恢复成null，_count会减1，该线程进入_waitSet并等待唤醒。\n        * _recursions：锁的重入次数   \n        * _count：用来记录当前线程拥有锁的次数  \n       \n    * 缺点：依赖操作系统的锁，会阻塞线程，唤醒和阻塞都需要用户态和内核态的切换       \n\n\n# 四、对象内存分配\n\n* 对象头\n```\n32bit JVM (8字节)\n    mark word: 32bit\n        在对象未被锁定的状态：25bit hashcode + 4bit 对象分代年龄 + 2bit存储锁标志位 + 1bit 固定为0\n    类型指针：32bit\n    \n64bit JVM (16字节)\n\n    mark word: 64bit\n    类型指针：64bit\n    \n数组长度（Array Length）\n    如果对象是一个数组，那么对象头还需要有额外的空间用于存储数组的长度。\n    这部分数据的长度也随着JVM架构的不同而不同：32位的JVM上，长度为32位；64位JVM则为64位。\n    64位JVM如果开启+UseCompressedOops选项，该区域长度也将由64位压缩至32位。\n```\n* 实例数据\n```\n基本类型与引用类型\n    boolean             1\n    byte                1\n    shot                2\n    char                2\n    int                 4\n    float               4\n    long                8   \n    double              8\n```\n* 栗子\n```\nClass A {\n    int i;\n    byte b;\n    String str;\n}\n```\n![内存分配](2020-05-16-java对象/内存分配.png)\n# 五、对象的继承\n![对象继承](2020-05-16-java对象/对象继承.png)\n\n这个程序执行的基本流程是：\n\n1. 虚拟机加载Test类，提取类信息到方法区；\n\n2. 通过保存在方法去的字节码，虚拟机开始执行main方法，main函数入栈；\n\n3. 执行Student s = new Student();给student实例对象分配堆空间。又因为实现自己要先实现父类，所以，虚拟机加载person类到方法区，并在堆中为父类成员变量在子类空间中初始化。然后加载student类到方法区，为子类的成员变量分配空间并初始化。\n\n4. 接下来两条语句为成员变量赋值，由于name跟age是从父类继承而来，会被保存在子类父对象中，所以就根据引用变量s持有的引用找到堆中的对象(子类对象)，然后给name跟age赋值。\n\n5. 调用say()方法，通过引用变量s持有的引用找到堆中的实例对象，通过实例对象持有的本类在方法区的引用，找到本类的类型信息，定位到say()方法。say()方法入栈。开始执行say()方法中的字节码。\n\n6. say()方法执行完毕，say方法出栈，程序回到main方法，main方法执行完毕出栈，主线程消亡，虚拟机实例消亡，程序结束。\n\n总结：相同的方法会被重写，变量没有重写之说，如果子类声明了跟父类一样的变量，那意味着子类将有两个相同名称的变量。一个存放在子类实例对象中，一个存放在父类子对象中。父类的private变量，也会被继承并且初始化在子类父对象中，只不过对外不可见。\n\n\n\n","slug":"2020-05-16-java对象","published":1,"updated":"2024-12-09T03:22:02.674Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxj003ca13knspmqpb2","content":"<h1 id=\"一、讲讲对象\"><a href=\"#一、讲讲对象\" class=\"headerlink\" title=\"一、讲讲对象\"></a>一、讲讲对象</h1><p>从对象结构、对象创建过程、锁升级过程说明</p>\n<h1 id=\"二、对象结构\"><a href=\"#二、对象结构\" class=\"headerlink\" title=\"二、对象结构\"></a>二、对象结构</h1><ul>\n<li>对象=对象头+实例数据+数据填充</li>\n<li>对象头=markword+classpointer+数组大小</li>\n<li>markword=hashcode+GC年龄+锁标识+偏向锁标识<br>32bit虚拟机:<br><img src=\"/2020/05/16/2020-05-16-java对象/%E5%AF%B9%E8%B1%A1%E5%A4%B4.png\" alt=\"对象头\"></li>\n</ul>\n<p>25bit的hashcode，4bit的GC年龄(0-15岁)，1bit的偏向锁标识，2bit的锁标志位（4种状态） = 32bit</p>\n<a id=\"more\"></a>  \n\n<h1 id=\"三、锁升级\"><a href=\"#三、锁升级\" class=\"headerlink\" title=\"三、锁升级\"></a>三、锁升级</h1><p>从锁的种类，锁的定义等方面进行讲述。</p>\n<ul>\n<li><p>无锁：对象默认进来是没有锁的</p>\n</li>\n<li><p>偏向锁：</p>\n<ol>\n<li>锁产生背景：同步代码块，通过经验验证，一般同时只有一个线程使用，从而竞争较少。</li>\n<li>锁实现原理：对象头的markwork中记录当前线程的ID，表示偏向该线程。</li>\n<li>锁升级过程：当线程执行同步代码块，判断对象是否有锁，无锁的话，对象头的markword中记录当前线程的ID（CAS操作），<pre><code>表示偏向该线程。线程进入代码块，只需要判断对象的是否偏向该线程（首先判断偏向锁标识，再判断markword中存储的线程ID）。</code></pre></li>\n<li>锁释放：线程不会主动释放锁，只有当其他线程竞争时，才会继续锁的升级。       </li>\n</ol>\n</li>\n<li><p>轻量级锁：</p>\n<ol>\n<li>锁产生背景：不阻塞线程，通过自旋的方式，提升性能。</li>\n<li>锁实现原理：从线程栈桢中创建Lock Record空间，然后将对象的markword复制到Lock record空间，然后通过CAS操作<br>将对象的markword更新为指向Lock record的指针，Lock record的owner指向了markword。</li>\n<li>锁升级过程：当线程自旋超过一定次数时，或者是超过2个线程竞争资源，都会升级成重量级锁。    </li>\n</ol>\n<ul>\n<li>优点：竞争时，只需要让现场自旋尝试去获取锁，而不需要阻塞线程。</li>\n<li>缺点：自旋，适合执行时间短，自旋时间长容易消耗CPU资源。    </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>重量级锁：<br>1、锁实现原理：通过对象的monitor锁，而monitor锁依赖操作系统的MutexLock（互斥锁）<br>  将markword的值替换成指向MutexLock的指针<br>2、monitor锁实现原理:</p>\n<ol>\n<li>每个对象都有监视器</li>\n<li>字节码指令：monitorEnter和monitorExit</li>\n<li>c++实现ObjectMonitor，以下为重要属性<ul>\n<li>_owner：监视器持有者</li>\n<li>_entryList：存放处于blocked状态的线程列表，多个线程同时访问进来会进入这个集合</li>\n<li>_waitSet：当持有monitor的线程调用wait()方法时，该线程会释放monitor，_owner变量恢复成null，_count会减1，该线程进入_waitSet并等待唤醒。</li>\n<li>_recursions：锁的重入次数   </li>\n<li>_count：用来记录当前线程拥有锁的次数  </li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>缺点：依赖操作系统的锁，会阻塞线程，唤醒和阻塞都需要用户态和内核态的切换       </li>\n</ul>\n</li>\n</ul>\n<h1 id=\"四、对象内存分配\"><a href=\"#四、对象内存分配\" class=\"headerlink\" title=\"四、对象内存分配\"></a>四、对象内存分配</h1><ul>\n<li><p>对象头</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">32bit JVM (8字节)</span><br><span class=\"line\">    mark word: 32bit</span><br><span class=\"line\">        在对象未被锁定的状态：25bit hashcode + 4bit 对象分代年龄 + 2bit存储锁标志位 + 1bit 固定为0</span><br><span class=\"line\">    类型指针：32bit</span><br><span class=\"line\">    </span><br><span class=\"line\">64bit JVM (16字节)</span><br><span class=\"line\"></span><br><span class=\"line\">    mark word: 64bit</span><br><span class=\"line\">    类型指针：64bit</span><br><span class=\"line\">    </span><br><span class=\"line\">数组长度（Array Length）</span><br><span class=\"line\">    如果对象是一个数组，那么对象头还需要有额外的空间用于存储数组的长度。</span><br><span class=\"line\">    这部分数据的长度也随着JVM架构的不同而不同：32位的JVM上，长度为32位；64位JVM则为64位。</span><br><span class=\"line\">    64位JVM如果开启+UseCompressedOops选项，该区域长度也将由64位压缩至32位。</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>实例数据</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">基本类型与引用类型</span><br><span class=\"line\">    boolean             1</span><br><span class=\"line\">    byte                1</span><br><span class=\"line\">    shot                2</span><br><span class=\"line\">    char                2</span><br><span class=\"line\">    int                 4</span><br><span class=\"line\">    float               4</span><br><span class=\"line\">    long                8   </span><br><span class=\"line\">    double              8</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>栗子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Class A &#123;</span><br><span class=\"line\">    int i;</span><br><span class=\"line\">    byte b;</span><br><span class=\"line\">    String str;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p><img src=\"/2020/05/16/2020-05-16-java对象/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D.png\" alt=\"内存分配\"></p>\n<h1 id=\"五、对象的继承\"><a href=\"#五、对象的继承\" class=\"headerlink\" title=\"五、对象的继承\"></a>五、对象的继承</h1><p><img src=\"/2020/05/16/2020-05-16-java对象/%E5%AF%B9%E8%B1%A1%E7%BB%A7%E6%89%BF.png\" alt=\"对象继承\"></p>\n<p>这个程序执行的基本流程是：</p>\n<ol>\n<li><p>虚拟机加载Test类，提取类信息到方法区；</p>\n</li>\n<li><p>通过保存在方法去的字节码，虚拟机开始执行main方法，main函数入栈；</p>\n</li>\n<li><p>执行Student s = new Student();给student实例对象分配堆空间。又因为实现自己要先实现父类，所以，虚拟机加载person类到方法区，并在堆中为父类成员变量在子类空间中初始化。然后加载student类到方法区，为子类的成员变量分配空间并初始化。</p>\n</li>\n<li><p>接下来两条语句为成员变量赋值，由于name跟age是从父类继承而来，会被保存在子类父对象中，所以就根据引用变量s持有的引用找到堆中的对象(子类对象)，然后给name跟age赋值。</p>\n</li>\n<li><p>调用say()方法，通过引用变量s持有的引用找到堆中的实例对象，通过实例对象持有的本类在方法区的引用，找到本类的类型信息，定位到say()方法。say()方法入栈。开始执行say()方法中的字节码。</p>\n</li>\n<li><p>say()方法执行完毕，say方法出栈，程序回到main方法，main方法执行完毕出栈，主线程消亡，虚拟机实例消亡，程序结束。</p>\n</li>\n</ol>\n<p>总结：相同的方法会被重写，变量没有重写之说，如果子类声明了跟父类一样的变量，那意味着子类将有两个相同名称的变量。一个存放在子类实例对象中，一个存放在父类子对象中。父类的private变量，也会被继承并且初始化在子类父对象中，只不过对外不可见。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、讲讲对象\"><a href=\"#一、讲讲对象\" class=\"headerlink\" title=\"一、讲讲对象\"></a>一、讲讲对象</h1><p>从对象结构、对象创建过程、锁升级过程说明</p>\n<h1 id=\"二、对象结构\"><a href=\"#二、对象结构\" class=\"headerlink\" title=\"二、对象结构\"></a>二、对象结构</h1><ul>\n<li>对象=对象头+实例数据+数据填充</li>\n<li>对象头=markword+classpointer+数组大小</li>\n<li>markword=hashcode+GC年龄+锁标识+偏向锁标识<br>32bit虚拟机:<br><img src=\"/2020/05/16/2020-05-16-java对象/%E5%AF%B9%E8%B1%A1%E5%A4%B4.png\" alt=\"对象头\"></li>\n</ul>\n<p>25bit的hashcode，4bit的GC年龄(0-15岁)，1bit的偏向锁标识，2bit的锁标志位（4种状态） = 32bit</p>","more":"<h1 id=\"三、锁升级\"><a href=\"#三、锁升级\" class=\"headerlink\" title=\"三、锁升级\"></a>三、锁升级</h1><p>从锁的种类，锁的定义等方面进行讲述。</p>\n<ul>\n<li><p>无锁：对象默认进来是没有锁的</p>\n</li>\n<li><p>偏向锁：</p>\n<ol>\n<li>锁产生背景：同步代码块，通过经验验证，一般同时只有一个线程使用，从而竞争较少。</li>\n<li>锁实现原理：对象头的markwork中记录当前线程的ID，表示偏向该线程。</li>\n<li>锁升级过程：当线程执行同步代码块，判断对象是否有锁，无锁的话，对象头的markword中记录当前线程的ID（CAS操作），<pre><code>表示偏向该线程。线程进入代码块，只需要判断对象的是否偏向该线程（首先判断偏向锁标识，再判断markword中存储的线程ID）。</code></pre></li>\n<li>锁释放：线程不会主动释放锁，只有当其他线程竞争时，才会继续锁的升级。       </li>\n</ol>\n</li>\n<li><p>轻量级锁：</p>\n<ol>\n<li>锁产生背景：不阻塞线程，通过自旋的方式，提升性能。</li>\n<li>锁实现原理：从线程栈桢中创建Lock Record空间，然后将对象的markword复制到Lock record空间，然后通过CAS操作<br>将对象的markword更新为指向Lock record的指针，Lock record的owner指向了markword。</li>\n<li>锁升级过程：当线程自旋超过一定次数时，或者是超过2个线程竞争资源，都会升级成重量级锁。    </li>\n</ol>\n<ul>\n<li>优点：竞争时，只需要让现场自旋尝试去获取锁，而不需要阻塞线程。</li>\n<li>缺点：自旋，适合执行时间短，自旋时间长容易消耗CPU资源。    </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>重量级锁：<br>1、锁实现原理：通过对象的monitor锁，而monitor锁依赖操作系统的MutexLock（互斥锁）<br>  将markword的值替换成指向MutexLock的指针<br>2、monitor锁实现原理:</p>\n<ol>\n<li>每个对象都有监视器</li>\n<li>字节码指令：monitorEnter和monitorExit</li>\n<li>c++实现ObjectMonitor，以下为重要属性<ul>\n<li>_owner：监视器持有者</li>\n<li>_entryList：存放处于blocked状态的线程列表，多个线程同时访问进来会进入这个集合</li>\n<li>_waitSet：当持有monitor的线程调用wait()方法时，该线程会释放monitor，_owner变量恢复成null，_count会减1，该线程进入_waitSet并等待唤醒。</li>\n<li>_recursions：锁的重入次数   </li>\n<li>_count：用来记录当前线程拥有锁的次数  </li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>缺点：依赖操作系统的锁，会阻塞线程，唤醒和阻塞都需要用户态和内核态的切换       </li>\n</ul>\n</li>\n</ul>\n<h1 id=\"四、对象内存分配\"><a href=\"#四、对象内存分配\" class=\"headerlink\" title=\"四、对象内存分配\"></a>四、对象内存分配</h1><ul>\n<li><p>对象头</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">32bit JVM (8字节)</span><br><span class=\"line\">    mark word: 32bit</span><br><span class=\"line\">        在对象未被锁定的状态：25bit hashcode + 4bit 对象分代年龄 + 2bit存储锁标志位 + 1bit 固定为0</span><br><span class=\"line\">    类型指针：32bit</span><br><span class=\"line\">    </span><br><span class=\"line\">64bit JVM (16字节)</span><br><span class=\"line\"></span><br><span class=\"line\">    mark word: 64bit</span><br><span class=\"line\">    类型指针：64bit</span><br><span class=\"line\">    </span><br><span class=\"line\">数组长度（Array Length）</span><br><span class=\"line\">    如果对象是一个数组，那么对象头还需要有额外的空间用于存储数组的长度。</span><br><span class=\"line\">    这部分数据的长度也随着JVM架构的不同而不同：32位的JVM上，长度为32位；64位JVM则为64位。</span><br><span class=\"line\">    64位JVM如果开启+UseCompressedOops选项，该区域长度也将由64位压缩至32位。</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>实例数据</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">基本类型与引用类型</span><br><span class=\"line\">    boolean             1</span><br><span class=\"line\">    byte                1</span><br><span class=\"line\">    shot                2</span><br><span class=\"line\">    char                2</span><br><span class=\"line\">    int                 4</span><br><span class=\"line\">    float               4</span><br><span class=\"line\">    long                8   </span><br><span class=\"line\">    double              8</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>栗子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Class A &#123;</span><br><span class=\"line\">    int i;</span><br><span class=\"line\">    byte b;</span><br><span class=\"line\">    String str;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p><img src=\"/2020/05/16/2020-05-16-java对象/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D.png\" alt=\"内存分配\"></p>\n<h1 id=\"五、对象的继承\"><a href=\"#五、对象的继承\" class=\"headerlink\" title=\"五、对象的继承\"></a>五、对象的继承</h1><p><img src=\"/2020/05/16/2020-05-16-java对象/%E5%AF%B9%E8%B1%A1%E7%BB%A7%E6%89%BF.png\" alt=\"对象继承\"></p>\n<p>这个程序执行的基本流程是：</p>\n<ol>\n<li><p>虚拟机加载Test类，提取类信息到方法区；</p>\n</li>\n<li><p>通过保存在方法去的字节码，虚拟机开始执行main方法，main函数入栈；</p>\n</li>\n<li><p>执行Student s = new Student();给student实例对象分配堆空间。又因为实现自己要先实现父类，所以，虚拟机加载person类到方法区，并在堆中为父类成员变量在子类空间中初始化。然后加载student类到方法区，为子类的成员变量分配空间并初始化。</p>\n</li>\n<li><p>接下来两条语句为成员变量赋值，由于name跟age是从父类继承而来，会被保存在子类父对象中，所以就根据引用变量s持有的引用找到堆中的对象(子类对象)，然后给name跟age赋值。</p>\n</li>\n<li><p>调用say()方法，通过引用变量s持有的引用找到堆中的实例对象，通过实例对象持有的本类在方法区的引用，找到本类的类型信息，定位到say()方法。say()方法入栈。开始执行say()方法中的字节码。</p>\n</li>\n<li><p>say()方法执行完毕，say方法出栈，程序回到main方法，main方法执行完毕出栈，主线程消亡，虚拟机实例消亡，程序结束。</p>\n</li>\n</ol>\n<p>总结：相同的方法会被重写，变量没有重写之说，如果子类声明了跟父类一样的变量，那意味着子类将有两个相同名称的变量。一个存放在子类实例对象中，一个存放在父类子对象中。父类的private变量，也会被继承并且初始化在子类父对象中，只不过对外不可见。</p>"},{"title":"订单ES","date":"2020-06-07T13:46:54.000Z","_content":"\n# 一、背景\n1. 随着订单越来越多，基于MySQL关系型数据库的查询容易遇到瓶颈。\n2. 订单管理平台的复杂查询。\n\n以上多种原因，有了订单数据存入ES的诉求。\n\n# 二、数据同步方案：\n\n\n\n考虑订单数据迁入ES，需要考虑的因素。\n\n* 最终选择了方案2\n\n<!--more-->  \n\n# 三、常见问题及解决方案\n![常见问题及解决方案](2020-06-07-订单ES/常见问题及解决方案.png)\n\n\n# 四、需要考虑的问题\n\n1. 评估全量索引重建的时间范围\n    * 初次同步索引批量重建，以月为单位分段进行数据同步；另外支持按自定义时间段进行数据检查的补偿机制，用于修复一些业务遗漏造成的数据不一致，具体时间跨度可根据触发实际场景调节；\n2. 订单数据是否有删除或者淘汰机制，如果没有，分片逐渐增加，rebalance过程会逐渐增加。\n    * 随着数据越来越多，\n3. 订单整体数据量有多大，准备设置多少个分片，分片越大，添加或删除节点过程中数据rebalance的过程越长，这个过程中性能较差。\n\n# 五、创建索引\n1. 基于订单号查询\n2. 基于商品查询\n3. 基于订单时间查询\n4. 基于城市查询\n5. 基于用户查询\n6. 以及其他场景，建立以下索引结构（部分）\n\n```\n{\n  \"tk_jz_mid_order-20200628\": {\n    \"mappings\": {\n      \"ty_mid_order\": {\n        \"properties\": {\n          \"create_time\": {\n            \"format\": \"yyyy-MM-dd HH:mm:ss\",\n            \"store\": true,\n            \"type\": \"date\"\n          },\n          \"parent_id\": {\n            \"store\": true,\n            \"type\": \"long\"\n          },\n          \"id\": {\n            \"store\": true,\n            \"type\": \"long\"\n          },\n          \"city_id\": {\n            \"store\": true,\n            \"type\": \"integer\"\n          },\n          \"order_date\": {\n            \"format\": \"yyyy-MM-dd HH:mm:ss\",\n            \"store\": true,\n            \"type\": \"date\"\n          },\n          \"uid\": {\n            \"store\": true,\n            \"type\": \"long\"\n          }\n          \"order_properties\": {\n            \"type\": \"nested\",\n            \"properties\": {\n              \"create_time\": {\n                \"format\": \"yyyy-MM-dd HH:mm:ss\",\n                \"store\": true,\n                \"type\": \"date\"\n              },\n              \"property_key\": {\n                \"analyzer\": \"ik_smart\",\n                \"store\": true,\n                \"type\": \"text\"\n              },\n              \"property_value\": {\n                \"analyzer\": \"ik_smart\",\n                \"store\": true,\n                \"type\": \"text\"\n              },\n              \"property_name\": {\n                \"analyzer\": \"ik_smart\",\n                \"store\": true,\n                \"type\": \"text\"\n              }\n            }\n          },\n          \"order_purchases\": {\n            \"type\": \"nested\",\n            \"properties\": {\n              \"sku_bar_code\": {\n                \"store\": true,\n                \"type\": \"long\"\n              },\n              \"create_time\": {\n                \"format\": \"yyyy-MM-dd HH:mm:ss\",\n                \"store\": true,\n                \"type\": \"date\"\n              },\n              \"spu_name\": {\n                \"analyzer\": \"ik_smart\",\n                \"store\": true,\n                \"type\": \"text\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n* es版本6.X\n* 对商品名称分词，对词项生成倒排索引。\n* 对订单属性分词，对词项生成倒排索引。\n","source":"_posts/2020-06-07-订单ES.md","raw":"---\ntitle: 订单ES\ndate:  2020-06-07 21:46:54\ntags: es\ncategories: ES\n---\n\n# 一、背景\n1. 随着订单越来越多，基于MySQL关系型数据库的查询容易遇到瓶颈。\n2. 订单管理平台的复杂查询。\n\n以上多种原因，有了订单数据存入ES的诉求。\n\n# 二、数据同步方案：\n\n\n\n考虑订单数据迁入ES，需要考虑的因素。\n\n* 最终选择了方案2\n\n<!--more-->  \n\n# 三、常见问题及解决方案\n![常见问题及解决方案](2020-06-07-订单ES/常见问题及解决方案.png)\n\n\n# 四、需要考虑的问题\n\n1. 评估全量索引重建的时间范围\n    * 初次同步索引批量重建，以月为单位分段进行数据同步；另外支持按自定义时间段进行数据检查的补偿机制，用于修复一些业务遗漏造成的数据不一致，具体时间跨度可根据触发实际场景调节；\n2. 订单数据是否有删除或者淘汰机制，如果没有，分片逐渐增加，rebalance过程会逐渐增加。\n    * 随着数据越来越多，\n3. 订单整体数据量有多大，准备设置多少个分片，分片越大，添加或删除节点过程中数据rebalance的过程越长，这个过程中性能较差。\n\n# 五、创建索引\n1. 基于订单号查询\n2. 基于商品查询\n3. 基于订单时间查询\n4. 基于城市查询\n5. 基于用户查询\n6. 以及其他场景，建立以下索引结构（部分）\n\n```\n{\n  \"tk_jz_mid_order-20200628\": {\n    \"mappings\": {\n      \"ty_mid_order\": {\n        \"properties\": {\n          \"create_time\": {\n            \"format\": \"yyyy-MM-dd HH:mm:ss\",\n            \"store\": true,\n            \"type\": \"date\"\n          },\n          \"parent_id\": {\n            \"store\": true,\n            \"type\": \"long\"\n          },\n          \"id\": {\n            \"store\": true,\n            \"type\": \"long\"\n          },\n          \"city_id\": {\n            \"store\": true,\n            \"type\": \"integer\"\n          },\n          \"order_date\": {\n            \"format\": \"yyyy-MM-dd HH:mm:ss\",\n            \"store\": true,\n            \"type\": \"date\"\n          },\n          \"uid\": {\n            \"store\": true,\n            \"type\": \"long\"\n          }\n          \"order_properties\": {\n            \"type\": \"nested\",\n            \"properties\": {\n              \"create_time\": {\n                \"format\": \"yyyy-MM-dd HH:mm:ss\",\n                \"store\": true,\n                \"type\": \"date\"\n              },\n              \"property_key\": {\n                \"analyzer\": \"ik_smart\",\n                \"store\": true,\n                \"type\": \"text\"\n              },\n              \"property_value\": {\n                \"analyzer\": \"ik_smart\",\n                \"store\": true,\n                \"type\": \"text\"\n              },\n              \"property_name\": {\n                \"analyzer\": \"ik_smart\",\n                \"store\": true,\n                \"type\": \"text\"\n              }\n            }\n          },\n          \"order_purchases\": {\n            \"type\": \"nested\",\n            \"properties\": {\n              \"sku_bar_code\": {\n                \"store\": true,\n                \"type\": \"long\"\n              },\n              \"create_time\": {\n                \"format\": \"yyyy-MM-dd HH:mm:ss\",\n                \"store\": true,\n                \"type\": \"date\"\n              },\n              \"spu_name\": {\n                \"analyzer\": \"ik_smart\",\n                \"store\": true,\n                \"type\": \"text\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n* es版本6.X\n* 对商品名称分词，对词项生成倒排索引。\n* 对订单属性分词，对词项生成倒排索引。\n","slug":"2020-06-07-订单ES","published":1,"updated":"2024-10-14T09:38:12.309Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxk003fa13k4yth221h","content":"<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><ol>\n<li>随着订单越来越多，基于MySQL关系型数据库的查询容易遇到瓶颈。</li>\n<li>订单管理平台的复杂查询。</li>\n</ol>\n<p>以上多种原因，有了订单数据存入ES的诉求。</p>\n<h1 id=\"二、数据同步方案：\"><a href=\"#二、数据同步方案：\" class=\"headerlink\" title=\"二、数据同步方案：\"></a>二、数据同步方案：</h1><p>考虑订单数据迁入ES，需要考虑的因素。</p>\n<ul>\n<li>最终选择了方案2</li>\n</ul>\n<a id=\"more\"></a>  \n\n<h1 id=\"三、常见问题及解决方案\"><a href=\"#三、常见问题及解决方案\" class=\"headerlink\" title=\"三、常见问题及解决方案\"></a>三、常见问题及解决方案</h1><p><img src=\"/2020/06/07/2020-06-07-订单ES/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.png\" alt=\"常见问题及解决方案\"></p>\n<h1 id=\"四、需要考虑的问题\"><a href=\"#四、需要考虑的问题\" class=\"headerlink\" title=\"四、需要考虑的问题\"></a>四、需要考虑的问题</h1><ol>\n<li>评估全量索引重建的时间范围<ul>\n<li>初次同步索引批量重建，以月为单位分段进行数据同步；另外支持按自定义时间段进行数据检查的补偿机制，用于修复一些业务遗漏造成的数据不一致，具体时间跨度可根据触发实际场景调节；</li>\n</ul>\n</li>\n<li>订单数据是否有删除或者淘汰机制，如果没有，分片逐渐增加，rebalance过程会逐渐增加。<ul>\n<li>随着数据越来越多，</li>\n</ul>\n</li>\n<li>订单整体数据量有多大，准备设置多少个分片，分片越大，添加或删除节点过程中数据rebalance的过程越长，这个过程中性能较差。</li>\n</ol>\n<h1 id=\"五、创建索引\"><a href=\"#五、创建索引\" class=\"headerlink\" title=\"五、创建索引\"></a>五、创建索引</h1><ol>\n<li>基于订单号查询</li>\n<li>基于商品查询</li>\n<li>基于订单时间查询</li>\n<li>基于城市查询</li>\n<li>基于用户查询</li>\n<li>以及其他场景，建立以下索引结构（部分）</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;tk_jz_mid_order-20200628&quot;: &#123;</span><br><span class=\"line\">    &quot;mappings&quot;: &#123;</span><br><span class=\"line\">      &quot;ty_mid_order&quot;: &#123;</span><br><span class=\"line\">        &quot;properties&quot;: &#123;</span><br><span class=\"line\">          &quot;create_time&quot;: &#123;</span><br><span class=\"line\">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;date&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;parent_id&quot;: &#123;</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;long&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;id&quot;: &#123;</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;long&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;city_id&quot;: &#123;</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;integer&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;order_date&quot;: &#123;</span><br><span class=\"line\">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;date&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;uid&quot;: &#123;</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;long&quot;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">          &quot;order_properties&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;nested&quot;,</span><br><span class=\"line\">            &quot;properties&quot;: &#123;</span><br><span class=\"line\">              &quot;create_time&quot;: &#123;</span><br><span class=\"line\">                &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;date&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;property_key&quot;: &#123;</span><br><span class=\"line\">                &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;text&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;property_value&quot;: &#123;</span><br><span class=\"line\">                &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;text&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;property_name&quot;: &#123;</span><br><span class=\"line\">                &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;text&quot;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;order_purchases&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;nested&quot;,</span><br><span class=\"line\">            &quot;properties&quot;: &#123;</span><br><span class=\"line\">              &quot;sku_bar_code&quot;: &#123;</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;long&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;create_time&quot;: &#123;</span><br><span class=\"line\">                &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;date&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;spu_name&quot;: &#123;</span><br><span class=\"line\">                &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;text&quot;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>es版本6.X</li>\n<li>对商品名称分词，对词项生成倒排索引。</li>\n<li>对订单属性分词，对词项生成倒排索引。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h1><ol>\n<li>随着订单越来越多，基于MySQL关系型数据库的查询容易遇到瓶颈。</li>\n<li>订单管理平台的复杂查询。</li>\n</ol>\n<p>以上多种原因，有了订单数据存入ES的诉求。</p>\n<h1 id=\"二、数据同步方案：\"><a href=\"#二、数据同步方案：\" class=\"headerlink\" title=\"二、数据同步方案：\"></a>二、数据同步方案：</h1><p>考虑订单数据迁入ES，需要考虑的因素。</p>\n<ul>\n<li>最终选择了方案2</li>\n</ul>","more":"<h1 id=\"三、常见问题及解决方案\"><a href=\"#三、常见问题及解决方案\" class=\"headerlink\" title=\"三、常见问题及解决方案\"></a>三、常见问题及解决方案</h1><p><img src=\"/2020/06/07/2020-06-07-订单ES/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.png\" alt=\"常见问题及解决方案\"></p>\n<h1 id=\"四、需要考虑的问题\"><a href=\"#四、需要考虑的问题\" class=\"headerlink\" title=\"四、需要考虑的问题\"></a>四、需要考虑的问题</h1><ol>\n<li>评估全量索引重建的时间范围<ul>\n<li>初次同步索引批量重建，以月为单位分段进行数据同步；另外支持按自定义时间段进行数据检查的补偿机制，用于修复一些业务遗漏造成的数据不一致，具体时间跨度可根据触发实际场景调节；</li>\n</ul>\n</li>\n<li>订单数据是否有删除或者淘汰机制，如果没有，分片逐渐增加，rebalance过程会逐渐增加。<ul>\n<li>随着数据越来越多，</li>\n</ul>\n</li>\n<li>订单整体数据量有多大，准备设置多少个分片，分片越大，添加或删除节点过程中数据rebalance的过程越长，这个过程中性能较差。</li>\n</ol>\n<h1 id=\"五、创建索引\"><a href=\"#五、创建索引\" class=\"headerlink\" title=\"五、创建索引\"></a>五、创建索引</h1><ol>\n<li>基于订单号查询</li>\n<li>基于商品查询</li>\n<li>基于订单时间查询</li>\n<li>基于城市查询</li>\n<li>基于用户查询</li>\n<li>以及其他场景，建立以下索引结构（部分）</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;tk_jz_mid_order-20200628&quot;: &#123;</span><br><span class=\"line\">    &quot;mappings&quot;: &#123;</span><br><span class=\"line\">      &quot;ty_mid_order&quot;: &#123;</span><br><span class=\"line\">        &quot;properties&quot;: &#123;</span><br><span class=\"line\">          &quot;create_time&quot;: &#123;</span><br><span class=\"line\">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;date&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;parent_id&quot;: &#123;</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;long&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;id&quot;: &#123;</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;long&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;city_id&quot;: &#123;</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;integer&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;order_date&quot;: &#123;</span><br><span class=\"line\">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;date&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;uid&quot;: &#123;</span><br><span class=\"line\">            &quot;store&quot;: true,</span><br><span class=\"line\">            &quot;type&quot;: &quot;long&quot;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">          &quot;order_properties&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;nested&quot;,</span><br><span class=\"line\">            &quot;properties&quot;: &#123;</span><br><span class=\"line\">              &quot;create_time&quot;: &#123;</span><br><span class=\"line\">                &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;date&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;property_key&quot;: &#123;</span><br><span class=\"line\">                &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;text&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;property_value&quot;: &#123;</span><br><span class=\"line\">                &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;text&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;property_name&quot;: &#123;</span><br><span class=\"line\">                &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;text&quot;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &quot;order_purchases&quot;: &#123;</span><br><span class=\"line\">            &quot;type&quot;: &quot;nested&quot;,</span><br><span class=\"line\">            &quot;properties&quot;: &#123;</span><br><span class=\"line\">              &quot;sku_bar_code&quot;: &#123;</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;long&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;create_time&quot;: &#123;</span><br><span class=\"line\">                &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;date&quot;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              &quot;spu_name&quot;: &#123;</span><br><span class=\"line\">                &quot;analyzer&quot;: &quot;ik_smart&quot;,</span><br><span class=\"line\">                &quot;store&quot;: true,</span><br><span class=\"line\">                &quot;type&quot;: &quot;text&quot;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>es版本6.X</li>\n<li>对商品名称分词，对词项生成倒排索引。</li>\n<li>对订单属性分词，对词项生成倒排索引。</li>\n</ul>"},{"title":"分库分表","date":"2020-07-01T03:29:00.000Z","_content":"# 一、方案对比\n\n## 方案一：基于uid做分库，建立映射\n![方案一](2020-07-01-分库分表/方案一.png)\n* 订单表：基于UID进行分库。\n* 映射表：建立orderId和uid的映射表，并对映射表进行分库（基于orderId）。\n\n<!--more-->  \n\n**对比**\n![方案一对比](2020-07-01-分库分表/方案一对比.png)\n**优缺点**\n![方案一优缺点](2020-07-01-分库分表/方案一优缺点.png)\n\n# 方案二：orderId分库+同步机制/服务双写\n![方案二](2020-07-01-分库分表/方案二.png)\n* 两套数据，第一套基于orderId进行分库\n* 第二套基于uid进行反库\n* 老套数据通过binlog同步\n \n **对比**\n ![方案二对比](2020-07-01-分库分表/方案二对比.png)\n **优缺点**\n ![方案二优缺点](2020-07-01-分库分表/方案二优缺点.png)\n\n\n# 方案三：orderId用户基因分库\n* uid：通过雪花算法生成\n* orderId：往订单ID中添加用户的因子，保证可以基于uid和orderId查\n\n参考雪花算法生成策略，对订单ID进行相应生成策略处理\n\n| 1    | 41   |5     | 14   | 3   |\n| --------   | -----:  | :----:  | ---- | ----|\n|标志位 |时间戳 |机器码 |用户基因  |随机码|\n|1位 |41位 |5位 |12位  |5位|\n\n\n## 如何通过orderId和uid进行查询呢？如何获得同样的分片索引？\n1. 相同点：orderId中有用户的基因\n2. 结论：基于用户基因做分片索引确认\n\n### 1、基于订单ID获取分片索引\n* orderId >> 3 ：订单右移3位，舍弃掉了随机码\n* orderId >> 3 & 0b111111111111：对用户基因进行处理\n* (orderId >> 3 & 0b111111111111)%dbCount：对数据库数量进行取余，得到下标\n\n### 2、基于用户ID获取分片索引\n* uid >> 22：去除掉雪花算法后22位\n* uid >> 22 & & 0b111111111111：对用户进行处理\n* (uid >> 22 & 0b111111111111)%dbCount：对数据库数量进行取余，得到下标\n\n\n# 二、方案实现\n通过Sharding-JDBC + druid\n","source":"_posts/2020-07-01-分库分表.md","raw":"---\ntitle: 分库分表\ndate: 2020-07-01 11:29:00\ntags: Sharding-JDBC\n---\n# 一、方案对比\n\n## 方案一：基于uid做分库，建立映射\n![方案一](2020-07-01-分库分表/方案一.png)\n* 订单表：基于UID进行分库。\n* 映射表：建立orderId和uid的映射表，并对映射表进行分库（基于orderId）。\n\n<!--more-->  \n\n**对比**\n![方案一对比](2020-07-01-分库分表/方案一对比.png)\n**优缺点**\n![方案一优缺点](2020-07-01-分库分表/方案一优缺点.png)\n\n# 方案二：orderId分库+同步机制/服务双写\n![方案二](2020-07-01-分库分表/方案二.png)\n* 两套数据，第一套基于orderId进行分库\n* 第二套基于uid进行反库\n* 老套数据通过binlog同步\n \n **对比**\n ![方案二对比](2020-07-01-分库分表/方案二对比.png)\n **优缺点**\n ![方案二优缺点](2020-07-01-分库分表/方案二优缺点.png)\n\n\n# 方案三：orderId用户基因分库\n* uid：通过雪花算法生成\n* orderId：往订单ID中添加用户的因子，保证可以基于uid和orderId查\n\n参考雪花算法生成策略，对订单ID进行相应生成策略处理\n\n| 1    | 41   |5     | 14   | 3   |\n| --------   | -----:  | :----:  | ---- | ----|\n|标志位 |时间戳 |机器码 |用户基因  |随机码|\n|1位 |41位 |5位 |12位  |5位|\n\n\n## 如何通过orderId和uid进行查询呢？如何获得同样的分片索引？\n1. 相同点：orderId中有用户的基因\n2. 结论：基于用户基因做分片索引确认\n\n### 1、基于订单ID获取分片索引\n* orderId >> 3 ：订单右移3位，舍弃掉了随机码\n* orderId >> 3 & 0b111111111111：对用户基因进行处理\n* (orderId >> 3 & 0b111111111111)%dbCount：对数据库数量进行取余，得到下标\n\n### 2、基于用户ID获取分片索引\n* uid >> 22：去除掉雪花算法后22位\n* uid >> 22 & & 0b111111111111：对用户进行处理\n* (uid >> 22 & 0b111111111111)%dbCount：对数据库数量进行取余，得到下标\n\n\n# 二、方案实现\n通过Sharding-JDBC + druid\n","slug":"2020-07-01-分库分表","published":1,"updated":"2024-10-14T09:38:12.323Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxl003ja13k0d6kywuu","content":"<h1 id=\"一、方案对比\"><a href=\"#一、方案对比\" class=\"headerlink\" title=\"一、方案对比\"></a>一、方案对比</h1><h2 id=\"方案一：基于uid做分库，建立映射\"><a href=\"#方案一：基于uid做分库，建立映射\" class=\"headerlink\" title=\"方案一：基于uid做分库，建立映射\"></a>方案一：基于uid做分库，建立映射</h2><p><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%B8%80.png\" alt=\"方案一\"></p>\n<ul>\n<li>订单表：基于UID进行分库。</li>\n<li>映射表：建立orderId和uid的映射表，并对映射表进行分库（基于orderId）。</li>\n</ul>\n<a id=\"more\"></a>  \n\n<p><strong>对比</strong><br><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%B8%80%E5%AF%B9%E6%AF%94.png\" alt=\"方案一对比\"><br><strong>优缺点</strong><br><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%B8%80%E4%BC%98%E7%BC%BA%E7%82%B9.png\" alt=\"方案一优缺点\"></p>\n<h1 id=\"方案二：orderId分库-同步机制-服务双写\"><a href=\"#方案二：orderId分库-同步机制-服务双写\" class=\"headerlink\" title=\"方案二：orderId分库+同步机制/服务双写\"></a>方案二：orderId分库+同步机制/服务双写</h1><p><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%BA%8C.png\" alt=\"方案二\"></p>\n<ul>\n<li><p>两套数据，第一套基于orderId进行分库</p>\n</li>\n<li><p>第二套基于uid进行反库</p>\n</li>\n<li><p>老套数据通过binlog同步</p>\n<p><strong>对比</strong><br><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%BA%8C%E5%AF%B9%E6%AF%94.png\" alt=\"方案二对比\"><br><strong>优缺点</strong><br><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%BA%8C%E4%BC%98%E7%BC%BA%E7%82%B9.png\" alt=\"方案二优缺点\"></p>\n</li>\n</ul>\n<h1 id=\"方案三：orderId用户基因分库\"><a href=\"#方案三：orderId用户基因分库\" class=\"headerlink\" title=\"方案三：orderId用户基因分库\"></a>方案三：orderId用户基因分库</h1><ul>\n<li>uid：通过雪花算法生成</li>\n<li>orderId：往订单ID中添加用户的因子，保证可以基于uid和orderId查</li>\n</ul>\n<p>参考雪花算法生成策略，对订单ID进行相应生成策略处理</p>\n<table>\n<thead>\n<tr>\n<th>1</th>\n<th align=\"right\">41</th>\n<th align=\"center\">5</th>\n<th>14</th>\n<th>3</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>标志位</td>\n<td align=\"right\">时间戳</td>\n<td align=\"center\">机器码</td>\n<td>用户基因</td>\n<td>随机码</td>\n</tr>\n<tr>\n<td>1位</td>\n<td align=\"right\">41位</td>\n<td align=\"center\">5位</td>\n<td>12位</td>\n<td>5位</td>\n</tr>\n</tbody></table>\n<h2 id=\"如何通过orderId和uid进行查询呢？如何获得同样的分片索引？\"><a href=\"#如何通过orderId和uid进行查询呢？如何获得同样的分片索引？\" class=\"headerlink\" title=\"如何通过orderId和uid进行查询呢？如何获得同样的分片索引？\"></a>如何通过orderId和uid进行查询呢？如何获得同样的分片索引？</h2><ol>\n<li>相同点：orderId中有用户的基因</li>\n<li>结论：基于用户基因做分片索引确认</li>\n</ol>\n<h3 id=\"1、基于订单ID获取分片索引\"><a href=\"#1、基于订单ID获取分片索引\" class=\"headerlink\" title=\"1、基于订单ID获取分片索引\"></a>1、基于订单ID获取分片索引</h3><ul>\n<li>orderId &gt;&gt; 3 ：订单右移3位，舍弃掉了随机码</li>\n<li>orderId &gt;&gt; 3 &amp; 0b111111111111：对用户基因进行处理</li>\n<li>(orderId &gt;&gt; 3 &amp; 0b111111111111)%dbCount：对数据库数量进行取余，得到下标</li>\n</ul>\n<h3 id=\"2、基于用户ID获取分片索引\"><a href=\"#2、基于用户ID获取分片索引\" class=\"headerlink\" title=\"2、基于用户ID获取分片索引\"></a>2、基于用户ID获取分片索引</h3><ul>\n<li>uid &gt;&gt; 22：去除掉雪花算法后22位</li>\n<li>uid &gt;&gt; 22 &amp; &amp; 0b111111111111：对用户进行处理</li>\n<li>(uid &gt;&gt; 22 &amp; 0b111111111111)%dbCount：对数据库数量进行取余，得到下标</li>\n</ul>\n<h1 id=\"二、方案实现\"><a href=\"#二、方案实现\" class=\"headerlink\" title=\"二、方案实现\"></a>二、方案实现</h1><p>通过Sharding-JDBC + druid</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、方案对比\"><a href=\"#一、方案对比\" class=\"headerlink\" title=\"一、方案对比\"></a>一、方案对比</h1><h2 id=\"方案一：基于uid做分库，建立映射\"><a href=\"#方案一：基于uid做分库，建立映射\" class=\"headerlink\" title=\"方案一：基于uid做分库，建立映射\"></a>方案一：基于uid做分库，建立映射</h2><p><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%B8%80.png\" alt=\"方案一\"></p>\n<ul>\n<li>订单表：基于UID进行分库。</li>\n<li>映射表：建立orderId和uid的映射表，并对映射表进行分库（基于orderId）。</li>\n</ul>","more":"<p><strong>对比</strong><br><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%B8%80%E5%AF%B9%E6%AF%94.png\" alt=\"方案一对比\"><br><strong>优缺点</strong><br><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%B8%80%E4%BC%98%E7%BC%BA%E7%82%B9.png\" alt=\"方案一优缺点\"></p>\n<h1 id=\"方案二：orderId分库-同步机制-服务双写\"><a href=\"#方案二：orderId分库-同步机制-服务双写\" class=\"headerlink\" title=\"方案二：orderId分库+同步机制/服务双写\"></a>方案二：orderId分库+同步机制/服务双写</h1><p><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%BA%8C.png\" alt=\"方案二\"></p>\n<ul>\n<li><p>两套数据，第一套基于orderId进行分库</p>\n</li>\n<li><p>第二套基于uid进行反库</p>\n</li>\n<li><p>老套数据通过binlog同步</p>\n<p><strong>对比</strong><br><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%BA%8C%E5%AF%B9%E6%AF%94.png\" alt=\"方案二对比\"><br><strong>优缺点</strong><br><img src=\"/2020/07/01/2020-07-01-分库分表/%E6%96%B9%E6%A1%88%E4%BA%8C%E4%BC%98%E7%BC%BA%E7%82%B9.png\" alt=\"方案二优缺点\"></p>\n</li>\n</ul>\n<h1 id=\"方案三：orderId用户基因分库\"><a href=\"#方案三：orderId用户基因分库\" class=\"headerlink\" title=\"方案三：orderId用户基因分库\"></a>方案三：orderId用户基因分库</h1><ul>\n<li>uid：通过雪花算法生成</li>\n<li>orderId：往订单ID中添加用户的因子，保证可以基于uid和orderId查</li>\n</ul>\n<p>参考雪花算法生成策略，对订单ID进行相应生成策略处理</p>\n<table>\n<thead>\n<tr>\n<th>1</th>\n<th align=\"right\">41</th>\n<th align=\"center\">5</th>\n<th>14</th>\n<th>3</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>标志位</td>\n<td align=\"right\">时间戳</td>\n<td align=\"center\">机器码</td>\n<td>用户基因</td>\n<td>随机码</td>\n</tr>\n<tr>\n<td>1位</td>\n<td align=\"right\">41位</td>\n<td align=\"center\">5位</td>\n<td>12位</td>\n<td>5位</td>\n</tr>\n</tbody></table>\n<h2 id=\"如何通过orderId和uid进行查询呢？如何获得同样的分片索引？\"><a href=\"#如何通过orderId和uid进行查询呢？如何获得同样的分片索引？\" class=\"headerlink\" title=\"如何通过orderId和uid进行查询呢？如何获得同样的分片索引？\"></a>如何通过orderId和uid进行查询呢？如何获得同样的分片索引？</h2><ol>\n<li>相同点：orderId中有用户的基因</li>\n<li>结论：基于用户基因做分片索引确认</li>\n</ol>\n<h3 id=\"1、基于订单ID获取分片索引\"><a href=\"#1、基于订单ID获取分片索引\" class=\"headerlink\" title=\"1、基于订单ID获取分片索引\"></a>1、基于订单ID获取分片索引</h3><ul>\n<li>orderId &gt;&gt; 3 ：订单右移3位，舍弃掉了随机码</li>\n<li>orderId &gt;&gt; 3 &amp; 0b111111111111：对用户基因进行处理</li>\n<li>(orderId &gt;&gt; 3 &amp; 0b111111111111)%dbCount：对数据库数量进行取余，得到下标</li>\n</ul>\n<h3 id=\"2、基于用户ID获取分片索引\"><a href=\"#2、基于用户ID获取分片索引\" class=\"headerlink\" title=\"2、基于用户ID获取分片索引\"></a>2、基于用户ID获取分片索引</h3><ul>\n<li>uid &gt;&gt; 22：去除掉雪花算法后22位</li>\n<li>uid &gt;&gt; 22 &amp; &amp; 0b111111111111：对用户进行处理</li>\n<li>(uid &gt;&gt; 22 &amp; 0b111111111111)%dbCount：对数据库数量进行取余，得到下标</li>\n</ul>\n<h1 id=\"二、方案实现\"><a href=\"#二、方案实现\" class=\"headerlink\" title=\"二、方案实现\"></a>二、方案实现</h1><p>通过Sharding-JDBC + druid</p>"},{"title":"交易账单","date":"2020-10-19T02:20:45.000Z","_content":"\n# 一、项目描述\n\n保洁交易，承担着家政侧保洁所有业务。记录着订单的正向交易流程和退款逆向流程。\n\n<!--more-->  \n\n# 二、整体架构\n![流程图](2020-10-19-交易账单/交易流程图.png)\n\n> * 保洁交易，记录着订单所有的支付方式，如券支付、卡支付、三方支付。\n> * 当三方支付金额大于0时，去收银台创建收银台账单。\n> * 支付成功回调时，保洁交易去核销卡、核销券、通知业务线、推送资金池。\n> * 退款时，先进行退卡、退券，然后再退三方。\n\n\n# 三、业务模式\n![业务模式](2020-10-19-交易账单/业务模式.png)\n\n> * 1、预付单，需要预先进行支付（预付分成预付周期单和预付普通单）\n> * 2、周期单，分成套餐母单和预付周期单（套餐母单不需要进行支付，预付周期单需要进行支付）。\n> * 3、预付周期单子单，保洁交易需要根据预付周期单进行拆分（子单不需要再进行支付，但是要生成支付记录，对母单进行金额拆分）。\n> * 4、后付，为子单补充账单（保洁业务会出现预付订单服务时间不够的情况，创建后付账单需要用户再次支付）。\n> * 5、退款，按订单进行退款，需要获取该订单下的预付+后付账单+已退款+罚款进行金额校验计算。\n\n\n# 四、表结构\n![表结构关系图](2020-10-19-交易账单/表结构关系图.png)\n\n**说明**：一个订单对应一个交易trade，一个交易trade对应多个账单，一个账单对应多个账单历史（bill_history 记录账单状态和核心字段变化），一个账单对应多个账单项bill_item(账单由哪些子项组成)，一个账单对应一个支付记录，一个账单对应多个退款记录（一个账单分多次退），一个支付记录对应多个支付详情，一个退款记录对应多个退款详情。\n\n![表结构具体内容](2020-10-19-交易账单/表结构具体内容.png)\n\n\n# 五、状态流转图\n![交易状态流转](2020-10-19-交易账单/交易状态流转.png)\n![账单状态流转](2020-10-19-交易账单/账单状态流转.png)\n\n\n# 六、数据幂等处理\n方式：采用Redis分布式锁，对订单进行加锁，防止并发操作导致的数据的幂等问题。\n\n1、创建账单：为防止订单账单的多次创建，添加对订单的锁。\n```\nString key = Constants.CREATE_BILL_KEY_PREFIX + tradeParam.getOrderId();\nString value = UUID.randomUUID().toString();\nif (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) {\n    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);\n}    \n//内部处理时，去判断该订单的交易账单是否存在，存在就不重复创建。\n//以订单为唯一键\ntradeService.createTrade(tradeParam);\n```\n2、支付成功回调。（防止收银台多次调用交易而产生的数据幂等问题）  \n\n    1、账单已关闭，需要原路退款（防止订单超时时取消，支付成功回调才回来）。\n    2、重复调用：账单已支付，比对三方支付流水号，如果相等，则为重复调用，此时不做其他处理。【唯一键：三方支付流水号】\n    3、重复支付：账单已支付，比对收银台账单号，如果不相等为重复支付，需要做三方退款处理。（收银台已过滤重复支付场景，到交易侧发生概率极低）\n```\n--支付回调\nString key = Constants.UPDATE_TRADE_KEY_PREFIX + payNotifyParam.getOrderId();\nString value = UUID.randomUUID().toString();\nif (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) {\n    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);\n}\ntradeService.payNotify(payNotifyParam);\n```\n3、退款处理：对订单加锁，防止一个订单产生多次退款记录。\n```\nString lockKey = Constants.TRADE_REFUND_KEY_PREFIX + refundDto.getOrderId();\n//判断是否重复退款\ngetTradeRefundService().checkRepeatRefund(refundDto);\n```\n\n# 七、数据一致性\n订单下单的一个整体流程涉及的业务系统多，相互之间都易产生数据一致性问题，系统未采用分布式事务如2PC、3PC、TCC等，采用最终一致性方案达到数据的一致性。 \n \n1、订单&交易  \n**交易支付完成时，需要同步订单支付完成状态，交易是如何做的呢？**\n- 1、交易收到收银台的支付成功回调，交易进行内部逻辑数据处理，例如核销券、扣减卡。\n- 2、当上面的操作完成时，对订单进行状态同步。\n- 3、同步机制：（重试+MQ）\n    - 3.1、通过HTTP通知订单，重试3次，若重试3次失败时，将发送订单支付完成MQ消息。\n    - 3.2、交易自发自收MQ消息，这种方式能够保证业务解耦，不需要再关注MQ消息，并且通过MQ的持久化机制防止状态同步消息丢失。\n    - 3.3、若订单超时时间仍未完成支付，订单将调用交易的关闭账单接口，此时需要交易关注支付回调和关闭账单之间的数据状态扭转问题。\n\n2、交易&券  \n当收银台支付成功回调回来时，交易需要进行券的核销，此时认为三方支付完成，即使券的核销操作异常，也不进行退款，需要券保障核销接口的一定成功，若券服务宕机这种问题，需要采用另外方式保障通知券系统进行券的核销。\n- 方案：也是通过MQ的方式。\n\n\n3、交易&收银台  \n收银台支付完成后，需要同步交易账单支付状态，收银台内部使用方式也为**重试+MQ**方式，保证最后能够调用交易的RPC接口。\n\n\n4、交易  \n更新交易账单：与支付成功回调接口使用同一把锁，防止并发操作导致的数据一致性问题。\n```\n--关闭交易和账单\nString key = Constants.UPDATE_TRADE_KEY_PREFIX + orderId;\nString value = UUID.randomUUID().toString();\nif (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) {\n    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);\n}\ntradeService.closeTrade(orderId);\n```\n","source":"_posts/2020-10-19-交易账单.md","raw":"---\ntitle: 交易账单\ndate: 2020-10-19 10:20:45\ntags: 交易\n---\n\n# 一、项目描述\n\n保洁交易，承担着家政侧保洁所有业务。记录着订单的正向交易流程和退款逆向流程。\n\n<!--more-->  \n\n# 二、整体架构\n![流程图](2020-10-19-交易账单/交易流程图.png)\n\n> * 保洁交易，记录着订单所有的支付方式，如券支付、卡支付、三方支付。\n> * 当三方支付金额大于0时，去收银台创建收银台账单。\n> * 支付成功回调时，保洁交易去核销卡、核销券、通知业务线、推送资金池。\n> * 退款时，先进行退卡、退券，然后再退三方。\n\n\n# 三、业务模式\n![业务模式](2020-10-19-交易账单/业务模式.png)\n\n> * 1、预付单，需要预先进行支付（预付分成预付周期单和预付普通单）\n> * 2、周期单，分成套餐母单和预付周期单（套餐母单不需要进行支付，预付周期单需要进行支付）。\n> * 3、预付周期单子单，保洁交易需要根据预付周期单进行拆分（子单不需要再进行支付，但是要生成支付记录，对母单进行金额拆分）。\n> * 4、后付，为子单补充账单（保洁业务会出现预付订单服务时间不够的情况，创建后付账单需要用户再次支付）。\n> * 5、退款，按订单进行退款，需要获取该订单下的预付+后付账单+已退款+罚款进行金额校验计算。\n\n\n# 四、表结构\n![表结构关系图](2020-10-19-交易账单/表结构关系图.png)\n\n**说明**：一个订单对应一个交易trade，一个交易trade对应多个账单，一个账单对应多个账单历史（bill_history 记录账单状态和核心字段变化），一个账单对应多个账单项bill_item(账单由哪些子项组成)，一个账单对应一个支付记录，一个账单对应多个退款记录（一个账单分多次退），一个支付记录对应多个支付详情，一个退款记录对应多个退款详情。\n\n![表结构具体内容](2020-10-19-交易账单/表结构具体内容.png)\n\n\n# 五、状态流转图\n![交易状态流转](2020-10-19-交易账单/交易状态流转.png)\n![账单状态流转](2020-10-19-交易账单/账单状态流转.png)\n\n\n# 六、数据幂等处理\n方式：采用Redis分布式锁，对订单进行加锁，防止并发操作导致的数据的幂等问题。\n\n1、创建账单：为防止订单账单的多次创建，添加对订单的锁。\n```\nString key = Constants.CREATE_BILL_KEY_PREFIX + tradeParam.getOrderId();\nString value = UUID.randomUUID().toString();\nif (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) {\n    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);\n}    \n//内部处理时，去判断该订单的交易账单是否存在，存在就不重复创建。\n//以订单为唯一键\ntradeService.createTrade(tradeParam);\n```\n2、支付成功回调。（防止收银台多次调用交易而产生的数据幂等问题）  \n\n    1、账单已关闭，需要原路退款（防止订单超时时取消，支付成功回调才回来）。\n    2、重复调用：账单已支付，比对三方支付流水号，如果相等，则为重复调用，此时不做其他处理。【唯一键：三方支付流水号】\n    3、重复支付：账单已支付，比对收银台账单号，如果不相等为重复支付，需要做三方退款处理。（收银台已过滤重复支付场景，到交易侧发生概率极低）\n```\n--支付回调\nString key = Constants.UPDATE_TRADE_KEY_PREFIX + payNotifyParam.getOrderId();\nString value = UUID.randomUUID().toString();\nif (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) {\n    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);\n}\ntradeService.payNotify(payNotifyParam);\n```\n3、退款处理：对订单加锁，防止一个订单产生多次退款记录。\n```\nString lockKey = Constants.TRADE_REFUND_KEY_PREFIX + refundDto.getOrderId();\n//判断是否重复退款\ngetTradeRefundService().checkRepeatRefund(refundDto);\n```\n\n# 七、数据一致性\n订单下单的一个整体流程涉及的业务系统多，相互之间都易产生数据一致性问题，系统未采用分布式事务如2PC、3PC、TCC等，采用最终一致性方案达到数据的一致性。 \n \n1、订单&交易  \n**交易支付完成时，需要同步订单支付完成状态，交易是如何做的呢？**\n- 1、交易收到收银台的支付成功回调，交易进行内部逻辑数据处理，例如核销券、扣减卡。\n- 2、当上面的操作完成时，对订单进行状态同步。\n- 3、同步机制：（重试+MQ）\n    - 3.1、通过HTTP通知订单，重试3次，若重试3次失败时，将发送订单支付完成MQ消息。\n    - 3.2、交易自发自收MQ消息，这种方式能够保证业务解耦，不需要再关注MQ消息，并且通过MQ的持久化机制防止状态同步消息丢失。\n    - 3.3、若订单超时时间仍未完成支付，订单将调用交易的关闭账单接口，此时需要交易关注支付回调和关闭账单之间的数据状态扭转问题。\n\n2、交易&券  \n当收银台支付成功回调回来时，交易需要进行券的核销，此时认为三方支付完成，即使券的核销操作异常，也不进行退款，需要券保障核销接口的一定成功，若券服务宕机这种问题，需要采用另外方式保障通知券系统进行券的核销。\n- 方案：也是通过MQ的方式。\n\n\n3、交易&收银台  \n收银台支付完成后，需要同步交易账单支付状态，收银台内部使用方式也为**重试+MQ**方式，保证最后能够调用交易的RPC接口。\n\n\n4、交易  \n更新交易账单：与支付成功回调接口使用同一把锁，防止并发操作导致的数据一致性问题。\n```\n--关闭交易和账单\nString key = Constants.UPDATE_TRADE_KEY_PREFIX + orderId;\nString value = UUID.randomUUID().toString();\nif (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) {\n    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);\n}\ntradeService.closeTrade(orderId);\n```\n","slug":"2020-10-19-交易账单","published":1,"updated":"2024-10-14T09:38:12.330Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxm003ma13kzoywubny","content":"<h1 id=\"一、项目描述\"><a href=\"#一、项目描述\" class=\"headerlink\" title=\"一、项目描述\"></a>一、项目描述</h1><p>保洁交易，承担着家政侧保洁所有业务。记录着订单的正向交易流程和退款逆向流程。</p>\n<a id=\"more\"></a>  \n\n<h1 id=\"二、整体架构\"><a href=\"#二、整体架构\" class=\"headerlink\" title=\"二、整体架构\"></a>二、整体架构</h1><p><img src=\"/2020/10/19/2020-10-19-交易账单/%E4%BA%A4%E6%98%93%E6%B5%81%E7%A8%8B%E5%9B%BE.png\" alt=\"流程图\"></p>\n<blockquote>\n<ul>\n<li>保洁交易，记录着订单所有的支付方式，如券支付、卡支付、三方支付。</li>\n<li>当三方支付金额大于0时，去收银台创建收银台账单。</li>\n<li>支付成功回调时，保洁交易去核销卡、核销券、通知业务线、推送资金池。</li>\n<li>退款时，先进行退卡、退券，然后再退三方。</li>\n</ul>\n</blockquote>\n<h1 id=\"三、业务模式\"><a href=\"#三、业务模式\" class=\"headerlink\" title=\"三、业务模式\"></a>三、业务模式</h1><p><img src=\"/2020/10/19/2020-10-19-交易账单/%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%BC%8F.png\" alt=\"业务模式\"></p>\n<blockquote>\n<ul>\n<li>1、预付单，需要预先进行支付（预付分成预付周期单和预付普通单）</li>\n<li>2、周期单，分成套餐母单和预付周期单（套餐母单不需要进行支付，预付周期单需要进行支付）。</li>\n<li>3、预付周期单子单，保洁交易需要根据预付周期单进行拆分（子单不需要再进行支付，但是要生成支付记录，对母单进行金额拆分）。</li>\n<li>4、后付，为子单补充账单（保洁业务会出现预付订单服务时间不够的情况，创建后付账单需要用户再次支付）。</li>\n<li>5、退款，按订单进行退款，需要获取该订单下的预付+后付账单+已退款+罚款进行金额校验计算。</li>\n</ul>\n</blockquote>\n<h1 id=\"四、表结构\"><a href=\"#四、表结构\" class=\"headerlink\" title=\"四、表结构\"></a>四、表结构</h1><p><img src=\"/2020/10/19/2020-10-19-交易账单/%E8%A1%A8%E7%BB%93%E6%9E%84%E5%85%B3%E7%B3%BB%E5%9B%BE.png\" alt=\"表结构关系图\"></p>\n<p><strong>说明</strong>：一个订单对应一个交易trade，一个交易trade对应多个账单，一个账单对应多个账单历史（bill_history 记录账单状态和核心字段变化），一个账单对应多个账单项bill_item(账单由哪些子项组成)，一个账单对应一个支付记录，一个账单对应多个退款记录（一个账单分多次退），一个支付记录对应多个支付详情，一个退款记录对应多个退款详情。</p>\n<p><img src=\"/2020/10/19/2020-10-19-交易账单/%E8%A1%A8%E7%BB%93%E6%9E%84%E5%85%B7%E4%BD%93%E5%86%85%E5%AE%B9.png\" alt=\"表结构具体内容\"></p>\n<h1 id=\"五、状态流转图\"><a href=\"#五、状态流转图\" class=\"headerlink\" title=\"五、状态流转图\"></a>五、状态流转图</h1><p><img src=\"/2020/10/19/2020-10-19-交易账单/%E4%BA%A4%E6%98%93%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC.png\" alt=\"交易状态流转\"><br><img src=\"/2020/10/19/2020-10-19-交易账单/%E8%B4%A6%E5%8D%95%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC.png\" alt=\"账单状态流转\"></p>\n<h1 id=\"六、数据幂等处理\"><a href=\"#六、数据幂等处理\" class=\"headerlink\" title=\"六、数据幂等处理\"></a>六、数据幂等处理</h1><p>方式：采用Redis分布式锁，对订单进行加锁，防止并发操作导致的数据的幂等问题。</p>\n<p>1、创建账单：为防止订单账单的多次创建，添加对订单的锁。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String key = Constants.CREATE_BILL_KEY_PREFIX + tradeParam.getOrderId();</span><br><span class=\"line\">String value = UUID.randomUUID().toString();</span><br><span class=\"line\">if (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) &#123;</span><br><span class=\"line\">    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);</span><br><span class=\"line\">&#125;    </span><br><span class=\"line\">//内部处理时，去判断该订单的交易账单是否存在，存在就不重复创建。</span><br><span class=\"line\">//以订单为唯一键</span><br><span class=\"line\">tradeService.createTrade(tradeParam);</span><br></pre></td></tr></table></figure>\n\n<p>2、支付成功回调。（防止收银台多次调用交易而产生的数据幂等问题）  </p>\n<pre><code>1、账单已关闭，需要原路退款（防止订单超时时取消，支付成功回调才回来）。\n2、重复调用：账单已支付，比对三方支付流水号，如果相等，则为重复调用，此时不做其他处理。【唯一键：三方支付流水号】\n3、重复支付：账单已支付，比对收银台账单号，如果不相等为重复支付，需要做三方退款处理。（收银台已过滤重复支付场景，到交易侧发生概率极低）</code></pre><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--支付回调</span><br><span class=\"line\">String key = Constants.UPDATE_TRADE_KEY_PREFIX + payNotifyParam.getOrderId();</span><br><span class=\"line\">String value = UUID.randomUUID().toString();</span><br><span class=\"line\">if (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) &#123;</span><br><span class=\"line\">    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">tradeService.payNotify(payNotifyParam);</span><br></pre></td></tr></table></figure>\n\n<p>3、退款处理：对订单加锁，防止一个订单产生多次退款记录。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String lockKey = Constants.TRADE_REFUND_KEY_PREFIX + refundDto.getOrderId();</span><br><span class=\"line\">//判断是否重复退款</span><br><span class=\"line\">getTradeRefundService().checkRepeatRefund(refundDto);</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"七、数据一致性\"><a href=\"#七、数据一致性\" class=\"headerlink\" title=\"七、数据一致性\"></a>七、数据一致性</h1><p>订单下单的一个整体流程涉及的业务系统多，相互之间都易产生数据一致性问题，系统未采用分布式事务如2PC、3PC、TCC等，采用最终一致性方案达到数据的一致性。 </p>\n<p>1、订单&amp;交易<br><strong>交易支付完成时，需要同步订单支付完成状态，交易是如何做的呢？</strong></p>\n<ul>\n<li>1、交易收到收银台的支付成功回调，交易进行内部逻辑数据处理，例如核销券、扣减卡。</li>\n<li>2、当上面的操作完成时，对订单进行状态同步。</li>\n<li>3、同步机制：（重试+MQ）<ul>\n<li>3.1、通过HTTP通知订单，重试3次，若重试3次失败时，将发送订单支付完成MQ消息。</li>\n<li>3.2、交易自发自收MQ消息，这种方式能够保证业务解耦，不需要再关注MQ消息，并且通过MQ的持久化机制防止状态同步消息丢失。</li>\n<li>3.3、若订单超时时间仍未完成支付，订单将调用交易的关闭账单接口，此时需要交易关注支付回调和关闭账单之间的数据状态扭转问题。</li>\n</ul>\n</li>\n</ul>\n<p>2、交易&amp;券<br>当收银台支付成功回调回来时，交易需要进行券的核销，此时认为三方支付完成，即使券的核销操作异常，也不进行退款，需要券保障核销接口的一定成功，若券服务宕机这种问题，需要采用另外方式保障通知券系统进行券的核销。</p>\n<ul>\n<li>方案：也是通过MQ的方式。</li>\n</ul>\n<p>3、交易&amp;收银台<br>收银台支付完成后，需要同步交易账单支付状态，收银台内部使用方式也为<strong>重试+MQ</strong>方式，保证最后能够调用交易的RPC接口。</p>\n<p>4、交易<br>更新交易账单：与支付成功回调接口使用同一把锁，防止并发操作导致的数据一致性问题。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--关闭交易和账单</span><br><span class=\"line\">String key = Constants.UPDATE_TRADE_KEY_PREFIX + orderId;</span><br><span class=\"line\">String value = UUID.randomUUID().toString();</span><br><span class=\"line\">if (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) &#123;</span><br><span class=\"line\">    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">tradeService.closeTrade(orderId);</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"<h1 id=\"一、项目描述\"><a href=\"#一、项目描述\" class=\"headerlink\" title=\"一、项目描述\"></a>一、项目描述</h1><p>保洁交易，承担着家政侧保洁所有业务。记录着订单的正向交易流程和退款逆向流程。</p>","more":"<h1 id=\"二、整体架构\"><a href=\"#二、整体架构\" class=\"headerlink\" title=\"二、整体架构\"></a>二、整体架构</h1><p><img src=\"/2020/10/19/2020-10-19-交易账单/%E4%BA%A4%E6%98%93%E6%B5%81%E7%A8%8B%E5%9B%BE.png\" alt=\"流程图\"></p>\n<blockquote>\n<ul>\n<li>保洁交易，记录着订单所有的支付方式，如券支付、卡支付、三方支付。</li>\n<li>当三方支付金额大于0时，去收银台创建收银台账单。</li>\n<li>支付成功回调时，保洁交易去核销卡、核销券、通知业务线、推送资金池。</li>\n<li>退款时，先进行退卡、退券，然后再退三方。</li>\n</ul>\n</blockquote>\n<h1 id=\"三、业务模式\"><a href=\"#三、业务模式\" class=\"headerlink\" title=\"三、业务模式\"></a>三、业务模式</h1><p><img src=\"/2020/10/19/2020-10-19-交易账单/%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%BC%8F.png\" alt=\"业务模式\"></p>\n<blockquote>\n<ul>\n<li>1、预付单，需要预先进行支付（预付分成预付周期单和预付普通单）</li>\n<li>2、周期单，分成套餐母单和预付周期单（套餐母单不需要进行支付，预付周期单需要进行支付）。</li>\n<li>3、预付周期单子单，保洁交易需要根据预付周期单进行拆分（子单不需要再进行支付，但是要生成支付记录，对母单进行金额拆分）。</li>\n<li>4、后付，为子单补充账单（保洁业务会出现预付订单服务时间不够的情况，创建后付账单需要用户再次支付）。</li>\n<li>5、退款，按订单进行退款，需要获取该订单下的预付+后付账单+已退款+罚款进行金额校验计算。</li>\n</ul>\n</blockquote>\n<h1 id=\"四、表结构\"><a href=\"#四、表结构\" class=\"headerlink\" title=\"四、表结构\"></a>四、表结构</h1><p><img src=\"/2020/10/19/2020-10-19-交易账单/%E8%A1%A8%E7%BB%93%E6%9E%84%E5%85%B3%E7%B3%BB%E5%9B%BE.png\" alt=\"表结构关系图\"></p>\n<p><strong>说明</strong>：一个订单对应一个交易trade，一个交易trade对应多个账单，一个账单对应多个账单历史（bill_history 记录账单状态和核心字段变化），一个账单对应多个账单项bill_item(账单由哪些子项组成)，一个账单对应一个支付记录，一个账单对应多个退款记录（一个账单分多次退），一个支付记录对应多个支付详情，一个退款记录对应多个退款详情。</p>\n<p><img src=\"/2020/10/19/2020-10-19-交易账单/%E8%A1%A8%E7%BB%93%E6%9E%84%E5%85%B7%E4%BD%93%E5%86%85%E5%AE%B9.png\" alt=\"表结构具体内容\"></p>\n<h1 id=\"五、状态流转图\"><a href=\"#五、状态流转图\" class=\"headerlink\" title=\"五、状态流转图\"></a>五、状态流转图</h1><p><img src=\"/2020/10/19/2020-10-19-交易账单/%E4%BA%A4%E6%98%93%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC.png\" alt=\"交易状态流转\"><br><img src=\"/2020/10/19/2020-10-19-交易账单/%E8%B4%A6%E5%8D%95%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC.png\" alt=\"账单状态流转\"></p>\n<h1 id=\"六、数据幂等处理\"><a href=\"#六、数据幂等处理\" class=\"headerlink\" title=\"六、数据幂等处理\"></a>六、数据幂等处理</h1><p>方式：采用Redis分布式锁，对订单进行加锁，防止并发操作导致的数据的幂等问题。</p>\n<p>1、创建账单：为防止订单账单的多次创建，添加对订单的锁。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String key = Constants.CREATE_BILL_KEY_PREFIX + tradeParam.getOrderId();</span><br><span class=\"line\">String value = UUID.randomUUID().toString();</span><br><span class=\"line\">if (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) &#123;</span><br><span class=\"line\">    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);</span><br><span class=\"line\">&#125;    </span><br><span class=\"line\">//内部处理时，去判断该订单的交易账单是否存在，存在就不重复创建。</span><br><span class=\"line\">//以订单为唯一键</span><br><span class=\"line\">tradeService.createTrade(tradeParam);</span><br></pre></td></tr></table></figure>\n\n<p>2、支付成功回调。（防止收银台多次调用交易而产生的数据幂等问题）  </p>\n<pre><code>1、账单已关闭，需要原路退款（防止订单超时时取消，支付成功回调才回来）。\n2、重复调用：账单已支付，比对三方支付流水号，如果相等，则为重复调用，此时不做其他处理。【唯一键：三方支付流水号】\n3、重复支付：账单已支付，比对收银台账单号，如果不相等为重复支付，需要做三方退款处理。（收银台已过滤重复支付场景，到交易侧发生概率极低）</code></pre><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--支付回调</span><br><span class=\"line\">String key = Constants.UPDATE_TRADE_KEY_PREFIX + payNotifyParam.getOrderId();</span><br><span class=\"line\">String value = UUID.randomUUID().toString();</span><br><span class=\"line\">if (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) &#123;</span><br><span class=\"line\">    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">tradeService.payNotify(payNotifyParam);</span><br></pre></td></tr></table></figure>\n\n<p>3、退款处理：对订单加锁，防止一个订单产生多次退款记录。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String lockKey = Constants.TRADE_REFUND_KEY_PREFIX + refundDto.getOrderId();</span><br><span class=\"line\">//判断是否重复退款</span><br><span class=\"line\">getTradeRefundService().checkRepeatRefund(refundDto);</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"七、数据一致性\"><a href=\"#七、数据一致性\" class=\"headerlink\" title=\"七、数据一致性\"></a>七、数据一致性</h1><p>订单下单的一个整体流程涉及的业务系统多，相互之间都易产生数据一致性问题，系统未采用分布式事务如2PC、3PC、TCC等，采用最终一致性方案达到数据的一致性。 </p>\n<p>1、订单&amp;交易<br><strong>交易支付完成时，需要同步订单支付完成状态，交易是如何做的呢？</strong></p>\n<ul>\n<li>1、交易收到收银台的支付成功回调，交易进行内部逻辑数据处理，例如核销券、扣减卡。</li>\n<li>2、当上面的操作完成时，对订单进行状态同步。</li>\n<li>3、同步机制：（重试+MQ）<ul>\n<li>3.1、通过HTTP通知订单，重试3次，若重试3次失败时，将发送订单支付完成MQ消息。</li>\n<li>3.2、交易自发自收MQ消息，这种方式能够保证业务解耦，不需要再关注MQ消息，并且通过MQ的持久化机制防止状态同步消息丢失。</li>\n<li>3.3、若订单超时时间仍未完成支付，订单将调用交易的关闭账单接口，此时需要交易关注支付回调和关闭账单之间的数据状态扭转问题。</li>\n</ul>\n</li>\n</ul>\n<p>2、交易&amp;券<br>当收银台支付成功回调回来时，交易需要进行券的核销，此时认为三方支付完成，即使券的核销操作异常，也不进行退款，需要券保障核销接口的一定成功，若券服务宕机这种问题，需要采用另外方式保障通知券系统进行券的核销。</p>\n<ul>\n<li>方案：也是通过MQ的方式。</li>\n</ul>\n<p>3、交易&amp;收银台<br>收银台支付完成后，需要同步交易账单支付状态，收银台内部使用方式也为<strong>重试+MQ</strong>方式，保证最后能够调用交易的RPC接口。</p>\n<p>4、交易<br>更新交易账单：与支付成功回调接口使用同一把锁，防止并发操作导致的数据一致性问题。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--关闭交易和账单</span><br><span class=\"line\">String key = Constants.UPDATE_TRADE_KEY_PREFIX + orderId;</span><br><span class=\"line\">String value = UUID.randomUUID().toString();</span><br><span class=\"line\">if (!RedisLock.lock(key, value, Constants.EXPIRE_TIME)) &#123;</span><br><span class=\"line\">    throw new GeneralException(ErrorCodeEnum.REPEATED_REQUESTS);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">tradeService.closeTrade(orderId);</span><br></pre></td></tr></table></figure>"},{"title":"springmvc","date":"2021-01-04T14:18:37.000Z","_content":"\n#  一、HandlerMapping映射过程\n![ha](2021-01-04-springmvc/springmvc-handlermapping.png)\n\n<!--more-->  \n\n## 1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter\n## 2、初始化HandlerMapping，\n* 首先会获取容器中所有的beanName\n* 遍历beanName，判断beanName对应**类的类型**是否是Controller或者是RequestMapping\n* 然后反射获取类的所有方法，对方法生成RequestMappingInfo对象，并且和类的RequestMappingInfo对象合并。\n* 最终生成了一个**map<标注了的方法，整合后的标记对象>，** key=method, value=RequestMappingInfo\n* 然后遍历这个map，完成三者关系的映射（路径，方法，mappingInfo对象）\n* **map<路径，mappingInfo对象>**，key=路径，value=mappingInfo对象\n* **map<mappingInfo对象, handlerMethod>**，key=mappingInfo对象，value=handlerMethod\n* 三大集合到此完成。\n\n```\nmap<标注了的方法，整合后的标记对象>，key=method, value=RequestMappingInfo\nmap<路径，mappingInfo对象>，key=路径，value=mappingInfo对象\nmap<mappingInfo对象, handlerMethod>，key=mappingInfo对象，value=handlerMethod\n```\n\n## 3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的\n26个\n## 4、请求执行过程\n* Dispatch.doService()方法，根据URL获取到HandlerMethod，并将hendlerMehtod和interceptor拦截器封装成HandlerExecutionChain。\n* 然后根据HandlerExecutionChain.handler找到相应的HandlerAdapter\n* mappedHandler.applyPreHandle(processedRequest, response)，首先会执行interceptor拦截器，所有拦截器通过，继续往下执行\n* HandlerAdapter执行（方法执行准备）\n    * adapter.invokeHandelMethod() -> modelFactory.initModel()\n        * 获取注释了@ModelAttribute的方法\n        * 执行方法，将返回值设置到model内\n    * **model**：进行方法调用时的方法传递\n* 继续执行（实际方法调用）\n    *  Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs);，获取方法的所有参数\n    * 遍历参数集合，获取参数对应的参数解析器HandlerMethodArgumentResolver\n    * 然后参数解析，argmentResolvers.resolveArgument()\n    * 具体解析如下：\n        * 获取参数类型\n        * 获取参数值\n        * 进行参数封装\n        * 最后可以调用DataBinder，进行数据绑定、数据格式化、数据验证\n* > 自定义一个参数解析器需要实现HandlerMethodArgumentResolver接口，重写supportsParameter和resolveArgument方法，配置文件中加入resolver配置\n参数解析完成后，进行方法调用，获取返回值\nreturnValue\n* 再调用returnValueHandler进行返回值解析\n* 生成modelAndView\n    * ModelMap model = mavContainer.getModel();\n    * ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model);\n* 视图解析器：viewResolver\n    * processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);\n\n# 二、整体流程\n![流程](2021-01-04-springmvc/springmvc-流程.png)\n","source":"_posts/2021-01-04-springmvc.md","raw":"---\ntitle: springmvc\ndate: 2021-01-04 22:18:37\ntags: spring springmvc\ncategories:\n  - [spring, springmvc]\n---\n\n#  一、HandlerMapping映射过程\n![ha](2021-01-04-springmvc/springmvc-handlermapping.png)\n\n<!--more-->  \n\n## 1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter\n## 2、初始化HandlerMapping，\n* 首先会获取容器中所有的beanName\n* 遍历beanName，判断beanName对应**类的类型**是否是Controller或者是RequestMapping\n* 然后反射获取类的所有方法，对方法生成RequestMappingInfo对象，并且和类的RequestMappingInfo对象合并。\n* 最终生成了一个**map<标注了的方法，整合后的标记对象>，** key=method, value=RequestMappingInfo\n* 然后遍历这个map，完成三者关系的映射（路径，方法，mappingInfo对象）\n* **map<路径，mappingInfo对象>**，key=路径，value=mappingInfo对象\n* **map<mappingInfo对象, handlerMethod>**，key=mappingInfo对象，value=handlerMethod\n* 三大集合到此完成。\n\n```\nmap<标注了的方法，整合后的标记对象>，key=method, value=RequestMappingInfo\nmap<路径，mappingInfo对象>，key=路径，value=mappingInfo对象\nmap<mappingInfo对象, handlerMethod>，key=mappingInfo对象，value=handlerMethod\n```\n\n## 3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的\n26个\n## 4、请求执行过程\n* Dispatch.doService()方法，根据URL获取到HandlerMethod，并将hendlerMehtod和interceptor拦截器封装成HandlerExecutionChain。\n* 然后根据HandlerExecutionChain.handler找到相应的HandlerAdapter\n* mappedHandler.applyPreHandle(processedRequest, response)，首先会执行interceptor拦截器，所有拦截器通过，继续往下执行\n* HandlerAdapter执行（方法执行准备）\n    * adapter.invokeHandelMethod() -> modelFactory.initModel()\n        * 获取注释了@ModelAttribute的方法\n        * 执行方法，将返回值设置到model内\n    * **model**：进行方法调用时的方法传递\n* 继续执行（实际方法调用）\n    *  Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs);，获取方法的所有参数\n    * 遍历参数集合，获取参数对应的参数解析器HandlerMethodArgumentResolver\n    * 然后参数解析，argmentResolvers.resolveArgument()\n    * 具体解析如下：\n        * 获取参数类型\n        * 获取参数值\n        * 进行参数封装\n        * 最后可以调用DataBinder，进行数据绑定、数据格式化、数据验证\n* > 自定义一个参数解析器需要实现HandlerMethodArgumentResolver接口，重写supportsParameter和resolveArgument方法，配置文件中加入resolver配置\n参数解析完成后，进行方法调用，获取返回值\nreturnValue\n* 再调用returnValueHandler进行返回值解析\n* 生成modelAndView\n    * ModelMap model = mavContainer.getModel();\n    * ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model);\n* 视图解析器：viewResolver\n    * processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);\n\n# 二、整体流程\n![流程](2021-01-04-springmvc/springmvc-流程.png)\n","slug":"2021-01-04-springmvc","published":1,"updated":"2024-10-18T01:56:29.763Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxo003pa13k47m3h8tj","content":"<h1 id=\"一、HandlerMapping映射过程\"><a href=\"#一、HandlerMapping映射过程\" class=\"headerlink\" title=\"一、HandlerMapping映射过程\"></a>一、HandlerMapping映射过程</h1><p><img src=\"/2021/01/04/2021-01-04-springmvc/springmvc-handlermapping.png\" alt=\"ha\"></p>\n<a id=\"more\"></a>  \n\n<h2 id=\"1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter\"><a href=\"#1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter\" class=\"headerlink\" title=\"1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter\"></a>1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter</h2><h2 id=\"2、初始化HandlerMapping，\"><a href=\"#2、初始化HandlerMapping，\" class=\"headerlink\" title=\"2、初始化HandlerMapping，\"></a>2、初始化HandlerMapping，</h2><ul>\n<li>首先会获取容器中所有的beanName</li>\n<li>遍历beanName，判断beanName对应<strong>类的类型</strong>是否是Controller或者是RequestMapping</li>\n<li>然后反射获取类的所有方法，对方法生成RequestMappingInfo对象，并且和类的RequestMappingInfo对象合并。</li>\n<li>最终生成了一个<strong>map&lt;标注了的方法，整合后的标记对象&gt;，</strong> key=method, value=RequestMappingInfo</li>\n<li>然后遍历这个map，完成三者关系的映射（路径，方法，mappingInfo对象）</li>\n<li><strong>map&lt;路径，mappingInfo对象&gt;</strong>，key=路径，value=mappingInfo对象</li>\n<li><strong>map&lt;mappingInfo对象, handlerMethod&gt;</strong>，key=mappingInfo对象，value=handlerMethod</li>\n<li>三大集合到此完成。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map&lt;标注了的方法，整合后的标记对象&gt;，key=method, value=RequestMappingInfo</span><br><span class=\"line\">map&lt;路径，mappingInfo对象&gt;，key=路径，value=mappingInfo对象</span><br><span class=\"line\">map&lt;mappingInfo对象, handlerMethod&gt;，key=mappingInfo对象，value=handlerMethod</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的\"><a href=\"#3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的\" class=\"headerlink\" title=\"3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的\"></a>3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的</h2><p>26个</p>\n<h2 id=\"4、请求执行过程\"><a href=\"#4、请求执行过程\" class=\"headerlink\" title=\"4、请求执行过程\"></a>4、请求执行过程</h2><ul>\n<li>Dispatch.doService()方法，根据URL获取到HandlerMethod，并将hendlerMehtod和interceptor拦截器封装成HandlerExecutionChain。</li>\n<li>然后根据HandlerExecutionChain.handler找到相应的HandlerAdapter</li>\n<li>mappedHandler.applyPreHandle(processedRequest, response)，首先会执行interceptor拦截器，所有拦截器通过，继续往下执行</li>\n<li>HandlerAdapter执行（方法执行准备）<ul>\n<li>adapter.invokeHandelMethod() -&gt; modelFactory.initModel()<ul>\n<li>获取注释了@ModelAttribute的方法</li>\n<li>执行方法，将返回值设置到model内</li>\n</ul>\n</li>\n<li><strong>model</strong>：进行方法调用时的方法传递</li>\n</ul>\n</li>\n<li>继续执行（实际方法调用）<ul>\n<li>Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs);，获取方法的所有参数</li>\n<li>遍历参数集合，获取参数对应的参数解析器HandlerMethodArgumentResolver</li>\n<li>然后参数解析，argmentResolvers.resolveArgument()</li>\n<li>具体解析如下：<ul>\n<li>获取参数类型</li>\n<li>获取参数值</li>\n<li>进行参数封装</li>\n<li>最后可以调用DataBinder，进行数据绑定、数据格式化、数据验证</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><blockquote>\n<p>自定义一个参数解析器需要实现HandlerMethodArgumentResolver接口，重写supportsParameter和resolveArgument方法，配置文件中加入resolver配置<br>参数解析完成后，进行方法调用，获取返回值<br>returnValue</p>\n</blockquote>\n</li>\n<li>再调用returnValueHandler进行返回值解析</li>\n<li>生成modelAndView<ul>\n<li>ModelMap model = mavContainer.getModel();</li>\n<li>ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model);</li>\n</ul>\n</li>\n<li>视图解析器：viewResolver<ul>\n<li>processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"二、整体流程\"><a href=\"#二、整体流程\" class=\"headerlink\" title=\"二、整体流程\"></a>二、整体流程</h1><p><img src=\"/2021/01/04/2021-01-04-springmvc/springmvc-%E6%B5%81%E7%A8%8B.png\" alt=\"流程\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、HandlerMapping映射过程\"><a href=\"#一、HandlerMapping映射过程\" class=\"headerlink\" title=\"一、HandlerMapping映射过程\"></a>一、HandlerMapping映射过程</h1><p><img src=\"/2021/01/04/2021-01-04-springmvc/springmvc-handlermapping.png\" alt=\"ha\"></p>","more":"<h2 id=\"1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter\"><a href=\"#1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter\" class=\"headerlink\" title=\"1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter\"></a>1、Dispatcher在初始化的过程中，会初始化HandlerMapping，HandlerAdapter</h2><h2 id=\"2、初始化HandlerMapping，\"><a href=\"#2、初始化HandlerMapping，\" class=\"headerlink\" title=\"2、初始化HandlerMapping，\"></a>2、初始化HandlerMapping，</h2><ul>\n<li>首先会获取容器中所有的beanName</li>\n<li>遍历beanName，判断beanName对应<strong>类的类型</strong>是否是Controller或者是RequestMapping</li>\n<li>然后反射获取类的所有方法，对方法生成RequestMappingInfo对象，并且和类的RequestMappingInfo对象合并。</li>\n<li>最终生成了一个<strong>map&lt;标注了的方法，整合后的标记对象&gt;，</strong> key=method, value=RequestMappingInfo</li>\n<li>然后遍历这个map，完成三者关系的映射（路径，方法，mappingInfo对象）</li>\n<li><strong>map&lt;路径，mappingInfo对象&gt;</strong>，key=路径，value=mappingInfo对象</li>\n<li><strong>map&lt;mappingInfo对象, handlerMethod&gt;</strong>，key=mappingInfo对象，value=handlerMethod</li>\n<li>三大集合到此完成。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map&lt;标注了的方法，整合后的标记对象&gt;，key=method, value=RequestMappingInfo</span><br><span class=\"line\">map&lt;路径，mappingInfo对象&gt;，key=路径，value=mappingInfo对象</span><br><span class=\"line\">map&lt;mappingInfo对象, handlerMethod&gt;，key=mappingInfo对象，value=handlerMethod</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的\"><a href=\"#3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的\" class=\"headerlink\" title=\"3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的\"></a>3、初始化HandlerAdapter，注入默认的参数解析器（多个）和默认的</h2><p>26个</p>\n<h2 id=\"4、请求执行过程\"><a href=\"#4、请求执行过程\" class=\"headerlink\" title=\"4、请求执行过程\"></a>4、请求执行过程</h2><ul>\n<li>Dispatch.doService()方法，根据URL获取到HandlerMethod，并将hendlerMehtod和interceptor拦截器封装成HandlerExecutionChain。</li>\n<li>然后根据HandlerExecutionChain.handler找到相应的HandlerAdapter</li>\n<li>mappedHandler.applyPreHandle(processedRequest, response)，首先会执行interceptor拦截器，所有拦截器通过，继续往下执行</li>\n<li>HandlerAdapter执行（方法执行准备）<ul>\n<li>adapter.invokeHandelMethod() -&gt; modelFactory.initModel()<ul>\n<li>获取注释了@ModelAttribute的方法</li>\n<li>执行方法，将返回值设置到model内</li>\n</ul>\n</li>\n<li><strong>model</strong>：进行方法调用时的方法传递</li>\n</ul>\n</li>\n<li>继续执行（实际方法调用）<ul>\n<li>Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs);，获取方法的所有参数</li>\n<li>遍历参数集合，获取参数对应的参数解析器HandlerMethodArgumentResolver</li>\n<li>然后参数解析，argmentResolvers.resolveArgument()</li>\n<li>具体解析如下：<ul>\n<li>获取参数类型</li>\n<li>获取参数值</li>\n<li>进行参数封装</li>\n<li>最后可以调用DataBinder，进行数据绑定、数据格式化、数据验证</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><blockquote>\n<p>自定义一个参数解析器需要实现HandlerMethodArgumentResolver接口，重写supportsParameter和resolveArgument方法，配置文件中加入resolver配置<br>参数解析完成后，进行方法调用，获取返回值<br>returnValue</p>\n</blockquote>\n</li>\n<li>再调用returnValueHandler进行返回值解析</li>\n<li>生成modelAndView<ul>\n<li>ModelMap model = mavContainer.getModel();</li>\n<li>ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model);</li>\n</ul>\n</li>\n<li>视图解析器：viewResolver<ul>\n<li>processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"二、整体流程\"><a href=\"#二、整体流程\" class=\"headerlink\" title=\"二、整体流程\"></a>二、整体流程</h1><p><img src=\"/2021/01/04/2021-01-04-springmvc/springmvc-%E6%B5%81%E7%A8%8B.png\" alt=\"流程\"></p>"},{"title":"《性能优化系列》启动优化","date":"2024-03-01T02:00:00.000Z","_content":"\n    这是性能优化系列的第一篇文章，主要介绍的是系统的启动优化。\n\n### 一、背景\n在阿里巴巴内部经过多年的实践，1-5-10 早已成为各个业务稳定性、基础设施稳定性以及大促保障的重要牵引指标。\n    \n    1分钟发现：做到故障的一分钟发现，首先需要有完善的监控/告警体系，其次需要有明确的故障结构化定义\n    5分钟响应：做到故障的 5 分钟响应，首先需要有一套标准的应急响应流程，其次需要能够快速定位问题，作出恢复决策\n    10分钟快恢：1-5-10 场景的核心是快恢，发现体系和响应体系建设都是为了快速的恢复故障。要建设快恢体系首先需要建立起快恢能力，其次要针对故障特征合理使用快恢能力。\n```dtd\n⭐️ 快恢手段：手段有很多，比如应用重启，系统回滚，机器下线，重新发布，扩容限流等等，本篇文章主要介绍应用重启。\n```\n为了满足系统稳定性、高可用的建设，达成1-5-10对于故障处理的时效性目标，对商品发布应用进行启动优化（满足10分钟快恢）。\n\n<!-- more -->\n\n### 二、现状\n![](2024-03-01-性能优化-启动优化/编译发布流程图.png)\n**优化前：** 应用从构建、部署，整体耗时12分钟。\n\n### 三、优化手段\n优化手段也非常多项，包括容器优化、构建优化、编译优化，本文对阿里内部组件的优化不做过多解释，应用启动的主要瓶颈在于bean的初始化过程，因此本篇文章主要讲解spring bean异步化优化。\n\n[阿里内部组件优化](https://markdown.com.cn/basic-syntax/links.html \"阿里内部组件优化\")\n\n#### ⭐️ spring bean异步化优化\n应用启动速度主要的瓶颈在于bean的初始化过程（init，afterPropertiesSet方法的耗时），很多中间件bean的初始化逻辑涉及到网络io，且在没有相互依赖的情况下串行执行。将这一部分中间件bean进行异步加载，是提升启动速度的一个探索方向。\n\n解决方案：   \n```dtd\n1、自动扫描可批量异步的中间件bean，而后，在bean的初始化阶段利用线程池并行执行其初始化逻辑。  \n2、允许使用方自行配置耗时bean以享受异步加速能力。(需使用方自行确认依赖关系满足异步条件)\n```\n\n### 四、使用示例\n主要针对中间件。\n#### A.解决方案1：  \n自定义注解，例如@SofaAsyncInit。（注：此注解为SOFABoot项目的注解）\n![](2024-03-01-性能优化-启动优化/启动加速-自动扫描异步类.png)\n\n#### B.解决方案2：\n```dtd\n手动指定要异步初始化的bean，格式为bean名称列表：如****.async-init=tairClient,mqclient。\n```\n当时所在团队使用的这种方案。\n\n### 五、原理\n#### A:首先需要知道spring的bean初始化流程。\n我们先知道afterPropertiesSet()和Init()方法的执行时机，因为Bean初始化耗时主要是这2个方法。\n![](2024-03-01-性能优化-启动优化/spring实例初始化流程.png)\n步骤1：遍历beanDefinitionNames集合     \n步骤2：检查缓存中或者实例工厂中是否有对应的实例    \n步骤3：创建bean实例    \n    bean初始化时，会执行AbstractAutowireCapableBeanFactory#invokeInitMethods的方法，方法内部会执行2个方法：afterPropertiesSet()方法 & invokeCustomInitMethod()。\n```dtd\n1. afterPropertiesSet()方法：需要类实现InitializingBean接口。\n2. invokeCustomInitMethod()方法：会执行自定义的init()方法。\n```\n#### B:实现异步加载\n既然知道了afterPropertiesSet()和init()2个方法的执行时机和流程，那么接下来就是设法实现异步加载执行了。\n\n***⭐️ 基于注解的实现方式：***    \n**1. 首先解析注解，收集信息**    \n通过实现BeanFactoryPostProcessor接口（bean工厂的后置处理器，可以获取bean的示例或定义等。同时可以修改bean的属性），来进行注解的解析。\n```dtd\ncom.alipay.sofa.runtime.spring.AsyncInitBeanFactoryPostProcessor#registerAsyncInitBean\n```\n实现BeanFactoryPostProcessor接口：\n![具体实现](2024-03-01-性能优化-启动优化/注解解析.png)\n![具体实现](2024-03-01-性能优化-启动优化/AsyncInitBeanFactoryPostProcessor-registerAsyncInitBean.png)\n***收集Bean信息：***\nregisterAsyncInitBean 方法，把可以异步执行的 init 方法的 Bean 收集起来，用 Map 来进行的存储。\n![具体实现](2024-03-01-性能优化-启动优化/registerAsyncInitBean具体实现.png)\n\n**2. 然后异步化处理**  \n实现BeanPostProcessor接口（bean的后置处理器）\n```dtd\ncom.alipay.sofa.runtime.spring.AsyncProxyBeanPostProcessor#postProcessBeforeInitialization\n```\n![beanpostprocessor](2024-03-01-性能优化-启动优化/beanpostprocessor.png)\n关键点，就在 AsyncInitializeBeanMethodInvoker 里面，因为这个里面有真正判断是否要进行异步初始化的逻辑，主要解读一下这个类。  \n首先，关注一下它的这三个参数：\n```dtd\ninitCountDownLatch：是 CountDownLatch 对象，其中 count 初始化为 1\nisAsyncCalling：表示是否正在异步执行 init 方法。\nisAsyncCalled：表示是否已经异步执行过 init 方法。\n```\n通过这三个字段，就可以感知到一个 Bean 是否已经或者正在异步执行其 init 方法。    \n![异步化](2024-03-01-性能优化-启动优化/异步化.png)\n核心逻辑就是通过AsyncTaskExecutor.submitTask()把init()扔到线程池里面去执行。\n\n[SOFABoot](https://www.cnblogs.com/thisiswhy/p/17457499.html,\"SOFABoot\")    \n[参考文章1](https://developer.aliyun.com/article/1239199, \"Bean异步初始化，让你的应用启动飞起来\")   \n[spring异步化](https://mp.weixin.qq.com/s/-qzXuiE7fcGS7JXxFbu6jg?poc_token=HHhxD2ejr-ur6eD3TaHJ2lUVP5m4UbF5awelDrdo, \"\")\n\n### 六、成果\n下图只是展示了长啥样，不是真实数据：\n![性能效果](2024-03-01-性能优化-启动优化/性能效果.png)\n```dtd\n优化前：12分    \n优化后：7分30s\n```","source":"_posts/2024-03-01-性能优化-启动优化.md","raw":"---\ntitle: 《性能优化系列》启动优化\ndate: 2024-03-01 10:00:00\ncategories:\n  - [数据库, mysql, 性能优化]\n  - [性能优化]\n  - [阿里]\n  - [稳定性]\ntags:\n    - 阿里\n---\n\n    这是性能优化系列的第一篇文章，主要介绍的是系统的启动优化。\n\n### 一、背景\n在阿里巴巴内部经过多年的实践，1-5-10 早已成为各个业务稳定性、基础设施稳定性以及大促保障的重要牵引指标。\n    \n    1分钟发现：做到故障的一分钟发现，首先需要有完善的监控/告警体系，其次需要有明确的故障结构化定义\n    5分钟响应：做到故障的 5 分钟响应，首先需要有一套标准的应急响应流程，其次需要能够快速定位问题，作出恢复决策\n    10分钟快恢：1-5-10 场景的核心是快恢，发现体系和响应体系建设都是为了快速的恢复故障。要建设快恢体系首先需要建立起快恢能力，其次要针对故障特征合理使用快恢能力。\n```dtd\n⭐️ 快恢手段：手段有很多，比如应用重启，系统回滚，机器下线，重新发布，扩容限流等等，本篇文章主要介绍应用重启。\n```\n为了满足系统稳定性、高可用的建设，达成1-5-10对于故障处理的时效性目标，对商品发布应用进行启动优化（满足10分钟快恢）。\n\n<!-- more -->\n\n### 二、现状\n![](2024-03-01-性能优化-启动优化/编译发布流程图.png)\n**优化前：** 应用从构建、部署，整体耗时12分钟。\n\n### 三、优化手段\n优化手段也非常多项，包括容器优化、构建优化、编译优化，本文对阿里内部组件的优化不做过多解释，应用启动的主要瓶颈在于bean的初始化过程，因此本篇文章主要讲解spring bean异步化优化。\n\n[阿里内部组件优化](https://markdown.com.cn/basic-syntax/links.html \"阿里内部组件优化\")\n\n#### ⭐️ spring bean异步化优化\n应用启动速度主要的瓶颈在于bean的初始化过程（init，afterPropertiesSet方法的耗时），很多中间件bean的初始化逻辑涉及到网络io，且在没有相互依赖的情况下串行执行。将这一部分中间件bean进行异步加载，是提升启动速度的一个探索方向。\n\n解决方案：   \n```dtd\n1、自动扫描可批量异步的中间件bean，而后，在bean的初始化阶段利用线程池并行执行其初始化逻辑。  \n2、允许使用方自行配置耗时bean以享受异步加速能力。(需使用方自行确认依赖关系满足异步条件)\n```\n\n### 四、使用示例\n主要针对中间件。\n#### A.解决方案1：  \n自定义注解，例如@SofaAsyncInit。（注：此注解为SOFABoot项目的注解）\n![](2024-03-01-性能优化-启动优化/启动加速-自动扫描异步类.png)\n\n#### B.解决方案2：\n```dtd\n手动指定要异步初始化的bean，格式为bean名称列表：如****.async-init=tairClient,mqclient。\n```\n当时所在团队使用的这种方案。\n\n### 五、原理\n#### A:首先需要知道spring的bean初始化流程。\n我们先知道afterPropertiesSet()和Init()方法的执行时机，因为Bean初始化耗时主要是这2个方法。\n![](2024-03-01-性能优化-启动优化/spring实例初始化流程.png)\n步骤1：遍历beanDefinitionNames集合     \n步骤2：检查缓存中或者实例工厂中是否有对应的实例    \n步骤3：创建bean实例    \n    bean初始化时，会执行AbstractAutowireCapableBeanFactory#invokeInitMethods的方法，方法内部会执行2个方法：afterPropertiesSet()方法 & invokeCustomInitMethod()。\n```dtd\n1. afterPropertiesSet()方法：需要类实现InitializingBean接口。\n2. invokeCustomInitMethod()方法：会执行自定义的init()方法。\n```\n#### B:实现异步加载\n既然知道了afterPropertiesSet()和init()2个方法的执行时机和流程，那么接下来就是设法实现异步加载执行了。\n\n***⭐️ 基于注解的实现方式：***    \n**1. 首先解析注解，收集信息**    \n通过实现BeanFactoryPostProcessor接口（bean工厂的后置处理器，可以获取bean的示例或定义等。同时可以修改bean的属性），来进行注解的解析。\n```dtd\ncom.alipay.sofa.runtime.spring.AsyncInitBeanFactoryPostProcessor#registerAsyncInitBean\n```\n实现BeanFactoryPostProcessor接口：\n![具体实现](2024-03-01-性能优化-启动优化/注解解析.png)\n![具体实现](2024-03-01-性能优化-启动优化/AsyncInitBeanFactoryPostProcessor-registerAsyncInitBean.png)\n***收集Bean信息：***\nregisterAsyncInitBean 方法，把可以异步执行的 init 方法的 Bean 收集起来，用 Map 来进行的存储。\n![具体实现](2024-03-01-性能优化-启动优化/registerAsyncInitBean具体实现.png)\n\n**2. 然后异步化处理**  \n实现BeanPostProcessor接口（bean的后置处理器）\n```dtd\ncom.alipay.sofa.runtime.spring.AsyncProxyBeanPostProcessor#postProcessBeforeInitialization\n```\n![beanpostprocessor](2024-03-01-性能优化-启动优化/beanpostprocessor.png)\n关键点，就在 AsyncInitializeBeanMethodInvoker 里面，因为这个里面有真正判断是否要进行异步初始化的逻辑，主要解读一下这个类。  \n首先，关注一下它的这三个参数：\n```dtd\ninitCountDownLatch：是 CountDownLatch 对象，其中 count 初始化为 1\nisAsyncCalling：表示是否正在异步执行 init 方法。\nisAsyncCalled：表示是否已经异步执行过 init 方法。\n```\n通过这三个字段，就可以感知到一个 Bean 是否已经或者正在异步执行其 init 方法。    \n![异步化](2024-03-01-性能优化-启动优化/异步化.png)\n核心逻辑就是通过AsyncTaskExecutor.submitTask()把init()扔到线程池里面去执行。\n\n[SOFABoot](https://www.cnblogs.com/thisiswhy/p/17457499.html,\"SOFABoot\")    \n[参考文章1](https://developer.aliyun.com/article/1239199, \"Bean异步初始化，让你的应用启动飞起来\")   \n[spring异步化](https://mp.weixin.qq.com/s/-qzXuiE7fcGS7JXxFbu6jg?poc_token=HHhxD2ejr-ur6eD3TaHJ2lUVP5m4UbF5awelDrdo, \"\")\n\n### 六、成果\n下图只是展示了长啥样，不是真实数据：\n![性能效果](2024-03-01-性能优化-启动优化/性能效果.png)\n```dtd\n优化前：12分    \n优化后：7分30s\n```","slug":"2024-03-01-性能优化-启动优化","published":1,"updated":"2024-12-09T03:26:17.297Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxp003ta13kv3huyqvk","content":"<pre><code>这是性能优化系列的第一篇文章，主要介绍的是系统的启动优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在阿里巴巴内部经过多年的实践，1-5-10 早已成为各个业务稳定性、基础设施稳定性以及大促保障的重要牵引指标。</p>\n<pre><code>1分钟发现：做到故障的一分钟发现，首先需要有完善的监控/告警体系，其次需要有明确的故障结构化定义\n5分钟响应：做到故障的 5 分钟响应，首先需要有一套标准的应急响应流程，其次需要能够快速定位问题，作出恢复决策\n10分钟快恢：1-5-10 场景的核心是快恢，发现体系和响应体系建设都是为了快速的恢复故障。要建设快恢体系首先需要建立起快恢能力，其次要针对故障特征合理使用快恢能力。</code></pre><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">⭐️ 快恢手段：手段有很多，比如应用重启，系统回滚，机器下线，重新发布，扩容限流等等，本篇文章主要介绍应用重启。</span><br></pre></td></tr></table></figure>\n\n<p>为了满足系统稳定性、高可用的建设，达成1-5-10对于故障处理的时效性目标，对商品发布应用进行启动优化（满足10分钟快恢）。</p>\n<a id=\"more\"></a>\n\n<h3 id=\"二、现状\"><a href=\"#二、现状\" class=\"headerlink\" title=\"二、现状\"></a>二、现状</h3><p><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E7%BC%96%E8%AF%91%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B%E5%9B%BE.png\" alt><br><strong>优化前：</strong> 应用从构建、部署，整体耗时12分钟。</p>\n<h3 id=\"三、优化手段\"><a href=\"#三、优化手段\" class=\"headerlink\" title=\"三、优化手段\"></a>三、优化手段</h3><p>优化手段也非常多项，包括容器优化、构建优化、编译优化，本文对阿里内部组件的优化不做过多解释，应用启动的主要瓶颈在于bean的初始化过程，因此本篇文章主要讲解spring bean异步化优化。</p>\n<p><a href=\"https://markdown.com.cn/basic-syntax/links.html\" title=\"阿里内部组件优化\" target=\"_blank\" rel=\"noopener\">阿里内部组件优化</a></p>\n<h4 id=\"⭐️-spring-bean异步化优化\"><a href=\"#⭐️-spring-bean异步化优化\" class=\"headerlink\" title=\"⭐️ spring bean异步化优化\"></a>⭐️ spring bean异步化优化</h4><p>应用启动速度主要的瓶颈在于bean的初始化过程（init，afterPropertiesSet方法的耗时），很多中间件bean的初始化逻辑涉及到网络io，且在没有相互依赖的情况下串行执行。将这一部分中间件bean进行异步加载，是提升启动速度的一个探索方向。</p>\n<p>解决方案：   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、自动扫描可批量异步的中间件bean，而后，在bean的初始化阶段利用线程池并行执行其初始化逻辑。  </span><br><span class=\"line\">2、允许使用方自行配置耗时bean以享受异步加速能力。(需使用方自行确认依赖关系满足异步条件)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"四、使用示例\"><a href=\"#四、使用示例\" class=\"headerlink\" title=\"四、使用示例\"></a>四、使用示例</h3><p>主要针对中间件。</p>\n<h4 id=\"A-解决方案1：\"><a href=\"#A-解决方案1：\" class=\"headerlink\" title=\"A.解决方案1：\"></a>A.解决方案1：</h4><p>自定义注解，例如@SofaAsyncInit。（注：此注解为SOFABoot项目的注解）<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E5%90%AF%E5%8A%A8%E5%8A%A0%E9%80%9F-%E8%87%AA%E5%8A%A8%E6%89%AB%E6%8F%8F%E5%BC%82%E6%AD%A5%E7%B1%BB.png\" alt></p>\n<h4 id=\"B-解决方案2：\"><a href=\"#B-解决方案2：\" class=\"headerlink\" title=\"B.解决方案2：\"></a>B.解决方案2：</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">手动指定要异步初始化的bean，格式为bean名称列表：如****.async-init=tairClient,mqclient。</span><br></pre></td></tr></table></figure>\n\n<p>当时所在团队使用的这种方案。</p>\n<h3 id=\"五、原理\"><a href=\"#五、原理\" class=\"headerlink\" title=\"五、原理\"></a>五、原理</h3><h4 id=\"A-首先需要知道spring的bean初始化流程。\"><a href=\"#A-首先需要知道spring的bean初始化流程。\" class=\"headerlink\" title=\"A:首先需要知道spring的bean初始化流程。\"></a>A:首先需要知道spring的bean初始化流程。</h4><p>我们先知道afterPropertiesSet()和Init()方法的执行时机，因为Bean初始化耗时主要是这2个方法。<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/spring%E5%AE%9E%E4%BE%8B%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B.png\" alt><br>步骤1：遍历beanDefinitionNames集合<br>步骤2：检查缓存中或者实例工厂中是否有对应的实例<br>步骤3：创建bean实例<br>    bean初始化时，会执行AbstractAutowireCapableBeanFactory#invokeInitMethods的方法，方法内部会执行2个方法：afterPropertiesSet()方法 &amp; invokeCustomInitMethod()。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. afterPropertiesSet()方法：需要类实现InitializingBean接口。</span><br><span class=\"line\">2. invokeCustomInitMethod()方法：会执行自定义的init()方法。</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"B-实现异步加载\"><a href=\"#B-实现异步加载\" class=\"headerlink\" title=\"B:实现异步加载\"></a>B:实现异步加载</h4><p>既然知道了afterPropertiesSet()和init()2个方法的执行时机和流程，那么接下来就是设法实现异步加载执行了。</p>\n<p><strong><em>⭐️ 基于注解的实现方式：</em></strong><br><strong>1. 首先解析注解，收集信息</strong><br>通过实现BeanFactoryPostProcessor接口（bean工厂的后置处理器，可以获取bean的示例或定义等。同时可以修改bean的属性），来进行注解的解析。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">com.alipay.sofa.runtime.spring.AsyncInitBeanFactoryPostProcessor#registerAsyncInitBean</span><br></pre></td></tr></table></figure>\n\n<p>实现BeanFactoryPostProcessor接口：<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E6%B3%A8%E8%A7%A3%E8%A7%A3%E6%9E%90.png\" alt=\"具体实现\"><br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/AsyncInitBeanFactoryPostProcessor-registerAsyncInitBean.png\" alt=\"具体实现\"><br><strong><em>收集Bean信息：</em></strong><br>registerAsyncInitBean 方法，把可以异步执行的 init 方法的 Bean 收集起来，用 Map 来进行的存储。<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/registerAsyncInitBean%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0.png\" alt=\"具体实现\"></p>\n<p><strong>2. 然后异步化处理</strong><br>实现BeanPostProcessor接口（bean的后置处理器）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">com.alipay.sofa.runtime.spring.AsyncProxyBeanPostProcessor#postProcessBeforeInitialization</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/beanpostprocessor.png\" alt=\"beanpostprocessor\"><br>关键点，就在 AsyncInitializeBeanMethodInvoker 里面，因为这个里面有真正判断是否要进行异步初始化的逻辑，主要解读一下这个类。<br>首先，关注一下它的这三个参数：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">initCountDownLatch：是 CountDownLatch 对象，其中 count 初始化为 1</span><br><span class=\"line\">isAsyncCalling：表示是否正在异步执行 init 方法。</span><br><span class=\"line\">isAsyncCalled：表示是否已经异步执行过 init 方法。</span><br></pre></td></tr></table></figure>\n\n<p>通过这三个字段，就可以感知到一个 Bean 是否已经或者正在异步执行其 init 方法。<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E5%BC%82%E6%AD%A5%E5%8C%96.png\" alt=\"异步化\"><br>核心逻辑就是通过AsyncTaskExecutor.submitTask()把init()扔到线程池里面去执行。</p>\n<p><a href=\"https://www.cnblogs.com/thisiswhy/p/17457499.html,\" sofaboot\"\" target=\"_blank\" rel=\"noopener\">SOFABoot</a><br><a href=\"https://developer.aliyun.com/article/1239199,\" title=\"Bean异步初始化，让你的应用启动飞起来\" target=\"_blank\" rel=\"noopener\">参考文章1</a><br><a href=\"https://mp.weixin.qq.com/s/-qzXuiE7fcGS7JXxFbu6jg?poc_token=HHhxD2ejr-ur6eD3TaHJ2lUVP5m4UbF5awelDrdo,\" target=\"_blank\" rel=\"noopener\">spring异步化</a></p>\n<h3 id=\"六、成果\"><a href=\"#六、成果\" class=\"headerlink\" title=\"六、成果\"></a>六、成果</h3><p>下图只是展示了长啥样，不是真实数据：<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E6%80%A7%E8%83%BD%E6%95%88%E6%9E%9C.png\" alt=\"性能效果\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">优化前：12分    </span><br><span class=\"line\">优化后：7分30s</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<pre><code>这是性能优化系列的第一篇文章，主要介绍的是系统的启动优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在阿里巴巴内部经过多年的实践，1-5-10 早已成为各个业务稳定性、基础设施稳定性以及大促保障的重要牵引指标。</p>\n<pre><code>1分钟发现：做到故障的一分钟发现，首先需要有完善的监控/告警体系，其次需要有明确的故障结构化定义\n5分钟响应：做到故障的 5 分钟响应，首先需要有一套标准的应急响应流程，其次需要能够快速定位问题，作出恢复决策\n10分钟快恢：1-5-10 场景的核心是快恢，发现体系和响应体系建设都是为了快速的恢复故障。要建设快恢体系首先需要建立起快恢能力，其次要针对故障特征合理使用快恢能力。</code></pre><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">⭐️ 快恢手段：手段有很多，比如应用重启，系统回滚，机器下线，重新发布，扩容限流等等，本篇文章主要介绍应用重启。</span><br></pre></td></tr></table></figure>\n\n<p>为了满足系统稳定性、高可用的建设，达成1-5-10对于故障处理的时效性目标，对商品发布应用进行启动优化（满足10分钟快恢）。</p>","more":"<h3 id=\"二、现状\"><a href=\"#二、现状\" class=\"headerlink\" title=\"二、现状\"></a>二、现状</h3><p><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E7%BC%96%E8%AF%91%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B%E5%9B%BE.png\" alt><br><strong>优化前：</strong> 应用从构建、部署，整体耗时12分钟。</p>\n<h3 id=\"三、优化手段\"><a href=\"#三、优化手段\" class=\"headerlink\" title=\"三、优化手段\"></a>三、优化手段</h3><p>优化手段也非常多项，包括容器优化、构建优化、编译优化，本文对阿里内部组件的优化不做过多解释，应用启动的主要瓶颈在于bean的初始化过程，因此本篇文章主要讲解spring bean异步化优化。</p>\n<p><a href=\"https://markdown.com.cn/basic-syntax/links.html\" title=\"阿里内部组件优化\" target=\"_blank\" rel=\"noopener\">阿里内部组件优化</a></p>\n<h4 id=\"⭐️-spring-bean异步化优化\"><a href=\"#⭐️-spring-bean异步化优化\" class=\"headerlink\" title=\"⭐️ spring bean异步化优化\"></a>⭐️ spring bean异步化优化</h4><p>应用启动速度主要的瓶颈在于bean的初始化过程（init，afterPropertiesSet方法的耗时），很多中间件bean的初始化逻辑涉及到网络io，且在没有相互依赖的情况下串行执行。将这一部分中间件bean进行异步加载，是提升启动速度的一个探索方向。</p>\n<p>解决方案：   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、自动扫描可批量异步的中间件bean，而后，在bean的初始化阶段利用线程池并行执行其初始化逻辑。  </span><br><span class=\"line\">2、允许使用方自行配置耗时bean以享受异步加速能力。(需使用方自行确认依赖关系满足异步条件)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"四、使用示例\"><a href=\"#四、使用示例\" class=\"headerlink\" title=\"四、使用示例\"></a>四、使用示例</h3><p>主要针对中间件。</p>\n<h4 id=\"A-解决方案1：\"><a href=\"#A-解决方案1：\" class=\"headerlink\" title=\"A.解决方案1：\"></a>A.解决方案1：</h4><p>自定义注解，例如@SofaAsyncInit。（注：此注解为SOFABoot项目的注解）<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E5%90%AF%E5%8A%A8%E5%8A%A0%E9%80%9F-%E8%87%AA%E5%8A%A8%E6%89%AB%E6%8F%8F%E5%BC%82%E6%AD%A5%E7%B1%BB.png\" alt></p>\n<h4 id=\"B-解决方案2：\"><a href=\"#B-解决方案2：\" class=\"headerlink\" title=\"B.解决方案2：\"></a>B.解决方案2：</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">手动指定要异步初始化的bean，格式为bean名称列表：如****.async-init=tairClient,mqclient。</span><br></pre></td></tr></table></figure>\n\n<p>当时所在团队使用的这种方案。</p>\n<h3 id=\"五、原理\"><a href=\"#五、原理\" class=\"headerlink\" title=\"五、原理\"></a>五、原理</h3><h4 id=\"A-首先需要知道spring的bean初始化流程。\"><a href=\"#A-首先需要知道spring的bean初始化流程。\" class=\"headerlink\" title=\"A:首先需要知道spring的bean初始化流程。\"></a>A:首先需要知道spring的bean初始化流程。</h4><p>我们先知道afterPropertiesSet()和Init()方法的执行时机，因为Bean初始化耗时主要是这2个方法。<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/spring%E5%AE%9E%E4%BE%8B%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B.png\" alt><br>步骤1：遍历beanDefinitionNames集合<br>步骤2：检查缓存中或者实例工厂中是否有对应的实例<br>步骤3：创建bean实例<br>    bean初始化时，会执行AbstractAutowireCapableBeanFactory#invokeInitMethods的方法，方法内部会执行2个方法：afterPropertiesSet()方法 &amp; invokeCustomInitMethod()。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. afterPropertiesSet()方法：需要类实现InitializingBean接口。</span><br><span class=\"line\">2. invokeCustomInitMethod()方法：会执行自定义的init()方法。</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"B-实现异步加载\"><a href=\"#B-实现异步加载\" class=\"headerlink\" title=\"B:实现异步加载\"></a>B:实现异步加载</h4><p>既然知道了afterPropertiesSet()和init()2个方法的执行时机和流程，那么接下来就是设法实现异步加载执行了。</p>\n<p><strong><em>⭐️ 基于注解的实现方式：</em></strong><br><strong>1. 首先解析注解，收集信息</strong><br>通过实现BeanFactoryPostProcessor接口（bean工厂的后置处理器，可以获取bean的示例或定义等。同时可以修改bean的属性），来进行注解的解析。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">com.alipay.sofa.runtime.spring.AsyncInitBeanFactoryPostProcessor#registerAsyncInitBean</span><br></pre></td></tr></table></figure>\n\n<p>实现BeanFactoryPostProcessor接口：<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E6%B3%A8%E8%A7%A3%E8%A7%A3%E6%9E%90.png\" alt=\"具体实现\"><br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/AsyncInitBeanFactoryPostProcessor-registerAsyncInitBean.png\" alt=\"具体实现\"><br><strong><em>收集Bean信息：</em></strong><br>registerAsyncInitBean 方法，把可以异步执行的 init 方法的 Bean 收集起来，用 Map 来进行的存储。<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/registerAsyncInitBean%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0.png\" alt=\"具体实现\"></p>\n<p><strong>2. 然后异步化处理</strong><br>实现BeanPostProcessor接口（bean的后置处理器）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">com.alipay.sofa.runtime.spring.AsyncProxyBeanPostProcessor#postProcessBeforeInitialization</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/beanpostprocessor.png\" alt=\"beanpostprocessor\"><br>关键点，就在 AsyncInitializeBeanMethodInvoker 里面，因为这个里面有真正判断是否要进行异步初始化的逻辑，主要解读一下这个类。<br>首先，关注一下它的这三个参数：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">initCountDownLatch：是 CountDownLatch 对象，其中 count 初始化为 1</span><br><span class=\"line\">isAsyncCalling：表示是否正在异步执行 init 方法。</span><br><span class=\"line\">isAsyncCalled：表示是否已经异步执行过 init 方法。</span><br></pre></td></tr></table></figure>\n\n<p>通过这三个字段，就可以感知到一个 Bean 是否已经或者正在异步执行其 init 方法。<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E5%BC%82%E6%AD%A5%E5%8C%96.png\" alt=\"异步化\"><br>核心逻辑就是通过AsyncTaskExecutor.submitTask()把init()扔到线程池里面去执行。</p>\n<p><a href=\"https://www.cnblogs.com/thisiswhy/p/17457499.html,\" sofaboot\"\" target=\"_blank\" rel=\"noopener\">SOFABoot</a><br><a href=\"https://developer.aliyun.com/article/1239199,\" title=\"Bean异步初始化，让你的应用启动飞起来\" target=\"_blank\" rel=\"noopener\">参考文章1</a><br><a href=\"https://mp.weixin.qq.com/s/-qzXuiE7fcGS7JXxFbu6jg?poc_token=HHhxD2ejr-ur6eD3TaHJ2lUVP5m4UbF5awelDrdo,\" target=\"_blank\" rel=\"noopener\">spring异步化</a></p>\n<h3 id=\"六、成果\"><a href=\"#六、成果\" class=\"headerlink\" title=\"六、成果\"></a>六、成果</h3><p>下图只是展示了长啥样，不是真实数据：<br><img src=\"/2024/03/01/2024-03-01-性能优化-启动优化/%E6%80%A7%E8%83%BD%E6%95%88%E6%9E%9C.png\" alt=\"性能效果\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">优化前：12分    </span><br><span class=\"line\">优化后：7分30s</span><br></pre></td></tr></table></figure>"},{"title":"《性能优化系列》MySQL查询优化","date":"2024-03-03T02:00:00.000Z","_content":"\n    这是性能优化系列的第二篇文章，主要介绍的是数据库使用的相关优化。\n\n### 一、背景\n在阿里的工作中，经历的业务繁多，也累积了丰富的数据库使用优化经验。   \n本文通过分享多个优化案例来对该部分内容进行说明。    \n\n    1、商品货架关系优化。\n    2、交易定时任务查询优化。\n\n<!-- more -->\n\n### 二 案例1：商品货架关系优化\n| 术语        | 描述    |\n|:---| ---:|\n| 商品适用门店    | 商品能够销售的门店 |\n| 货架关系 | 展示商品  |\n\n商品和店铺有2个关联表，item_store_relation和store_item_relation表，单库64表。   \n**表结构如下：**\n```dtd\n商品适用门店表：\nitem_store_relation {\n    item_id: long 分表键\n    store_id: long\n    UNIQUE (item_id, store_id)\n} \n货架关系表：\nstore_item_relation {\n    store_id: long 分表键\n    item_id,\n    UNIQUE (store_id, item_id)\n}\n```\n\n**商品货架关系业务场景：**\n*业务说明：*\n在更新商品业务中，会更新商品的可销售门店信息，此时会先根据itemId去查item_store_relation & store_item_relation2张表得到所有的storeId，2者进行业务计算，最终去更新数据库。\n{% plantuml %}\nparticipant 业务\nparticipant 商品发布系统\ndatabase mysql\n\n业务->商品发布系统 : 更新商品门店信息\n商品发布系统->mysql: 根据itemId分页查询出所有的item_store_relation\nmysql-->商品发布系统: 返回store_id\n商品发布系统->mysql: 根据itemId分页查询出所有的store_item_relation\nmysql-->商品发布系统: 返回store_id\n商品发布系统->商品发布系统: 业务计算，得出结果集。\n商品发布系统->mysql: 更新数据库\n{% endplantuml %}\n\n\n整个业务过程存在问题（主要是大的连锁品牌，存在1W+个门店）：\n> 问题1：分库分表的查询问题，在查询store_item_relation时，只能通过itemId遍历所有的store_item_relation表（itemId不是分布键，storeId才是），导致性能特别差，最终导致接口耗时高，业务调用时频繁出现接口超时问题，也会导致商品分布系统MySQL的负载增加，影响系统稳定性。\n> 问题1：分库分表的查询问题，一般情况下，商品适用门店和货架关系，数据量是会一致的，但是某些场景，会存在2者数据量不一致的情况（例如item_store_relation < store_item_relation），因此不能通过item_store_relation获取的storeId去查询store_item_relation，只能通过itemId遍历所有的store_item_relation表，导致性能特别差，最终导致接口耗时高，业务调用时频繁出现接口超时问题，也会导致商品分布系统MySQL的负载增加，影响系统稳定性。\n\n#### ⭐️优化1：采用“游标” + “并发”优化查询\n\n##### “游标”\n分页查询，加入游标后，可提升查询效率。     \n优化前SQL：\n```dtd\nselect store_d from item_store_relation where item_id = ? order by store_id limit 0, 100;\n```\n优化后SQL：\n```dtd\n\nselect store_id from item_store_relation where item_id = ? and store_id > ? order by store_id limit 0, 100;\n```\n\n##### “并发”\n针对性能问题，采用的方案是先从item_store_relation获取所有的storeId，再通过分组、多线程异步去获取store_item_relation数据。 \n示例代码如下：\n```java\npublic static List<Long> queryAllStoreId(Long itemId) {\n    //此处省略具体的service方法\n    List<ItemStoreRelation> itemStoreRelationList = new ArrayList<>();\n    //对storeId分组\n    Map<Long, List<Long>> groupedObjects = itemStoreRelationList.stream()\n            .map(ItemStoreRelation::getStoreId)\n            .collect(Collectors.groupingBy(obj -> obj % 64));\n\n    List<CompletableFuture<List<StoreItemRelation>>> futures = new ArrayList<>();\n    // 遍历分组后的结果\n    for (List<Long> storeIdList : groupedObjects.values()) {\n        CompletableFuture<List<StoreItemRelation>> future = CompletableFuture.supplyAsync(() -> \n                //查询store_item_relation\n                queryByStoreIds(storeIdList)\n        );\n        futures.add(future);\n    }\n\n    return futures.stream()\n            .map(CompletableFuture::join)\n            .flatMap(List::stream)\n            .map(StoreItemRelation::getStoreId)\n            .collect(Collectors.toList());\n}\n```\n\n- 优化结果：\n  - 接口由原来的3s+优化到了100ms，解决了性能问题。\n- 带来的问题：\n  - 因为对业务的不熟悉，以为2张关联表的数据是正反关系，数据量是会一致的，实际在某些场景，会存在2者数据量不一致的情况（例如item_store_relation < store_item_relation），因此不能通过item_store_relation获取的storeId去查询store_item_relation。\n\n因此接下来就是考虑其他方案了，考虑如何保存store_item_relation的数据，最终内部讨论，引入索引表，方案如下。\n\n#### ⭐️解决分库分表的查询问题\n本文重点：“异构索引表”是可以解决这个问题的。\n\n##### 引入异构索引表 \n简单来说，“异构索引表”是一个拿空间换时间的设计。具体如下：  \n![索引表](2024-03-03-性能优化-MySQL查询优化/异构索引表.png) \n引入异构索引表，代替store_item_relation功能，索引ID=itemId，索引值=storeId，再需要去获取货架关系时，只需要通过itemId去异构索引表获取数据，能充分利用分表键从而大大的提高查询效率。  \n表结构如下：  \n```dtd\naic_index {\n    id: 主键ID\n    index_id: 索引ID  (itemId，分表键)\n    index_value: 索引值  (storeId)\n    UNIQUE (index_id, index_value)\n}\n```\n更新后的时序图：    \n{% plantuml %}\nparticipant 业务\nparticipant 商品发布系统\ndatabase mysql\n\n业务->商品发布系统 : 更新商品门店信息\n商品发布系统->mysql: select store_id from item_store_relation where item_id=?\nmysql-->商品发布系统: 返回store_id\n商品发布系统-[#red]>mysql: select store_id from <color red>aic_index </color> where index_id=itemId\nmysql-->商品发布系统: 返回store_id\n商品发布系统->商品发布系统: 业务计算，得出结果集。\n商品发布系统->mysql: 更新数据库\n{% endplantuml %}\n\n解决了分库分表的查询问题，性能得到一定的提升，但是还是存在性能问题。  \n> 问题：串行查询，一次次分页查询表，仍然存在性能问题。\n\n{% plantuml %}\nparticipant 商品发布系统\ndatabase mysql\n\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 0,100;\nmysql-->商品发布系统: 返回store_id\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 100,100;\nmysql-->商品发布系统: 返回store_id\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 200,100;\nmysql-->商品发布系统: 返回store_id\n\n{% endplantuml %}\n\n> 思路是并发的去分页查询数据。 \n> - 前提1：控制并发线程数量，注意数据库连接资源、CPU资源、IO资源。 \n> - 前提2：相关场景并发不高，1W+的数据量，数据结构简单，有覆盖索引，并发查询不会有性能问题。\n> - 前提3：\n\n{% plantuml %}\nparticipant 商品发布系统\ndatabase mysql\n\n商品发布系统->mysql: select count(*) from aic_index where index_id=itemId;\nmysql-->商品发布系统: 返回数量\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 0,100;\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 100,100;\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 200,100;\nmysql-->商品发布系统: 返回store_id\nmysql-->商品发布系统: 返回store_id\nmysql-->商品发布系统: 返回store_id\n\n{% endplantuml %}\n\n### 三、总结：\n- 优化结果：大门店场景，接口由原来的3s+优化到了100ms。\n\nMore info: [异构索引表](https://mp.weixin.qq.com/s/qWYfIK8FmlS0yLgy8mhROw)\n","source":"_posts/2024-03-03-性能优化-MySQL查询优化.md","raw":"---\ntitle: 《性能优化系列》MySQL查询优化\ndate: 2024-03-03 10:00:00\ncategories: \n- [数据库, mysql, 性能优化]\n- [性能优化]\n- [阿里]\ntags:\n- 阿里\n---\n\n    这是性能优化系列的第二篇文章，主要介绍的是数据库使用的相关优化。\n\n### 一、背景\n在阿里的工作中，经历的业务繁多，也累积了丰富的数据库使用优化经验。   \n本文通过分享多个优化案例来对该部分内容进行说明。    \n\n    1、商品货架关系优化。\n    2、交易定时任务查询优化。\n\n<!-- more -->\n\n### 二 案例1：商品货架关系优化\n| 术语        | 描述    |\n|:---| ---:|\n| 商品适用门店    | 商品能够销售的门店 |\n| 货架关系 | 展示商品  |\n\n商品和店铺有2个关联表，item_store_relation和store_item_relation表，单库64表。   \n**表结构如下：**\n```dtd\n商品适用门店表：\nitem_store_relation {\n    item_id: long 分表键\n    store_id: long\n    UNIQUE (item_id, store_id)\n} \n货架关系表：\nstore_item_relation {\n    store_id: long 分表键\n    item_id,\n    UNIQUE (store_id, item_id)\n}\n```\n\n**商品货架关系业务场景：**\n*业务说明：*\n在更新商品业务中，会更新商品的可销售门店信息，此时会先根据itemId去查item_store_relation & store_item_relation2张表得到所有的storeId，2者进行业务计算，最终去更新数据库。\n{% plantuml %}\nparticipant 业务\nparticipant 商品发布系统\ndatabase mysql\n\n业务->商品发布系统 : 更新商品门店信息\n商品发布系统->mysql: 根据itemId分页查询出所有的item_store_relation\nmysql-->商品发布系统: 返回store_id\n商品发布系统->mysql: 根据itemId分页查询出所有的store_item_relation\nmysql-->商品发布系统: 返回store_id\n商品发布系统->商品发布系统: 业务计算，得出结果集。\n商品发布系统->mysql: 更新数据库\n{% endplantuml %}\n\n\n整个业务过程存在问题（主要是大的连锁品牌，存在1W+个门店）：\n> 问题1：分库分表的查询问题，在查询store_item_relation时，只能通过itemId遍历所有的store_item_relation表（itemId不是分布键，storeId才是），导致性能特别差，最终导致接口耗时高，业务调用时频繁出现接口超时问题，也会导致商品分布系统MySQL的负载增加，影响系统稳定性。\n> 问题1：分库分表的查询问题，一般情况下，商品适用门店和货架关系，数据量是会一致的，但是某些场景，会存在2者数据量不一致的情况（例如item_store_relation < store_item_relation），因此不能通过item_store_relation获取的storeId去查询store_item_relation，只能通过itemId遍历所有的store_item_relation表，导致性能特别差，最终导致接口耗时高，业务调用时频繁出现接口超时问题，也会导致商品分布系统MySQL的负载增加，影响系统稳定性。\n\n#### ⭐️优化1：采用“游标” + “并发”优化查询\n\n##### “游标”\n分页查询，加入游标后，可提升查询效率。     \n优化前SQL：\n```dtd\nselect store_d from item_store_relation where item_id = ? order by store_id limit 0, 100;\n```\n优化后SQL：\n```dtd\n\nselect store_id from item_store_relation where item_id = ? and store_id > ? order by store_id limit 0, 100;\n```\n\n##### “并发”\n针对性能问题，采用的方案是先从item_store_relation获取所有的storeId，再通过分组、多线程异步去获取store_item_relation数据。 \n示例代码如下：\n```java\npublic static List<Long> queryAllStoreId(Long itemId) {\n    //此处省略具体的service方法\n    List<ItemStoreRelation> itemStoreRelationList = new ArrayList<>();\n    //对storeId分组\n    Map<Long, List<Long>> groupedObjects = itemStoreRelationList.stream()\n            .map(ItemStoreRelation::getStoreId)\n            .collect(Collectors.groupingBy(obj -> obj % 64));\n\n    List<CompletableFuture<List<StoreItemRelation>>> futures = new ArrayList<>();\n    // 遍历分组后的结果\n    for (List<Long> storeIdList : groupedObjects.values()) {\n        CompletableFuture<List<StoreItemRelation>> future = CompletableFuture.supplyAsync(() -> \n                //查询store_item_relation\n                queryByStoreIds(storeIdList)\n        );\n        futures.add(future);\n    }\n\n    return futures.stream()\n            .map(CompletableFuture::join)\n            .flatMap(List::stream)\n            .map(StoreItemRelation::getStoreId)\n            .collect(Collectors.toList());\n}\n```\n\n- 优化结果：\n  - 接口由原来的3s+优化到了100ms，解决了性能问题。\n- 带来的问题：\n  - 因为对业务的不熟悉，以为2张关联表的数据是正反关系，数据量是会一致的，实际在某些场景，会存在2者数据量不一致的情况（例如item_store_relation < store_item_relation），因此不能通过item_store_relation获取的storeId去查询store_item_relation。\n\n因此接下来就是考虑其他方案了，考虑如何保存store_item_relation的数据，最终内部讨论，引入索引表，方案如下。\n\n#### ⭐️解决分库分表的查询问题\n本文重点：“异构索引表”是可以解决这个问题的。\n\n##### 引入异构索引表 \n简单来说，“异构索引表”是一个拿空间换时间的设计。具体如下：  \n![索引表](2024-03-03-性能优化-MySQL查询优化/异构索引表.png) \n引入异构索引表，代替store_item_relation功能，索引ID=itemId，索引值=storeId，再需要去获取货架关系时，只需要通过itemId去异构索引表获取数据，能充分利用分表键从而大大的提高查询效率。  \n表结构如下：  \n```dtd\naic_index {\n    id: 主键ID\n    index_id: 索引ID  (itemId，分表键)\n    index_value: 索引值  (storeId)\n    UNIQUE (index_id, index_value)\n}\n```\n更新后的时序图：    \n{% plantuml %}\nparticipant 业务\nparticipant 商品发布系统\ndatabase mysql\n\n业务->商品发布系统 : 更新商品门店信息\n商品发布系统->mysql: select store_id from item_store_relation where item_id=?\nmysql-->商品发布系统: 返回store_id\n商品发布系统-[#red]>mysql: select store_id from <color red>aic_index </color> where index_id=itemId\nmysql-->商品发布系统: 返回store_id\n商品发布系统->商品发布系统: 业务计算，得出结果集。\n商品发布系统->mysql: 更新数据库\n{% endplantuml %}\n\n解决了分库分表的查询问题，性能得到一定的提升，但是还是存在性能问题。  \n> 问题：串行查询，一次次分页查询表，仍然存在性能问题。\n\n{% plantuml %}\nparticipant 商品发布系统\ndatabase mysql\n\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 0,100;\nmysql-->商品发布系统: 返回store_id\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 100,100;\nmysql-->商品发布系统: 返回store_id\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 200,100;\nmysql-->商品发布系统: 返回store_id\n\n{% endplantuml %}\n\n> 思路是并发的去分页查询数据。 \n> - 前提1：控制并发线程数量，注意数据库连接资源、CPU资源、IO资源。 \n> - 前提2：相关场景并发不高，1W+的数据量，数据结构简单，有覆盖索引，并发查询不会有性能问题。\n> - 前提3：\n\n{% plantuml %}\nparticipant 商品发布系统\ndatabase mysql\n\n商品发布系统->mysql: select count(*) from aic_index where index_id=itemId;\nmysql-->商品发布系统: 返回数量\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 0,100;\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 100,100;\n商品发布系统->mysql: select store_id from aic_index where index_id=itemId limit 200,100;\nmysql-->商品发布系统: 返回store_id\nmysql-->商品发布系统: 返回store_id\nmysql-->商品发布系统: 返回store_id\n\n{% endplantuml %}\n\n### 三、总结：\n- 优化结果：大门店场景，接口由原来的3s+优化到了100ms。\n\nMore info: [异构索引表](https://mp.weixin.qq.com/s/qWYfIK8FmlS0yLgy8mhROw)\n","slug":"2024-03-03-性能优化-MySQL查询优化","published":1,"updated":"2024-12-09T03:26:17.288Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxq003wa13kaevt6bnb","content":"<pre><code>这是性能优化系列的第二篇文章，主要介绍的是数据库使用的相关优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在阿里的工作中，经历的业务繁多，也累积了丰富的数据库使用优化经验。<br>本文通过分享多个优化案例来对该部分内容进行说明。    </p>\n<pre><code>1、商品货架关系优化。\n2、交易定时任务查询优化。</code></pre><a id=\"more\"></a>\n\n<h3 id=\"二-案例1：商品货架关系优化\"><a href=\"#二-案例1：商品货架关系优化\" class=\"headerlink\" title=\"二 案例1：商品货架关系优化\"></a>二 案例1：商品货架关系优化</h3><table>\n<thead>\n<tr>\n<th align=\"left\">术语</th>\n<th align=\"right\">描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">商品适用门店</td>\n<td align=\"right\">商品能够销售的门店</td>\n</tr>\n<tr>\n<td align=\"left\">货架关系</td>\n<td align=\"right\">展示商品</td>\n</tr>\n</tbody></table>\n<p>商品和店铺有2个关联表，item_store_relation和store_item_relation表，单库64表。<br><strong>表结构如下：</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">商品适用门店表：</span><br><span class=\"line\">item_store_relation &#123;</span><br><span class=\"line\">    item_id: long 分表键</span><br><span class=\"line\">    store_id: long</span><br><span class=\"line\">    UNIQUE (item_id, store_id)</span><br><span class=\"line\">&#125; </span><br><span class=\"line\">货架关系表：</span><br><span class=\"line\">store_item_relation &#123;</span><br><span class=\"line\">    store_id: long 分表键</span><br><span class=\"line\">    item_id,</span><br><span class=\"line\">    UNIQUE (store_id, item_id)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>商品货架关系业务场景：</strong><br><em>业务说明：</em><br>在更新商品业务中，会更新商品的可销售门店信息，此时会先根据itemId去查item_store_relation &amp; store_item_relation2张表得到所有的storeId，2者进行业务计算，最终去更新数据库。</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHUB9ZrjEkXLm5I49FfxOzdTpuj7_YqntDppVlVhvxFbTAOabYKc9nga9kPN5X3XSNH9Uk7QPI1Ik5PxEtF9ks0IBrSlgAfxkcFzc_y5dZUYvCrRfsO0E1UXRiVDQxBhCaDTSpvMb7syk5Mv_DN_fY_QAdxRkUTJOyczFvV5OBI3Q-k2I_A3M-A3KdiIGpFuyBh5qNcqEi55xid_9qzZo8XimKIcs7cWDo0xLinwOD4h8lrYrylcxw-pqzJ_TD1phY-Ux9p-RDUJcxxN534rv_W4F-sTGDGDyytJKP0000\">\n\n\n<p>整个业务过程存在问题（主要是大的连锁品牌，存在1W+个门店）：</p>\n<blockquote>\n<p>问题1：分库分表的查询问题，在查询store_item_relation时，只能通过itemId遍历所有的store_item_relation表（itemId不是分布键，storeId才是），导致性能特别差，最终导致接口耗时高，业务调用时频繁出现接口超时问题，也会导致商品分布系统MySQL的负载增加，影响系统稳定性。<br>问题1：分库分表的查询问题，一般情况下，商品适用门店和货架关系，数据量是会一致的，但是某些场景，会存在2者数据量不一致的情况（例如item_store_relation &lt; store_item_relation），因此不能通过item_store_relation获取的storeId去查询store_item_relation，只能通过itemId遍历所有的store_item_relation表，导致性能特别差，最终导致接口耗时高，业务调用时频繁出现接口超时问题，也会导致商品分布系统MySQL的负载增加，影响系统稳定性。</p>\n</blockquote>\n<h4 id=\"⭐️优化1：采用“游标”-“并发”优化查询\"><a href=\"#⭐️优化1：采用“游标”-“并发”优化查询\" class=\"headerlink\" title=\"⭐️优化1：采用“游标” + “并发”优化查询\"></a>⭐️优化1：采用“游标” + “并发”优化查询</h4><h5 id=\"“游标”\"><a href=\"#“游标”\" class=\"headerlink\" title=\"“游标”\"></a>“游标”</h5><p>分页查询，加入游标后，可提升查询效率。<br>优化前SQL：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select store_d from item_store_relation where item_id = ? order by store_id limit 0, 100;</span><br></pre></td></tr></table></figure>\n\n<p>优化后SQL：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">select store_id from item_store_relation where item_id = ? and store_id &gt; ? order by store_id limit 0, 100;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"“并发”\"><a href=\"#“并发”\" class=\"headerlink\" title=\"“并发”\"></a>“并发”</h5><p>针对性能问题，采用的方案是先从item_store_relation获取所有的storeId，再通过分组、多线程异步去获取store_item_relation数据。<br>示例代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> List&lt;Long&gt; <span class=\"title\">queryAllStoreId</span><span class=\"params\">(Long itemId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//此处省略具体的service方法</span></span><br><span class=\"line\">    List&lt;ItemStoreRelation&gt; itemStoreRelationList = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">    <span class=\"comment\">//对storeId分组</span></span><br><span class=\"line\">    Map&lt;Long, List&lt;Long&gt;&gt; groupedObjects = itemStoreRelationList.stream()</span><br><span class=\"line\">            .map(ItemStoreRelation::getStoreId)</span><br><span class=\"line\">            .collect(Collectors.groupingBy(obj -&gt; obj % <span class=\"number\">64</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    List&lt;CompletableFuture&lt;List&lt;StoreItemRelation&gt;&gt;&gt; futures = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">    <span class=\"comment\">// 遍历分组后的结果</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (List&lt;Long&gt; storeIdList : groupedObjects.values()) &#123;</span><br><span class=\"line\">        CompletableFuture&lt;List&lt;StoreItemRelation&gt;&gt; future = CompletableFuture.supplyAsync(() -&gt; </span><br><span class=\"line\">                <span class=\"comment\">//查询store_item_relation</span></span><br><span class=\"line\">                queryByStoreIds(storeIdList)</span><br><span class=\"line\">        );</span><br><span class=\"line\">        futures.add(future);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> futures.stream()</span><br><span class=\"line\">            .map(CompletableFuture::join)</span><br><span class=\"line\">            .flatMap(List::stream)</span><br><span class=\"line\">            .map(StoreItemRelation::getStoreId)</span><br><span class=\"line\">            .collect(Collectors.toList());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>优化结果：<ul>\n<li>接口由原来的3s+优化到了100ms，解决了性能问题。</li>\n</ul>\n</li>\n<li>带来的问题：<ul>\n<li>因为对业务的不熟悉，以为2张关联表的数据是正反关系，数据量是会一致的，实际在某些场景，会存在2者数据量不一致的情况（例如item_store_relation &lt; store_item_relation），因此不能通过item_store_relation获取的storeId去查询store_item_relation。</li>\n</ul>\n</li>\n</ul>\n<p>因此接下来就是考虑其他方案了，考虑如何保存store_item_relation的数据，最终内部讨论，引入索引表，方案如下。</p>\n<h4 id=\"⭐️解决分库分表的查询问题\"><a href=\"#⭐️解决分库分表的查询问题\" class=\"headerlink\" title=\"⭐️解决分库分表的查询问题\"></a>⭐️解决分库分表的查询问题</h4><p>本文重点：“异构索引表”是可以解决这个问题的。</p>\n<h5 id=\"引入异构索引表\"><a href=\"#引入异构索引表\" class=\"headerlink\" title=\"引入异构索引表\"></a>引入异构索引表</h5><p>简单来说，“异构索引表”是一个拿空间换时间的设计。具体如下：<br><img src=\"/2024/03/03/2024-03-03-性能优化-MySQL查询优化/%E5%BC%82%E6%9E%84%E7%B4%A2%E5%BC%95%E8%A1%A8.png\" alt=\"索引表\"><br>引入异构索引表，代替store_item_relation功能，索引ID=itemId，索引值=storeId，再需要去获取货架关系时，只需要通过itemId去异构索引表获取数据，能充分利用分表键从而大大的提高查询效率。<br>表结构如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aic_index &#123;</span><br><span class=\"line\">    id: 主键ID</span><br><span class=\"line\">    index_id: 索引ID  (itemId，分表键)</span><br><span class=\"line\">    index_value: 索引值  (storeId)</span><br><span class=\"line\">    UNIQUE (index_id, index_value)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>更新后的时序图：    </p>\n<img src=\"http://www.plantuml.com/plantuml/svg/fP71IiD054NtynKFN0VteSQrto0Inio80qacJWRKdLMe88f8h04ZbUnSnO8kIYBsO-nCsfM_eCbG41gwSNlVlUyTxekmaCnZ4Gubp2QFwYf7qHz93GSgwQlREpMvgD-gkdf614kyZsCAmMbyv2DaKfQpQWKRTFQk7yPcj4XVL9dEfhdklw9Lj-Mq2ss8gKyz2R7aWhgCm87W0J190zT8WlfOCXx2yI4Lr4mOsTf6RTxg8h5XFhrNsMYvi-lyxeQWP6yjHC_ZFXVmwtCmyrmM4de2lSrMTPOuZTZmD5mxv9zGdJ7J-Bp8woBz_hXMdwcwBEigqQEdHJRuEZjVrwxvY1wEzKsXokG7\">\n\n<p>解决了分库分表的查询问题，性能得到一定的提升，但是还是存在性能问题。  </p>\n<blockquote>\n<p>问题：串行查询，一次次分页查询表，仍然存在性能问题。</p>\n</blockquote>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHU3grxUdangVz4v_kQ7w-UVVptVEvKX9B4fCIYrCLSYkB2tEuk32LwDg1fQmKYbDpKfDB58fByejIupDJ5DAAydCL4ZEJupFpKb8h5CepKejI5S1ieAnjPabghcUAGavcRcQ9We6EeO61DHVO85rTEqnBh1HUx9_oTFOycE4qSWVG5OF49KPak0G0\">\n\n<blockquote>\n<p>思路是并发的去分页查询数据。 </p>\n<ul>\n<li>前提1：控制并发线程数量，注意数据库连接资源、CPU资源、IO资源。 </li>\n<li>前提2：相关场景并发不高，1W+的数据量，数据结构简单，有覆盖索引，并发查询不会有性能问题。</li>\n<li>前提3：</li>\n</ul>\n</blockquote>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHU3grxUdangVz4v_kQ7w-UVVptVEvKX9B4fCIYrCLSYkB2tEuk32LwDg1fQmKYbDpKfDB59BpI_DADBGq5TAAydCL4ZEJupFpKb8h5CepKejI5S3i-CmKsyoIr5pF56iki6PTNJjCWwqKNkoVydJsl6TJDxnixoV2vkAI_A9KeDb4sQoGavcRMQ9We6DeO61D8yE1HjFIU2EOyOJ346OyZPG20000\">\n\n<h3 id=\"三、总结：\"><a href=\"#三、总结：\" class=\"headerlink\" title=\"三、总结：\"></a>三、总结：</h3><ul>\n<li>优化结果：大门店场景，接口由原来的3s+优化到了100ms。</li>\n</ul>\n<p>More info: <a href=\"https://mp.weixin.qq.com/s/qWYfIK8FmlS0yLgy8mhROw\" target=\"_blank\" rel=\"noopener\">异构索引表</a></p>\n","site":{"data":{}},"excerpt":"<pre><code>这是性能优化系列的第二篇文章，主要介绍的是数据库使用的相关优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在阿里的工作中，经历的业务繁多，也累积了丰富的数据库使用优化经验。<br>本文通过分享多个优化案例来对该部分内容进行说明。    </p>\n<pre><code>1、商品货架关系优化。\n2、交易定时任务查询优化。</code></pre>","more":"<h3 id=\"二-案例1：商品货架关系优化\"><a href=\"#二-案例1：商品货架关系优化\" class=\"headerlink\" title=\"二 案例1：商品货架关系优化\"></a>二 案例1：商品货架关系优化</h3><table>\n<thead>\n<tr>\n<th align=\"left\">术语</th>\n<th align=\"right\">描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">商品适用门店</td>\n<td align=\"right\">商品能够销售的门店</td>\n</tr>\n<tr>\n<td align=\"left\">货架关系</td>\n<td align=\"right\">展示商品</td>\n</tr>\n</tbody></table>\n<p>商品和店铺有2个关联表，item_store_relation和store_item_relation表，单库64表。<br><strong>表结构如下：</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">商品适用门店表：</span><br><span class=\"line\">item_store_relation &#123;</span><br><span class=\"line\">    item_id: long 分表键</span><br><span class=\"line\">    store_id: long</span><br><span class=\"line\">    UNIQUE (item_id, store_id)</span><br><span class=\"line\">&#125; </span><br><span class=\"line\">货架关系表：</span><br><span class=\"line\">store_item_relation &#123;</span><br><span class=\"line\">    store_id: long 分表键</span><br><span class=\"line\">    item_id,</span><br><span class=\"line\">    UNIQUE (store_id, item_id)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>商品货架关系业务场景：</strong><br><em>业务说明：</em><br>在更新商品业务中，会更新商品的可销售门店信息，此时会先根据itemId去查item_store_relation &amp; store_item_relation2张表得到所有的storeId，2者进行业务计算，最终去更新数据库。</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHUB9ZrjEkXLm5I49FfxOzdTpuj7_YqntDppVlVhvxFbTAOabYKc9nga9kPN5X3XSNH9Uk7QPI1Ik5PxEtF9ks0IBrSlgAfxkcFzc_y5dZUYvCrRfsO0E1UXRiVDQxBhCaDTSpvMb7syk5Mv_DN_fY_QAdxRkUTJOyczFvV5OBI3Q-k2I_A3M-A3KdiIGpFuyBh5qNcqEi55xid_9qzZo8XimKIcs7cWDo0xLinwOD4h8lrYrylcxw-pqzJ_TD1phY-Ux9p-RDUJcxxN534rv_W4F-sTGDGDyytJKP0000\">\n\n\n<p>整个业务过程存在问题（主要是大的连锁品牌，存在1W+个门店）：</p>\n<blockquote>\n<p>问题1：分库分表的查询问题，在查询store_item_relation时，只能通过itemId遍历所有的store_item_relation表（itemId不是分布键，storeId才是），导致性能特别差，最终导致接口耗时高，业务调用时频繁出现接口超时问题，也会导致商品分布系统MySQL的负载增加，影响系统稳定性。<br>问题1：分库分表的查询问题，一般情况下，商品适用门店和货架关系，数据量是会一致的，但是某些场景，会存在2者数据量不一致的情况（例如item_store_relation &lt; store_item_relation），因此不能通过item_store_relation获取的storeId去查询store_item_relation，只能通过itemId遍历所有的store_item_relation表，导致性能特别差，最终导致接口耗时高，业务调用时频繁出现接口超时问题，也会导致商品分布系统MySQL的负载增加，影响系统稳定性。</p>\n</blockquote>\n<h4 id=\"⭐️优化1：采用“游标”-“并发”优化查询\"><a href=\"#⭐️优化1：采用“游标”-“并发”优化查询\" class=\"headerlink\" title=\"⭐️优化1：采用“游标” + “并发”优化查询\"></a>⭐️优化1：采用“游标” + “并发”优化查询</h4><h5 id=\"“游标”\"><a href=\"#“游标”\" class=\"headerlink\" title=\"“游标”\"></a>“游标”</h5><p>分页查询，加入游标后，可提升查询效率。<br>优化前SQL：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select store_d from item_store_relation where item_id = ? order by store_id limit 0, 100;</span><br></pre></td></tr></table></figure>\n\n<p>优化后SQL：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">select store_id from item_store_relation where item_id = ? and store_id &gt; ? order by store_id limit 0, 100;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"“并发”\"><a href=\"#“并发”\" class=\"headerlink\" title=\"“并发”\"></a>“并发”</h5><p>针对性能问题，采用的方案是先从item_store_relation获取所有的storeId，再通过分组、多线程异步去获取store_item_relation数据。<br>示例代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> List&lt;Long&gt; <span class=\"title\">queryAllStoreId</span><span class=\"params\">(Long itemId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//此处省略具体的service方法</span></span><br><span class=\"line\">    List&lt;ItemStoreRelation&gt; itemStoreRelationList = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">    <span class=\"comment\">//对storeId分组</span></span><br><span class=\"line\">    Map&lt;Long, List&lt;Long&gt;&gt; groupedObjects = itemStoreRelationList.stream()</span><br><span class=\"line\">            .map(ItemStoreRelation::getStoreId)</span><br><span class=\"line\">            .collect(Collectors.groupingBy(obj -&gt; obj % <span class=\"number\">64</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    List&lt;CompletableFuture&lt;List&lt;StoreItemRelation&gt;&gt;&gt; futures = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">    <span class=\"comment\">// 遍历分组后的结果</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (List&lt;Long&gt; storeIdList : groupedObjects.values()) &#123;</span><br><span class=\"line\">        CompletableFuture&lt;List&lt;StoreItemRelation&gt;&gt; future = CompletableFuture.supplyAsync(() -&gt; </span><br><span class=\"line\">                <span class=\"comment\">//查询store_item_relation</span></span><br><span class=\"line\">                queryByStoreIds(storeIdList)</span><br><span class=\"line\">        );</span><br><span class=\"line\">        futures.add(future);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> futures.stream()</span><br><span class=\"line\">            .map(CompletableFuture::join)</span><br><span class=\"line\">            .flatMap(List::stream)</span><br><span class=\"line\">            .map(StoreItemRelation::getStoreId)</span><br><span class=\"line\">            .collect(Collectors.toList());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>优化结果：<ul>\n<li>接口由原来的3s+优化到了100ms，解决了性能问题。</li>\n</ul>\n</li>\n<li>带来的问题：<ul>\n<li>因为对业务的不熟悉，以为2张关联表的数据是正反关系，数据量是会一致的，实际在某些场景，会存在2者数据量不一致的情况（例如item_store_relation &lt; store_item_relation），因此不能通过item_store_relation获取的storeId去查询store_item_relation。</li>\n</ul>\n</li>\n</ul>\n<p>因此接下来就是考虑其他方案了，考虑如何保存store_item_relation的数据，最终内部讨论，引入索引表，方案如下。</p>\n<h4 id=\"⭐️解决分库分表的查询问题\"><a href=\"#⭐️解决分库分表的查询问题\" class=\"headerlink\" title=\"⭐️解决分库分表的查询问题\"></a>⭐️解决分库分表的查询问题</h4><p>本文重点：“异构索引表”是可以解决这个问题的。</p>\n<h5 id=\"引入异构索引表\"><a href=\"#引入异构索引表\" class=\"headerlink\" title=\"引入异构索引表\"></a>引入异构索引表</h5><p>简单来说，“异构索引表”是一个拿空间换时间的设计。具体如下：<br><img src=\"/2024/03/03/2024-03-03-性能优化-MySQL查询优化/%E5%BC%82%E6%9E%84%E7%B4%A2%E5%BC%95%E8%A1%A8.png\" alt=\"索引表\"><br>引入异构索引表，代替store_item_relation功能，索引ID=itemId，索引值=storeId，再需要去获取货架关系时，只需要通过itemId去异构索引表获取数据，能充分利用分表键从而大大的提高查询效率。<br>表结构如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aic_index &#123;</span><br><span class=\"line\">    id: 主键ID</span><br><span class=\"line\">    index_id: 索引ID  (itemId，分表键)</span><br><span class=\"line\">    index_value: 索引值  (storeId)</span><br><span class=\"line\">    UNIQUE (index_id, index_value)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>更新后的时序图：    </p>\n<img src=\"http://www.plantuml.com/plantuml/svg/fP71IiD054NtynKFN0VteSQrto0Inio80qacJWRKdLMe88f8h04ZbUnSnO8kIYBsO-nCsfM_eCbG41gwSNlVlUyTxekmaCnZ4Gubp2QFwYf7qHz93GSgwQlREpMvgD-gkdf614kyZsCAmMbyv2DaKfQpQWKRTFQk7yPcj4XVL9dEfhdklw9Lj-Mq2ss8gKyz2R7aWhgCm87W0J190zT8WlfOCXx2yI4Lr4mOsTf6RTxg8h5XFhrNsMYvi-lyxeQWP6yjHC_ZFXVmwtCmyrmM4de2lSrMTPOuZTZmD5mxv9zGdJ7J-Bp8woBz_hXMdwcwBEigqQEdHJRuEZjVrwxvY1wEzKsXokG7\">\n\n<p>解决了分库分表的查询问题，性能得到一定的提升，但是还是存在性能问题。  </p>\n<blockquote>\n<p>问题：串行查询，一次次分页查询表，仍然存在性能问题。</p>\n</blockquote>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHU3grxUdangVz4v_kQ7w-UVVptVEvKX9B4fCIYrCLSYkB2tEuk32LwDg1fQmKYbDpKfDB58fByejIupDJ5DAAydCL4ZEJupFpKb8h5CepKejI5S1ieAnjPabghcUAGavcRcQ9We6EeO61DHVO85rTEqnBh1HUx9_oTFOycE4qSWVG5OF49KPak0G0\">\n\n<blockquote>\n<p>思路是并发的去分页查询数据。 </p>\n<ul>\n<li>前提1：控制并发线程数量，注意数据库连接资源、CPU资源、IO资源。 </li>\n<li>前提2：相关场景并发不高，1W+的数据量，数据结构简单，有覆盖索引，并发查询不会有性能问题。</li>\n<li>前提3：</li>\n</ul>\n</blockquote>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHU3grxUdangVz4v_kQ7w-UVVptVEvKX9B4fCIYrCLSYkB2tEuk32LwDg1fQmKYbDpKfDB59BpI_DADBGq5TAAydCL4ZEJupFpKb8h5CepKejI5S3i-CmKsyoIr5pF56iki6PTNJjCWwqKNkoVydJsl6TJDxnixoV2vkAI_A9KeDb4sQoGavcRMQ9We6DeO61D8yE1HjFIU2EOyOJ346OyZPG20000\">\n\n<h3 id=\"三、总结：\"><a href=\"#三、总结：\" class=\"headerlink\" title=\"三、总结：\"></a>三、总结：</h3><ul>\n<li>优化结果：大门店场景，接口由原来的3s+优化到了100ms。</li>\n</ul>\n<p>More info: <a href=\"https://mp.weixin.qq.com/s/qWYfIK8FmlS0yLgy8mhROw\" target=\"_blank\" rel=\"noopener\">异构索引表</a></p>"},{"title":"《性能优化系列》多线程优化","date":"2024-03-05T02:00:00.000Z","_content":"\n    这是性能优化系列的第三篇文章，主要介绍的是多线程相关优化。\n\n### 一、背景\n在美团，主要是负责对资产管理系统的重构工作，现在对系统的作用及功能做介绍。\n- 系统定位：对美团的充电宝、优选物资、优选低值物资等资产的完整生命周期进行管理。\n- 主要功能：资产新增、资产重建、资产调整、资产折旧、资产处置等。\n\n对资产的操作，例如资产新增，一般是通过excel导入系统，导入的数据量最多30W行，如此大的数据量，处理时长达1小时，系统可以说是一种不可用的状态。当时从产品设计、系统架构、数据模型，对系统进行了重大的调整。本文主要对多线程方面进行讲解。\n\n<!-- more -->\n\n### 二、当前业务说明\n系统处理的时序图如下：\n\n{% plantuml %}\nactor 财务人员\nparticipant 资产管理系统\ndatabase mysql\n\n财务人员->资产管理系统 : 资产新增，导入excel\nactivate 资产管理系统\n资产管理系统->资产管理系统: 开启大事务\nactivate 资产管理系统\n资产管理系统->资产管理系统: 一条一条进行串行数据校验（格式校验）\n资产管理系统->mysql: 存在性校验，查询asset资产表\n资产管理系统->mysql: 保存数据\nmysql-->资产管理系统: 返回\ndeactivate 资产管理系统\n资产管理系统-->财务人员: 1小时后返回结果\n\n{% endplantuml %}\n\n伪代码如下：\n```java\nList<Object> assetList = new ArrayList<>();\n//开启事务：@Transaction\nfor (Object asset : assetList) {\n    //对资产进行校验\n    check(asset);\n    //数据存储\n    service.addAsset(asset);\n}\n```\n\n### 三、优化\n优化思路：\n- 大事务：解决大事务问题。\n- 并发：使用多线程提升性能。\n\n#### ⭐️ 使用CompletableFeature\n从业务的执行流程上看，可以把资产的操作分成2部分：\n- 第一部分：资产数据的校验。\n- 第二部分：资产数据的保存。\n\n2个操作是先后顺序，非常适合使用CompletableFeature。\n- 1、将资产进行分段，例如分成3段，每一段用多线程去并发处理（同时分割成3个小事务）。\n- 2、使用CompletableFuture.supplyAsync()，处理第一部分，生成对应的实体类。\n- 3、然后使用CompletableFuture.thenApplyAsync()处理第一部分返回的数据，进行数据的插入。\n\n伪代码如下：\n```java\n//1. 首先将assetList分组\nList<Integer> originalList = List.of(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nList<List<Integer>> copyPartition = Lists.partition(originalList, 3);\nList<CompletableFuture<Object>> futureList = copyPartition.stream().map(subList ->\n        //任务传递给supplyAsync()方法，该任务将在ForkJoinPool.commonPool()中异步完成运行\n        //最后，supplyAsync()将返回新的CompletableFuture，其值是通过调用给定的Supplier所获得的值。\n        CompletableFuture.supplyAsync(() -> {\n                    log.info(\"处理第{}段数据开始\", n);\n                    return checkImportAndBuildEvent(baseMessageMap, subList, totalCheckedMap, mis);\n            }, importForkJoinPool)\n            //thenApplyAsync()方法，从supplyAsync()获得的参数传递来执行给定的函数\n            .thenApplyAsync(eventSaveReqs -> {\n                    try {\n                        EventStrategyFactory.getStrategy(EventLargeCategoryEnum.IMPAIRMENT_ADD.getCode()).triggerEvent(eventSaveReqs);\n                        totalCheckedMap.get(BaseConstants.SUC_LIST).addAll(subList);\n                    } catch (Exception e) {\n                        log.error(\"资产新建失败\", e);\n                        subList.forEach(importDto -> {\n                            importDto.setFailReason(\"资产新建入库失败\");\n                        });\n                        totalCheckedMap.get(BaseConstants.FAIL_LIST).addAll(subList);\n                    }\n                    log.info(\"处理第{}段数据开始\", n);\n                    return null;\n                },\n                queryForkJoinPool\n            )\n).collect(toList());\nfutureList.stream().map(CompletableFuture::join).collect(Collectors.toList());\n```\n\n数据校验和保存，使用了2个线程池，达到业务隔离的作用：\n- importForkJoinPool：处理数据校验。\n- queryForkJoinPool：处理数据的存储。\n\n### 四、优化结果\n30W数据excel导入，由1小时优化到了2分钟，优化效果大大的提高了系统可用性。\n","source":"_posts/2024-03-05-性能优化-多线程优化.md","raw":"---\ntitle: 《性能优化系列》多线程优化\ndate: 2024-03-05 10:00:00\ncategories:\n  - [多线程, 并发]\n  - [性能优化]\n  - [美团]\ntags:\n- 美团\n---\n\n    这是性能优化系列的第三篇文章，主要介绍的是多线程相关优化。\n\n### 一、背景\n在美团，主要是负责对资产管理系统的重构工作，现在对系统的作用及功能做介绍。\n- 系统定位：对美团的充电宝、优选物资、优选低值物资等资产的完整生命周期进行管理。\n- 主要功能：资产新增、资产重建、资产调整、资产折旧、资产处置等。\n\n对资产的操作，例如资产新增，一般是通过excel导入系统，导入的数据量最多30W行，如此大的数据量，处理时长达1小时，系统可以说是一种不可用的状态。当时从产品设计、系统架构、数据模型，对系统进行了重大的调整。本文主要对多线程方面进行讲解。\n\n<!-- more -->\n\n### 二、当前业务说明\n系统处理的时序图如下：\n\n{% plantuml %}\nactor 财务人员\nparticipant 资产管理系统\ndatabase mysql\n\n财务人员->资产管理系统 : 资产新增，导入excel\nactivate 资产管理系统\n资产管理系统->资产管理系统: 开启大事务\nactivate 资产管理系统\n资产管理系统->资产管理系统: 一条一条进行串行数据校验（格式校验）\n资产管理系统->mysql: 存在性校验，查询asset资产表\n资产管理系统->mysql: 保存数据\nmysql-->资产管理系统: 返回\ndeactivate 资产管理系统\n资产管理系统-->财务人员: 1小时后返回结果\n\n{% endplantuml %}\n\n伪代码如下：\n```java\nList<Object> assetList = new ArrayList<>();\n//开启事务：@Transaction\nfor (Object asset : assetList) {\n    //对资产进行校验\n    check(asset);\n    //数据存储\n    service.addAsset(asset);\n}\n```\n\n### 三、优化\n优化思路：\n- 大事务：解决大事务问题。\n- 并发：使用多线程提升性能。\n\n#### ⭐️ 使用CompletableFeature\n从业务的执行流程上看，可以把资产的操作分成2部分：\n- 第一部分：资产数据的校验。\n- 第二部分：资产数据的保存。\n\n2个操作是先后顺序，非常适合使用CompletableFeature。\n- 1、将资产进行分段，例如分成3段，每一段用多线程去并发处理（同时分割成3个小事务）。\n- 2、使用CompletableFuture.supplyAsync()，处理第一部分，生成对应的实体类。\n- 3、然后使用CompletableFuture.thenApplyAsync()处理第一部分返回的数据，进行数据的插入。\n\n伪代码如下：\n```java\n//1. 首先将assetList分组\nList<Integer> originalList = List.of(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nList<List<Integer>> copyPartition = Lists.partition(originalList, 3);\nList<CompletableFuture<Object>> futureList = copyPartition.stream().map(subList ->\n        //任务传递给supplyAsync()方法，该任务将在ForkJoinPool.commonPool()中异步完成运行\n        //最后，supplyAsync()将返回新的CompletableFuture，其值是通过调用给定的Supplier所获得的值。\n        CompletableFuture.supplyAsync(() -> {\n                    log.info(\"处理第{}段数据开始\", n);\n                    return checkImportAndBuildEvent(baseMessageMap, subList, totalCheckedMap, mis);\n            }, importForkJoinPool)\n            //thenApplyAsync()方法，从supplyAsync()获得的参数传递来执行给定的函数\n            .thenApplyAsync(eventSaveReqs -> {\n                    try {\n                        EventStrategyFactory.getStrategy(EventLargeCategoryEnum.IMPAIRMENT_ADD.getCode()).triggerEvent(eventSaveReqs);\n                        totalCheckedMap.get(BaseConstants.SUC_LIST).addAll(subList);\n                    } catch (Exception e) {\n                        log.error(\"资产新建失败\", e);\n                        subList.forEach(importDto -> {\n                            importDto.setFailReason(\"资产新建入库失败\");\n                        });\n                        totalCheckedMap.get(BaseConstants.FAIL_LIST).addAll(subList);\n                    }\n                    log.info(\"处理第{}段数据开始\", n);\n                    return null;\n                },\n                queryForkJoinPool\n            )\n).collect(toList());\nfutureList.stream().map(CompletableFuture::join).collect(Collectors.toList());\n```\n\n数据校验和保存，使用了2个线程池，达到业务隔离的作用：\n- importForkJoinPool：处理数据校验。\n- queryForkJoinPool：处理数据的存储。\n\n### 四、优化结果\n30W数据excel导入，由1小时优化到了2分钟，优化效果大大的提高了系统可用性。\n","slug":"2024-03-05-性能优化-多线程优化","published":1,"updated":"2024-10-19T08:08:38.485Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxr0040a13kubvx69de","content":"<pre><code>这是性能优化系列的第三篇文章，主要介绍的是多线程相关优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在美团，主要是负责对资产管理系统的重构工作，现在对系统的作用及功能做介绍。</p>\n<ul>\n<li>系统定位：对美团的充电宝、优选物资、优选低值物资等资产的完整生命周期进行管理。</li>\n<li>主要功能：资产新增、资产重建、资产调整、资产折旧、资产处置等。</li>\n</ul>\n<p>对资产的操作，例如资产新增，一般是通过excel导入系统，导入的数据量最多30W行，如此大的数据量，处理时长达1小时，系统可以说是一种不可用的状态。当时从产品设计、系统架构、数据模型，对系统进行了重大的调整。本文主要对多线程方面进行讲解。</p>\n<a id=\"more\"></a>\n\n<h3 id=\"二、当前业务说明\"><a href=\"#二、当前业务说明\" class=\"headerlink\" title=\"二、当前业务说明\"></a>二、当前业务说明</h3><p>系统处理的时序图如下：</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/hP7FIiD04CRl-nJx0ZrupS5tMTCz1AhMPX6zvQ3YdxID-A_GDkq6IufW4xHAIHRoCZkRzTHNC3GM2Ws2u6LWXlb-y_4DCTbX2-jv0DTS9WdSzb2Jj9XbMaromB3-E9D9cCzuxbtaxscUZb2TCB97R8htJ-sZ1aARsjhkjW0RFnJr64FWBuKBaO3p2JqnQGCHard7XD6gIzkZAhw1GJZWHV0SokIciF8lJBbmr92NLMTzpLsvU2kgUeXLUwR6_El5NOfBDHOWkklsgXA_ogbm-Tg3mLGvuNhRLQE9ZW9YsvILEisdln5aDYmWfGEqcjMgpUli7le-gjC_9b7GDfvfu1s8k-hf4xnEISpJE-KFq3S0\">\n\n<p>伪代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Object&gt; assetList = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"comment\">//开启事务：@Transaction</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (Object asset : assetList) &#123;</span><br><span class=\"line\">    <span class=\"comment\">//对资产进行校验</span></span><br><span class=\"line\">    check(asset);</span><br><span class=\"line\">    <span class=\"comment\">//数据存储</span></span><br><span class=\"line\">    service.addAsset(asset);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"三、优化\"><a href=\"#三、优化\" class=\"headerlink\" title=\"三、优化\"></a>三、优化</h3><p>优化思路：</p>\n<ul>\n<li>大事务：解决大事务问题。</li>\n<li>并发：使用多线程提升性能。</li>\n</ul>\n<h4 id=\"⭐️-使用CompletableFeature\"><a href=\"#⭐️-使用CompletableFeature\" class=\"headerlink\" title=\"⭐️ 使用CompletableFeature\"></a>⭐️ 使用CompletableFeature</h4><p>从业务的执行流程上看，可以把资产的操作分成2部分：</p>\n<ul>\n<li>第一部分：资产数据的校验。</li>\n<li>第二部分：资产数据的保存。</li>\n</ul>\n<p>2个操作是先后顺序，非常适合使用CompletableFeature。</p>\n<ul>\n<li>1、将资产进行分段，例如分成3段，每一段用多线程去并发处理（同时分割成3个小事务）。</li>\n<li>2、使用CompletableFuture.supplyAsync()，处理第一部分，生成对应的实体类。</li>\n<li>3、然后使用CompletableFuture.thenApplyAsync()处理第一部分返回的数据，进行数据的插入。</li>\n</ul>\n<p>伪代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1. 首先将assetList分组</span></span><br><span class=\"line\">List&lt;Integer&gt; originalList = List.of(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>);</span><br><span class=\"line\">List&lt;List&lt;Integer&gt;&gt; copyPartition = Lists.partition(originalList, <span class=\"number\">3</span>);</span><br><span class=\"line\">List&lt;CompletableFuture&lt;Object&gt;&gt; futureList = copyPartition.stream().map(subList -&gt;</span><br><span class=\"line\">        <span class=\"comment\">//任务传递给supplyAsync()方法，该任务将在ForkJoinPool.commonPool()中异步完成运行</span></span><br><span class=\"line\">        <span class=\"comment\">//最后，supplyAsync()将返回新的CompletableFuture，其值是通过调用给定的Supplier所获得的值。</span></span><br><span class=\"line\">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class=\"line\">                    log.info(<span class=\"string\">\"处理第&#123;&#125;段数据开始\"</span>, n);</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> checkImportAndBuildEvent(baseMessageMap, subList, totalCheckedMap, mis);</span><br><span class=\"line\">            &#125;, importForkJoinPool)</span><br><span class=\"line\">            <span class=\"comment\">//thenApplyAsync()方法，从supplyAsync()获得的参数传递来执行给定的函数</span></span><br><span class=\"line\">            .thenApplyAsync(eventSaveReqs -&gt; &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                        EventStrategyFactory.getStrategy(EventLargeCategoryEnum.IMPAIRMENT_ADD.getCode()).triggerEvent(eventSaveReqs);</span><br><span class=\"line\">                        totalCheckedMap.get(BaseConstants.SUC_LIST).addAll(subList);</span><br><span class=\"line\">                    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                        log.error(<span class=\"string\">\"资产新建失败\"</span>, e);</span><br><span class=\"line\">                        subList.forEach(importDto -&gt; &#123;</span><br><span class=\"line\">                            importDto.setFailReason(<span class=\"string\">\"资产新建入库失败\"</span>);</span><br><span class=\"line\">                        &#125;);</span><br><span class=\"line\">                        totalCheckedMap.get(BaseConstants.FAIL_LIST).addAll(subList);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    log.info(<span class=\"string\">\"处理第&#123;&#125;段数据开始\"</span>, n);</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                queryForkJoinPool</span><br><span class=\"line\">            )</span><br><span class=\"line\">).collect(toList());</span><br><span class=\"line\">futureList.stream().map(CompletableFuture::join).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>\n\n<p>数据校验和保存，使用了2个线程池，达到业务隔离的作用：</p>\n<ul>\n<li>importForkJoinPool：处理数据校验。</li>\n<li>queryForkJoinPool：处理数据的存储。</li>\n</ul>\n<h3 id=\"四、优化结果\"><a href=\"#四、优化结果\" class=\"headerlink\" title=\"四、优化结果\"></a>四、优化结果</h3><p>30W数据excel导入，由1小时优化到了2分钟，优化效果大大的提高了系统可用性。</p>\n","site":{"data":{}},"excerpt":"<pre><code>这是性能优化系列的第三篇文章，主要介绍的是多线程相关优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在美团，主要是负责对资产管理系统的重构工作，现在对系统的作用及功能做介绍。</p>\n<ul>\n<li>系统定位：对美团的充电宝、优选物资、优选低值物资等资产的完整生命周期进行管理。</li>\n<li>主要功能：资产新增、资产重建、资产调整、资产折旧、资产处置等。</li>\n</ul>\n<p>对资产的操作，例如资产新增，一般是通过excel导入系统，导入的数据量最多30W行，如此大的数据量，处理时长达1小时，系统可以说是一种不可用的状态。当时从产品设计、系统架构、数据模型，对系统进行了重大的调整。本文主要对多线程方面进行讲解。</p>","more":"<h3 id=\"二、当前业务说明\"><a href=\"#二、当前业务说明\" class=\"headerlink\" title=\"二、当前业务说明\"></a>二、当前业务说明</h3><p>系统处理的时序图如下：</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/hP7FIiD04CRl-nJx0ZrupS5tMTCz1AhMPX6zvQ3YdxID-A_GDkq6IufW4xHAIHRoCZkRzTHNC3GM2Ws2u6LWXlb-y_4DCTbX2-jv0DTS9WdSzb2Jj9XbMaromB3-E9D9cCzuxbtaxscUZb2TCB97R8htJ-sZ1aARsjhkjW0RFnJr64FWBuKBaO3p2JqnQGCHard7XD6gIzkZAhw1GJZWHV0SokIciF8lJBbmr92NLMTzpLsvU2kgUeXLUwR6_El5NOfBDHOWkklsgXA_ogbm-Tg3mLGvuNhRLQE9ZW9YsvILEisdln5aDYmWfGEqcjMgpUli7le-gjC_9b7GDfvfu1s8k-hf4xnEISpJE-KFq3S0\">\n\n<p>伪代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Object&gt; assetList = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"comment\">//开启事务：@Transaction</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (Object asset : assetList) &#123;</span><br><span class=\"line\">    <span class=\"comment\">//对资产进行校验</span></span><br><span class=\"line\">    check(asset);</span><br><span class=\"line\">    <span class=\"comment\">//数据存储</span></span><br><span class=\"line\">    service.addAsset(asset);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"三、优化\"><a href=\"#三、优化\" class=\"headerlink\" title=\"三、优化\"></a>三、优化</h3><p>优化思路：</p>\n<ul>\n<li>大事务：解决大事务问题。</li>\n<li>并发：使用多线程提升性能。</li>\n</ul>\n<h4 id=\"⭐️-使用CompletableFeature\"><a href=\"#⭐️-使用CompletableFeature\" class=\"headerlink\" title=\"⭐️ 使用CompletableFeature\"></a>⭐️ 使用CompletableFeature</h4><p>从业务的执行流程上看，可以把资产的操作分成2部分：</p>\n<ul>\n<li>第一部分：资产数据的校验。</li>\n<li>第二部分：资产数据的保存。</li>\n</ul>\n<p>2个操作是先后顺序，非常适合使用CompletableFeature。</p>\n<ul>\n<li>1、将资产进行分段，例如分成3段，每一段用多线程去并发处理（同时分割成3个小事务）。</li>\n<li>2、使用CompletableFuture.supplyAsync()，处理第一部分，生成对应的实体类。</li>\n<li>3、然后使用CompletableFuture.thenApplyAsync()处理第一部分返回的数据，进行数据的插入。</li>\n</ul>\n<p>伪代码如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1. 首先将assetList分组</span></span><br><span class=\"line\">List&lt;Integer&gt; originalList = List.of(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>);</span><br><span class=\"line\">List&lt;List&lt;Integer&gt;&gt; copyPartition = Lists.partition(originalList, <span class=\"number\">3</span>);</span><br><span class=\"line\">List&lt;CompletableFuture&lt;Object&gt;&gt; futureList = copyPartition.stream().map(subList -&gt;</span><br><span class=\"line\">        <span class=\"comment\">//任务传递给supplyAsync()方法，该任务将在ForkJoinPool.commonPool()中异步完成运行</span></span><br><span class=\"line\">        <span class=\"comment\">//最后，supplyAsync()将返回新的CompletableFuture，其值是通过调用给定的Supplier所获得的值。</span></span><br><span class=\"line\">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class=\"line\">                    log.info(<span class=\"string\">\"处理第&#123;&#125;段数据开始\"</span>, n);</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> checkImportAndBuildEvent(baseMessageMap, subList, totalCheckedMap, mis);</span><br><span class=\"line\">            &#125;, importForkJoinPool)</span><br><span class=\"line\">            <span class=\"comment\">//thenApplyAsync()方法，从supplyAsync()获得的参数传递来执行给定的函数</span></span><br><span class=\"line\">            .thenApplyAsync(eventSaveReqs -&gt; &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                        EventStrategyFactory.getStrategy(EventLargeCategoryEnum.IMPAIRMENT_ADD.getCode()).triggerEvent(eventSaveReqs);</span><br><span class=\"line\">                        totalCheckedMap.get(BaseConstants.SUC_LIST).addAll(subList);</span><br><span class=\"line\">                    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                        log.error(<span class=\"string\">\"资产新建失败\"</span>, e);</span><br><span class=\"line\">                        subList.forEach(importDto -&gt; &#123;</span><br><span class=\"line\">                            importDto.setFailReason(<span class=\"string\">\"资产新建入库失败\"</span>);</span><br><span class=\"line\">                        &#125;);</span><br><span class=\"line\">                        totalCheckedMap.get(BaseConstants.FAIL_LIST).addAll(subList);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    log.info(<span class=\"string\">\"处理第&#123;&#125;段数据开始\"</span>, n);</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                &#125;,</span><br><span class=\"line\">                queryForkJoinPool</span><br><span class=\"line\">            )</span><br><span class=\"line\">).collect(toList());</span><br><span class=\"line\">futureList.stream().map(CompletableFuture::join).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>\n\n<p>数据校验和保存，使用了2个线程池，达到业务隔离的作用：</p>\n<ul>\n<li>importForkJoinPool：处理数据校验。</li>\n<li>queryForkJoinPool：处理数据的存储。</li>\n</ul>\n<h3 id=\"四、优化结果\"><a href=\"#四、优化结果\" class=\"headerlink\" title=\"四、优化结果\"></a>四、优化结果</h3><p>30W数据excel导入，由1小时优化到了2分钟，优化效果大大的提高了系统可用性。</p>"},{"title":"《性能优化系列》jvm优化","date":"2024-03-07T02:00:00.000Z","_content":"\n    这是性能优化系列的第四篇文章，主要介绍的是jvm相关优化。\n\n### 一、背景\n在做商品相关业务时，需要将A系统的部分功能迁移到商品系统，过程中遇到多个jvm的问题。\n- metaspace oom问题。\n- YGC频繁问题。\n\n<!-- more -->\n\nJVM配置如下：\n```\nJDK1.8\n-Xms8g\n-Xmx8g\n-Xmn4g\n-XX:MetaspaceSize=512M\n-XX:+UseConcMarkSweepGC\n```\n\n### 二、metaspace oom问题\n\n#### 问题表现\n应用在主预发环境部署后，经过一段时间，业务方寻找过来，说明主预发环境无法提供服务的问题。\n\n##### 1 初步分析\n应用无法提供响应，首先去Sunfire查看应用的基础监控项和业务监控项，如下为基础监控项：\n![metaspaceoom](2024-03-07-性能优化-jvm优化/metaspaceoom.png)\n*图片为网络图片，当时的图片未留存（错误类似）   \n> 分析结果：当时的第一感觉是metaspace基础监控项有问题，占用内存一直增加，可能是metaspace oom导致的应用崩溃。\n\n##### 2 查看错误日志\n查看错误日志，明显报出了java.lang.OutOfMemoryError: Metaspace。从这里就能够确定问题了。\n![metaspaceoom](2024-03-07-性能优化-jvm优化/业务日志.png)\n*图片为网络图片，当时的图片未留存（错误类似）\n\n> 分析结果：确定为 metaspace oom\n##### 3 GC 日志分析\n选择一台主机，查看 GC 日志，直接定位 Full GC 关键字。\n![metaspaceoom](2024-03-07-性能优化-jvm优化/GC日志.png)\n*图片为网络图片，当时的图片未留存（错误类似）\n\n> 分析结果：Full GC (Metadata GC Threshold) 说明此次全量垃圾回收是由于元数据空间达到了垃圾回收的阈值而触发的\n\n##### 4 metaspace oom分析\nmetaspace主要存储类的元数据，比如我们加载了一个类，那么这个类的信息就会按照一定的数据结构存储在Metaspace中。Metaspace的大小和加载类的数目有很大关系，加载的类越多，Metaspace占用内存也就越大。\n那接下来就应该dump heap，分析类的加载情况。\n\n##### 5 检查jvm类加载器及加载的类\n使用Arthas，检查当前jvm中的类加载器及加载的类，查询classloader中加载的类数量和列表。\n![metaspaceoom](2024-03-07-性能优化-jvm优化/classloader.png)\n*图片为网络图片，当时的图片未留存\n\n>分析结果：当时未成功分析出结果。\n\n##### 6 Dump heap\n使用的是阿里内部的grace，获取dump文件，然后进行分析。考虑到 metaspace 区是用来存储 class 元信息，因此如果要爆掉 metaspace 区，必然是加载了大量 class。直接定位到类标签上，\n![metaspaceoom](2024-03-07-性能优化-jvm优化/类视图.png)\n*图片为网络图片，当时的图片未留存 （数据类似）  \n然后查看内存泄露报表，报表中提示了DivisionCache缓存类（占内存的45%）存在泄露问题。\n> 分析结果：大量的加载了地址库DivisionCache缓存类（好像是长这样，忘了）\n\n##### 7 结论\n业务功能迁移，需要引入地址库的jar包，因为地址库缓存信息庞大，造成了应用metaspace oom。\n\n##### 8 优化\n增加metaspace的内存空间占比，从512M提升到了716M。【需要保障应用占用的内存不超过整个物理内存的80%，因为有一些其他程序在运行，例如监控、日志收集等】\n\n```\n-XX:MetaspaceSize=716M  //从512M提升到了716M\n```\n\n### 三、YGC频繁问题\n\n#### 问题表现\n在解决metaspace oom问题后，在程序启动时，又出现了YGC频繁的问题，应用部署完成后，YGC频率降低至正常情况。\n\n##### 1 查看基础监控\n查看基础监控，参考如下图：频率每分钟80次\n\n##### 2 分析\n通常情况下，由于新生代空间较小，Eden区很快被填满，就会导致频繁YGC，因此可以通过增大新生代空间来降低YGC的频率。\n\n##### 3 优化\n```\n-Xmn4860m //由4g调整到4860m\n```\n> 调大新生代空间后，应用启动YGC频繁问题得到解决。\n\n\n### 四、总结\nJVM调优的步骤总结\n- 1、事前：建立完善的基础监控，能够通过大盘快速定位问题。\n- 2、事中：保留现场，分析应用错误日志 & GC日志，充分利用各种可视化工具，提升排查效率。\n- 3、事后：根据具体情况进行针对性的优化。\n\n\nMore info: [从实际案例聊聊Java应用的GC优化](https://tech.meituan.com/2017/12/29/jvm-optimize.html)","source":"_posts/2024-03-07-性能优化-jvm优化.md","raw":"---\ntitle: 《性能优化系列》jvm优化\ndate: 2024-03-07 10:00:00\ncategories:\n  - [java, jvm, oom, ygc]\n  - [性能优化]\n  - [阿里]\ntags:\n- 阿里\n---\n\n    这是性能优化系列的第四篇文章，主要介绍的是jvm相关优化。\n\n### 一、背景\n在做商品相关业务时，需要将A系统的部分功能迁移到商品系统，过程中遇到多个jvm的问题。\n- metaspace oom问题。\n- YGC频繁问题。\n\n<!-- more -->\n\nJVM配置如下：\n```\nJDK1.8\n-Xms8g\n-Xmx8g\n-Xmn4g\n-XX:MetaspaceSize=512M\n-XX:+UseConcMarkSweepGC\n```\n\n### 二、metaspace oom问题\n\n#### 问题表现\n应用在主预发环境部署后，经过一段时间，业务方寻找过来，说明主预发环境无法提供服务的问题。\n\n##### 1 初步分析\n应用无法提供响应，首先去Sunfire查看应用的基础监控项和业务监控项，如下为基础监控项：\n![metaspaceoom](2024-03-07-性能优化-jvm优化/metaspaceoom.png)\n*图片为网络图片，当时的图片未留存（错误类似）   \n> 分析结果：当时的第一感觉是metaspace基础监控项有问题，占用内存一直增加，可能是metaspace oom导致的应用崩溃。\n\n##### 2 查看错误日志\n查看错误日志，明显报出了java.lang.OutOfMemoryError: Metaspace。从这里就能够确定问题了。\n![metaspaceoom](2024-03-07-性能优化-jvm优化/业务日志.png)\n*图片为网络图片，当时的图片未留存（错误类似）\n\n> 分析结果：确定为 metaspace oom\n##### 3 GC 日志分析\n选择一台主机，查看 GC 日志，直接定位 Full GC 关键字。\n![metaspaceoom](2024-03-07-性能优化-jvm优化/GC日志.png)\n*图片为网络图片，当时的图片未留存（错误类似）\n\n> 分析结果：Full GC (Metadata GC Threshold) 说明此次全量垃圾回收是由于元数据空间达到了垃圾回收的阈值而触发的\n\n##### 4 metaspace oom分析\nmetaspace主要存储类的元数据，比如我们加载了一个类，那么这个类的信息就会按照一定的数据结构存储在Metaspace中。Metaspace的大小和加载类的数目有很大关系，加载的类越多，Metaspace占用内存也就越大。\n那接下来就应该dump heap，分析类的加载情况。\n\n##### 5 检查jvm类加载器及加载的类\n使用Arthas，检查当前jvm中的类加载器及加载的类，查询classloader中加载的类数量和列表。\n![metaspaceoom](2024-03-07-性能优化-jvm优化/classloader.png)\n*图片为网络图片，当时的图片未留存\n\n>分析结果：当时未成功分析出结果。\n\n##### 6 Dump heap\n使用的是阿里内部的grace，获取dump文件，然后进行分析。考虑到 metaspace 区是用来存储 class 元信息，因此如果要爆掉 metaspace 区，必然是加载了大量 class。直接定位到类标签上，\n![metaspaceoom](2024-03-07-性能优化-jvm优化/类视图.png)\n*图片为网络图片，当时的图片未留存 （数据类似）  \n然后查看内存泄露报表，报表中提示了DivisionCache缓存类（占内存的45%）存在泄露问题。\n> 分析结果：大量的加载了地址库DivisionCache缓存类（好像是长这样，忘了）\n\n##### 7 结论\n业务功能迁移，需要引入地址库的jar包，因为地址库缓存信息庞大，造成了应用metaspace oom。\n\n##### 8 优化\n增加metaspace的内存空间占比，从512M提升到了716M。【需要保障应用占用的内存不超过整个物理内存的80%，因为有一些其他程序在运行，例如监控、日志收集等】\n\n```\n-XX:MetaspaceSize=716M  //从512M提升到了716M\n```\n\n### 三、YGC频繁问题\n\n#### 问题表现\n在解决metaspace oom问题后，在程序启动时，又出现了YGC频繁的问题，应用部署完成后，YGC频率降低至正常情况。\n\n##### 1 查看基础监控\n查看基础监控，参考如下图：频率每分钟80次\n\n##### 2 分析\n通常情况下，由于新生代空间较小，Eden区很快被填满，就会导致频繁YGC，因此可以通过增大新生代空间来降低YGC的频率。\n\n##### 3 优化\n```\n-Xmn4860m //由4g调整到4860m\n```\n> 调大新生代空间后，应用启动YGC频繁问题得到解决。\n\n\n### 四、总结\nJVM调优的步骤总结\n- 1、事前：建立完善的基础监控，能够通过大盘快速定位问题。\n- 2、事中：保留现场，分析应用错误日志 & GC日志，充分利用各种可视化工具，提升排查效率。\n- 3、事后：根据具体情况进行针对性的优化。\n\n\nMore info: [从实际案例聊聊Java应用的GC优化](https://tech.meituan.com/2017/12/29/jvm-optimize.html)","slug":"2024-03-07-性能优化-jvm优化","published":1,"updated":"2024-12-09T03:22:34.493Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxs0043a13k3w5jxill","content":"<pre><code>这是性能优化系列的第四篇文章，主要介绍的是jvm相关优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在做商品相关业务时，需要将A系统的部分功能迁移到商品系统，过程中遇到多个jvm的问题。</p>\n<ul>\n<li>metaspace oom问题。</li>\n<li>YGC频繁问题。</li>\n</ul>\n<a id=\"more\"></a>\n\n<p>JVM配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JDK1.8</span><br><span class=\"line\">-Xms8g</span><br><span class=\"line\">-Xmx8g</span><br><span class=\"line\">-Xmn4g</span><br><span class=\"line\">-XX:MetaspaceSize=512M</span><br><span class=\"line\">-XX:+UseConcMarkSweepGC</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"二、metaspace-oom问题\"><a href=\"#二、metaspace-oom问题\" class=\"headerlink\" title=\"二、metaspace oom问题\"></a>二、metaspace oom问题</h3><h4 id=\"问题表现\"><a href=\"#问题表现\" class=\"headerlink\" title=\"问题表现\"></a>问题表现</h4><p>应用在主预发环境部署后，经过一段时间，业务方寻找过来，说明主预发环境无法提供服务的问题。</p>\n<h5 id=\"1-初步分析\"><a href=\"#1-初步分析\" class=\"headerlink\" title=\"1 初步分析\"></a>1 初步分析</h5><p>应用无法提供响应，首先去Sunfire查看应用的基础监控项和业务监控项，如下为基础监控项：<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/metaspaceoom.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存（错误类似）   </p>\n<blockquote>\n<p>分析结果：当时的第一感觉是metaspace基础监控项有问题，占用内存一直增加，可能是metaspace oom导致的应用崩溃。</p>\n</blockquote>\n<h5 id=\"2-查看错误日志\"><a href=\"#2-查看错误日志\" class=\"headerlink\" title=\"2 查看错误日志\"></a>2 查看错误日志</h5><p>查看错误日志，明显报出了java.lang.OutOfMemoryError: Metaspace。从这里就能够确定问题了。<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/%E4%B8%9A%E5%8A%A1%E6%97%A5%E5%BF%97.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存（错误类似）</p>\n<blockquote>\n<p>分析结果：确定为 metaspace oom</p>\n</blockquote>\n<h5 id=\"3-GC-日志分析\"><a href=\"#3-GC-日志分析\" class=\"headerlink\" title=\"3 GC 日志分析\"></a>3 GC 日志分析</h5><p>选择一台主机，查看 GC 日志，直接定位 Full GC 关键字。<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/GC%E6%97%A5%E5%BF%97.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存（错误类似）</p>\n<blockquote>\n<p>分析结果：Full GC (Metadata GC Threshold) 说明此次全量垃圾回收是由于元数据空间达到了垃圾回收的阈值而触发的</p>\n</blockquote>\n<h5 id=\"4-metaspace-oom分析\"><a href=\"#4-metaspace-oom分析\" class=\"headerlink\" title=\"4 metaspace oom分析\"></a>4 metaspace oom分析</h5><p>metaspace主要存储类的元数据，比如我们加载了一个类，那么这个类的信息就会按照一定的数据结构存储在Metaspace中。Metaspace的大小和加载类的数目有很大关系，加载的类越多，Metaspace占用内存也就越大。<br>那接下来就应该dump heap，分析类的加载情况。</p>\n<h5 id=\"5-检查jvm类加载器及加载的类\"><a href=\"#5-检查jvm类加载器及加载的类\" class=\"headerlink\" title=\"5 检查jvm类加载器及加载的类\"></a>5 检查jvm类加载器及加载的类</h5><p>使用Arthas，检查当前jvm中的类加载器及加载的类，查询classloader中加载的类数量和列表。<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/classloader.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存</p>\n<blockquote>\n<p>分析结果：当时未成功分析出结果。</p>\n</blockquote>\n<h5 id=\"6-Dump-heap\"><a href=\"#6-Dump-heap\" class=\"headerlink\" title=\"6 Dump heap\"></a>6 Dump heap</h5><p>使用的是阿里内部的grace，获取dump文件，然后进行分析。考虑到 metaspace 区是用来存储 class 元信息，因此如果要爆掉 metaspace 区，必然是加载了大量 class。直接定位到类标签上，<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/%E7%B1%BB%E8%A7%86%E5%9B%BE.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存 （数据类似）<br>然后查看内存泄露报表，报表中提示了DivisionCache缓存类（占内存的45%）存在泄露问题。</p>\n<blockquote>\n<p>分析结果：大量的加载了地址库DivisionCache缓存类（好像是长这样，忘了）</p>\n</blockquote>\n<h5 id=\"7-结论\"><a href=\"#7-结论\" class=\"headerlink\" title=\"7 结论\"></a>7 结论</h5><p>业务功能迁移，需要引入地址库的jar包，因为地址库缓存信息庞大，造成了应用metaspace oom。</p>\n<h5 id=\"8-优化\"><a href=\"#8-优化\" class=\"headerlink\" title=\"8 优化\"></a>8 优化</h5><p>增加metaspace的内存空间占比，从512M提升到了716M。【需要保障应用占用的内存不超过整个物理内存的80%，因为有一些其他程序在运行，例如监控、日志收集等】</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-XX:MetaspaceSize=716M  //从512M提升到了716M</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"三、YGC频繁问题\"><a href=\"#三、YGC频繁问题\" class=\"headerlink\" title=\"三、YGC频繁问题\"></a>三、YGC频繁问题</h3><h4 id=\"问题表现-1\"><a href=\"#问题表现-1\" class=\"headerlink\" title=\"问题表现\"></a>问题表现</h4><p>在解决metaspace oom问题后，在程序启动时，又出现了YGC频繁的问题，应用部署完成后，YGC频率降低至正常情况。</p>\n<h5 id=\"1-查看基础监控\"><a href=\"#1-查看基础监控\" class=\"headerlink\" title=\"1 查看基础监控\"></a>1 查看基础监控</h5><p>查看基础监控，参考如下图：频率每分钟80次</p>\n<h5 id=\"2-分析\"><a href=\"#2-分析\" class=\"headerlink\" title=\"2 分析\"></a>2 分析</h5><p>通常情况下，由于新生代空间较小，Eden区很快被填满，就会导致频繁YGC，因此可以通过增大新生代空间来降低YGC的频率。</p>\n<h5 id=\"3-优化\"><a href=\"#3-优化\" class=\"headerlink\" title=\"3 优化\"></a>3 优化</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-Xmn4860m //由4g调整到4860m</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>调大新生代空间后，应用启动YGC频繁问题得到解决。</p>\n</blockquote>\n<h3 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h3><p>JVM调优的步骤总结</p>\n<ul>\n<li>1、事前：建立完善的基础监控，能够通过大盘快速定位问题。</li>\n<li>2、事中：保留现场，分析应用错误日志 &amp; GC日志，充分利用各种可视化工具，提升排查效率。</li>\n<li>3、事后：根据具体情况进行针对性的优化。</li>\n</ul>\n<p>More info: <a href=\"https://tech.meituan.com/2017/12/29/jvm-optimize.html\" target=\"_blank\" rel=\"noopener\">从实际案例聊聊Java应用的GC优化</a></p>\n","site":{"data":{}},"excerpt":"<pre><code>这是性能优化系列的第四篇文章，主要介绍的是jvm相关优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在做商品相关业务时，需要将A系统的部分功能迁移到商品系统，过程中遇到多个jvm的问题。</p>\n<ul>\n<li>metaspace oom问题。</li>\n<li>YGC频繁问题。</li>\n</ul>","more":"<p>JVM配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JDK1.8</span><br><span class=\"line\">-Xms8g</span><br><span class=\"line\">-Xmx8g</span><br><span class=\"line\">-Xmn4g</span><br><span class=\"line\">-XX:MetaspaceSize=512M</span><br><span class=\"line\">-XX:+UseConcMarkSweepGC</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"二、metaspace-oom问题\"><a href=\"#二、metaspace-oom问题\" class=\"headerlink\" title=\"二、metaspace oom问题\"></a>二、metaspace oom问题</h3><h4 id=\"问题表现\"><a href=\"#问题表现\" class=\"headerlink\" title=\"问题表现\"></a>问题表现</h4><p>应用在主预发环境部署后，经过一段时间，业务方寻找过来，说明主预发环境无法提供服务的问题。</p>\n<h5 id=\"1-初步分析\"><a href=\"#1-初步分析\" class=\"headerlink\" title=\"1 初步分析\"></a>1 初步分析</h5><p>应用无法提供响应，首先去Sunfire查看应用的基础监控项和业务监控项，如下为基础监控项：<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/metaspaceoom.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存（错误类似）   </p>\n<blockquote>\n<p>分析结果：当时的第一感觉是metaspace基础监控项有问题，占用内存一直增加，可能是metaspace oom导致的应用崩溃。</p>\n</blockquote>\n<h5 id=\"2-查看错误日志\"><a href=\"#2-查看错误日志\" class=\"headerlink\" title=\"2 查看错误日志\"></a>2 查看错误日志</h5><p>查看错误日志，明显报出了java.lang.OutOfMemoryError: Metaspace。从这里就能够确定问题了。<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/%E4%B8%9A%E5%8A%A1%E6%97%A5%E5%BF%97.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存（错误类似）</p>\n<blockquote>\n<p>分析结果：确定为 metaspace oom</p>\n</blockquote>\n<h5 id=\"3-GC-日志分析\"><a href=\"#3-GC-日志分析\" class=\"headerlink\" title=\"3 GC 日志分析\"></a>3 GC 日志分析</h5><p>选择一台主机，查看 GC 日志，直接定位 Full GC 关键字。<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/GC%E6%97%A5%E5%BF%97.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存（错误类似）</p>\n<blockquote>\n<p>分析结果：Full GC (Metadata GC Threshold) 说明此次全量垃圾回收是由于元数据空间达到了垃圾回收的阈值而触发的</p>\n</blockquote>\n<h5 id=\"4-metaspace-oom分析\"><a href=\"#4-metaspace-oom分析\" class=\"headerlink\" title=\"4 metaspace oom分析\"></a>4 metaspace oom分析</h5><p>metaspace主要存储类的元数据，比如我们加载了一个类，那么这个类的信息就会按照一定的数据结构存储在Metaspace中。Metaspace的大小和加载类的数目有很大关系，加载的类越多，Metaspace占用内存也就越大。<br>那接下来就应该dump heap，分析类的加载情况。</p>\n<h5 id=\"5-检查jvm类加载器及加载的类\"><a href=\"#5-检查jvm类加载器及加载的类\" class=\"headerlink\" title=\"5 检查jvm类加载器及加载的类\"></a>5 检查jvm类加载器及加载的类</h5><p>使用Arthas，检查当前jvm中的类加载器及加载的类，查询classloader中加载的类数量和列表。<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/classloader.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存</p>\n<blockquote>\n<p>分析结果：当时未成功分析出结果。</p>\n</blockquote>\n<h5 id=\"6-Dump-heap\"><a href=\"#6-Dump-heap\" class=\"headerlink\" title=\"6 Dump heap\"></a>6 Dump heap</h5><p>使用的是阿里内部的grace，获取dump文件，然后进行分析。考虑到 metaspace 区是用来存储 class 元信息，因此如果要爆掉 metaspace 区，必然是加载了大量 class。直接定位到类标签上，<br><img src=\"/2024/03/07/2024-03-07-性能优化-jvm优化/%E7%B1%BB%E8%A7%86%E5%9B%BE.png\" alt=\"metaspaceoom\"><br>*图片为网络图片，当时的图片未留存 （数据类似）<br>然后查看内存泄露报表，报表中提示了DivisionCache缓存类（占内存的45%）存在泄露问题。</p>\n<blockquote>\n<p>分析结果：大量的加载了地址库DivisionCache缓存类（好像是长这样，忘了）</p>\n</blockquote>\n<h5 id=\"7-结论\"><a href=\"#7-结论\" class=\"headerlink\" title=\"7 结论\"></a>7 结论</h5><p>业务功能迁移，需要引入地址库的jar包，因为地址库缓存信息庞大，造成了应用metaspace oom。</p>\n<h5 id=\"8-优化\"><a href=\"#8-优化\" class=\"headerlink\" title=\"8 优化\"></a>8 优化</h5><p>增加metaspace的内存空间占比，从512M提升到了716M。【需要保障应用占用的内存不超过整个物理内存的80%，因为有一些其他程序在运行，例如监控、日志收集等】</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-XX:MetaspaceSize=716M  //从512M提升到了716M</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"三、YGC频繁问题\"><a href=\"#三、YGC频繁问题\" class=\"headerlink\" title=\"三、YGC频繁问题\"></a>三、YGC频繁问题</h3><h4 id=\"问题表现-1\"><a href=\"#问题表现-1\" class=\"headerlink\" title=\"问题表现\"></a>问题表现</h4><p>在解决metaspace oom问题后，在程序启动时，又出现了YGC频繁的问题，应用部署完成后，YGC频率降低至正常情况。</p>\n<h5 id=\"1-查看基础监控\"><a href=\"#1-查看基础监控\" class=\"headerlink\" title=\"1 查看基础监控\"></a>1 查看基础监控</h5><p>查看基础监控，参考如下图：频率每分钟80次</p>\n<h5 id=\"2-分析\"><a href=\"#2-分析\" class=\"headerlink\" title=\"2 分析\"></a>2 分析</h5><p>通常情况下，由于新生代空间较小，Eden区很快被填满，就会导致频繁YGC，因此可以通过增大新生代空间来降低YGC的频率。</p>\n<h5 id=\"3-优化\"><a href=\"#3-优化\" class=\"headerlink\" title=\"3 优化\"></a>3 优化</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-Xmn4860m //由4g调整到4860m</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>调大新生代空间后，应用启动YGC频繁问题得到解决。</p>\n</blockquote>\n<h3 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h3><p>JVM调优的步骤总结</p>\n<ul>\n<li>1、事前：建立完善的基础监控，能够通过大盘快速定位问题。</li>\n<li>2、事中：保留现场，分析应用错误日志 &amp; GC日志，充分利用各种可视化工具，提升排查效率。</li>\n<li>3、事后：根据具体情况进行针对性的优化。</li>\n</ul>\n<p>More info: <a href=\"https://tech.meituan.com/2017/12/29/jvm-optimize.html\" target=\"_blank\" rel=\"noopener\">从实际案例聊聊Java应用的GC优化</a></p>"},{"title":"《性能优化系列》服务RT上升","date":"2024-03-20T02:00:00.000Z","_content":"\n    这是性能优化系列的第五篇文章，主要介绍的是服务RT上升问题的分析及原理。\n\n### 一、背景\n某一个时期，交易服务经常会出现服务RT上升问题，导致业务成功率下降，然后业务就找过来了，交易应用作为核心应用，需要及时响应和处理。\n\n<!-- more -->\n\n机器配置如下：\n```\nCPU=8核\n内存=16GB\n磁盘=60GB\n```\n\nJVM配置如下：\n```\nJDK1.8\n-Xms12g\n-Xmx12g\n-Xmn8g\n-XX:+UseG1GC\n```\n\n### 二、分析流程\n\n#### 问题表现\n交易服务某个接口的RT上升，导致上游业务成功率下降。\n\n##### 1 初步分析\n当时从几个方面去做了考虑：\n- 是不是业务流量骤增，导致应用负载升高，从而导致服务RT上升？\n- 是不是应用GC频率高、GC耗时长导致的？\n- 是不是最近有发布新需求或者更新导致的？\n\n##### 2 查询监控\n业务监控：\n- 首先去Sunfire查看应用的业务监控项，找到对应的业务场景，分析RT99监控项，跟昨日对比上升明显。\n- 再次去查看流量上涨情况，分析流量，数据跟昨日同时段差不多。\n\n> 分析结果：业务流量没有上涨，不是业务原因导致的。\n\n基础监控：\n- 查看GC（ygc, fgc），没有明显上涨；查看内存使用情况（新生代、老年代、metaspace），没有明显上涨。\n- 查看CPU，没有明显上涨；查看磁盘IO，没有明显上涨。\n- 查看线程数量，没有明显上涨。\n- 查看MySQL监控项；查看tair监控项；\n\n> 分析结果：未发现问题。\n\n##### 3 分析应用热点问题\n执行arthas的profiler命令，生成应用热点的火焰图。\n```\nprofiler start\n```\n> 默认情况下，生成的是 cpu 的火焰图，即 event 为cpu。 \n\n未贴实际的情况，参考下图：\n![trace](2024-03-20-性能优化-服务RT上升/profiler.png)\n\n> 分析结果：未发现明显问题。\n\n##### 4 执行Arthas的trace命令\ntrace 能方便的帮助你定位和发现因 RT 高而导致的性能问题缺陷。\n```\ntrace com.alibaba.***.**OrderFacade  queryOrder\n```\n未贴实际的情况，参考下图：\n![trace](2024-03-20-性能优化-服务RT上升/trace.png)\n\n> 分析结果：未发现明显问题。\n\n##### 5 机器摘流\n分析了一段时间后，未发现明显情况，于是对问题机器进行摘流处理。然后进行其他的分析，例如dump、GC啥的。\n\n##### 6 分析最近上线功能\n- 变更1：CMS升级成G1。\n- 变更2：拉单优化。\n- 变更3：scheduler jar升级。\n\n使用排除法，对变更2 & 变更3进行代码的review和与中间件的沟通，不是造成RT上升的原因。最后怀疑是垃圾收集器的问题造成的。\n\n##### 7 应用更新重新部署\n将G1还原成CMS，应用部署上线后，未发现问题。    \n\n为什么要升级G1呢？\n\n##### 8 思考：为什么G1会影响RT呢？\n- 适应期问题：\n新的垃圾收集器在应用程序运行初期可能需要一定的时间来适应应用的内存使用模式和对象分配特点。在这个适应期内，可能会出现性能波动，导致接口 RT 上升。\nG1 垃圾收集器在初始阶段可能会进行一些额外的后台活动，如初始的堆空间划分和记忆集（Remembered Set）的建立等。\n- 配置问题：\nG1 的默认配置可能并不完全适合特定的应用程序。例如，堆大小、年轻代和老年代的比例、并发标记周期的启动阈值等参数可能需要根据应用的实际情况进行调整。\n如果堆大小设置不合理，可能导致频繁的垃圾收集，从而增加接口响应时间。\n- 应用程序特性：\n某些应用程序的特性可能与 G1 的工作方式不太匹配。例如，如果应用程序有大量的短期存活对象，G1 的分代收集策略可能不如 CMS 高效。\n如果应用程序的内存分配模式非常不均匀，可能会导致 G1 在某些区域进行过多的垃圾收集，影响性能。\n","source":"_posts/2024-03-20-性能优化-服务RT上升.md","raw":"---\ntitle: 《性能优化系列》服务RT上升\ndate: 2024-03-20 10:00:00\ncategories:\n  - [java, jvm, RT, ygc]\n  - [性能优化]\n  - [阿里]\ntags:\n- 阿里\n---\n\n    这是性能优化系列的第五篇文章，主要介绍的是服务RT上升问题的分析及原理。\n\n### 一、背景\n某一个时期，交易服务经常会出现服务RT上升问题，导致业务成功率下降，然后业务就找过来了，交易应用作为核心应用，需要及时响应和处理。\n\n<!-- more -->\n\n机器配置如下：\n```\nCPU=8核\n内存=16GB\n磁盘=60GB\n```\n\nJVM配置如下：\n```\nJDK1.8\n-Xms12g\n-Xmx12g\n-Xmn8g\n-XX:+UseG1GC\n```\n\n### 二、分析流程\n\n#### 问题表现\n交易服务某个接口的RT上升，导致上游业务成功率下降。\n\n##### 1 初步分析\n当时从几个方面去做了考虑：\n- 是不是业务流量骤增，导致应用负载升高，从而导致服务RT上升？\n- 是不是应用GC频率高、GC耗时长导致的？\n- 是不是最近有发布新需求或者更新导致的？\n\n##### 2 查询监控\n业务监控：\n- 首先去Sunfire查看应用的业务监控项，找到对应的业务场景，分析RT99监控项，跟昨日对比上升明显。\n- 再次去查看流量上涨情况，分析流量，数据跟昨日同时段差不多。\n\n> 分析结果：业务流量没有上涨，不是业务原因导致的。\n\n基础监控：\n- 查看GC（ygc, fgc），没有明显上涨；查看内存使用情况（新生代、老年代、metaspace），没有明显上涨。\n- 查看CPU，没有明显上涨；查看磁盘IO，没有明显上涨。\n- 查看线程数量，没有明显上涨。\n- 查看MySQL监控项；查看tair监控项；\n\n> 分析结果：未发现问题。\n\n##### 3 分析应用热点问题\n执行arthas的profiler命令，生成应用热点的火焰图。\n```\nprofiler start\n```\n> 默认情况下，生成的是 cpu 的火焰图，即 event 为cpu。 \n\n未贴实际的情况，参考下图：\n![trace](2024-03-20-性能优化-服务RT上升/profiler.png)\n\n> 分析结果：未发现明显问题。\n\n##### 4 执行Arthas的trace命令\ntrace 能方便的帮助你定位和发现因 RT 高而导致的性能问题缺陷。\n```\ntrace com.alibaba.***.**OrderFacade  queryOrder\n```\n未贴实际的情况，参考下图：\n![trace](2024-03-20-性能优化-服务RT上升/trace.png)\n\n> 分析结果：未发现明显问题。\n\n##### 5 机器摘流\n分析了一段时间后，未发现明显情况，于是对问题机器进行摘流处理。然后进行其他的分析，例如dump、GC啥的。\n\n##### 6 分析最近上线功能\n- 变更1：CMS升级成G1。\n- 变更2：拉单优化。\n- 变更3：scheduler jar升级。\n\n使用排除法，对变更2 & 变更3进行代码的review和与中间件的沟通，不是造成RT上升的原因。最后怀疑是垃圾收集器的问题造成的。\n\n##### 7 应用更新重新部署\n将G1还原成CMS，应用部署上线后，未发现问题。    \n\n为什么要升级G1呢？\n\n##### 8 思考：为什么G1会影响RT呢？\n- 适应期问题：\n新的垃圾收集器在应用程序运行初期可能需要一定的时间来适应应用的内存使用模式和对象分配特点。在这个适应期内，可能会出现性能波动，导致接口 RT 上升。\nG1 垃圾收集器在初始阶段可能会进行一些额外的后台活动，如初始的堆空间划分和记忆集（Remembered Set）的建立等。\n- 配置问题：\nG1 的默认配置可能并不完全适合特定的应用程序。例如，堆大小、年轻代和老年代的比例、并发标记周期的启动阈值等参数可能需要根据应用的实际情况进行调整。\n如果堆大小设置不合理，可能导致频繁的垃圾收集，从而增加接口响应时间。\n- 应用程序特性：\n某些应用程序的特性可能与 G1 的工作方式不太匹配。例如，如果应用程序有大量的短期存活对象，G1 的分代收集策略可能不如 CMS 高效。\n如果应用程序的内存分配模式非常不均匀，可能会导致 G1 在某些区域进行过多的垃圾收集，影响性能。\n","slug":"2024-03-20-性能优化-服务RT上升","published":1,"updated":"2024-12-09T03:22:02.564Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxu0046a13kdnncsydf","content":"<pre><code>这是性能优化系列的第五篇文章，主要介绍的是服务RT上升问题的分析及原理。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>某一个时期，交易服务经常会出现服务RT上升问题，导致业务成功率下降，然后业务就找过来了，交易应用作为核心应用，需要及时响应和处理。</p>\n<a id=\"more\"></a>\n\n<p>机器配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CPU=8核</span><br><span class=\"line\">内存=16GB</span><br><span class=\"line\">磁盘=60GB</span><br></pre></td></tr></table></figure>\n\n<p>JVM配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JDK1.8</span><br><span class=\"line\">-Xms12g</span><br><span class=\"line\">-Xmx12g</span><br><span class=\"line\">-Xmn8g</span><br><span class=\"line\">-XX:+UseG1GC</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"二、分析流程\"><a href=\"#二、分析流程\" class=\"headerlink\" title=\"二、分析流程\"></a>二、分析流程</h3><h4 id=\"问题表现\"><a href=\"#问题表现\" class=\"headerlink\" title=\"问题表现\"></a>问题表现</h4><p>交易服务某个接口的RT上升，导致上游业务成功率下降。</p>\n<h5 id=\"1-初步分析\"><a href=\"#1-初步分析\" class=\"headerlink\" title=\"1 初步分析\"></a>1 初步分析</h5><p>当时从几个方面去做了考虑：</p>\n<ul>\n<li>是不是业务流量骤增，导致应用负载升高，从而导致服务RT上升？</li>\n<li>是不是应用GC频率高、GC耗时长导致的？</li>\n<li>是不是最近有发布新需求或者更新导致的？</li>\n</ul>\n<h5 id=\"2-查询监控\"><a href=\"#2-查询监控\" class=\"headerlink\" title=\"2 查询监控\"></a>2 查询监控</h5><p>业务监控：</p>\n<ul>\n<li>首先去Sunfire查看应用的业务监控项，找到对应的业务场景，分析RT99监控项，跟昨日对比上升明显。</li>\n<li>再次去查看流量上涨情况，分析流量，数据跟昨日同时段差不多。</li>\n</ul>\n<blockquote>\n<p>分析结果：业务流量没有上涨，不是业务原因导致的。</p>\n</blockquote>\n<p>基础监控：</p>\n<ul>\n<li>查看GC（ygc, fgc），没有明显上涨；查看内存使用情况（新生代、老年代、metaspace），没有明显上涨。</li>\n<li>查看CPU，没有明显上涨；查看磁盘IO，没有明显上涨。</li>\n<li>查看线程数量，没有明显上涨。</li>\n<li>查看MySQL监控项；查看tair监控项；</li>\n</ul>\n<blockquote>\n<p>分析结果：未发现问题。</p>\n</blockquote>\n<h5 id=\"3-分析应用热点问题\"><a href=\"#3-分析应用热点问题\" class=\"headerlink\" title=\"3 分析应用热点问题\"></a>3 分析应用热点问题</h5><p>执行arthas的profiler命令，生成应用热点的火焰图。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">profiler start</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>默认情况下，生成的是 cpu 的火焰图，即 event 为cpu。 </p>\n</blockquote>\n<p>未贴实际的情况，参考下图：<br><img src=\"/2024/03/20/2024-03-20-性能优化-服务RT上升/profiler.png\" alt=\"trace\"></p>\n<blockquote>\n<p>分析结果：未发现明显问题。</p>\n</blockquote>\n<h5 id=\"4-执行Arthas的trace命令\"><a href=\"#4-执行Arthas的trace命令\" class=\"headerlink\" title=\"4 执行Arthas的trace命令\"></a>4 执行Arthas的trace命令</h5><p>trace 能方便的帮助你定位和发现因 RT 高而导致的性能问题缺陷。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trace com.alibaba.***.**OrderFacade  queryOrder</span><br></pre></td></tr></table></figure>\n\n<p>未贴实际的情况，参考下图：<br><img src=\"/2024/03/20/2024-03-20-性能优化-服务RT上升/trace.png\" alt=\"trace\"></p>\n<blockquote>\n<p>分析结果：未发现明显问题。</p>\n</blockquote>\n<h5 id=\"5-机器摘流\"><a href=\"#5-机器摘流\" class=\"headerlink\" title=\"5 机器摘流\"></a>5 机器摘流</h5><p>分析了一段时间后，未发现明显情况，于是对问题机器进行摘流处理。然后进行其他的分析，例如dump、GC啥的。</p>\n<h5 id=\"6-分析最近上线功能\"><a href=\"#6-分析最近上线功能\" class=\"headerlink\" title=\"6 分析最近上线功能\"></a>6 分析最近上线功能</h5><ul>\n<li>变更1：CMS升级成G1。</li>\n<li>变更2：拉单优化。</li>\n<li>变更3：scheduler jar升级。</li>\n</ul>\n<p>使用排除法，对变更2 &amp; 变更3进行代码的review和与中间件的沟通，不是造成RT上升的原因。最后怀疑是垃圾收集器的问题造成的。</p>\n<h5 id=\"7-应用更新重新部署\"><a href=\"#7-应用更新重新部署\" class=\"headerlink\" title=\"7 应用更新重新部署\"></a>7 应用更新重新部署</h5><p>将G1还原成CMS，应用部署上线后，未发现问题。    </p>\n<p>为什么要升级G1呢？</p>\n<h5 id=\"8-思考：为什么G1会影响RT呢？\"><a href=\"#8-思考：为什么G1会影响RT呢？\" class=\"headerlink\" title=\"8 思考：为什么G1会影响RT呢？\"></a>8 思考：为什么G1会影响RT呢？</h5><ul>\n<li>适应期问题：<br>新的垃圾收集器在应用程序运行初期可能需要一定的时间来适应应用的内存使用模式和对象分配特点。在这个适应期内，可能会出现性能波动，导致接口 RT 上升。<br>G1 垃圾收集器在初始阶段可能会进行一些额外的后台活动，如初始的堆空间划分和记忆集（Remembered Set）的建立等。</li>\n<li>配置问题：<br>G1 的默认配置可能并不完全适合特定的应用程序。例如，堆大小、年轻代和老年代的比例、并发标记周期的启动阈值等参数可能需要根据应用的实际情况进行调整。<br>如果堆大小设置不合理，可能导致频繁的垃圾收集，从而增加接口响应时间。</li>\n<li>应用程序特性：<br>某些应用程序的特性可能与 G1 的工作方式不太匹配。例如，如果应用程序有大量的短期存活对象，G1 的分代收集策略可能不如 CMS 高效。<br>如果应用程序的内存分配模式非常不均匀，可能会导致 G1 在某些区域进行过多的垃圾收集，影响性能。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<pre><code>这是性能优化系列的第五篇文章，主要介绍的是服务RT上升问题的分析及原理。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>某一个时期，交易服务经常会出现服务RT上升问题，导致业务成功率下降，然后业务就找过来了，交易应用作为核心应用，需要及时响应和处理。</p>","more":"<p>机器配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CPU=8核</span><br><span class=\"line\">内存=16GB</span><br><span class=\"line\">磁盘=60GB</span><br></pre></td></tr></table></figure>\n\n<p>JVM配置如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JDK1.8</span><br><span class=\"line\">-Xms12g</span><br><span class=\"line\">-Xmx12g</span><br><span class=\"line\">-Xmn8g</span><br><span class=\"line\">-XX:+UseG1GC</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"二、分析流程\"><a href=\"#二、分析流程\" class=\"headerlink\" title=\"二、分析流程\"></a>二、分析流程</h3><h4 id=\"问题表现\"><a href=\"#问题表现\" class=\"headerlink\" title=\"问题表现\"></a>问题表现</h4><p>交易服务某个接口的RT上升，导致上游业务成功率下降。</p>\n<h5 id=\"1-初步分析\"><a href=\"#1-初步分析\" class=\"headerlink\" title=\"1 初步分析\"></a>1 初步分析</h5><p>当时从几个方面去做了考虑：</p>\n<ul>\n<li>是不是业务流量骤增，导致应用负载升高，从而导致服务RT上升？</li>\n<li>是不是应用GC频率高、GC耗时长导致的？</li>\n<li>是不是最近有发布新需求或者更新导致的？</li>\n</ul>\n<h5 id=\"2-查询监控\"><a href=\"#2-查询监控\" class=\"headerlink\" title=\"2 查询监控\"></a>2 查询监控</h5><p>业务监控：</p>\n<ul>\n<li>首先去Sunfire查看应用的业务监控项，找到对应的业务场景，分析RT99监控项，跟昨日对比上升明显。</li>\n<li>再次去查看流量上涨情况，分析流量，数据跟昨日同时段差不多。</li>\n</ul>\n<blockquote>\n<p>分析结果：业务流量没有上涨，不是业务原因导致的。</p>\n</blockquote>\n<p>基础监控：</p>\n<ul>\n<li>查看GC（ygc, fgc），没有明显上涨；查看内存使用情况（新生代、老年代、metaspace），没有明显上涨。</li>\n<li>查看CPU，没有明显上涨；查看磁盘IO，没有明显上涨。</li>\n<li>查看线程数量，没有明显上涨。</li>\n<li>查看MySQL监控项；查看tair监控项；</li>\n</ul>\n<blockquote>\n<p>分析结果：未发现问题。</p>\n</blockquote>\n<h5 id=\"3-分析应用热点问题\"><a href=\"#3-分析应用热点问题\" class=\"headerlink\" title=\"3 分析应用热点问题\"></a>3 分析应用热点问题</h5><p>执行arthas的profiler命令，生成应用热点的火焰图。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">profiler start</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>默认情况下，生成的是 cpu 的火焰图，即 event 为cpu。 </p>\n</blockquote>\n<p>未贴实际的情况，参考下图：<br><img src=\"/2024/03/20/2024-03-20-性能优化-服务RT上升/profiler.png\" alt=\"trace\"></p>\n<blockquote>\n<p>分析结果：未发现明显问题。</p>\n</blockquote>\n<h5 id=\"4-执行Arthas的trace命令\"><a href=\"#4-执行Arthas的trace命令\" class=\"headerlink\" title=\"4 执行Arthas的trace命令\"></a>4 执行Arthas的trace命令</h5><p>trace 能方便的帮助你定位和发现因 RT 高而导致的性能问题缺陷。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trace com.alibaba.***.**OrderFacade  queryOrder</span><br></pre></td></tr></table></figure>\n\n<p>未贴实际的情况，参考下图：<br><img src=\"/2024/03/20/2024-03-20-性能优化-服务RT上升/trace.png\" alt=\"trace\"></p>\n<blockquote>\n<p>分析结果：未发现明显问题。</p>\n</blockquote>\n<h5 id=\"5-机器摘流\"><a href=\"#5-机器摘流\" class=\"headerlink\" title=\"5 机器摘流\"></a>5 机器摘流</h5><p>分析了一段时间后，未发现明显情况，于是对问题机器进行摘流处理。然后进行其他的分析，例如dump、GC啥的。</p>\n<h5 id=\"6-分析最近上线功能\"><a href=\"#6-分析最近上线功能\" class=\"headerlink\" title=\"6 分析最近上线功能\"></a>6 分析最近上线功能</h5><ul>\n<li>变更1：CMS升级成G1。</li>\n<li>变更2：拉单优化。</li>\n<li>变更3：scheduler jar升级。</li>\n</ul>\n<p>使用排除法，对变更2 &amp; 变更3进行代码的review和与中间件的沟通，不是造成RT上升的原因。最后怀疑是垃圾收集器的问题造成的。</p>\n<h5 id=\"7-应用更新重新部署\"><a href=\"#7-应用更新重新部署\" class=\"headerlink\" title=\"7 应用更新重新部署\"></a>7 应用更新重新部署</h5><p>将G1还原成CMS，应用部署上线后，未发现问题。    </p>\n<p>为什么要升级G1呢？</p>\n<h5 id=\"8-思考：为什么G1会影响RT呢？\"><a href=\"#8-思考：为什么G1会影响RT呢？\" class=\"headerlink\" title=\"8 思考：为什么G1会影响RT呢？\"></a>8 思考：为什么G1会影响RT呢？</h5><ul>\n<li>适应期问题：<br>新的垃圾收集器在应用程序运行初期可能需要一定的时间来适应应用的内存使用模式和对象分配特点。在这个适应期内，可能会出现性能波动，导致接口 RT 上升。<br>G1 垃圾收集器在初始阶段可能会进行一些额外的后台活动，如初始的堆空间划分和记忆集（Remembered Set）的建立等。</li>\n<li>配置问题：<br>G1 的默认配置可能并不完全适合特定的应用程序。例如，堆大小、年轻代和老年代的比例、并发标记周期的启动阈值等参数可能需要根据应用的实际情况进行调整。<br>如果堆大小设置不合理，可能导致频繁的垃圾收集，从而增加接口响应时间。</li>\n<li>应用程序特性：<br>某些应用程序的特性可能与 G1 的工作方式不太匹配。例如，如果应用程序有大量的短期存活对象，G1 的分代收集策略可能不如 CMS 高效。<br>如果应用程序的内存分配模式非常不均匀，可能会导致 G1 在某些区域进行过多的垃圾收集，影响性能。</li>\n</ul>"},{"title":"《性能优化系列》日志优化","date":"2024-04-10T02:00:00.000Z","_content":"\n    这是性能优化系列的第六篇文章，主要介绍的是日志原理分析及优化。\n\n### 一、背景\n团队内部推动使用异步打印日志的优化工作，及日日常工作中遇到的日志问题，因此做一个总结。\n\n<!-- more -->\n\n### 二、日志原理\n\n#### 1 日志框架介绍\n![trace](2024-04-10-性能优化-日志优化/日志框架_日志系统.png)\n* 日志框架  \n标准接口类型，也叫作 Facade ，也就是只提供接口，没有具体实现。开发者可以基于日志标准接口提供的规范自己实现一套。\n> JCL：Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging\n> SLF4J:  是一套简易Java日志Facade，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）\n\n* 日志系统      \n这一类框架主要基于日志的标准接口规范实现或者就是单纯的实现不依赖任何标准。\n> Log4j/Log4j2、Logback、JUL 这四个实现是比较常用的日志实现。\n\n#### 2 日志使用\n##### ⭐️ Slf4j+Logback入门实践  \n* maven配置\n```dtd\n<!--日志框架接口-->\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>slf4j-api</artifactId>\n</dependency>\n<!--日志框架接口实现-->\n<dependency>\n    <groupId>ch.qos.logback</groupId>\n    <artifactId>logback-classic</artifactId>\n</dependency>\n<!--日志框架核心组件-->\n<dependency>\n    <groupId>ch.qos.logback</groupId>\n    <artifactId>logback-core</artifactId>\n</dependency>\n```\n* 配置文件  \nlogback.xml\n```dtd\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<configuration>\n    <!--默认日志配置-->\n    <include resource=\"org/springframework/boot/logging/logback/defaults.xml\"/>\n    <!-- 控制台日志 -->\n    <appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\">\n        <encoder charset=\"UTF-8\">\n            <pattern>${CONSOLE_LOG_PATTERN}</pattern>\n        </encoder>\n    </appender>\n    <!-- Info日志 -->\n    <appender name=\"FILE-INFO\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n        <file>${LOG_PATH}/${LOG_FILE}-info.log</file>\n        <append>true</append>\n        <filter class=\"ch.qos.logback.classic.filter.LevelFilter\">\n            <level>INFO</level>\n            <onMatch>ACCEPT</onMatch>\n            <onMismatch>NEUTRAL</onMismatch>\n        </filter>\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n            <fileNamePattern>${LOG_PATH}/${LOG_FILE}-info-%d{yyyy-MM-dd}.%i.log</fileNamePattern> <!-- 日志文件的路径和名称 -->\n            <timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\">\n                <maxFileSize>200MB</maxFileSize> <!-- 单个日志文件的最大大小 -->\n            </timeBasedFileNamingAndTriggeringPolicy>\n            <maxHistory>15</maxHistory> <!-- 保留的历史日志文件数量 -->\n            <totalSizeCap>2GB</totalSizeCap> <!-- 所有日志文件的总大小上限 -->\n            <cleanHistoryOnStart>true</cleanHistoryOnStart> <!-- 在启动时清除历史日志文件 -->\n        </rollingPolicy>\n        <encoder charset=\"UTF-8\">\n            <pattern>${FILE_LOG_PATTERN}</pattern>\n        </encoder>\n    </appender>\n\n    <!-- 异步输出 -->\n    <appender name=\"info-asyn\" class=\"ch.qos.logback.classic.AsyncAppender\">\n        <appender-ref ref=\"FILE-INFO\"/>\n        <queueSize>512</queueSize> <!-- 异步队列的大小 -->\n    </appender>\n    </appender>\n    <!-- 应用日志 -->\n    <logger name=\"com.alibaba.alsc.order\" additivity=\"false\">\n        <appender-ref ref=\"CONSOLE\"/>\n        <appender-ref ref=\"FILE-INFO\"/>\n    </logger>\n    <!-- 总日志出口 -->\n    <root level=\"${logging.level.root}\">\n        <appender-ref ref=\"CONSOLE\"/>\n        <appender-ref ref=\"info-asyn\"/>\n    </root>\n</configuration>\n```\n\n* 代码示例\n```dtd\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class MyClass {\n    private static final Logger logger = LoggerFactory.getLogger(MyClass.class);\n\n    public void doSomething() {\n        logger.info(\"doing something\");\n    }\n}\n```\n在上面的代码中，我们通过LoggerFactory.getLogger()方法获取了一个Logger实例，并使用logger.info()方法记录了一条日志。\n\n\n#### 3 日志原理\nMore info: [深入掌握Java日志体系，再也不迷路了](https://juejin.cn/post/6905026199722917902#heading-0)\n\n##### 3.1 异步日志实现\n同步输出\n{% plantuml %}\n(*)-> \"业务程序\"\n-> \"日志打印\"\n-> \"业务程序 \"\n->(*)\n{% endplantuml %}\n\n异步输出\n{% plantuml %}\nstart\nfork\n: 业务thread;\nfork again\n: 日志thread;\nend fork\nstop\n{% endplantuml %}\n\n###### ⭐️ 异步日志实现原理AsyncAppender\nlogback异步输出日志是通过AsyncAppender实现的。AsyncAppender可以异步的记录 ILoggingEvents日志事件。\n![AsyncAppender](2024-04-10-性能优化-日志优化/AsyncAppender.png)\nLogback的异步输出采用生产者消费者的模式，将生成的日志放入消息队列中，并将创建一个线程用于输出日志事件，有效的解决了这个问题，提高了程序的性能。\n```dtd\n<!-- 文件 异步日志(async) -->\n    <appender name=\"ASYNC_LOG\" class=\"ch.qos.logback.classic.AsyncAppender\" >\n        <!-- 不丢失日志.默认的256/5,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->\n        <discardingThreshold>0</discardingThreshold>\n        <!-- 更改默认的队列的长度,默认值为256 -->\n        <queueSize>25</queueSize>\n        <neverBlock>false</neverBlock>\n        <!-- 添加附加的appender,最多只能添加一个 -->\n        <appender-ref ref=\"fileLog\" />\n    </appender>\n```\n![日志入队列流程](2024-04-10-性能优化-日志优化/日志入队列流程.png)\n\n> 注意：写文件是异步线程，但是写queue是同步的，如果配置出现问题，也会导致工作线程阻塞。\n\n相关源码    \n```dtd\nlogback中的异步输出日志使用了AsyncAppender这个appender，通过看AsyncAppender源码，跟到它的父类AsyncAppenderBase，\n\n可以看到它有几个重要的成员变量：\nAppenderAttachableImpl<E> aai = new AppenderAttachableImpl<E>();\nBlockingQueue<E> blockingQueue;\nAsyncAppenderBase<E>.Worker worker = new AsyncAppenderBase.Worker();\n```\n\n### 三、日志配置错误案例\n#### 背景\n商品分布平台，经常触发磁盘利用率异常告警，错误如下：\n![磁盘利用率](2024-04-10-性能优化-日志优化/磁盘利用率.jpeg)\n\n需要进入运维平台，手动清空日志，及缩小日志清理的时间。\n\n#### ⭐️ 问题排查\n* 为什么打印了这么多日志？  \n> 商品结构复杂，每次查询、操作都打印的话，会打印非常多的日志，磁盘占用也高。\n\n* 机器配置\n```dtd\nCPU=8核\n内存=16GB\n磁盘=100GB\n```\n进入机器，查看应用的日志文件，发现应用的历史日志未清除，导致磁盘利用率高。\n\n* 查看logback配置   \n示例如下：\n```dtd\n<configuration>\n    <appender name=\"DAILY_ROLLING_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n        <file>application.log</file>\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n            <!-- 按天滚动 -->\n            <fileNamePattern>application-%d{yyyy-MM-dd}.log</fileNamePattern>\n            <!-- 设置单个日志文件最大大小为 5GB -->\n            <maxFileSize>5GB</maxFileSize>\n        </rollingPolicy>\n        <encoder>\n            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>\n        </encoder>\n    </appender>\n\n    <root level=\"INFO\">\n        <appender-ref ref=\"DAILY_ROLLING_FILE\" />\n    </root>\n</configuration>\n```\n> 错误1：单个文件5G，配置不正确。 \n> 错误2：没有配置日志保留时间。\n> 错误3：未配置总日志文件大小限制。\n> 错误4：未配置异步打印。\n\n* 优化\n```dtd\n<appender name=\"TRACE_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n    <file>${PATH}/trace.log</file>\n    <rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n        <FileNamePattern>${PATH}/trace.%d{yyyy-MM-dd}.%i.log</FileNamePattern>\n        <!--保存多少天的日志-->\n        <maxHistory>7</maxHistory>\n        <!--自定义日志总大小-->\n        <totalSizeCap>30G</totalSizeCap>\n        <!--单个文件大小上限-->\n        <maxFileSize>300M</maxFileSize>\n        <!--在只有设置为true并且 maxHistory 不为零才能起效。-->\n        <cleanHistoryOnStart>true</cleanHistoryOnStart>\n    </rollingPolicy>\n    <!--输出格式-->\n    <encoder>\n        <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %-50logger{50}:%-4line %green(%-8X{UUID}) %msg%n</pattern>\n        <charset>utf8</charset>\n    </encoder>\n</appender>\n```\n\n","source":"_posts/2024-04-10-性能优化-日志优化.md","raw":"---\ntitle: 《性能优化系列》日志优化\ndate: 2024-04-10 10:00:00\ncategories:\n  - [日志]\n  - [性能优化]\n  - [阿里]\ntags:\n- 阿里\n---\n\n    这是性能优化系列的第六篇文章，主要介绍的是日志原理分析及优化。\n\n### 一、背景\n团队内部推动使用异步打印日志的优化工作，及日日常工作中遇到的日志问题，因此做一个总结。\n\n<!-- more -->\n\n### 二、日志原理\n\n#### 1 日志框架介绍\n![trace](2024-04-10-性能优化-日志优化/日志框架_日志系统.png)\n* 日志框架  \n标准接口类型，也叫作 Facade ，也就是只提供接口，没有具体实现。开发者可以基于日志标准接口提供的规范自己实现一套。\n> JCL：Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging\n> SLF4J:  是一套简易Java日志Facade，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）\n\n* 日志系统      \n这一类框架主要基于日志的标准接口规范实现或者就是单纯的实现不依赖任何标准。\n> Log4j/Log4j2、Logback、JUL 这四个实现是比较常用的日志实现。\n\n#### 2 日志使用\n##### ⭐️ Slf4j+Logback入门实践  \n* maven配置\n```dtd\n<!--日志框架接口-->\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>slf4j-api</artifactId>\n</dependency>\n<!--日志框架接口实现-->\n<dependency>\n    <groupId>ch.qos.logback</groupId>\n    <artifactId>logback-classic</artifactId>\n</dependency>\n<!--日志框架核心组件-->\n<dependency>\n    <groupId>ch.qos.logback</groupId>\n    <artifactId>logback-core</artifactId>\n</dependency>\n```\n* 配置文件  \nlogback.xml\n```dtd\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<configuration>\n    <!--默认日志配置-->\n    <include resource=\"org/springframework/boot/logging/logback/defaults.xml\"/>\n    <!-- 控制台日志 -->\n    <appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\">\n        <encoder charset=\"UTF-8\">\n            <pattern>${CONSOLE_LOG_PATTERN}</pattern>\n        </encoder>\n    </appender>\n    <!-- Info日志 -->\n    <appender name=\"FILE-INFO\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n        <file>${LOG_PATH}/${LOG_FILE}-info.log</file>\n        <append>true</append>\n        <filter class=\"ch.qos.logback.classic.filter.LevelFilter\">\n            <level>INFO</level>\n            <onMatch>ACCEPT</onMatch>\n            <onMismatch>NEUTRAL</onMismatch>\n        </filter>\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n            <fileNamePattern>${LOG_PATH}/${LOG_FILE}-info-%d{yyyy-MM-dd}.%i.log</fileNamePattern> <!-- 日志文件的路径和名称 -->\n            <timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\">\n                <maxFileSize>200MB</maxFileSize> <!-- 单个日志文件的最大大小 -->\n            </timeBasedFileNamingAndTriggeringPolicy>\n            <maxHistory>15</maxHistory> <!-- 保留的历史日志文件数量 -->\n            <totalSizeCap>2GB</totalSizeCap> <!-- 所有日志文件的总大小上限 -->\n            <cleanHistoryOnStart>true</cleanHistoryOnStart> <!-- 在启动时清除历史日志文件 -->\n        </rollingPolicy>\n        <encoder charset=\"UTF-8\">\n            <pattern>${FILE_LOG_PATTERN}</pattern>\n        </encoder>\n    </appender>\n\n    <!-- 异步输出 -->\n    <appender name=\"info-asyn\" class=\"ch.qos.logback.classic.AsyncAppender\">\n        <appender-ref ref=\"FILE-INFO\"/>\n        <queueSize>512</queueSize> <!-- 异步队列的大小 -->\n    </appender>\n    </appender>\n    <!-- 应用日志 -->\n    <logger name=\"com.alibaba.alsc.order\" additivity=\"false\">\n        <appender-ref ref=\"CONSOLE\"/>\n        <appender-ref ref=\"FILE-INFO\"/>\n    </logger>\n    <!-- 总日志出口 -->\n    <root level=\"${logging.level.root}\">\n        <appender-ref ref=\"CONSOLE\"/>\n        <appender-ref ref=\"info-asyn\"/>\n    </root>\n</configuration>\n```\n\n* 代码示例\n```dtd\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class MyClass {\n    private static final Logger logger = LoggerFactory.getLogger(MyClass.class);\n\n    public void doSomething() {\n        logger.info(\"doing something\");\n    }\n}\n```\n在上面的代码中，我们通过LoggerFactory.getLogger()方法获取了一个Logger实例，并使用logger.info()方法记录了一条日志。\n\n\n#### 3 日志原理\nMore info: [深入掌握Java日志体系，再也不迷路了](https://juejin.cn/post/6905026199722917902#heading-0)\n\n##### 3.1 异步日志实现\n同步输出\n{% plantuml %}\n(*)-> \"业务程序\"\n-> \"日志打印\"\n-> \"业务程序 \"\n->(*)\n{% endplantuml %}\n\n异步输出\n{% plantuml %}\nstart\nfork\n: 业务thread;\nfork again\n: 日志thread;\nend fork\nstop\n{% endplantuml %}\n\n###### ⭐️ 异步日志实现原理AsyncAppender\nlogback异步输出日志是通过AsyncAppender实现的。AsyncAppender可以异步的记录 ILoggingEvents日志事件。\n![AsyncAppender](2024-04-10-性能优化-日志优化/AsyncAppender.png)\nLogback的异步输出采用生产者消费者的模式，将生成的日志放入消息队列中，并将创建一个线程用于输出日志事件，有效的解决了这个问题，提高了程序的性能。\n```dtd\n<!-- 文件 异步日志(async) -->\n    <appender name=\"ASYNC_LOG\" class=\"ch.qos.logback.classic.AsyncAppender\" >\n        <!-- 不丢失日志.默认的256/5,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->\n        <discardingThreshold>0</discardingThreshold>\n        <!-- 更改默认的队列的长度,默认值为256 -->\n        <queueSize>25</queueSize>\n        <neverBlock>false</neverBlock>\n        <!-- 添加附加的appender,最多只能添加一个 -->\n        <appender-ref ref=\"fileLog\" />\n    </appender>\n```\n![日志入队列流程](2024-04-10-性能优化-日志优化/日志入队列流程.png)\n\n> 注意：写文件是异步线程，但是写queue是同步的，如果配置出现问题，也会导致工作线程阻塞。\n\n相关源码    \n```dtd\nlogback中的异步输出日志使用了AsyncAppender这个appender，通过看AsyncAppender源码，跟到它的父类AsyncAppenderBase，\n\n可以看到它有几个重要的成员变量：\nAppenderAttachableImpl<E> aai = new AppenderAttachableImpl<E>();\nBlockingQueue<E> blockingQueue;\nAsyncAppenderBase<E>.Worker worker = new AsyncAppenderBase.Worker();\n```\n\n### 三、日志配置错误案例\n#### 背景\n商品分布平台，经常触发磁盘利用率异常告警，错误如下：\n![磁盘利用率](2024-04-10-性能优化-日志优化/磁盘利用率.jpeg)\n\n需要进入运维平台，手动清空日志，及缩小日志清理的时间。\n\n#### ⭐️ 问题排查\n* 为什么打印了这么多日志？  \n> 商品结构复杂，每次查询、操作都打印的话，会打印非常多的日志，磁盘占用也高。\n\n* 机器配置\n```dtd\nCPU=8核\n内存=16GB\n磁盘=100GB\n```\n进入机器，查看应用的日志文件，发现应用的历史日志未清除，导致磁盘利用率高。\n\n* 查看logback配置   \n示例如下：\n```dtd\n<configuration>\n    <appender name=\"DAILY_ROLLING_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n        <file>application.log</file>\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n            <!-- 按天滚动 -->\n            <fileNamePattern>application-%d{yyyy-MM-dd}.log</fileNamePattern>\n            <!-- 设置单个日志文件最大大小为 5GB -->\n            <maxFileSize>5GB</maxFileSize>\n        </rollingPolicy>\n        <encoder>\n            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>\n        </encoder>\n    </appender>\n\n    <root level=\"INFO\">\n        <appender-ref ref=\"DAILY_ROLLING_FILE\" />\n    </root>\n</configuration>\n```\n> 错误1：单个文件5G，配置不正确。 \n> 错误2：没有配置日志保留时间。\n> 错误3：未配置总日志文件大小限制。\n> 错误4：未配置异步打印。\n\n* 优化\n```dtd\n<appender name=\"TRACE_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n    <file>${PATH}/trace.log</file>\n    <rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\n        <FileNamePattern>${PATH}/trace.%d{yyyy-MM-dd}.%i.log</FileNamePattern>\n        <!--保存多少天的日志-->\n        <maxHistory>7</maxHistory>\n        <!--自定义日志总大小-->\n        <totalSizeCap>30G</totalSizeCap>\n        <!--单个文件大小上限-->\n        <maxFileSize>300M</maxFileSize>\n        <!--在只有设置为true并且 maxHistory 不为零才能起效。-->\n        <cleanHistoryOnStart>true</cleanHistoryOnStart>\n    </rollingPolicy>\n    <!--输出格式-->\n    <encoder>\n        <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %-50logger{50}:%-4line %green(%-8X{UUID}) %msg%n</pattern>\n        <charset>utf8</charset>\n    </encoder>\n</appender>\n```\n\n","slug":"2024-04-10-性能优化-日志优化","published":1,"updated":"2024-10-21T12:39:41.072Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxw004aa13k2vcl54ui","content":"<pre><code>这是性能优化系列的第六篇文章，主要介绍的是日志原理分析及优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>团队内部推动使用异步打印日志的优化工作，及日日常工作中遇到的日志问题，因此做一个总结。</p>\n<a id=\"more\"></a>\n\n<h3 id=\"二、日志原理\"><a href=\"#二、日志原理\" class=\"headerlink\" title=\"二、日志原理\"></a>二、日志原理</h3><h4 id=\"1-日志框架介绍\"><a href=\"#1-日志框架介绍\" class=\"headerlink\" title=\"1 日志框架介绍\"></a>1 日志框架介绍</h4><p><img src=\"/2024/04/10/2024-04-10-性能优化-日志优化/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6_%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F.png\" alt=\"trace\"></p>\n<ul>\n<li><p>日志框架<br>标准接口类型，也叫作 Facade ，也就是只提供接口，没有具体实现。开发者可以基于日志标准接口提供的规范自己实现一套。</p>\n<blockquote>\n<p>JCL：Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging<br>SLF4J:  是一套简易Java日志Facade，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）</p>\n</blockquote>\n</li>\n<li><p>日志系统<br>这一类框架主要基于日志的标准接口规范实现或者就是单纯的实现不依赖任何标准。</p>\n<blockquote>\n<p>Log4j/Log4j2、Logback、JUL 这四个实现是比较常用的日志实现。</p>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"2-日志使用\"><a href=\"#2-日志使用\" class=\"headerlink\" title=\"2 日志使用\"></a>2 日志使用</h4><h5 id=\"⭐️-Slf4j-Logback入门实践\"><a href=\"#⭐️-Slf4j-Logback入门实践\" class=\"headerlink\" title=\"⭐️ Slf4j+Logback入门实践\"></a>⭐️ Slf4j+Logback入门实践</h5><ul>\n<li><p>maven配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--日志框架接口--&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;!--日志框架接口实现--&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;!--日志框架核心组件--&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;logback-core&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置文件<br>logback.xml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;!--默认日志配置--&gt;</span><br><span class=\"line\">    &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;/&gt;</span><br><span class=\"line\">    &lt;!-- 控制台日志 --&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;</span><br><span class=\"line\">        &lt;encoder charset=&quot;UTF-8&quot;&gt;</span><br><span class=\"line\">            &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt;</span><br><span class=\"line\">        &lt;/encoder&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\">    &lt;!-- Info日志 --&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;FILE-INFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;</span><br><span class=\"line\">        &lt;file&gt;$&#123;LOG_PATH&#125;/$&#123;LOG_FILE&#125;-info.log&lt;/file&gt;</span><br><span class=\"line\">        &lt;append&gt;true&lt;/append&gt;</span><br><span class=\"line\">        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;</span><br><span class=\"line\">            &lt;level&gt;INFO&lt;/level&gt;</span><br><span class=\"line\">            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;</span><br><span class=\"line\">            &lt;onMismatch&gt;NEUTRAL&lt;/onMismatch&gt;</span><br><span class=\"line\">        &lt;/filter&gt;</span><br><span class=\"line\">        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;</span><br><span class=\"line\">            &lt;fileNamePattern&gt;$&#123;LOG_PATH&#125;/$&#123;LOG_FILE&#125;-info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;!-- 日志文件的路径和名称 --&gt;</span><br><span class=\"line\">            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;</span><br><span class=\"line\">                &lt;maxFileSize&gt;200MB&lt;/maxFileSize&gt; &lt;!-- 单个日志文件的最大大小 --&gt;</span><br><span class=\"line\">            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;</span><br><span class=\"line\">            &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;!-- 保留的历史日志文件数量 --&gt;</span><br><span class=\"line\">            &lt;totalSizeCap&gt;2GB&lt;/totalSizeCap&gt; &lt;!-- 所有日志文件的总大小上限 --&gt;</span><br><span class=\"line\">            &lt;cleanHistoryOnStart&gt;true&lt;/cleanHistoryOnStart&gt; &lt;!-- 在启动时清除历史日志文件 --&gt;</span><br><span class=\"line\">        &lt;/rollingPolicy&gt;</span><br><span class=\"line\">        &lt;encoder charset=&quot;UTF-8&quot;&gt;</span><br><span class=\"line\">            &lt;pattern&gt;$&#123;FILE_LOG_PATTERN&#125;&lt;/pattern&gt;</span><br><span class=\"line\">        &lt;/encoder&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;!-- 异步输出 --&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;info-asyn&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;FILE-INFO&quot;/&gt;</span><br><span class=\"line\">        &lt;queueSize&gt;512&lt;/queueSize&gt; &lt;!-- 异步队列的大小 --&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\">    &lt;!-- 应用日志 --&gt;</span><br><span class=\"line\">    &lt;logger name=&quot;com.alibaba.alsc.order&quot; additivity=&quot;false&quot;&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;FILE-INFO&quot;/&gt;</span><br><span class=\"line\">    &lt;/logger&gt;</span><br><span class=\"line\">    &lt;!-- 总日志出口 --&gt;</span><br><span class=\"line\">    &lt;root level=&quot;$&#123;logging.level.root&#125;&quot;&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;info-asyn&quot;/&gt;</span><br><span class=\"line\">    &lt;/root&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>代码示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import org.slf4j.Logger;</span><br><span class=\"line\">import org.slf4j.LoggerFactory;</span><br><span class=\"line\"></span><br><span class=\"line\">public class MyClass &#123;</span><br><span class=\"line\">    private static final Logger logger = LoggerFactory.getLogger(MyClass.class);</span><br><span class=\"line\"></span><br><span class=\"line\">    public void doSomething() &#123;</span><br><span class=\"line\">        logger.info(&quot;doing something&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>在上面的代码中，我们通过LoggerFactory.getLogger()方法获取了一个Logger实例，并使用logger.info()方法记录了一条日志。</p>\n<h4 id=\"3-日志原理\"><a href=\"#3-日志原理\" class=\"headerlink\" title=\"3 日志原理\"></a>3 日志原理</h4><p>More info: <a href=\"https://juejin.cn/post/6905026199722917902#heading-0\" target=\"_blank\" rel=\"noopener\">深入掌握Java日志体系，再也不迷路了</a></p>\n<h5 id=\"3-1-异步日志实现\"><a href=\"#3-1-异步日志实现\" class=\"headerlink\" title=\"3.1 异步日志实现\"></a>3.1 异步日志实现</h5><p>同步输出</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/qz3IrBLJK7goOzRJheNFLtG_tTMln0KIUJPzwTFzqvzrJdxQkm4YWgn60IIaeQK90000\">\n\n<p>异步输出</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/Aov9B2hXIiilokQoKdYoOzRJheKb6KMfYIdMO465nFJ4p3oWrBFfIv_kdmwJIirBKG3hAIx9Bm00\">\n\n<h6 id=\"⭐️-异步日志实现原理AsyncAppender\"><a href=\"#⭐️-异步日志实现原理AsyncAppender\" class=\"headerlink\" title=\"⭐️ 异步日志实现原理AsyncAppender\"></a>⭐️ 异步日志实现原理AsyncAppender</h6><p>logback异步输出日志是通过AsyncAppender实现的。AsyncAppender可以异步的记录 ILoggingEvents日志事件。<br><img src=\"/2024/04/10/2024-04-10-性能优化-日志优化/AsyncAppender.png\" alt=\"AsyncAppender\"><br>Logback的异步输出采用生产者消费者的模式，将生成的日志放入消息队列中，并将创建一个线程用于输出日志事件，有效的解决了这个问题，提高了程序的性能。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!-- 文件 异步日志(async) --&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;ASYNC_LOG&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot; &gt;</span><br><span class=\"line\">        &lt;!-- 不丢失日志.默认的256/5,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt;</span><br><span class=\"line\">        &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt;</span><br><span class=\"line\">        &lt;!-- 更改默认的队列的长度,默认值为256 --&gt;</span><br><span class=\"line\">        &lt;queueSize&gt;25&lt;/queueSize&gt;</span><br><span class=\"line\">        &lt;neverBlock&gt;false&lt;/neverBlock&gt;</span><br><span class=\"line\">        &lt;!-- 添加附加的appender,最多只能添加一个 --&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;fileLog&quot; /&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/04/10/2024-04-10-性能优化-日志优化/%E6%97%A5%E5%BF%97%E5%85%A5%E9%98%9F%E5%88%97%E6%B5%81%E7%A8%8B.png\" alt=\"日志入队列流程\"></p>\n<blockquote>\n<p>注意：写文件是异步线程，但是写queue是同步的，如果配置出现问题，也会导致工作线程阻塞。</p>\n</blockquote>\n<p>相关源码    </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logback中的异步输出日志使用了AsyncAppender这个appender，通过看AsyncAppender源码，跟到它的父类AsyncAppenderBase，</span><br><span class=\"line\"></span><br><span class=\"line\">可以看到它有几个重要的成员变量：</span><br><span class=\"line\">AppenderAttachableImpl&lt;E&gt; aai = new AppenderAttachableImpl&lt;E&gt;();</span><br><span class=\"line\">BlockingQueue&lt;E&gt; blockingQueue;</span><br><span class=\"line\">AsyncAppenderBase&lt;E&gt;.Worker worker = new AsyncAppenderBase.Worker();</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"三、日志配置错误案例\"><a href=\"#三、日志配置错误案例\" class=\"headerlink\" title=\"三、日志配置错误案例\"></a>三、日志配置错误案例</h3><h4 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h4><p>商品分布平台，经常触发磁盘利用率异常告警，错误如下：<br><img src=\"/2024/04/10/2024-04-10-性能优化-日志优化/%E7%A3%81%E7%9B%98%E5%88%A9%E7%94%A8%E7%8E%87.jpeg\" alt=\"磁盘利用率\"></p>\n<p>需要进入运维平台，手动清空日志，及缩小日志清理的时间。</p>\n<h4 id=\"⭐️-问题排查\"><a href=\"#⭐️-问题排查\" class=\"headerlink\" title=\"⭐️ 问题排查\"></a>⭐️ 问题排查</h4><ul>\n<li><p>为什么打印了这么多日志？  </p>\n<blockquote>\n<p>商品结构复杂，每次查询、操作都打印的话，会打印非常多的日志，磁盘占用也高。</p>\n</blockquote>\n</li>\n<li><p>机器配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CPU=8核</span><br><span class=\"line\">内存=16GB</span><br><span class=\"line\">磁盘=100GB</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>进入机器，查看应用的日志文件，发现应用的历史日志未清除，导致磁盘利用率高。</p>\n<ul>\n<li>查看logback配置<br>示例如下：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;DAILY_ROLLING_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;</span><br><span class=\"line\">        &lt;file&gt;application.log&lt;/file&gt;</span><br><span class=\"line\">        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;</span><br><span class=\"line\">            &lt;!-- 按天滚动 --&gt;</span><br><span class=\"line\">            &lt;fileNamePattern&gt;application-%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt;</span><br><span class=\"line\">            &lt;!-- 设置单个日志文件最大大小为 5GB --&gt;</span><br><span class=\"line\">            &lt;maxFileSize&gt;5GB&lt;/maxFileSize&gt;</span><br><span class=\"line\">        &lt;/rollingPolicy&gt;</span><br><span class=\"line\">        &lt;encoder&gt;</span><br><span class=\"line\">            &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt;</span><br><span class=\"line\">        &lt;/encoder&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;root level=&quot;INFO&quot;&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;DAILY_ROLLING_FILE&quot; /&gt;</span><br><span class=\"line\">    &lt;/root&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<blockquote>\n<p>错误1：单个文件5G，配置不正确。<br>错误2：没有配置日志保留时间。<br>错误3：未配置总日志文件大小限制。<br>错误4：未配置异步打印。</p>\n</blockquote>\n<ul>\n<li>优化<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;appender name=&quot;TRACE_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;</span><br><span class=\"line\">    &lt;file&gt;$&#123;PATH&#125;/trace.log&lt;/file&gt;</span><br><span class=\"line\">    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt;</span><br><span class=\"line\">        &lt;FileNamePattern&gt;$&#123;PATH&#125;/trace.%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/FileNamePattern&gt;</span><br><span class=\"line\">        &lt;!--保存多少天的日志--&gt;</span><br><span class=\"line\">        &lt;maxHistory&gt;7&lt;/maxHistory&gt;</span><br><span class=\"line\">        &lt;!--自定义日志总大小--&gt;</span><br><span class=\"line\">        &lt;totalSizeCap&gt;30G&lt;/totalSizeCap&gt;</span><br><span class=\"line\">        &lt;!--单个文件大小上限--&gt;</span><br><span class=\"line\">        &lt;maxFileSize&gt;300M&lt;/maxFileSize&gt;</span><br><span class=\"line\">        &lt;!--在只有设置为true并且 maxHistory 不为零才能起效。--&gt;</span><br><span class=\"line\">        &lt;cleanHistoryOnStart&gt;true&lt;/cleanHistoryOnStart&gt;</span><br><span class=\"line\">    &lt;/rollingPolicy&gt;</span><br><span class=\"line\">    &lt;!--输出格式--&gt;</span><br><span class=\"line\">    &lt;encoder&gt;</span><br><span class=\"line\">        &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %-5level %-50logger&#123;50&#125;:%-4line %green(%-8X&#123;UUID&#125;) %msg%n&lt;/pattern&gt;</span><br><span class=\"line\">        &lt;charset&gt;utf8&lt;/charset&gt;</span><br><span class=\"line\">    &lt;/encoder&gt;</span><br><span class=\"line\">&lt;/appender&gt;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<pre><code>这是性能优化系列的第六篇文章，主要介绍的是日志原理分析及优化。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>团队内部推动使用异步打印日志的优化工作，及日日常工作中遇到的日志问题，因此做一个总结。</p>","more":"<h3 id=\"二、日志原理\"><a href=\"#二、日志原理\" class=\"headerlink\" title=\"二、日志原理\"></a>二、日志原理</h3><h4 id=\"1-日志框架介绍\"><a href=\"#1-日志框架介绍\" class=\"headerlink\" title=\"1 日志框架介绍\"></a>1 日志框架介绍</h4><p><img src=\"/2024/04/10/2024-04-10-性能优化-日志优化/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6_%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F.png\" alt=\"trace\"></p>\n<ul>\n<li><p>日志框架<br>标准接口类型，也叫作 Facade ，也就是只提供接口，没有具体实现。开发者可以基于日志标准接口提供的规范自己实现一套。</p>\n<blockquote>\n<p>JCL：Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging<br>SLF4J:  是一套简易Java日志Facade，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）</p>\n</blockquote>\n</li>\n<li><p>日志系统<br>这一类框架主要基于日志的标准接口规范实现或者就是单纯的实现不依赖任何标准。</p>\n<blockquote>\n<p>Log4j/Log4j2、Logback、JUL 这四个实现是比较常用的日志实现。</p>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"2-日志使用\"><a href=\"#2-日志使用\" class=\"headerlink\" title=\"2 日志使用\"></a>2 日志使用</h4><h5 id=\"⭐️-Slf4j-Logback入门实践\"><a href=\"#⭐️-Slf4j-Logback入门实践\" class=\"headerlink\" title=\"⭐️ Slf4j+Logback入门实践\"></a>⭐️ Slf4j+Logback入门实践</h5><ul>\n<li><p>maven配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!--日志框架接口--&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;!--日志框架接口实现--&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br><span class=\"line\">&lt;!--日志框架核心组件--&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;logback-core&lt;/artifactId&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>配置文件<br>logback.xml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;!--默认日志配置--&gt;</span><br><span class=\"line\">    &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;/&gt;</span><br><span class=\"line\">    &lt;!-- 控制台日志 --&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;</span><br><span class=\"line\">        &lt;encoder charset=&quot;UTF-8&quot;&gt;</span><br><span class=\"line\">            &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt;</span><br><span class=\"line\">        &lt;/encoder&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\">    &lt;!-- Info日志 --&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;FILE-INFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;</span><br><span class=\"line\">        &lt;file&gt;$&#123;LOG_PATH&#125;/$&#123;LOG_FILE&#125;-info.log&lt;/file&gt;</span><br><span class=\"line\">        &lt;append&gt;true&lt;/append&gt;</span><br><span class=\"line\">        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;</span><br><span class=\"line\">            &lt;level&gt;INFO&lt;/level&gt;</span><br><span class=\"line\">            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;</span><br><span class=\"line\">            &lt;onMismatch&gt;NEUTRAL&lt;/onMismatch&gt;</span><br><span class=\"line\">        &lt;/filter&gt;</span><br><span class=\"line\">        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;</span><br><span class=\"line\">            &lt;fileNamePattern&gt;$&#123;LOG_PATH&#125;/$&#123;LOG_FILE&#125;-info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;!-- 日志文件的路径和名称 --&gt;</span><br><span class=\"line\">            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;</span><br><span class=\"line\">                &lt;maxFileSize&gt;200MB&lt;/maxFileSize&gt; &lt;!-- 单个日志文件的最大大小 --&gt;</span><br><span class=\"line\">            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;</span><br><span class=\"line\">            &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;!-- 保留的历史日志文件数量 --&gt;</span><br><span class=\"line\">            &lt;totalSizeCap&gt;2GB&lt;/totalSizeCap&gt; &lt;!-- 所有日志文件的总大小上限 --&gt;</span><br><span class=\"line\">            &lt;cleanHistoryOnStart&gt;true&lt;/cleanHistoryOnStart&gt; &lt;!-- 在启动时清除历史日志文件 --&gt;</span><br><span class=\"line\">        &lt;/rollingPolicy&gt;</span><br><span class=\"line\">        &lt;encoder charset=&quot;UTF-8&quot;&gt;</span><br><span class=\"line\">            &lt;pattern&gt;$&#123;FILE_LOG_PATTERN&#125;&lt;/pattern&gt;</span><br><span class=\"line\">        &lt;/encoder&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;!-- 异步输出 --&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;info-asyn&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;FILE-INFO&quot;/&gt;</span><br><span class=\"line\">        &lt;queueSize&gt;512&lt;/queueSize&gt; &lt;!-- 异步队列的大小 --&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\">    &lt;!-- 应用日志 --&gt;</span><br><span class=\"line\">    &lt;logger name=&quot;com.alibaba.alsc.order&quot; additivity=&quot;false&quot;&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;FILE-INFO&quot;/&gt;</span><br><span class=\"line\">    &lt;/logger&gt;</span><br><span class=\"line\">    &lt;!-- 总日志出口 --&gt;</span><br><span class=\"line\">    &lt;root level=&quot;$&#123;logging.level.root&#125;&quot;&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;info-asyn&quot;/&gt;</span><br><span class=\"line\">    &lt;/root&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>代码示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import org.slf4j.Logger;</span><br><span class=\"line\">import org.slf4j.LoggerFactory;</span><br><span class=\"line\"></span><br><span class=\"line\">public class MyClass &#123;</span><br><span class=\"line\">    private static final Logger logger = LoggerFactory.getLogger(MyClass.class);</span><br><span class=\"line\"></span><br><span class=\"line\">    public void doSomething() &#123;</span><br><span class=\"line\">        logger.info(&quot;doing something&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>在上面的代码中，我们通过LoggerFactory.getLogger()方法获取了一个Logger实例，并使用logger.info()方法记录了一条日志。</p>\n<h4 id=\"3-日志原理\"><a href=\"#3-日志原理\" class=\"headerlink\" title=\"3 日志原理\"></a>3 日志原理</h4><p>More info: <a href=\"https://juejin.cn/post/6905026199722917902#heading-0\" target=\"_blank\" rel=\"noopener\">深入掌握Java日志体系，再也不迷路了</a></p>\n<h5 id=\"3-1-异步日志实现\"><a href=\"#3-1-异步日志实现\" class=\"headerlink\" title=\"3.1 异步日志实现\"></a>3.1 异步日志实现</h5><p>同步输出</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/qz3IrBLJK7goOzRJheNFLtG_tTMln0KIUJPzwTFzqvzrJdxQkm4YWgn60IIaeQK90000\">\n\n<p>异步输出</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/Aov9B2hXIiilokQoKdYoOzRJheKb6KMfYIdMO465nFJ4p3oWrBFfIv_kdmwJIirBKG3hAIx9Bm00\">\n\n<h6 id=\"⭐️-异步日志实现原理AsyncAppender\"><a href=\"#⭐️-异步日志实现原理AsyncAppender\" class=\"headerlink\" title=\"⭐️ 异步日志实现原理AsyncAppender\"></a>⭐️ 异步日志实现原理AsyncAppender</h6><p>logback异步输出日志是通过AsyncAppender实现的。AsyncAppender可以异步的记录 ILoggingEvents日志事件。<br><img src=\"/2024/04/10/2024-04-10-性能优化-日志优化/AsyncAppender.png\" alt=\"AsyncAppender\"><br>Logback的异步输出采用生产者消费者的模式，将生成的日志放入消息队列中，并将创建一个线程用于输出日志事件，有效的解决了这个问题，提高了程序的性能。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!-- 文件 异步日志(async) --&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;ASYNC_LOG&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot; &gt;</span><br><span class=\"line\">        &lt;!-- 不丢失日志.默认的256/5,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt;</span><br><span class=\"line\">        &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt;</span><br><span class=\"line\">        &lt;!-- 更改默认的队列的长度,默认值为256 --&gt;</span><br><span class=\"line\">        &lt;queueSize&gt;25&lt;/queueSize&gt;</span><br><span class=\"line\">        &lt;neverBlock&gt;false&lt;/neverBlock&gt;</span><br><span class=\"line\">        &lt;!-- 添加附加的appender,最多只能添加一个 --&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;fileLog&quot; /&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/04/10/2024-04-10-性能优化-日志优化/%E6%97%A5%E5%BF%97%E5%85%A5%E9%98%9F%E5%88%97%E6%B5%81%E7%A8%8B.png\" alt=\"日志入队列流程\"></p>\n<blockquote>\n<p>注意：写文件是异步线程，但是写queue是同步的，如果配置出现问题，也会导致工作线程阻塞。</p>\n</blockquote>\n<p>相关源码    </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logback中的异步输出日志使用了AsyncAppender这个appender，通过看AsyncAppender源码，跟到它的父类AsyncAppenderBase，</span><br><span class=\"line\"></span><br><span class=\"line\">可以看到它有几个重要的成员变量：</span><br><span class=\"line\">AppenderAttachableImpl&lt;E&gt; aai = new AppenderAttachableImpl&lt;E&gt;();</span><br><span class=\"line\">BlockingQueue&lt;E&gt; blockingQueue;</span><br><span class=\"line\">AsyncAppenderBase&lt;E&gt;.Worker worker = new AsyncAppenderBase.Worker();</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"三、日志配置错误案例\"><a href=\"#三、日志配置错误案例\" class=\"headerlink\" title=\"三、日志配置错误案例\"></a>三、日志配置错误案例</h3><h4 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h4><p>商品分布平台，经常触发磁盘利用率异常告警，错误如下：<br><img src=\"/2024/04/10/2024-04-10-性能优化-日志优化/%E7%A3%81%E7%9B%98%E5%88%A9%E7%94%A8%E7%8E%87.jpeg\" alt=\"磁盘利用率\"></p>\n<p>需要进入运维平台，手动清空日志，及缩小日志清理的时间。</p>\n<h4 id=\"⭐️-问题排查\"><a href=\"#⭐️-问题排查\" class=\"headerlink\" title=\"⭐️ 问题排查\"></a>⭐️ 问题排查</h4><ul>\n<li><p>为什么打印了这么多日志？  </p>\n<blockquote>\n<p>商品结构复杂，每次查询、操作都打印的话，会打印非常多的日志，磁盘占用也高。</p>\n</blockquote>\n</li>\n<li><p>机器配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CPU=8核</span><br><span class=\"line\">内存=16GB</span><br><span class=\"line\">磁盘=100GB</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>进入机器，查看应用的日志文件，发现应用的历史日志未清除，导致磁盘利用率高。</p>\n<ul>\n<li>查看logback配置<br>示例如下：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;appender name=&quot;DAILY_ROLLING_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;</span><br><span class=\"line\">        &lt;file&gt;application.log&lt;/file&gt;</span><br><span class=\"line\">        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;</span><br><span class=\"line\">            &lt;!-- 按天滚动 --&gt;</span><br><span class=\"line\">            &lt;fileNamePattern&gt;application-%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt;</span><br><span class=\"line\">            &lt;!-- 设置单个日志文件最大大小为 5GB --&gt;</span><br><span class=\"line\">            &lt;maxFileSize&gt;5GB&lt;/maxFileSize&gt;</span><br><span class=\"line\">        &lt;/rollingPolicy&gt;</span><br><span class=\"line\">        &lt;encoder&gt;</span><br><span class=\"line\">            &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt;</span><br><span class=\"line\">        &lt;/encoder&gt;</span><br><span class=\"line\">    &lt;/appender&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;root level=&quot;INFO&quot;&gt;</span><br><span class=\"line\">        &lt;appender-ref ref=&quot;DAILY_ROLLING_FILE&quot; /&gt;</span><br><span class=\"line\">    &lt;/root&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<blockquote>\n<p>错误1：单个文件5G，配置不正确。<br>错误2：没有配置日志保留时间。<br>错误3：未配置总日志文件大小限制。<br>错误4：未配置异步打印。</p>\n</blockquote>\n<ul>\n<li>优化<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;appender name=&quot;TRACE_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;</span><br><span class=\"line\">    &lt;file&gt;$&#123;PATH&#125;/trace.log&lt;/file&gt;</span><br><span class=\"line\">    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt;</span><br><span class=\"line\">        &lt;FileNamePattern&gt;$&#123;PATH&#125;/trace.%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/FileNamePattern&gt;</span><br><span class=\"line\">        &lt;!--保存多少天的日志--&gt;</span><br><span class=\"line\">        &lt;maxHistory&gt;7&lt;/maxHistory&gt;</span><br><span class=\"line\">        &lt;!--自定义日志总大小--&gt;</span><br><span class=\"line\">        &lt;totalSizeCap&gt;30G&lt;/totalSizeCap&gt;</span><br><span class=\"line\">        &lt;!--单个文件大小上限--&gt;</span><br><span class=\"line\">        &lt;maxFileSize&gt;300M&lt;/maxFileSize&gt;</span><br><span class=\"line\">        &lt;!--在只有设置为true并且 maxHistory 不为零才能起效。--&gt;</span><br><span class=\"line\">        &lt;cleanHistoryOnStart&gt;true&lt;/cleanHistoryOnStart&gt;</span><br><span class=\"line\">    &lt;/rollingPolicy&gt;</span><br><span class=\"line\">    &lt;!--输出格式--&gt;</span><br><span class=\"line\">    &lt;encoder&gt;</span><br><span class=\"line\">        &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %-5level %-50logger&#123;50&#125;:%-4line %green(%-8X&#123;UUID&#125;) %msg%n&lt;/pattern&gt;</span><br><span class=\"line\">        &lt;charset&gt;utf8&lt;/charset&gt;</span><br><span class=\"line\">    &lt;/encoder&gt;</span><br><span class=\"line\">&lt;/appender&gt;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>"},{"title":"《稳定性》线程池的“控”","date":"2024-06-03T02:00:00.000Z","_content":"\n    这是系统稳定性系列的第二篇文章，主要介绍的是通过监控系统的线程池状态来表现“控”。\n\n### 一、线程池监控\n团队专门做了稳定性专项，本文通过监控线程池来说明如何做高可用建设中的“控”。\n<!-- more -->\n![总监控](2024-06-03-稳定性-线程池监控/总监控.png)\n常规的线程池监控，监控项过少，无法展示线程池的更多数据，也无法监控独立线程池的状态。\n\n### 二、线程池监控的意义\n- 确保系统性能：资源利用优化 & 性能瓶颈检测。\n- 提高系统可靠性：故障预警 & 系统稳定性保障。\n- 便于系统调试和优化：问题排查 & 性能优化。\n\n\n\n### 三、线程池状态监控\n#### 3.1 如何监控运行数据\n这里提供两种常规思路：\n- 线程池运行时埋点，每一次运行任务都进行统计；\n- 定时获取线程池的运行数据。\n\n采用方案2：通过定时任务来获取\n```java\n/**\n * ThreadPoolMonitor 负责线程池与监控方法的管理；\n */\npublic class ThreadPoolMonitor {\n    //线程池集合\n    private static final Map<String, FutureWrapper> THREAD_POOL_MAP = new ConcurrentHashMap<>();\n    //定时任务线程池\n    private static final ScheduledThreadPoolExecutor SCHEDULE_THREAD_POOL = new ScheduledThreadPoolExecutor(8, new NamedThreadFactory(\"ThreadPoolMonitor\"));\n    private static final Long DEFAULT_MONITOR_PERIOD_TIME_MILLS = 1000L;\n    \n    //将线程池纳入监控\n    public static void monitor(String name, ThreadPoolExecutor threadPoolExecutor) {\n        if (threadPoolExecutor instanceof MonitoredThreadPoolExecutor) {\n            throw new IllegalArgumentException(\"MonitoredThreadPoolExecutor is already monitored.\");\n        } else {\n            monitor0(name, threadPoolExecutor, DEFAULT_MONITOR_PERIOD_TIME_MILLS);\n        }\n    }\n    /**\n     * 将线程池纳入监控\n     * @param threadPoolExecutor\n     */\n    static void monitor(MonitoredThreadPoolExecutor threadPoolExecutor) {\n        monitor0(threadPoolExecutor.poolName(), threadPoolExecutor, DEFAULT_MONITOR_PERIOD_TIME_MILLS);\n    }\n\n    private static void monitor0(String name, ThreadPoolExecutor threadPoolExecutor, long monitorPeriodTimeMills) {\n        PoolMonitorTask poolMonitorTask = new PoolMonitorTask(threadPoolExecutor, name);\n        THREAD_POOL_MAP.compute(name, (k, v) -> {\n            if (v == null) {\n                return new ThreadPoolMonitor.FutureWrapper(SCHEDULE_THREAD_POOL.scheduleWithFixedDelay(poolMonitorTask, 0L, monitorPeriodTimeMills, TimeUnit.MILLISECONDS), threadPoolExecutor);\n            } else {\n                throw new IllegalStateException(\"duplicate pool name: \" + name);\n            }\n        });\n    }\n\n    /**\n     * 封装线程池\n     */\n    static class FutureWrapper {\n        private final Future<?> future;\n        private final ThreadPoolExecutor threadPoolExecutor;\n\n        public FutureWrapper(Future<?> future, ThreadPoolExecutor threadPoolExecutor) {\n            this.future = future;\n            this.threadPoolExecutor = threadPoolExecutor;\n        }\n    }\n}\n```\n为什么不使用第一种方案？\n![ThreadPoolExecutor加锁](2024-06-03-稳定性-线程池监控/ThreadPoolExecutor加锁.png)\n性能差：ThreadPoolExecutor 提供了方法，例如获取当前线程数、活跃线程数、最大出现线程数、线程池任务完成总量 的线程池 API 会先获取到 mainLock，然后才开始计算。\n\n#### 3.2 监控的指标有哪些？\n> - **线程池当前负载：** 当前线程数 / 最大线程数\n> - **线程池峰值负载：** 当前线程数 / 最大线程数，线程池运行期间最大的负载\n> - **核心线程数：** 线程池的核心线程数\n> - **最大线程数：** 线程池限制同时存在的线程数\n> - **当前线程数：** 当前线程池的线程数\n> - **活跃线程数：** 执行任务的线程的大致数目\n> - **最大出现线程数：** 线程池中运行以来同时存在的最大线程数\n> - **阻塞队列：** 线程池暂存任务的容器\n> - **队列容量：** 队列中允许元素的最大数量\n> - **队列元素：** 队列中已存放的元素数量\n> - **队列剩余容量：** 队列中还可以存放的元素数量\n> - **线程池任务完成总量：** 已完成执行的任务的大致总数\n> - **拒绝策略执行次数：** 运行时抛出的拒绝次数总数\n\n这些指标可以帮助我们解决大多数因为线程池而导致的问题排查。\n\n#### 3.3 配置监控大盘\n配置大盘如下：\n![线程池监控大盘](2024-06-03-稳定性-线程池监控/线程池监控大盘.png)\n\n参考文章:  \n[线程池饱和异常](https://blog.csdn.net/bemavery/article/details/129809483)   \n[线程池如何监控，才能帮助开发者快速定位线上错误？](https://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&mid=2651509011&idx=1&sn=dec9cd01d0a8d891ea21dc6e05f5c9c0&chksm=bd25bd6c8a52347a5471e7fa4368155648baf694a8c0fc0910488dc7496fa95995712121eb77#rd)    \n[Java 线程池监控](https://www.renzhen.online/archives/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9B%91%E6%8E%A7)       ","source":"_posts/2024-06-03-稳定性-线程池监控.md","raw":"---\ntitle: 《稳定性》线程池的“控”\ndate: 2024-06-03 10:00:00\ncategories:\n  - [线程池]\n  - [高可用]\n  - [稳定性]\n---\n\n    这是系统稳定性系列的第二篇文章，主要介绍的是通过监控系统的线程池状态来表现“控”。\n\n### 一、线程池监控\n团队专门做了稳定性专项，本文通过监控线程池来说明如何做高可用建设中的“控”。\n<!-- more -->\n![总监控](2024-06-03-稳定性-线程池监控/总监控.png)\n常规的线程池监控，监控项过少，无法展示线程池的更多数据，也无法监控独立线程池的状态。\n\n### 二、线程池监控的意义\n- 确保系统性能：资源利用优化 & 性能瓶颈检测。\n- 提高系统可靠性：故障预警 & 系统稳定性保障。\n- 便于系统调试和优化：问题排查 & 性能优化。\n\n\n\n### 三、线程池状态监控\n#### 3.1 如何监控运行数据\n这里提供两种常规思路：\n- 线程池运行时埋点，每一次运行任务都进行统计；\n- 定时获取线程池的运行数据。\n\n采用方案2：通过定时任务来获取\n```java\n/**\n * ThreadPoolMonitor 负责线程池与监控方法的管理；\n */\npublic class ThreadPoolMonitor {\n    //线程池集合\n    private static final Map<String, FutureWrapper> THREAD_POOL_MAP = new ConcurrentHashMap<>();\n    //定时任务线程池\n    private static final ScheduledThreadPoolExecutor SCHEDULE_THREAD_POOL = new ScheduledThreadPoolExecutor(8, new NamedThreadFactory(\"ThreadPoolMonitor\"));\n    private static final Long DEFAULT_MONITOR_PERIOD_TIME_MILLS = 1000L;\n    \n    //将线程池纳入监控\n    public static void monitor(String name, ThreadPoolExecutor threadPoolExecutor) {\n        if (threadPoolExecutor instanceof MonitoredThreadPoolExecutor) {\n            throw new IllegalArgumentException(\"MonitoredThreadPoolExecutor is already monitored.\");\n        } else {\n            monitor0(name, threadPoolExecutor, DEFAULT_MONITOR_PERIOD_TIME_MILLS);\n        }\n    }\n    /**\n     * 将线程池纳入监控\n     * @param threadPoolExecutor\n     */\n    static void monitor(MonitoredThreadPoolExecutor threadPoolExecutor) {\n        monitor0(threadPoolExecutor.poolName(), threadPoolExecutor, DEFAULT_MONITOR_PERIOD_TIME_MILLS);\n    }\n\n    private static void monitor0(String name, ThreadPoolExecutor threadPoolExecutor, long monitorPeriodTimeMills) {\n        PoolMonitorTask poolMonitorTask = new PoolMonitorTask(threadPoolExecutor, name);\n        THREAD_POOL_MAP.compute(name, (k, v) -> {\n            if (v == null) {\n                return new ThreadPoolMonitor.FutureWrapper(SCHEDULE_THREAD_POOL.scheduleWithFixedDelay(poolMonitorTask, 0L, monitorPeriodTimeMills, TimeUnit.MILLISECONDS), threadPoolExecutor);\n            } else {\n                throw new IllegalStateException(\"duplicate pool name: \" + name);\n            }\n        });\n    }\n\n    /**\n     * 封装线程池\n     */\n    static class FutureWrapper {\n        private final Future<?> future;\n        private final ThreadPoolExecutor threadPoolExecutor;\n\n        public FutureWrapper(Future<?> future, ThreadPoolExecutor threadPoolExecutor) {\n            this.future = future;\n            this.threadPoolExecutor = threadPoolExecutor;\n        }\n    }\n}\n```\n为什么不使用第一种方案？\n![ThreadPoolExecutor加锁](2024-06-03-稳定性-线程池监控/ThreadPoolExecutor加锁.png)\n性能差：ThreadPoolExecutor 提供了方法，例如获取当前线程数、活跃线程数、最大出现线程数、线程池任务完成总量 的线程池 API 会先获取到 mainLock，然后才开始计算。\n\n#### 3.2 监控的指标有哪些？\n> - **线程池当前负载：** 当前线程数 / 最大线程数\n> - **线程池峰值负载：** 当前线程数 / 最大线程数，线程池运行期间最大的负载\n> - **核心线程数：** 线程池的核心线程数\n> - **最大线程数：** 线程池限制同时存在的线程数\n> - **当前线程数：** 当前线程池的线程数\n> - **活跃线程数：** 执行任务的线程的大致数目\n> - **最大出现线程数：** 线程池中运行以来同时存在的最大线程数\n> - **阻塞队列：** 线程池暂存任务的容器\n> - **队列容量：** 队列中允许元素的最大数量\n> - **队列元素：** 队列中已存放的元素数量\n> - **队列剩余容量：** 队列中还可以存放的元素数量\n> - **线程池任务完成总量：** 已完成执行的任务的大致总数\n> - **拒绝策略执行次数：** 运行时抛出的拒绝次数总数\n\n这些指标可以帮助我们解决大多数因为线程池而导致的问题排查。\n\n#### 3.3 配置监控大盘\n配置大盘如下：\n![线程池监控大盘](2024-06-03-稳定性-线程池监控/线程池监控大盘.png)\n\n参考文章:  \n[线程池饱和异常](https://blog.csdn.net/bemavery/article/details/129809483)   \n[线程池如何监控，才能帮助开发者快速定位线上错误？](https://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&mid=2651509011&idx=1&sn=dec9cd01d0a8d891ea21dc6e05f5c9c0&chksm=bd25bd6c8a52347a5471e7fa4368155648baf694a8c0fc0910488dc7496fa95995712121eb77#rd)    \n[Java 线程池监控](https://www.renzhen.online/archives/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9B%91%E6%8E%A7)       ","slug":"2024-06-03-稳定性-线程池监控","published":1,"updated":"2024-10-25T03:41:53.543Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxx004da13k59e5rrr2","content":"<pre><code>这是系统稳定性系列的第二篇文章，主要介绍的是通过监控系统的线程池状态来表现“控”。</code></pre><h3 id=\"一、线程池监控\"><a href=\"#一、线程池监控\" class=\"headerlink\" title=\"一、线程池监控\"></a>一、线程池监控</h3><p>团队专门做了稳定性专项，本文通过监控线程池来说明如何做高可用建设中的“控”。</p>\n<a id=\"more\"></a>\n<p><img src=\"/2024/06/03/2024-06-03-稳定性-线程池监控/%E6%80%BB%E7%9B%91%E6%8E%A7.png\" alt=\"总监控\"><br>常规的线程池监控，监控项过少，无法展示线程池的更多数据，也无法监控独立线程池的状态。</p>\n<h3 id=\"二、线程池监控的意义\"><a href=\"#二、线程池监控的意义\" class=\"headerlink\" title=\"二、线程池监控的意义\"></a>二、线程池监控的意义</h3><ul>\n<li>确保系统性能：资源利用优化 &amp; 性能瓶颈检测。</li>\n<li>提高系统可靠性：故障预警 &amp; 系统稳定性保障。</li>\n<li>便于系统调试和优化：问题排查 &amp; 性能优化。</li>\n</ul>\n<h3 id=\"三、线程池状态监控\"><a href=\"#三、线程池状态监控\" class=\"headerlink\" title=\"三、线程池状态监控\"></a>三、线程池状态监控</h3><h4 id=\"3-1-如何监控运行数据\"><a href=\"#3-1-如何监控运行数据\" class=\"headerlink\" title=\"3.1 如何监控运行数据\"></a>3.1 如何监控运行数据</h4><p>这里提供两种常规思路：</p>\n<ul>\n<li>线程池运行时埋点，每一次运行任务都进行统计；</li>\n<li>定时获取线程池的运行数据。</li>\n</ul>\n<p>采用方案2：通过定时任务来获取</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * ThreadPoolMonitor 负责线程池与监控方法的管理；</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ThreadPoolMonitor</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//线程池集合</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Map&lt;String, FutureWrapper&gt; THREAD_POOL_MAP = <span class=\"keyword\">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class=\"line\">    <span class=\"comment\">//定时任务线程池</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> ScheduledThreadPoolExecutor SCHEDULE_THREAD_POOL = <span class=\"keyword\">new</span> ScheduledThreadPoolExecutor(<span class=\"number\">8</span>, <span class=\"keyword\">new</span> NamedThreadFactory(<span class=\"string\">\"ThreadPoolMonitor\"</span>));</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Long DEFAULT_MONITOR_PERIOD_TIME_MILLS = <span class=\"number\">1000L</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//将线程池纳入监控</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">monitor</span><span class=\"params\">(String name, ThreadPoolExecutor threadPoolExecutor)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (threadPoolExecutor <span class=\"keyword\">instanceof</span> MonitoredThreadPoolExecutor) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(<span class=\"string\">\"MonitoredThreadPoolExecutor is already monitored.\"</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            monitor0(name, threadPoolExecutor, DEFAULT_MONITOR_PERIOD_TIME_MILLS);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 将线程池纳入监控</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> threadPoolExecutor</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">monitor</span><span class=\"params\">(MonitoredThreadPoolExecutor threadPoolExecutor)</span> </span>&#123;</span><br><span class=\"line\">        monitor0(threadPoolExecutor.poolName(), threadPoolExecutor, DEFAULT_MONITOR_PERIOD_TIME_MILLS);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">monitor0</span><span class=\"params\">(String name, ThreadPoolExecutor threadPoolExecutor, <span class=\"keyword\">long</span> monitorPeriodTimeMills)</span> </span>&#123;</span><br><span class=\"line\">        PoolMonitorTask poolMonitorTask = <span class=\"keyword\">new</span> PoolMonitorTask(threadPoolExecutor, name);</span><br><span class=\"line\">        THREAD_POOL_MAP.compute(name, (k, v) -&gt; &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (v == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> ThreadPoolMonitor.FutureWrapper(SCHEDULE_THREAD_POOL.scheduleWithFixedDelay(poolMonitorTask, <span class=\"number\">0L</span>, monitorPeriodTimeMills, TimeUnit.MILLISECONDS), threadPoolExecutor);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalStateException(<span class=\"string\">\"duplicate pool name: \"</span> + name);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 封装线程池</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FutureWrapper</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> Future&lt;?&gt; future;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> ThreadPoolExecutor threadPoolExecutor;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">FutureWrapper</span><span class=\"params\">(Future&lt;?&gt; future, ThreadPoolExecutor threadPoolExecutor)</span> </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.future = future;</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.threadPoolExecutor = threadPoolExecutor;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>为什么不使用第一种方案？<br><img src=\"/2024/06/03/2024-06-03-稳定性-线程池监控/ThreadPoolExecutor%E5%8A%A0%E9%94%81.png\" alt=\"ThreadPoolExecutor加锁\"><br>性能差：ThreadPoolExecutor 提供了方法，例如获取当前线程数、活跃线程数、最大出现线程数、线程池任务完成总量 的线程池 API 会先获取到 mainLock，然后才开始计算。</p>\n<h4 id=\"3-2-监控的指标有哪些？\"><a href=\"#3-2-监控的指标有哪些？\" class=\"headerlink\" title=\"3.2 监控的指标有哪些？\"></a>3.2 监控的指标有哪些？</h4><blockquote>\n<ul>\n<li><strong>线程池当前负载：</strong> 当前线程数 / 最大线程数</li>\n<li><strong>线程池峰值负载：</strong> 当前线程数 / 最大线程数，线程池运行期间最大的负载</li>\n<li><strong>核心线程数：</strong> 线程池的核心线程数</li>\n<li><strong>最大线程数：</strong> 线程池限制同时存在的线程数</li>\n<li><strong>当前线程数：</strong> 当前线程池的线程数</li>\n<li><strong>活跃线程数：</strong> 执行任务的线程的大致数目</li>\n<li><strong>最大出现线程数：</strong> 线程池中运行以来同时存在的最大线程数</li>\n<li><strong>阻塞队列：</strong> 线程池暂存任务的容器</li>\n<li><strong>队列容量：</strong> 队列中允许元素的最大数量</li>\n<li><strong>队列元素：</strong> 队列中已存放的元素数量</li>\n<li><strong>队列剩余容量：</strong> 队列中还可以存放的元素数量</li>\n<li><strong>线程池任务完成总量：</strong> 已完成执行的任务的大致总数</li>\n<li><strong>拒绝策略执行次数：</strong> 运行时抛出的拒绝次数总数</li>\n</ul>\n</blockquote>\n<p>这些指标可以帮助我们解决大多数因为线程池而导致的问题排查。</p>\n<h4 id=\"3-3-配置监控大盘\"><a href=\"#3-3-配置监控大盘\" class=\"headerlink\" title=\"3.3 配置监控大盘\"></a>3.3 配置监控大盘</h4><p>配置大盘如下：<br><img src=\"/2024/06/03/2024-06-03-稳定性-线程池监控/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9B%91%E6%8E%A7%E5%A4%A7%E7%9B%98.png\" alt=\"线程池监控大盘\"></p>\n<p>参考文章:<br><a href=\"https://blog.csdn.net/bemavery/article/details/129809483\" target=\"_blank\" rel=\"noopener\">线程池饱和异常</a><br><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&mid=2651509011&idx=1&sn=dec9cd01d0a8d891ea21dc6e05f5c9c0&chksm=bd25bd6c8a52347a5471e7fa4368155648baf694a8c0fc0910488dc7496fa95995712121eb77#rd\" target=\"_blank\" rel=\"noopener\">线程池如何监控，才能帮助开发者快速定位线上错误？</a><br><a href=\"https://www.renzhen.online/archives/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9B%91%E6%8E%A7\" target=\"_blank\" rel=\"noopener\">Java 线程池监控</a>       </p>\n","site":{"data":{}},"excerpt":"<pre><code>这是系统稳定性系列的第二篇文章，主要介绍的是通过监控系统的线程池状态来表现“控”。</code></pre><h3 id=\"一、线程池监控\"><a href=\"#一、线程池监控\" class=\"headerlink\" title=\"一、线程池监控\"></a>一、线程池监控</h3><p>团队专门做了稳定性专项，本文通过监控线程池来说明如何做高可用建设中的“控”。</p>","more":"<p><img src=\"/2024/06/03/2024-06-03-稳定性-线程池监控/%E6%80%BB%E7%9B%91%E6%8E%A7.png\" alt=\"总监控\"><br>常规的线程池监控，监控项过少，无法展示线程池的更多数据，也无法监控独立线程池的状态。</p>\n<h3 id=\"二、线程池监控的意义\"><a href=\"#二、线程池监控的意义\" class=\"headerlink\" title=\"二、线程池监控的意义\"></a>二、线程池监控的意义</h3><ul>\n<li>确保系统性能：资源利用优化 &amp; 性能瓶颈检测。</li>\n<li>提高系统可靠性：故障预警 &amp; 系统稳定性保障。</li>\n<li>便于系统调试和优化：问题排查 &amp; 性能优化。</li>\n</ul>\n<h3 id=\"三、线程池状态监控\"><a href=\"#三、线程池状态监控\" class=\"headerlink\" title=\"三、线程池状态监控\"></a>三、线程池状态监控</h3><h4 id=\"3-1-如何监控运行数据\"><a href=\"#3-1-如何监控运行数据\" class=\"headerlink\" title=\"3.1 如何监控运行数据\"></a>3.1 如何监控运行数据</h4><p>这里提供两种常规思路：</p>\n<ul>\n<li>线程池运行时埋点，每一次运行任务都进行统计；</li>\n<li>定时获取线程池的运行数据。</li>\n</ul>\n<p>采用方案2：通过定时任务来获取</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * ThreadPoolMonitor 负责线程池与监控方法的管理；</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ThreadPoolMonitor</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//线程池集合</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Map&lt;String, FutureWrapper&gt; THREAD_POOL_MAP = <span class=\"keyword\">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class=\"line\">    <span class=\"comment\">//定时任务线程池</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> ScheduledThreadPoolExecutor SCHEDULE_THREAD_POOL = <span class=\"keyword\">new</span> ScheduledThreadPoolExecutor(<span class=\"number\">8</span>, <span class=\"keyword\">new</span> NamedThreadFactory(<span class=\"string\">\"ThreadPoolMonitor\"</span>));</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Long DEFAULT_MONITOR_PERIOD_TIME_MILLS = <span class=\"number\">1000L</span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//将线程池纳入监控</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">monitor</span><span class=\"params\">(String name, ThreadPoolExecutor threadPoolExecutor)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (threadPoolExecutor <span class=\"keyword\">instanceof</span> MonitoredThreadPoolExecutor) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(<span class=\"string\">\"MonitoredThreadPoolExecutor is already monitored.\"</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            monitor0(name, threadPoolExecutor, DEFAULT_MONITOR_PERIOD_TIME_MILLS);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 将线程池纳入监控</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> threadPoolExecutor</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">monitor</span><span class=\"params\">(MonitoredThreadPoolExecutor threadPoolExecutor)</span> </span>&#123;</span><br><span class=\"line\">        monitor0(threadPoolExecutor.poolName(), threadPoolExecutor, DEFAULT_MONITOR_PERIOD_TIME_MILLS);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">monitor0</span><span class=\"params\">(String name, ThreadPoolExecutor threadPoolExecutor, <span class=\"keyword\">long</span> monitorPeriodTimeMills)</span> </span>&#123;</span><br><span class=\"line\">        PoolMonitorTask poolMonitorTask = <span class=\"keyword\">new</span> PoolMonitorTask(threadPoolExecutor, name);</span><br><span class=\"line\">        THREAD_POOL_MAP.compute(name, (k, v) -&gt; &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (v == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> ThreadPoolMonitor.FutureWrapper(SCHEDULE_THREAD_POOL.scheduleWithFixedDelay(poolMonitorTask, <span class=\"number\">0L</span>, monitorPeriodTimeMills, TimeUnit.MILLISECONDS), threadPoolExecutor);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalStateException(<span class=\"string\">\"duplicate pool name: \"</span> + name);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 封装线程池</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FutureWrapper</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> Future&lt;?&gt; future;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> ThreadPoolExecutor threadPoolExecutor;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">FutureWrapper</span><span class=\"params\">(Future&lt;?&gt; future, ThreadPoolExecutor threadPoolExecutor)</span> </span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.future = future;</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.threadPoolExecutor = threadPoolExecutor;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>为什么不使用第一种方案？<br><img src=\"/2024/06/03/2024-06-03-稳定性-线程池监控/ThreadPoolExecutor%E5%8A%A0%E9%94%81.png\" alt=\"ThreadPoolExecutor加锁\"><br>性能差：ThreadPoolExecutor 提供了方法，例如获取当前线程数、活跃线程数、最大出现线程数、线程池任务完成总量 的线程池 API 会先获取到 mainLock，然后才开始计算。</p>\n<h4 id=\"3-2-监控的指标有哪些？\"><a href=\"#3-2-监控的指标有哪些？\" class=\"headerlink\" title=\"3.2 监控的指标有哪些？\"></a>3.2 监控的指标有哪些？</h4><blockquote>\n<ul>\n<li><strong>线程池当前负载：</strong> 当前线程数 / 最大线程数</li>\n<li><strong>线程池峰值负载：</strong> 当前线程数 / 最大线程数，线程池运行期间最大的负载</li>\n<li><strong>核心线程数：</strong> 线程池的核心线程数</li>\n<li><strong>最大线程数：</strong> 线程池限制同时存在的线程数</li>\n<li><strong>当前线程数：</strong> 当前线程池的线程数</li>\n<li><strong>活跃线程数：</strong> 执行任务的线程的大致数目</li>\n<li><strong>最大出现线程数：</strong> 线程池中运行以来同时存在的最大线程数</li>\n<li><strong>阻塞队列：</strong> 线程池暂存任务的容器</li>\n<li><strong>队列容量：</strong> 队列中允许元素的最大数量</li>\n<li><strong>队列元素：</strong> 队列中已存放的元素数量</li>\n<li><strong>队列剩余容量：</strong> 队列中还可以存放的元素数量</li>\n<li><strong>线程池任务完成总量：</strong> 已完成执行的任务的大致总数</li>\n<li><strong>拒绝策略执行次数：</strong> 运行时抛出的拒绝次数总数</li>\n</ul>\n</blockquote>\n<p>这些指标可以帮助我们解决大多数因为线程池而导致的问题排查。</p>\n<h4 id=\"3-3-配置监控大盘\"><a href=\"#3-3-配置监控大盘\" class=\"headerlink\" title=\"3.3 配置监控大盘\"></a>3.3 配置监控大盘</h4><p>配置大盘如下：<br><img src=\"/2024/06/03/2024-06-03-稳定性-线程池监控/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9B%91%E6%8E%A7%E5%A4%A7%E7%9B%98.png\" alt=\"线程池监控大盘\"></p>\n<p>参考文章:<br><a href=\"https://blog.csdn.net/bemavery/article/details/129809483\" target=\"_blank\" rel=\"noopener\">线程池饱和异常</a><br><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&mid=2651509011&idx=1&sn=dec9cd01d0a8d891ea21dc6e05f5c9c0&chksm=bd25bd6c8a52347a5471e7fa4368155648baf694a8c0fc0910488dc7496fa95995712121eb77#rd\" target=\"_blank\" rel=\"noopener\">线程池如何监控，才能帮助开发者快速定位线上错误？</a><br><a href=\"https://www.renzhen.online/archives/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9B%91%E6%8E%A7\" target=\"_blank\" rel=\"noopener\">Java 线程池监控</a>       </p>"},{"title":"《系统重构》资产管理系统重构","date":"2024-05-04T02:00:00.000Z","_content":"\n    这是系统重构系列的第一篇文章，主要介绍的是美团资产管理系统的重构及分布式数据库的运用。\n\n### 一、背景\n资产管理系统，主要是对充电宝、优选物资、优选低值物资等资产完整生命周期的管理。\n\n- 资产新增、资产调整、资产重建、资产折旧、资产减值等。\n\n<!-- more -->\n为什么资产系统需要重新架构呢？\n- 产品层面：产品设计问题，导致报账不准确。\n- 性能问题：30W资产数据的操作，需要耗时1小时。\n- 大事务问题：导致数据库性能问题；数据一致性风险。\n- 数据量大：资产数据2KW，折旧数据数十亿，未做好分库分表。\n\n### 二、重构前准备\n- 规划阶段\n  - 明确目标：解决上面提到的问题。\n  - 评估现状：对现有系统进行全面的评估，包括代码质量、架构设计、数据库结构、性能瓶颈、可维护性等方面。了解系统的优势和不足，确定重构的重点和难点。\n  - 制定计划：\n    - 根据目标和现状评估，制定详细的重构计划。确定重构的范围、步骤、时间表、资源需求等。将重构任务分解为可管理的子任务，分配给相应的团队成员。\n    - 考虑到重构可能会对现有业务产生影响，制定合理的风险应对措施和回滚计划。\n- 准备阶段\n  - 建立测试环境\n  - 技术选型\n- 实施阶段\n  - 代码重构\n  - 数据库重构\n  - 性能优化\n- 测试\n- 监控和优化\n\n\n### 三、重构\n> 评估现状：\n- 代码质量差，可读性差，维护成本高。\n- 数据库结构未满足业务需求，性能差，可用性差。\n- 性能差。\n\n> 制定计划：\n- 重构范围：产品结构、数据模型。\n- 步骤确认：\n  - 方案设计：完整的一个详细设计过程。\n    - 系统架构：分层结构；技术选型；前后端交互；功能模块确认。\n    - 数据模型：实体；库表结构。\n    - 性能&稳定性&测试：\n  - 拆分任务：\n    - 数据库相关：数据库资源申请、库表创建、数据迁移。\n    - 编码相关：确定代码结构，设计模式等确认。\n    - 稳定性：监控大盘配置；\n- 时间规划：\n  - 确认任务的优先级，各任务的时长安排，deadline确认。\n\n\n**本文主要从系统编码重构、性能问题、大事务解决等方面进行讲解。**\n#### 系统架构\n技术架构简图：\n![技术架构](2024-05-04-系统重构-资产管理系统重构/技术架构.png)    \n内部的业务系统，业务比较简单，传统的MVC三层架构。\n\n##### 1 确定数据存储\n数据库性能问题，是需要着重解决的。使用的MySQL，资产存量2KW，其他数据数十亿。为了解决存储瓶颈、性能下降、扩展性等问题，考虑分库分表。  \n当时有2种方案：\n- MySQL分库分表。\n  - 优点：支持事务，性能高，开发人员对MySQL熟悉。\n  - 缺点：需要进行数据的迁移，没有现成工具，需要编码调试。\n- 使用分布式数据库blade。\n  - 优点：\n    - 自动扩容，不需要太考虑分库分表的容量问题。\n    - 支持事务，操作上和MySQL很相似，无太多学习成本。\n    - 丰富的数据结构，完善的数据迁移工具，成本低。\n  - 缺点：稳定性和性能上未知，需要测试。（blade团队说稳定性99.95）\n\n从业务特性、系统定位，在对blade进行测试后，性能、稳定性上能够满足要求，所以觉得使用blade分布式数据库。\n\n> 最终的结果是好的，满足了业务要求，节约了成本。使用上的问题在文章后面的章节进行说明。\n\n##### 2 确定代码结构\n> 使用传统的MVC三层架构，简单明了，参考下图：\n\n![技术架构](2024-05-04-系统重构-资产管理系统重构/MVC三层架构.png)\n\n> 大量使用设计模式\n\n策略模式&模板方法：针对资产的功能，创建策略；定义事件抽象类。\n```java\n//抽象类\npublic abstract class EventStrategy {\n    public String code;\n    public abstract void triggerEvent(EventSaveReqs eventSaveReqs);\n}\n//具体的实现\n@Component\npublic class AssetAddEventStrategy extends EventStrategy {\n  @Override\n  public void triggerEvent(EventSaveReqs eventSaveReqs) {\n    //具体的操作\n  }\n}\n```\n\n工厂模式：EventStrategyFactory\n```dtd\n//策略工厂\npublic class EventStrategyFactory {\n    private final Map<String, EventStrategy> strategyMap;\n    public EventStrategyFactory(List<EventStrategy> strategies) {\n        strategyMap = strategies.stream().collect(Collectors.toMap(EventStrategy::getCode, strategy -> strategy));\n    }\n    EventStrategy getStrategy(String code) {\n        return strategyMap.get(code);\n    }\n}\n//使用\nEventStrategyFactory.getStrategy(EventLargeCategoryEnum.IMPAIRMENT_ADD.getCode());\n//根据事件类型，选择合适的策略。\n```\n\n适配器：将资产操作适配成事件；将MQ消息适配成事件。\n```java\npublic class Adapter {\n    public EventInfo adapter(EventSaveReqs eventSaveReqs){\n        //\n    }\n}\n```\n\n责任链：资产的校验\n```java\n//定义处理器\npublic interface Handler {\n    void setNextHandler(Handler nextHandler);\n    void handleRequest(EventSaveReqs request);\n}\n//基础信息校验\npublic class BaseInfoHandlerImpl implements Handler {\n  private Handler nextHandler;\n\n  @Override\n  public void setNextHandler(Handler nextHandler) {\n    this.nextHandler = nextHandler;\n  }\n  @Override\n  public void handleRequest(EventSaveReqs request) {\n    if (request.getType().equals(\"type1\")) {\n      //基础信息的校验\n    } else if (nextHandler!= null) {\n      nextHandler.handleRequest(request);\n    } else {\n      System.out.println(\"没有处理者能处理该请求\");\n    }\n  }\n}\n```\n\n##### 3 大事务解决\n使用TransantionTemplate代替@Transaction方式，进行更精细化的事务操作。\n```java\ntransactionTemplate.execute(status -> {\n    // 可以在这里执行其他数据库操作，如果出现异常，事务会回滚\n    return null;\n});\n```\n\n##### 4 性能优化\n资产新增，excel导入30W数据，应用处理耗时1小时，也是一个非常重要的点，需要进行优化。\n```java\nList<Integer> originalList = List.of(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nList<List<Integer>> copyPartition = Lists.partition(originalList, 3);\nList<CompletableFuture<Object>> futureList = copyPartition.stream().map(subList ->\n        //任务传递给supplyAsync()方法，该任务将在ForkJoinPool.commonPool()中异步完成运行\n        //最后，supplyAsync()将返回新的CompletableFuture，其值是通过调用给定的Supplier所获得的值。\n        CompletableFuture.supplyAsync(() -> {\n                    log.info(\"处理第{}段数据开始\", n);\n                    return checkAndBuildEvent(baseMessageMap, subList, totalCheckedMap, mis);\n                }, importForkJoinPool)\n                //thenApplyAsync()方法，从supplyAsync()获得的参数传递来执行给定的函数\n                .thenApplyAsync(eventSaveReqs -> {\n                            try {\n                                EventStrategyFactory.getStrategy(EventLargeCategoryEnum.ADD.getCode()).triggerEvent(eventSaveReqs);\n                                totalCheckedMap.get(BaseConstants.SUC_LIST).addAll(subList);\n                            } catch (Exception e) {\n                                log.error(\"新建失败\", e);\n                                subList.forEach(importDto -> {\n                                    importDto.setFailReason(\"新建入库失败\");\n                                });\n                                totalCheckedMap.get(BaseConstants.FAIL_LIST).addAll(subList);\n                            }\n                            log.info(\"处理第{}段数据开始\", n);\n                            return null;\n                        },\n                        queryForkJoinPool\n                )\n).collect(toList());\nfutureList.stream().map(CompletableFuture::join).collect(Collectors.toList());\n```\n通过并发的方式，优化到了2分钟。\n\n### 四、分布式数据库\n美团内部的blade分布式数据库，内部是基于TiDB进行内部定制化后的产品。\n\n- 使用注意事项：\n  - 事务失败：当写并发较大时，随着数据的不断插入和更新，Region 中的数据量会逐渐增加。当 Region 中的数据量超过一定阈值时，TiDB 会自动触发 Region 分裂，将一个大的 Region 分裂成两个较小的 Region，此时会导致事务操作失败，所以需要业务做兜底，进行重试操作。\n  - 大事务问题：客户端 commit 之前写入数据都在内存里面，TiDB 内存暴涨，一不小心就会 OOM，建议每 100～500 行写入一个事务。\n  - 使用场景：在数据一致性上，并不适合交易场景。","source":"_posts/2024-05-04-系统重构-资产管理系统重构.md","raw":"---\ntitle: 《系统重构》资产管理系统重构\ndate: 2024-05-04 10:00:00\ncategories:\n  - [数据库, 分布式数据库]\n  - [系统重构]\n  - [美团]\ntags:\n- 美团\n---\n\n    这是系统重构系列的第一篇文章，主要介绍的是美团资产管理系统的重构及分布式数据库的运用。\n\n### 一、背景\n资产管理系统，主要是对充电宝、优选物资、优选低值物资等资产完整生命周期的管理。\n\n- 资产新增、资产调整、资产重建、资产折旧、资产减值等。\n\n<!-- more -->\n为什么资产系统需要重新架构呢？\n- 产品层面：产品设计问题，导致报账不准确。\n- 性能问题：30W资产数据的操作，需要耗时1小时。\n- 大事务问题：导致数据库性能问题；数据一致性风险。\n- 数据量大：资产数据2KW，折旧数据数十亿，未做好分库分表。\n\n### 二、重构前准备\n- 规划阶段\n  - 明确目标：解决上面提到的问题。\n  - 评估现状：对现有系统进行全面的评估，包括代码质量、架构设计、数据库结构、性能瓶颈、可维护性等方面。了解系统的优势和不足，确定重构的重点和难点。\n  - 制定计划：\n    - 根据目标和现状评估，制定详细的重构计划。确定重构的范围、步骤、时间表、资源需求等。将重构任务分解为可管理的子任务，分配给相应的团队成员。\n    - 考虑到重构可能会对现有业务产生影响，制定合理的风险应对措施和回滚计划。\n- 准备阶段\n  - 建立测试环境\n  - 技术选型\n- 实施阶段\n  - 代码重构\n  - 数据库重构\n  - 性能优化\n- 测试\n- 监控和优化\n\n\n### 三、重构\n> 评估现状：\n- 代码质量差，可读性差，维护成本高。\n- 数据库结构未满足业务需求，性能差，可用性差。\n- 性能差。\n\n> 制定计划：\n- 重构范围：产品结构、数据模型。\n- 步骤确认：\n  - 方案设计：完整的一个详细设计过程。\n    - 系统架构：分层结构；技术选型；前后端交互；功能模块确认。\n    - 数据模型：实体；库表结构。\n    - 性能&稳定性&测试：\n  - 拆分任务：\n    - 数据库相关：数据库资源申请、库表创建、数据迁移。\n    - 编码相关：确定代码结构，设计模式等确认。\n    - 稳定性：监控大盘配置；\n- 时间规划：\n  - 确认任务的优先级，各任务的时长安排，deadline确认。\n\n\n**本文主要从系统编码重构、性能问题、大事务解决等方面进行讲解。**\n#### 系统架构\n技术架构简图：\n![技术架构](2024-05-04-系统重构-资产管理系统重构/技术架构.png)    \n内部的业务系统，业务比较简单，传统的MVC三层架构。\n\n##### 1 确定数据存储\n数据库性能问题，是需要着重解决的。使用的MySQL，资产存量2KW，其他数据数十亿。为了解决存储瓶颈、性能下降、扩展性等问题，考虑分库分表。  \n当时有2种方案：\n- MySQL分库分表。\n  - 优点：支持事务，性能高，开发人员对MySQL熟悉。\n  - 缺点：需要进行数据的迁移，没有现成工具，需要编码调试。\n- 使用分布式数据库blade。\n  - 优点：\n    - 自动扩容，不需要太考虑分库分表的容量问题。\n    - 支持事务，操作上和MySQL很相似，无太多学习成本。\n    - 丰富的数据结构，完善的数据迁移工具，成本低。\n  - 缺点：稳定性和性能上未知，需要测试。（blade团队说稳定性99.95）\n\n从业务特性、系统定位，在对blade进行测试后，性能、稳定性上能够满足要求，所以觉得使用blade分布式数据库。\n\n> 最终的结果是好的，满足了业务要求，节约了成本。使用上的问题在文章后面的章节进行说明。\n\n##### 2 确定代码结构\n> 使用传统的MVC三层架构，简单明了，参考下图：\n\n![技术架构](2024-05-04-系统重构-资产管理系统重构/MVC三层架构.png)\n\n> 大量使用设计模式\n\n策略模式&模板方法：针对资产的功能，创建策略；定义事件抽象类。\n```java\n//抽象类\npublic abstract class EventStrategy {\n    public String code;\n    public abstract void triggerEvent(EventSaveReqs eventSaveReqs);\n}\n//具体的实现\n@Component\npublic class AssetAddEventStrategy extends EventStrategy {\n  @Override\n  public void triggerEvent(EventSaveReqs eventSaveReqs) {\n    //具体的操作\n  }\n}\n```\n\n工厂模式：EventStrategyFactory\n```dtd\n//策略工厂\npublic class EventStrategyFactory {\n    private final Map<String, EventStrategy> strategyMap;\n    public EventStrategyFactory(List<EventStrategy> strategies) {\n        strategyMap = strategies.stream().collect(Collectors.toMap(EventStrategy::getCode, strategy -> strategy));\n    }\n    EventStrategy getStrategy(String code) {\n        return strategyMap.get(code);\n    }\n}\n//使用\nEventStrategyFactory.getStrategy(EventLargeCategoryEnum.IMPAIRMENT_ADD.getCode());\n//根据事件类型，选择合适的策略。\n```\n\n适配器：将资产操作适配成事件；将MQ消息适配成事件。\n```java\npublic class Adapter {\n    public EventInfo adapter(EventSaveReqs eventSaveReqs){\n        //\n    }\n}\n```\n\n责任链：资产的校验\n```java\n//定义处理器\npublic interface Handler {\n    void setNextHandler(Handler nextHandler);\n    void handleRequest(EventSaveReqs request);\n}\n//基础信息校验\npublic class BaseInfoHandlerImpl implements Handler {\n  private Handler nextHandler;\n\n  @Override\n  public void setNextHandler(Handler nextHandler) {\n    this.nextHandler = nextHandler;\n  }\n  @Override\n  public void handleRequest(EventSaveReqs request) {\n    if (request.getType().equals(\"type1\")) {\n      //基础信息的校验\n    } else if (nextHandler!= null) {\n      nextHandler.handleRequest(request);\n    } else {\n      System.out.println(\"没有处理者能处理该请求\");\n    }\n  }\n}\n```\n\n##### 3 大事务解决\n使用TransantionTemplate代替@Transaction方式，进行更精细化的事务操作。\n```java\ntransactionTemplate.execute(status -> {\n    // 可以在这里执行其他数据库操作，如果出现异常，事务会回滚\n    return null;\n});\n```\n\n##### 4 性能优化\n资产新增，excel导入30W数据，应用处理耗时1小时，也是一个非常重要的点，需要进行优化。\n```java\nList<Integer> originalList = List.of(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nList<List<Integer>> copyPartition = Lists.partition(originalList, 3);\nList<CompletableFuture<Object>> futureList = copyPartition.stream().map(subList ->\n        //任务传递给supplyAsync()方法，该任务将在ForkJoinPool.commonPool()中异步完成运行\n        //最后，supplyAsync()将返回新的CompletableFuture，其值是通过调用给定的Supplier所获得的值。\n        CompletableFuture.supplyAsync(() -> {\n                    log.info(\"处理第{}段数据开始\", n);\n                    return checkAndBuildEvent(baseMessageMap, subList, totalCheckedMap, mis);\n                }, importForkJoinPool)\n                //thenApplyAsync()方法，从supplyAsync()获得的参数传递来执行给定的函数\n                .thenApplyAsync(eventSaveReqs -> {\n                            try {\n                                EventStrategyFactory.getStrategy(EventLargeCategoryEnum.ADD.getCode()).triggerEvent(eventSaveReqs);\n                                totalCheckedMap.get(BaseConstants.SUC_LIST).addAll(subList);\n                            } catch (Exception e) {\n                                log.error(\"新建失败\", e);\n                                subList.forEach(importDto -> {\n                                    importDto.setFailReason(\"新建入库失败\");\n                                });\n                                totalCheckedMap.get(BaseConstants.FAIL_LIST).addAll(subList);\n                            }\n                            log.info(\"处理第{}段数据开始\", n);\n                            return null;\n                        },\n                        queryForkJoinPool\n                )\n).collect(toList());\nfutureList.stream().map(CompletableFuture::join).collect(Collectors.toList());\n```\n通过并发的方式，优化到了2分钟。\n\n### 四、分布式数据库\n美团内部的blade分布式数据库，内部是基于TiDB进行内部定制化后的产品。\n\n- 使用注意事项：\n  - 事务失败：当写并发较大时，随着数据的不断插入和更新，Region 中的数据量会逐渐增加。当 Region 中的数据量超过一定阈值时，TiDB 会自动触发 Region 分裂，将一个大的 Region 分裂成两个较小的 Region，此时会导致事务操作失败，所以需要业务做兜底，进行重试操作。\n  - 大事务问题：客户端 commit 之前写入数据都在内存里面，TiDB 内存暴涨，一不小心就会 OOM，建议每 100～500 行写入一个事务。\n  - 使用场景：在数据一致性上，并不适合交易场景。","slug":"2024-05-04-系统重构-资产管理系统重构","published":1,"updated":"2024-12-09T03:26:17.258Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxy004ga13kaa80yl72","content":"<pre><code>这是系统重构系列的第一篇文章，主要介绍的是美团资产管理系统的重构及分布式数据库的运用。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>资产管理系统，主要是对充电宝、优选物资、优选低值物资等资产完整生命周期的管理。</p>\n<ul>\n<li>资产新增、资产调整、资产重建、资产折旧、资产减值等。</li>\n</ul>\n<a id=\"more\"></a>\n<p>为什么资产系统需要重新架构呢？</p>\n<ul>\n<li>产品层面：产品设计问题，导致报账不准确。</li>\n<li>性能问题：30W资产数据的操作，需要耗时1小时。</li>\n<li>大事务问题：导致数据库性能问题；数据一致性风险。</li>\n<li>数据量大：资产数据2KW，折旧数据数十亿，未做好分库分表。</li>\n</ul>\n<h3 id=\"二、重构前准备\"><a href=\"#二、重构前准备\" class=\"headerlink\" title=\"二、重构前准备\"></a>二、重构前准备</h3><ul>\n<li>规划阶段<ul>\n<li>明确目标：解决上面提到的问题。</li>\n<li>评估现状：对现有系统进行全面的评估，包括代码质量、架构设计、数据库结构、性能瓶颈、可维护性等方面。了解系统的优势和不足，确定重构的重点和难点。</li>\n<li>制定计划：<ul>\n<li>根据目标和现状评估，制定详细的重构计划。确定重构的范围、步骤、时间表、资源需求等。将重构任务分解为可管理的子任务，分配给相应的团队成员。</li>\n<li>考虑到重构可能会对现有业务产生影响，制定合理的风险应对措施和回滚计划。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>准备阶段<ul>\n<li>建立测试环境</li>\n<li>技术选型</li>\n</ul>\n</li>\n<li>实施阶段<ul>\n<li>代码重构</li>\n<li>数据库重构</li>\n<li>性能优化</li>\n</ul>\n</li>\n<li>测试</li>\n<li>监控和优化</li>\n</ul>\n<h3 id=\"三、重构\"><a href=\"#三、重构\" class=\"headerlink\" title=\"三、重构\"></a>三、重构</h3><blockquote>\n<p>评估现状：</p>\n<ul>\n<li>代码质量差，可读性差，维护成本高。</li>\n<li>数据库结构未满足业务需求，性能差，可用性差。</li>\n<li>性能差。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>制定计划：</p>\n<ul>\n<li>重构范围：产品结构、数据模型。</li>\n<li>步骤确认：<ul>\n<li>方案设计：完整的一个详细设计过程。<ul>\n<li>系统架构：分层结构；技术选型；前后端交互；功能模块确认。</li>\n<li>数据模型：实体；库表结构。</li>\n<li>性能&amp;稳定性&amp;测试：</li>\n</ul>\n</li>\n<li>拆分任务：<ul>\n<li>数据库相关：数据库资源申请、库表创建、数据迁移。</li>\n<li>编码相关：确定代码结构，设计模式等确认。</li>\n<li>稳定性：监控大盘配置；</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>时间规划：<ul>\n<li>确认任务的优先级，各任务的时长安排，deadline确认。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<p><strong>本文主要从系统编码重构、性能问题、大事务解决等方面进行讲解。</strong></p>\n<h4 id=\"系统架构\"><a href=\"#系统架构\" class=\"headerlink\" title=\"系统架构\"></a>系统架构</h4><p>技术架构简图：<br><img src=\"/2024/05/04/2024-05-04-系统重构-资产管理系统重构/%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84.png\" alt=\"技术架构\"><br>内部的业务系统，业务比较简单，传统的MVC三层架构。</p>\n<h5 id=\"1-确定数据存储\"><a href=\"#1-确定数据存储\" class=\"headerlink\" title=\"1 确定数据存储\"></a>1 确定数据存储</h5><p>数据库性能问题，是需要着重解决的。使用的MySQL，资产存量2KW，其他数据数十亿。为了解决存储瓶颈、性能下降、扩展性等问题，考虑分库分表。<br>当时有2种方案：</p>\n<ul>\n<li>MySQL分库分表。<ul>\n<li>优点：支持事务，性能高，开发人员对MySQL熟悉。</li>\n<li>缺点：需要进行数据的迁移，没有现成工具，需要编码调试。</li>\n</ul>\n</li>\n<li>使用分布式数据库blade。<ul>\n<li>优点：<ul>\n<li>自动扩容，不需要太考虑分库分表的容量问题。</li>\n<li>支持事务，操作上和MySQL很相似，无太多学习成本。</li>\n<li>丰富的数据结构，完善的数据迁移工具，成本低。</li>\n</ul>\n</li>\n<li>缺点：稳定性和性能上未知，需要测试。（blade团队说稳定性99.95）</li>\n</ul>\n</li>\n</ul>\n<p>从业务特性、系统定位，在对blade进行测试后，性能、稳定性上能够满足要求，所以觉得使用blade分布式数据库。</p>\n<blockquote>\n<p>最终的结果是好的，满足了业务要求，节约了成本。使用上的问题在文章后面的章节进行说明。</p>\n</blockquote>\n<h5 id=\"2-确定代码结构\"><a href=\"#2-确定代码结构\" class=\"headerlink\" title=\"2 确定代码结构\"></a>2 确定代码结构</h5><blockquote>\n<p>使用传统的MVC三层架构，简单明了，参考下图：</p>\n</blockquote>\n<p><img src=\"/2024/05/04/2024-05-04-系统重构-资产管理系统重构/MVC%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84.png\" alt=\"技术架构\"></p>\n<blockquote>\n<p>大量使用设计模式</p>\n</blockquote>\n<p>策略模式&amp;模板方法：针对资产的功能，创建策略；定义事件抽象类。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//抽象类</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EventStrategy</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> String code;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> <span class=\"keyword\">void</span> <span class=\"title\">triggerEvent</span><span class=\"params\">(EventSaveReqs eventSaveReqs)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//具体的实现</span></span><br><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AssetAddEventStrategy</span> <span class=\"keyword\">extends</span> <span class=\"title\">EventStrategy</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"meta\">@Override</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">triggerEvent</span><span class=\"params\">(EventSaveReqs eventSaveReqs)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//具体的操作</span></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>工厂模式：EventStrategyFactory</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//策略工厂</span><br><span class=\"line\">public class EventStrategyFactory &#123;</span><br><span class=\"line\">    private final Map&lt;String, EventStrategy&gt; strategyMap;</span><br><span class=\"line\">    public EventStrategyFactory(List&lt;EventStrategy&gt; strategies) &#123;</span><br><span class=\"line\">        strategyMap = strategies.stream().collect(Collectors.toMap(EventStrategy::getCode, strategy -&gt; strategy));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    EventStrategy getStrategy(String code) &#123;</span><br><span class=\"line\">        return strategyMap.get(code);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//使用</span><br><span class=\"line\">EventStrategyFactory.getStrategy(EventLargeCategoryEnum.IMPAIRMENT_ADD.getCode());</span><br><span class=\"line\">//根据事件类型，选择合适的策略。</span><br></pre></td></tr></table></figure>\n\n<p>适配器：将资产操作适配成事件；将MQ消息适配成事件。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Adapter</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> EventInfo <span class=\"title\">adapter</span><span class=\"params\">(EventSaveReqs eventSaveReqs)</span></span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>责任链：资产的校验</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//定义处理器</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Handler</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">setNextHandler</span><span class=\"params\">(Handler nextHandler)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">handleRequest</span><span class=\"params\">(EventSaveReqs request)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//基础信息校验</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BaseInfoHandlerImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">Handler</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> Handler nextHandler;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"meta\">@Override</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setNextHandler</span><span class=\"params\">(Handler nextHandler)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">this</span>.nextHandler = nextHandler;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"meta\">@Override</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">handleRequest</span><span class=\"params\">(EventSaveReqs request)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (request.getType().equals(<span class=\"string\">\"type1\"</span>)) &#123;</span><br><span class=\"line\">      <span class=\"comment\">//基础信息的校验</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (nextHandler!= <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">      nextHandler.handleRequest(request);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">      System.out.println(<span class=\"string\">\"没有处理者能处理该请求\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"3-大事务解决\"><a href=\"#3-大事务解决\" class=\"headerlink\" title=\"3 大事务解决\"></a>3 大事务解决</h5><p>使用TransantionTemplate代替@Transaction方式，进行更精细化的事务操作。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">transactionTemplate.execute(status -&gt; &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 可以在这里执行其他数据库操作，如果出现异常，事务会回滚</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"4-性能优化\"><a href=\"#4-性能优化\" class=\"headerlink\" title=\"4 性能优化\"></a>4 性能优化</h5><p>资产新增，excel导入30W数据，应用处理耗时1小时，也是一个非常重要的点，需要进行优化。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Integer&gt; originalList = List.of(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>);</span><br><span class=\"line\">List&lt;List&lt;Integer&gt;&gt; copyPartition = Lists.partition(originalList, <span class=\"number\">3</span>);</span><br><span class=\"line\">List&lt;CompletableFuture&lt;Object&gt;&gt; futureList = copyPartition.stream().map(subList -&gt;</span><br><span class=\"line\">        <span class=\"comment\">//任务传递给supplyAsync()方法，该任务将在ForkJoinPool.commonPool()中异步完成运行</span></span><br><span class=\"line\">        <span class=\"comment\">//最后，supplyAsync()将返回新的CompletableFuture，其值是通过调用给定的Supplier所获得的值。</span></span><br><span class=\"line\">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class=\"line\">                    log.info(<span class=\"string\">\"处理第&#123;&#125;段数据开始\"</span>, n);</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> checkAndBuildEvent(baseMessageMap, subList, totalCheckedMap, mis);</span><br><span class=\"line\">                &#125;, importForkJoinPool)</span><br><span class=\"line\">                <span class=\"comment\">//thenApplyAsync()方法，从supplyAsync()获得的参数传递来执行给定的函数</span></span><br><span class=\"line\">                .thenApplyAsync(eventSaveReqs -&gt; &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                                EventStrategyFactory.getStrategy(EventLargeCategoryEnum.ADD.getCode()).triggerEvent(eventSaveReqs);</span><br><span class=\"line\">                                totalCheckedMap.get(BaseConstants.SUC_LIST).addAll(subList);</span><br><span class=\"line\">                            &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                                log.error(<span class=\"string\">\"新建失败\"</span>, e);</span><br><span class=\"line\">                                subList.forEach(importDto -&gt; &#123;</span><br><span class=\"line\">                                    importDto.setFailReason(<span class=\"string\">\"新建入库失败\"</span>);</span><br><span class=\"line\">                                &#125;);</span><br><span class=\"line\">                                totalCheckedMap.get(BaseConstants.FAIL_LIST).addAll(subList);</span><br><span class=\"line\">                            &#125;</span><br><span class=\"line\">                            log.info(<span class=\"string\">\"处理第&#123;&#125;段数据开始\"</span>, n);</span><br><span class=\"line\">                            <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        queryForkJoinPool</span><br><span class=\"line\">                )</span><br><span class=\"line\">).collect(toList());</span><br><span class=\"line\">futureList.stream().map(CompletableFuture::join).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>\n\n<p>通过并发的方式，优化到了2分钟。</p>\n<h3 id=\"四、分布式数据库\"><a href=\"#四、分布式数据库\" class=\"headerlink\" title=\"四、分布式数据库\"></a>四、分布式数据库</h3><p>美团内部的blade分布式数据库，内部是基于TiDB进行内部定制化后的产品。</p>\n<ul>\n<li>使用注意事项：<ul>\n<li>事务失败：当写并发较大时，随着数据的不断插入和更新，Region 中的数据量会逐渐增加。当 Region 中的数据量超过一定阈值时，TiDB 会自动触发 Region 分裂，将一个大的 Region 分裂成两个较小的 Region，此时会导致事务操作失败，所以需要业务做兜底，进行重试操作。</li>\n<li>大事务问题：客户端 commit 之前写入数据都在内存里面，TiDB 内存暴涨，一不小心就会 OOM，建议每 100～500 行写入一个事务。</li>\n<li>使用场景：在数据一致性上，并不适合交易场景。</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<pre><code>这是系统重构系列的第一篇文章，主要介绍的是美团资产管理系统的重构及分布式数据库的运用。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>资产管理系统，主要是对充电宝、优选物资、优选低值物资等资产完整生命周期的管理。</p>\n<ul>\n<li>资产新增、资产调整、资产重建、资产折旧、资产减值等。</li>\n</ul>","more":"<p>为什么资产系统需要重新架构呢？</p>\n<ul>\n<li>产品层面：产品设计问题，导致报账不准确。</li>\n<li>性能问题：30W资产数据的操作，需要耗时1小时。</li>\n<li>大事务问题：导致数据库性能问题；数据一致性风险。</li>\n<li>数据量大：资产数据2KW，折旧数据数十亿，未做好分库分表。</li>\n</ul>\n<h3 id=\"二、重构前准备\"><a href=\"#二、重构前准备\" class=\"headerlink\" title=\"二、重构前准备\"></a>二、重构前准备</h3><ul>\n<li>规划阶段<ul>\n<li>明确目标：解决上面提到的问题。</li>\n<li>评估现状：对现有系统进行全面的评估，包括代码质量、架构设计、数据库结构、性能瓶颈、可维护性等方面。了解系统的优势和不足，确定重构的重点和难点。</li>\n<li>制定计划：<ul>\n<li>根据目标和现状评估，制定详细的重构计划。确定重构的范围、步骤、时间表、资源需求等。将重构任务分解为可管理的子任务，分配给相应的团队成员。</li>\n<li>考虑到重构可能会对现有业务产生影响，制定合理的风险应对措施和回滚计划。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>准备阶段<ul>\n<li>建立测试环境</li>\n<li>技术选型</li>\n</ul>\n</li>\n<li>实施阶段<ul>\n<li>代码重构</li>\n<li>数据库重构</li>\n<li>性能优化</li>\n</ul>\n</li>\n<li>测试</li>\n<li>监控和优化</li>\n</ul>\n<h3 id=\"三、重构\"><a href=\"#三、重构\" class=\"headerlink\" title=\"三、重构\"></a>三、重构</h3><blockquote>\n<p>评估现状：</p>\n<ul>\n<li>代码质量差，可读性差，维护成本高。</li>\n<li>数据库结构未满足业务需求，性能差，可用性差。</li>\n<li>性能差。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>制定计划：</p>\n<ul>\n<li>重构范围：产品结构、数据模型。</li>\n<li>步骤确认：<ul>\n<li>方案设计：完整的一个详细设计过程。<ul>\n<li>系统架构：分层结构；技术选型；前后端交互；功能模块确认。</li>\n<li>数据模型：实体；库表结构。</li>\n<li>性能&amp;稳定性&amp;测试：</li>\n</ul>\n</li>\n<li>拆分任务：<ul>\n<li>数据库相关：数据库资源申请、库表创建、数据迁移。</li>\n<li>编码相关：确定代码结构，设计模式等确认。</li>\n<li>稳定性：监控大盘配置；</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>时间规划：<ul>\n<li>确认任务的优先级，各任务的时长安排，deadline确认。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<p><strong>本文主要从系统编码重构、性能问题、大事务解决等方面进行讲解。</strong></p>\n<h4 id=\"系统架构\"><a href=\"#系统架构\" class=\"headerlink\" title=\"系统架构\"></a>系统架构</h4><p>技术架构简图：<br><img src=\"/2024/05/04/2024-05-04-系统重构-资产管理系统重构/%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84.png\" alt=\"技术架构\"><br>内部的业务系统，业务比较简单，传统的MVC三层架构。</p>\n<h5 id=\"1-确定数据存储\"><a href=\"#1-确定数据存储\" class=\"headerlink\" title=\"1 确定数据存储\"></a>1 确定数据存储</h5><p>数据库性能问题，是需要着重解决的。使用的MySQL，资产存量2KW，其他数据数十亿。为了解决存储瓶颈、性能下降、扩展性等问题，考虑分库分表。<br>当时有2种方案：</p>\n<ul>\n<li>MySQL分库分表。<ul>\n<li>优点：支持事务，性能高，开发人员对MySQL熟悉。</li>\n<li>缺点：需要进行数据的迁移，没有现成工具，需要编码调试。</li>\n</ul>\n</li>\n<li>使用分布式数据库blade。<ul>\n<li>优点：<ul>\n<li>自动扩容，不需要太考虑分库分表的容量问题。</li>\n<li>支持事务，操作上和MySQL很相似，无太多学习成本。</li>\n<li>丰富的数据结构，完善的数据迁移工具，成本低。</li>\n</ul>\n</li>\n<li>缺点：稳定性和性能上未知，需要测试。（blade团队说稳定性99.95）</li>\n</ul>\n</li>\n</ul>\n<p>从业务特性、系统定位，在对blade进行测试后，性能、稳定性上能够满足要求，所以觉得使用blade分布式数据库。</p>\n<blockquote>\n<p>最终的结果是好的，满足了业务要求，节约了成本。使用上的问题在文章后面的章节进行说明。</p>\n</blockquote>\n<h5 id=\"2-确定代码结构\"><a href=\"#2-确定代码结构\" class=\"headerlink\" title=\"2 确定代码结构\"></a>2 确定代码结构</h5><blockquote>\n<p>使用传统的MVC三层架构，简单明了，参考下图：</p>\n</blockquote>\n<p><img src=\"/2024/05/04/2024-05-04-系统重构-资产管理系统重构/MVC%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84.png\" alt=\"技术架构\"></p>\n<blockquote>\n<p>大量使用设计模式</p>\n</blockquote>\n<p>策略模式&amp;模板方法：针对资产的功能，创建策略；定义事件抽象类。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//抽象类</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">EventStrategy</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> String code;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> <span class=\"keyword\">void</span> <span class=\"title\">triggerEvent</span><span class=\"params\">(EventSaveReqs eventSaveReqs)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//具体的实现</span></span><br><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AssetAddEventStrategy</span> <span class=\"keyword\">extends</span> <span class=\"title\">EventStrategy</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"meta\">@Override</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">triggerEvent</span><span class=\"params\">(EventSaveReqs eventSaveReqs)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//具体的操作</span></span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>工厂模式：EventStrategyFactory</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//策略工厂</span><br><span class=\"line\">public class EventStrategyFactory &#123;</span><br><span class=\"line\">    private final Map&lt;String, EventStrategy&gt; strategyMap;</span><br><span class=\"line\">    public EventStrategyFactory(List&lt;EventStrategy&gt; strategies) &#123;</span><br><span class=\"line\">        strategyMap = strategies.stream().collect(Collectors.toMap(EventStrategy::getCode, strategy -&gt; strategy));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    EventStrategy getStrategy(String code) &#123;</span><br><span class=\"line\">        return strategyMap.get(code);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//使用</span><br><span class=\"line\">EventStrategyFactory.getStrategy(EventLargeCategoryEnum.IMPAIRMENT_ADD.getCode());</span><br><span class=\"line\">//根据事件类型，选择合适的策略。</span><br></pre></td></tr></table></figure>\n\n<p>适配器：将资产操作适配成事件；将MQ消息适配成事件。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Adapter</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> EventInfo <span class=\"title\">adapter</span><span class=\"params\">(EventSaveReqs eventSaveReqs)</span></span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>责任链：资产的校验</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//定义处理器</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Handler</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">setNextHandler</span><span class=\"params\">(Handler nextHandler)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">handleRequest</span><span class=\"params\">(EventSaveReqs request)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//基础信息校验</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BaseInfoHandlerImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">Handler</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> Handler nextHandler;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"meta\">@Override</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setNextHandler</span><span class=\"params\">(Handler nextHandler)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">this</span>.nextHandler = nextHandler;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"meta\">@Override</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">handleRequest</span><span class=\"params\">(EventSaveReqs request)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (request.getType().equals(<span class=\"string\">\"type1\"</span>)) &#123;</span><br><span class=\"line\">      <span class=\"comment\">//基础信息的校验</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (nextHandler!= <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">      nextHandler.handleRequest(request);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">      System.out.println(<span class=\"string\">\"没有处理者能处理该请求\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"3-大事务解决\"><a href=\"#3-大事务解决\" class=\"headerlink\" title=\"3 大事务解决\"></a>3 大事务解决</h5><p>使用TransantionTemplate代替@Transaction方式，进行更精细化的事务操作。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">transactionTemplate.execute(status -&gt; &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 可以在这里执行其他数据库操作，如果出现异常，事务会回滚</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"4-性能优化\"><a href=\"#4-性能优化\" class=\"headerlink\" title=\"4 性能优化\"></a>4 性能优化</h5><p>资产新增，excel导入30W数据，应用处理耗时1小时，也是一个非常重要的点，需要进行优化。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Integer&gt; originalList = List.of(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>, <span class=\"number\">10</span>);</span><br><span class=\"line\">List&lt;List&lt;Integer&gt;&gt; copyPartition = Lists.partition(originalList, <span class=\"number\">3</span>);</span><br><span class=\"line\">List&lt;CompletableFuture&lt;Object&gt;&gt; futureList = copyPartition.stream().map(subList -&gt;</span><br><span class=\"line\">        <span class=\"comment\">//任务传递给supplyAsync()方法，该任务将在ForkJoinPool.commonPool()中异步完成运行</span></span><br><span class=\"line\">        <span class=\"comment\">//最后，supplyAsync()将返回新的CompletableFuture，其值是通过调用给定的Supplier所获得的值。</span></span><br><span class=\"line\">        CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class=\"line\">                    log.info(<span class=\"string\">\"处理第&#123;&#125;段数据开始\"</span>, n);</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> checkAndBuildEvent(baseMessageMap, subList, totalCheckedMap, mis);</span><br><span class=\"line\">                &#125;, importForkJoinPool)</span><br><span class=\"line\">                <span class=\"comment\">//thenApplyAsync()方法，从supplyAsync()获得的参数传递来执行给定的函数</span></span><br><span class=\"line\">                .thenApplyAsync(eventSaveReqs -&gt; &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                                EventStrategyFactory.getStrategy(EventLargeCategoryEnum.ADD.getCode()).triggerEvent(eventSaveReqs);</span><br><span class=\"line\">                                totalCheckedMap.get(BaseConstants.SUC_LIST).addAll(subList);</span><br><span class=\"line\">                            &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">                                log.error(<span class=\"string\">\"新建失败\"</span>, e);</span><br><span class=\"line\">                                subList.forEach(importDto -&gt; &#123;</span><br><span class=\"line\">                                    importDto.setFailReason(<span class=\"string\">\"新建入库失败\"</span>);</span><br><span class=\"line\">                                &#125;);</span><br><span class=\"line\">                                totalCheckedMap.get(BaseConstants.FAIL_LIST).addAll(subList);</span><br><span class=\"line\">                            &#125;</span><br><span class=\"line\">                            log.info(<span class=\"string\">\"处理第&#123;&#125;段数据开始\"</span>, n);</span><br><span class=\"line\">                            <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                        &#125;,</span><br><span class=\"line\">                        queryForkJoinPool</span><br><span class=\"line\">                )</span><br><span class=\"line\">).collect(toList());</span><br><span class=\"line\">futureList.stream().map(CompletableFuture::join).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>\n\n<p>通过并发的方式，优化到了2分钟。</p>\n<h3 id=\"四、分布式数据库\"><a href=\"#四、分布式数据库\" class=\"headerlink\" title=\"四、分布式数据库\"></a>四、分布式数据库</h3><p>美团内部的blade分布式数据库，内部是基于TiDB进行内部定制化后的产品。</p>\n<ul>\n<li>使用注意事项：<ul>\n<li>事务失败：当写并发较大时，随着数据的不断插入和更新，Region 中的数据量会逐渐增加。当 Region 中的数据量超过一定阈值时，TiDB 会自动触发 Region 分裂，将一个大的 Region 分裂成两个较小的 Region，此时会导致事务操作失败，所以需要业务做兜底，进行重试操作。</li>\n<li>大事务问题：客户端 commit 之前写入数据都在内存里面，TiDB 内存暴涨，一不小心就会 OOM，建议每 100～500 行写入一个事务。</li>\n<li>使用场景：在数据一致性上，并不适合交易场景。</li>\n</ul>\n</li>\n</ul>"},{"title":"《Linux》CPU负载和利用率","date":"2024-06-05T02:00:00.000Z","_content":"\n    讲解负载和利用率。\n\n### 一、什么是CPU负载和利用率\n#### 1 [CPU负载](https://scoutapm.com/blog/understanding-load-averages)\n![CPU负载](2024-06-05-Linux-CPU负载和利用率/cpu负载.png)\n> **CPU负载：** CPU 负载考虑了正在使用 CPU 的进程以及等待 CPU 资源的进程。即使 CPU 使用率不高，如果有很多进程在等待 CPU，负载也可能较高。\n<!-- more -->\n- Load averages值在0.00-1的范围内(不包含1)：CPU正常运行这个是比较好的情况，桥上的车没有拥堵，没达到最大承受\n- Load averages值在1：表明CPU满负荷运行，桥上的车没有拥堵，达到了最大承受\n- Load averages值大于1：标明CPU超负荷运行， 桥上的车已经达到最大的承受，同时开始在桥的入口处开始堵车\n> Tips：上面说的是单核单线程的情况下，如果是多核多线程情况Load averages值就不是1了，例如我现在这个CPU8核16线程那么Load averages=16算是满负荷运行。\n\n#### 2 CPU利用率\n> **CPU利用率：** 是指在一段时间内 CPU 被占用的时间比例。它直接反映了 CPU 资源的实际使用情况。\n\n![CPU利用率](2024-06-05-Linux-CPU负载和利用率/CPU利用率.png)\n\n#### 3 示例\n双核CPU。\n![CPU负载示例](2024-06-05-Linux-CPU负载和利用率/CPU负载示例.png)\n> - CPU 负载[Load Avg]: 10.73, 6.80, 5.89\n    >   - 分别代表过去 1 分钟、5 分钟和 15 分钟的平均负载。\n>   - 分析平均负载：对于双核 CPU，理想状态下平均负载为 2 表示两个核心刚好满负荷。这里的数值明显高于双核满负荷状态，说明系统中有较多的进程在等待 CPU 资源，系统可能面临一定的压力。\n> - CPU 使用率[CPU usage]: 11.26% user, 11.95% sys, 76.78% idle\n    >   - 用户态 CPU 使用率（user）：表示用户空间的进程所占用的 CPU 时间比例。\n>   - 系统态 CPU 使用率（sys）：代表内核空间的进程所占用的 CPU 时间比例。\n>   - 空闲 CPU 使用率（idle）：表明 CPU 处于空闲状态的时间比例。\n>   - 分析 CPU 使用率：虽然目前 CPU 实际使用的比例不高，但较高的平均负载表明系统可能存在一些进程在排队等待 CPU 处理，或者可能有一些突发的高负载任务在某些时间段出现，导致平均负载升高。\n\n\n两者关系：\n- 一般情况下，当 CPU 使用率高时，负载也可能较高，因为有很多进程在使用 CPU，同时可能还有其他进程在等待 CPU。\n- 负载高并不一定意味着 CPU 使用率高。可能有很多进程在等待其他资源（如 I/O、内存等），而不是 CPU，导致负载升高但 CPU 使用率不高。\n  - 负载高而 CPU 利用率不高可能有以下原因：\n    - I/O 密集型任务：大量等待 I/O 操作\n    - 进程频繁切换：\n      - 主动切换：指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换\n      - 被动切换：进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。\n    - 资源竞争和等待\n\n### 二、对线程池容量规划的影响\n#### 2.1、CPU 利用率的影响\n- 低 CPU 利用率\n  - 如果 CPU 利用率较低，说明当前系统的计算资源未得到充分利用。在这种情况下，可以考虑适当增加线程池的容量。\n- 高 CPU 利用率\n  - 当 CPU 利用率过高时，可能会导致系统响应变慢，甚至出现卡顿或崩溃的情况。此时，不宜再增加线程池的容量，反而可能需要考虑减小线程池的大小或者优化任务的执行效率。\n\n#### 2.2、CPU 负载的影响\n- 低平均负载\n  - 如果系统的平均负载较低，说明系统中的任务数量相对较少，或者系统有足够的资源来处理当前的任务。在这种情况下，可以根据任务的特点和预期的负载增长来规划线程池的容量。\n- 高平均负载\n  - 当平均负载较高时，意味着系统中有较多的任务在等待处理，或者系统资源紧张。此时，需要谨慎调整线程池的容量。\n> **如果平均负载高但 CPU 利用率不高：** 可能是由于 I/O 等待等原因导致任务堆积。此时，可以考虑增加线程池的容量，以提高系统的并发处理能力，减少任务的等待时间。但要注意不要过度增加线程池的大小，以免导致资源竞争加剧和系统性能下降。\n> **如果平均负载高且 CPU 利用率也高：** 说明系统已经处于高负荷状态。此时，增加线程池的容量可能会进一步加重 CPU 负载，导致系统性能恶化。应该首先分析任务的执行情况，优化任务的执行效率，或者考虑增加硬件资源来缓解系统压力。\n\n参考文章：   \n[线程池的数量和线程池中线程数量如何设置-理论篇](https://juejin.cn/post/7066675779966337031)     \n[线程池的数量和线程池中线程数量如何设置-实践篇](https://juejin.cn/post/7067183465224994852)     \n[了解 Linux CPU 负载——什么时候应该担心？](https://scoutapm.com/blog/understanding-load-averages)\n","source":"_posts/2024-06-05-Linux-CPU负载和利用率.md","raw":"---\ntitle: 《Linux》CPU负载和利用率\ndate: 2024-06-05 10:00:00\ncategories:\n  - [linux]\n  - [线程池]\n---\n\n    讲解负载和利用率。\n\n### 一、什么是CPU负载和利用率\n#### 1 [CPU负载](https://scoutapm.com/blog/understanding-load-averages)\n![CPU负载](2024-06-05-Linux-CPU负载和利用率/cpu负载.png)\n> **CPU负载：** CPU 负载考虑了正在使用 CPU 的进程以及等待 CPU 资源的进程。即使 CPU 使用率不高，如果有很多进程在等待 CPU，负载也可能较高。\n<!-- more -->\n- Load averages值在0.00-1的范围内(不包含1)：CPU正常运行这个是比较好的情况，桥上的车没有拥堵，没达到最大承受\n- Load averages值在1：表明CPU满负荷运行，桥上的车没有拥堵，达到了最大承受\n- Load averages值大于1：标明CPU超负荷运行， 桥上的车已经达到最大的承受，同时开始在桥的入口处开始堵车\n> Tips：上面说的是单核单线程的情况下，如果是多核多线程情况Load averages值就不是1了，例如我现在这个CPU8核16线程那么Load averages=16算是满负荷运行。\n\n#### 2 CPU利用率\n> **CPU利用率：** 是指在一段时间内 CPU 被占用的时间比例。它直接反映了 CPU 资源的实际使用情况。\n\n![CPU利用率](2024-06-05-Linux-CPU负载和利用率/CPU利用率.png)\n\n#### 3 示例\n双核CPU。\n![CPU负载示例](2024-06-05-Linux-CPU负载和利用率/CPU负载示例.png)\n> - CPU 负载[Load Avg]: 10.73, 6.80, 5.89\n    >   - 分别代表过去 1 分钟、5 分钟和 15 分钟的平均负载。\n>   - 分析平均负载：对于双核 CPU，理想状态下平均负载为 2 表示两个核心刚好满负荷。这里的数值明显高于双核满负荷状态，说明系统中有较多的进程在等待 CPU 资源，系统可能面临一定的压力。\n> - CPU 使用率[CPU usage]: 11.26% user, 11.95% sys, 76.78% idle\n    >   - 用户态 CPU 使用率（user）：表示用户空间的进程所占用的 CPU 时间比例。\n>   - 系统态 CPU 使用率（sys）：代表内核空间的进程所占用的 CPU 时间比例。\n>   - 空闲 CPU 使用率（idle）：表明 CPU 处于空闲状态的时间比例。\n>   - 分析 CPU 使用率：虽然目前 CPU 实际使用的比例不高，但较高的平均负载表明系统可能存在一些进程在排队等待 CPU 处理，或者可能有一些突发的高负载任务在某些时间段出现，导致平均负载升高。\n\n\n两者关系：\n- 一般情况下，当 CPU 使用率高时，负载也可能较高，因为有很多进程在使用 CPU，同时可能还有其他进程在等待 CPU。\n- 负载高并不一定意味着 CPU 使用率高。可能有很多进程在等待其他资源（如 I/O、内存等），而不是 CPU，导致负载升高但 CPU 使用率不高。\n  - 负载高而 CPU 利用率不高可能有以下原因：\n    - I/O 密集型任务：大量等待 I/O 操作\n    - 进程频繁切换：\n      - 主动切换：指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换\n      - 被动切换：进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。\n    - 资源竞争和等待\n\n### 二、对线程池容量规划的影响\n#### 2.1、CPU 利用率的影响\n- 低 CPU 利用率\n  - 如果 CPU 利用率较低，说明当前系统的计算资源未得到充分利用。在这种情况下，可以考虑适当增加线程池的容量。\n- 高 CPU 利用率\n  - 当 CPU 利用率过高时，可能会导致系统响应变慢，甚至出现卡顿或崩溃的情况。此时，不宜再增加线程池的容量，反而可能需要考虑减小线程池的大小或者优化任务的执行效率。\n\n#### 2.2、CPU 负载的影响\n- 低平均负载\n  - 如果系统的平均负载较低，说明系统中的任务数量相对较少，或者系统有足够的资源来处理当前的任务。在这种情况下，可以根据任务的特点和预期的负载增长来规划线程池的容量。\n- 高平均负载\n  - 当平均负载较高时，意味着系统中有较多的任务在等待处理，或者系统资源紧张。此时，需要谨慎调整线程池的容量。\n> **如果平均负载高但 CPU 利用率不高：** 可能是由于 I/O 等待等原因导致任务堆积。此时，可以考虑增加线程池的容量，以提高系统的并发处理能力，减少任务的等待时间。但要注意不要过度增加线程池的大小，以免导致资源竞争加剧和系统性能下降。\n> **如果平均负载高且 CPU 利用率也高：** 说明系统已经处于高负荷状态。此时，增加线程池的容量可能会进一步加重 CPU 负载，导致系统性能恶化。应该首先分析任务的执行情况，优化任务的执行效率，或者考虑增加硬件资源来缓解系统压力。\n\n参考文章：   \n[线程池的数量和线程池中线程数量如何设置-理论篇](https://juejin.cn/post/7066675779966337031)     \n[线程池的数量和线程池中线程数量如何设置-实践篇](https://juejin.cn/post/7067183465224994852)     \n[了解 Linux CPU 负载——什么时候应该担心？](https://scoutapm.com/blog/understanding-load-averages)\n","slug":"2024-06-05-Linux-CPU负载和利用率","published":1,"updated":"2024-12-09T03:22:53.878Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnxz004ka13ku8ndbm3h","content":"<pre><code>讲解负载和利用率。</code></pre><h3 id=\"一、什么是CPU负载和利用率\"><a href=\"#一、什么是CPU负载和利用率\" class=\"headerlink\" title=\"一、什么是CPU负载和利用率\"></a>一、什么是CPU负载和利用率</h3><h4 id=\"1-CPU负载\"><a href=\"#1-CPU负载\" class=\"headerlink\" title=\"1 CPU负载\"></a>1 <a href=\"https://scoutapm.com/blog/understanding-load-averages\" target=\"_blank\" rel=\"noopener\">CPU负载</a></h4><p><img src=\"/2024/06/05/2024-06-05-Linux-CPU负载和利用率/cpu%E8%B4%9F%E8%BD%BD.png\" alt=\"CPU负载\"></p>\n<blockquote>\n<p><strong>CPU负载：</strong> CPU 负载考虑了正在使用 CPU 的进程以及等待 CPU 资源的进程。即使 CPU 使用率不高，如果有很多进程在等待 CPU，负载也可能较高。</p>\n</blockquote>\n<a id=\"more\"></a>\n<ul>\n<li>Load averages值在0.00-1的范围内(不包含1)：CPU正常运行这个是比较好的情况，桥上的车没有拥堵，没达到最大承受</li>\n<li>Load averages值在1：表明CPU满负荷运行，桥上的车没有拥堵，达到了最大承受</li>\n<li>Load averages值大于1：标明CPU超负荷运行， 桥上的车已经达到最大的承受，同时开始在桥的入口处开始堵车<blockquote>\n<p>Tips：上面说的是单核单线程的情况下，如果是多核多线程情况Load averages值就不是1了，例如我现在这个CPU8核16线程那么Load averages=16算是满负荷运行。</p>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"2-CPU利用率\"><a href=\"#2-CPU利用率\" class=\"headerlink\" title=\"2 CPU利用率\"></a>2 CPU利用率</h4><blockquote>\n<p><strong>CPU利用率：</strong> 是指在一段时间内 CPU 被占用的时间比例。它直接反映了 CPU 资源的实际使用情况。</p>\n</blockquote>\n<p><img src=\"/2024/06/05/2024-06-05-Linux-CPU负载和利用率/CPU%E5%88%A9%E7%94%A8%E7%8E%87.png\" alt=\"CPU利用率\"></p>\n<h4 id=\"3-示例\"><a href=\"#3-示例\" class=\"headerlink\" title=\"3 示例\"></a>3 示例</h4><p>双核CPU。<br><img src=\"/2024/06/05/2024-06-05-Linux-CPU负载和利用率/CPU%E8%B4%9F%E8%BD%BD%E7%A4%BA%E4%BE%8B.png\" alt=\"CPU负载示例\"></p>\n<blockquote>\n<ul>\n<li>CPU 负载[Load Avg]: 10.73, 6.80, 5.89<ul>\n<li>分别代表过去 1 分钟、5 分钟和 15 分钟的平均负载。</li>\n<li>分析平均负载：对于双核 CPU，理想状态下平均负载为 2 表示两个核心刚好满负荷。这里的数值明显高于双核满负荷状态，说明系统中有较多的进程在等待 CPU 资源，系统可能面临一定的压力。</li>\n</ul>\n</li>\n<li>CPU 使用率[CPU usage]: 11.26% user, 11.95% sys, 76.78% idle<ul>\n<li>用户态 CPU 使用率（user）：表示用户空间的进程所占用的 CPU 时间比例。</li>\n<li>系统态 CPU 使用率（sys）：代表内核空间的进程所占用的 CPU 时间比例。</li>\n<li>空闲 CPU 使用率（idle）：表明 CPU 处于空闲状态的时间比例。</li>\n<li>分析 CPU 使用率：虽然目前 CPU 实际使用的比例不高，但较高的平均负载表明系统可能存在一些进程在排队等待 CPU 处理，或者可能有一些突发的高负载任务在某些时间段出现，导致平均负载升高。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<p>两者关系：</p>\n<ul>\n<li>一般情况下，当 CPU 使用率高时，负载也可能较高，因为有很多进程在使用 CPU，同时可能还有其他进程在等待 CPU。</li>\n<li>负载高并不一定意味着 CPU 使用率高。可能有很多进程在等待其他资源（如 I/O、内存等），而不是 CPU，导致负载升高但 CPU 使用率不高。<ul>\n<li>负载高而 CPU 利用率不高可能有以下原因：<ul>\n<li>I/O 密集型任务：大量等待 I/O 操作</li>\n<li>进程频繁切换：<ul>\n<li>主动切换：指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换</li>\n<li>被动切换：进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。</li>\n</ul>\n</li>\n<li>资源竞争和等待</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"二、对线程池容量规划的影响\"><a href=\"#二、对线程池容量规划的影响\" class=\"headerlink\" title=\"二、对线程池容量规划的影响\"></a>二、对线程池容量规划的影响</h3><h4 id=\"2-1、CPU-利用率的影响\"><a href=\"#2-1、CPU-利用率的影响\" class=\"headerlink\" title=\"2.1、CPU 利用率的影响\"></a>2.1、CPU 利用率的影响</h4><ul>\n<li>低 CPU 利用率<ul>\n<li>如果 CPU 利用率较低，说明当前系统的计算资源未得到充分利用。在这种情况下，可以考虑适当增加线程池的容量。</li>\n</ul>\n</li>\n<li>高 CPU 利用率<ul>\n<li>当 CPU 利用率过高时，可能会导致系统响应变慢，甚至出现卡顿或崩溃的情况。此时，不宜再增加线程池的容量，反而可能需要考虑减小线程池的大小或者优化任务的执行效率。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-2、CPU-负载的影响\"><a href=\"#2-2、CPU-负载的影响\" class=\"headerlink\" title=\"2.2、CPU 负载的影响\"></a>2.2、CPU 负载的影响</h4><ul>\n<li>低平均负载<ul>\n<li>如果系统的平均负载较低，说明系统中的任务数量相对较少，或者系统有足够的资源来处理当前的任务。在这种情况下，可以根据任务的特点和预期的负载增长来规划线程池的容量。</li>\n</ul>\n</li>\n<li>高平均负载<ul>\n<li>当平均负载较高时，意味着系统中有较多的任务在等待处理，或者系统资源紧张。此时，需要谨慎调整线程池的容量。<blockquote>\n<p><strong>如果平均负载高但 CPU 利用率不高：</strong> 可能是由于 I/O 等待等原因导致任务堆积。此时，可以考虑增加线程池的容量，以提高系统的并发处理能力，减少任务的等待时间。但要注意不要过度增加线程池的大小，以免导致资源竞争加剧和系统性能下降。<br><strong>如果平均负载高且 CPU 利用率也高：</strong> 说明系统已经处于高负荷状态。此时，增加线程池的容量可能会进一步加重 CPU 负载，导致系统性能恶化。应该首先分析任务的执行情况，优化任务的执行效率，或者考虑增加硬件资源来缓解系统压力。</p>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<p>参考文章：<br><a href=\"https://juejin.cn/post/7066675779966337031\" target=\"_blank\" rel=\"noopener\">线程池的数量和线程池中线程数量如何设置-理论篇</a><br><a href=\"https://juejin.cn/post/7067183465224994852\" target=\"_blank\" rel=\"noopener\">线程池的数量和线程池中线程数量如何设置-实践篇</a><br><a href=\"https://scoutapm.com/blog/understanding-load-averages\" target=\"_blank\" rel=\"noopener\">了解 Linux CPU 负载——什么时候应该担心？</a></p>\n","site":{"data":{}},"excerpt":"<pre><code>讲解负载和利用率。</code></pre><h3 id=\"一、什么是CPU负载和利用率\"><a href=\"#一、什么是CPU负载和利用率\" class=\"headerlink\" title=\"一、什么是CPU负载和利用率\"></a>一、什么是CPU负载和利用率</h3><h4 id=\"1-CPU负载\"><a href=\"#1-CPU负载\" class=\"headerlink\" title=\"1 CPU负载\"></a>1 <a href=\"https://scoutapm.com/blog/understanding-load-averages\" target=\"_blank\" rel=\"noopener\">CPU负载</a></h4><p><img src=\"/2024/06/05/2024-06-05-Linux-CPU负载和利用率/cpu%E8%B4%9F%E8%BD%BD.png\" alt=\"CPU负载\"></p>\n<blockquote>\n<p><strong>CPU负载：</strong> CPU 负载考虑了正在使用 CPU 的进程以及等待 CPU 资源的进程。即使 CPU 使用率不高，如果有很多进程在等待 CPU，负载也可能较高。</p>\n</blockquote>","more":"<ul>\n<li>Load averages值在0.00-1的范围内(不包含1)：CPU正常运行这个是比较好的情况，桥上的车没有拥堵，没达到最大承受</li>\n<li>Load averages值在1：表明CPU满负荷运行，桥上的车没有拥堵，达到了最大承受</li>\n<li>Load averages值大于1：标明CPU超负荷运行， 桥上的车已经达到最大的承受，同时开始在桥的入口处开始堵车<blockquote>\n<p>Tips：上面说的是单核单线程的情况下，如果是多核多线程情况Load averages值就不是1了，例如我现在这个CPU8核16线程那么Load averages=16算是满负荷运行。</p>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"2-CPU利用率\"><a href=\"#2-CPU利用率\" class=\"headerlink\" title=\"2 CPU利用率\"></a>2 CPU利用率</h4><blockquote>\n<p><strong>CPU利用率：</strong> 是指在一段时间内 CPU 被占用的时间比例。它直接反映了 CPU 资源的实际使用情况。</p>\n</blockquote>\n<p><img src=\"/2024/06/05/2024-06-05-Linux-CPU负载和利用率/CPU%E5%88%A9%E7%94%A8%E7%8E%87.png\" alt=\"CPU利用率\"></p>\n<h4 id=\"3-示例\"><a href=\"#3-示例\" class=\"headerlink\" title=\"3 示例\"></a>3 示例</h4><p>双核CPU。<br><img src=\"/2024/06/05/2024-06-05-Linux-CPU负载和利用率/CPU%E8%B4%9F%E8%BD%BD%E7%A4%BA%E4%BE%8B.png\" alt=\"CPU负载示例\"></p>\n<blockquote>\n<ul>\n<li>CPU 负载[Load Avg]: 10.73, 6.80, 5.89<ul>\n<li>分别代表过去 1 分钟、5 分钟和 15 分钟的平均负载。</li>\n<li>分析平均负载：对于双核 CPU，理想状态下平均负载为 2 表示两个核心刚好满负荷。这里的数值明显高于双核满负荷状态，说明系统中有较多的进程在等待 CPU 资源，系统可能面临一定的压力。</li>\n</ul>\n</li>\n<li>CPU 使用率[CPU usage]: 11.26% user, 11.95% sys, 76.78% idle<ul>\n<li>用户态 CPU 使用率（user）：表示用户空间的进程所占用的 CPU 时间比例。</li>\n<li>系统态 CPU 使用率（sys）：代表内核空间的进程所占用的 CPU 时间比例。</li>\n<li>空闲 CPU 使用率（idle）：表明 CPU 处于空闲状态的时间比例。</li>\n<li>分析 CPU 使用率：虽然目前 CPU 实际使用的比例不高，但较高的平均负载表明系统可能存在一些进程在排队等待 CPU 处理，或者可能有一些突发的高负载任务在某些时间段出现，导致平均负载升高。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<p>两者关系：</p>\n<ul>\n<li>一般情况下，当 CPU 使用率高时，负载也可能较高，因为有很多进程在使用 CPU，同时可能还有其他进程在等待 CPU。</li>\n<li>负载高并不一定意味着 CPU 使用率高。可能有很多进程在等待其他资源（如 I/O、内存等），而不是 CPU，导致负载升高但 CPU 使用率不高。<ul>\n<li>负载高而 CPU 利用率不高可能有以下原因：<ul>\n<li>I/O 密集型任务：大量等待 I/O 操作</li>\n<li>进程频繁切换：<ul>\n<li>主动切换：指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换</li>\n<li>被动切换：进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。</li>\n</ul>\n</li>\n<li>资源竞争和等待</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"二、对线程池容量规划的影响\"><a href=\"#二、对线程池容量规划的影响\" class=\"headerlink\" title=\"二、对线程池容量规划的影响\"></a>二、对线程池容量规划的影响</h3><h4 id=\"2-1、CPU-利用率的影响\"><a href=\"#2-1、CPU-利用率的影响\" class=\"headerlink\" title=\"2.1、CPU 利用率的影响\"></a>2.1、CPU 利用率的影响</h4><ul>\n<li>低 CPU 利用率<ul>\n<li>如果 CPU 利用率较低，说明当前系统的计算资源未得到充分利用。在这种情况下，可以考虑适当增加线程池的容量。</li>\n</ul>\n</li>\n<li>高 CPU 利用率<ul>\n<li>当 CPU 利用率过高时，可能会导致系统响应变慢，甚至出现卡顿或崩溃的情况。此时，不宜再增加线程池的容量，反而可能需要考虑减小线程池的大小或者优化任务的执行效率。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-2、CPU-负载的影响\"><a href=\"#2-2、CPU-负载的影响\" class=\"headerlink\" title=\"2.2、CPU 负载的影响\"></a>2.2、CPU 负载的影响</h4><ul>\n<li>低平均负载<ul>\n<li>如果系统的平均负载较低，说明系统中的任务数量相对较少，或者系统有足够的资源来处理当前的任务。在这种情况下，可以根据任务的特点和预期的负载增长来规划线程池的容量。</li>\n</ul>\n</li>\n<li>高平均负载<ul>\n<li>当平均负载较高时，意味着系统中有较多的任务在等待处理，或者系统资源紧张。此时，需要谨慎调整线程池的容量。<blockquote>\n<p><strong>如果平均负载高但 CPU 利用率不高：</strong> 可能是由于 I/O 等待等原因导致任务堆积。此时，可以考虑增加线程池的容量，以提高系统的并发处理能力，减少任务的等待时间。但要注意不要过度增加线程池的大小，以免导致资源竞争加剧和系统性能下降。<br><strong>如果平均负载高且 CPU 利用率也高：</strong> 说明系统已经处于高负荷状态。此时，增加线程池的容量可能会进一步加重 CPU 负载，导致系统性能恶化。应该首先分析任务的执行情况，优化任务的执行效率，或者考虑增加硬件资源来缓解系统压力。</p>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<p>参考文章：<br><a href=\"https://juejin.cn/post/7066675779966337031\" target=\"_blank\" rel=\"noopener\">线程池的数量和线程池中线程数量如何设置-理论篇</a><br><a href=\"https://juejin.cn/post/7067183465224994852\" target=\"_blank\" rel=\"noopener\">线程池的数量和线程池中线程数量如何设置-实践篇</a><br><a href=\"https://scoutapm.com/blog/understanding-load-averages\" target=\"_blank\" rel=\"noopener\">了解 Linux CPU 负载——什么时候应该担心？</a></p>"},{"title":"《稳定性》高可用建设思路","date":"2024-05-29T02:00:00.000Z","_content":"\n    这是系统稳定性系列的第一篇文章，主要介绍的是一些高可用建设的基础知识。\n\n### 一、高可用\n> “高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。其计算公式是：可用率=（总时间-不可用时间）/总时间。\n\n高可用建设是确保系统在面临各种故障和挑战时仍能持续稳定运行，为用户提供可靠服务的一系列措施。\n<!-- more -->\n高可用建设总结归纳成3个方面：防、控、练。\n\n#### 1 防\n“防” 在高可用建设中代表着通过各种手段预防故障发生、防范风险因素和防止性能下降，为系统的高可用性提供坚实的基础。 可以从架构设计、技术选型、业务风险、容量规划等方面进行。\n\n⭐️ 架构设计\n- 通过合理的分布式架构设计，将系统拆分为多个独立的模块或服务，避免单点故障。\n- 进行冗余设计，对关键组件如数据库、服务器等进行备份，确保在主组件出现故障时，备用组件能够及时接管，保证系统的持续运行。\n\n⭐️ 风险梳理\n通过人工梳理或者工具梳理，分析业务流程中的风险点，采取相应的措施进行防范。例如分析交易主链路中的风险点。\n\n⭐️ 风险治理 \n针对风险梳理出来的问题进行治理，治理方案如下：\n> - 强弱依赖：判断强依赖是否可以降成弱依赖。\n> - 隔离建设：\n>   - 限流隔离：分应用隔离、分场景隔离。\n>   - 线程池隔离：\n>   - 功能隔离：\n>     - 应用分组隔离：例如交易服务可分成导购分组、下单分组。\n>     - 应用功能隔离：例如交易的商户订单、用户订单，可做隔离。\n>   - 资源隔离：例如缓存，针对不同业务，申请不同资源。\n> - 限流治理：\n>   - 保护自己\n>   - 保护下游\n> - 容灾建设：\n>   - 单元化\n\n\n\n#### 2 控\n> - 控” 意味着对系统的各个关键环节进行持续监控；能够快速发现系统中的异常情况；隔离故障影响；快速恢复服务。\n\n>- 发现响应：\n>    - 告警配置：\n>      - 基础指标：\n>        - 入口：RPC、消息、定时任务等。\n>        - 下游：RPC、数据库、缓存、消息等。\n>        - 容器：探活、CPU、内存、磁盘等。\n>        - JVM：GC、内存、线程池。\n>        - 其他：独立线程池、限流。\n>      - 业务指标：\n>        - 业务动作：例如下单量。\n>      - 异常指标：\n>        - 基础异常指标：例如CPU上涨20%。\n>        - 业务异常指标：例如下单成交量下跌5%。\n>    - 告警响应：\n>      - 告警分级（电话、短信、钉钉），\n>- 应急止血：\n>  - 应急三角色：止血、定位、同步。\n>  - 止血恢复：自动恢复、人工介入恢复。\n>  - 定位：交易大盘、工具、排障手册。\n\n#### 3 练\n> - 练\n>   - 攻防演练\n>   - 预案演练：注入","source":"_posts/2024-05-29-稳定性-高可用建设.md","raw":"---\ntitle: 《稳定性》高可用建设思路\ndate: 2024-05-29 10:00:00\ncategories:\n  - [稳定性]\n  - [高可用]\n---\n\n    这是系统稳定性系列的第一篇文章，主要介绍的是一些高可用建设的基础知识。\n\n### 一、高可用\n> “高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。其计算公式是：可用率=（总时间-不可用时间）/总时间。\n\n高可用建设是确保系统在面临各种故障和挑战时仍能持续稳定运行，为用户提供可靠服务的一系列措施。\n<!-- more -->\n高可用建设总结归纳成3个方面：防、控、练。\n\n#### 1 防\n“防” 在高可用建设中代表着通过各种手段预防故障发生、防范风险因素和防止性能下降，为系统的高可用性提供坚实的基础。 可以从架构设计、技术选型、业务风险、容量规划等方面进行。\n\n⭐️ 架构设计\n- 通过合理的分布式架构设计，将系统拆分为多个独立的模块或服务，避免单点故障。\n- 进行冗余设计，对关键组件如数据库、服务器等进行备份，确保在主组件出现故障时，备用组件能够及时接管，保证系统的持续运行。\n\n⭐️ 风险梳理\n通过人工梳理或者工具梳理，分析业务流程中的风险点，采取相应的措施进行防范。例如分析交易主链路中的风险点。\n\n⭐️ 风险治理 \n针对风险梳理出来的问题进行治理，治理方案如下：\n> - 强弱依赖：判断强依赖是否可以降成弱依赖。\n> - 隔离建设：\n>   - 限流隔离：分应用隔离、分场景隔离。\n>   - 线程池隔离：\n>   - 功能隔离：\n>     - 应用分组隔离：例如交易服务可分成导购分组、下单分组。\n>     - 应用功能隔离：例如交易的商户订单、用户订单，可做隔离。\n>   - 资源隔离：例如缓存，针对不同业务，申请不同资源。\n> - 限流治理：\n>   - 保护自己\n>   - 保护下游\n> - 容灾建设：\n>   - 单元化\n\n\n\n#### 2 控\n> - 控” 意味着对系统的各个关键环节进行持续监控；能够快速发现系统中的异常情况；隔离故障影响；快速恢复服务。\n\n>- 发现响应：\n>    - 告警配置：\n>      - 基础指标：\n>        - 入口：RPC、消息、定时任务等。\n>        - 下游：RPC、数据库、缓存、消息等。\n>        - 容器：探活、CPU、内存、磁盘等。\n>        - JVM：GC、内存、线程池。\n>        - 其他：独立线程池、限流。\n>      - 业务指标：\n>        - 业务动作：例如下单量。\n>      - 异常指标：\n>        - 基础异常指标：例如CPU上涨20%。\n>        - 业务异常指标：例如下单成交量下跌5%。\n>    - 告警响应：\n>      - 告警分级（电话、短信、钉钉），\n>- 应急止血：\n>  - 应急三角色：止血、定位、同步。\n>  - 止血恢复：自动恢复、人工介入恢复。\n>  - 定位：交易大盘、工具、排障手册。\n\n#### 3 练\n> - 练\n>   - 攻防演练\n>   - 预案演练：注入","slug":"2024-05-29-稳定性-高可用建设","published":1,"updated":"2024-10-25T03:31:58.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny0004na13ksluavuds","content":"<pre><code>这是系统稳定性系列的第一篇文章，主要介绍的是一些高可用建设的基础知识。</code></pre><h3 id=\"一、高可用\"><a href=\"#一、高可用\" class=\"headerlink\" title=\"一、高可用\"></a>一、高可用</h3><blockquote>\n<p>“高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。其计算公式是：可用率=（总时间-不可用时间）/总时间。</p>\n</blockquote>\n<p>高可用建设是确保系统在面临各种故障和挑战时仍能持续稳定运行，为用户提供可靠服务的一系列措施。</p>\n<a id=\"more\"></a>\n<p>高可用建设总结归纳成3个方面：防、控、练。</p>\n<h4 id=\"1-防\"><a href=\"#1-防\" class=\"headerlink\" title=\"1 防\"></a>1 防</h4><p>“防” 在高可用建设中代表着通过各种手段预防故障发生、防范风险因素和防止性能下降，为系统的高可用性提供坚实的基础。 可以从架构设计、技术选型、业务风险、容量规划等方面进行。</p>\n<p>⭐️ 架构设计</p>\n<ul>\n<li>通过合理的分布式架构设计，将系统拆分为多个独立的模块或服务，避免单点故障。</li>\n<li>进行冗余设计，对关键组件如数据库、服务器等进行备份，确保在主组件出现故障时，备用组件能够及时接管，保证系统的持续运行。</li>\n</ul>\n<p>⭐️ 风险梳理<br>通过人工梳理或者工具梳理，分析业务流程中的风险点，采取相应的措施进行防范。例如分析交易主链路中的风险点。</p>\n<p>⭐️ 风险治理<br>针对风险梳理出来的问题进行治理，治理方案如下：</p>\n<blockquote>\n<ul>\n<li>强弱依赖：判断强依赖是否可以降成弱依赖。</li>\n<li>隔离建设：<ul>\n<li>限流隔离：分应用隔离、分场景隔离。</li>\n<li>线程池隔离：</li>\n<li>功能隔离：<ul>\n<li>应用分组隔离：例如交易服务可分成导购分组、下单分组。</li>\n<li>应用功能隔离：例如交易的商户订单、用户订单，可做隔离。</li>\n</ul>\n</li>\n<li>资源隔离：例如缓存，针对不同业务，申请不同资源。</li>\n</ul>\n</li>\n<li>限流治理：<ul>\n<li>保护自己</li>\n<li>保护下游</li>\n</ul>\n</li>\n<li>容灾建设：<ul>\n<li>单元化</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h4 id=\"2-控\"><a href=\"#2-控\" class=\"headerlink\" title=\"2 控\"></a>2 控</h4><blockquote>\n<ul>\n<li>控” 意味着对系统的各个关键环节进行持续监控；能够快速发现系统中的异常情况；隔离故障影响；快速恢复服务。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>发现响应：<ul>\n<li>告警配置：<ul>\n<li>基础指标：<ul>\n<li>入口：RPC、消息、定时任务等。</li>\n<li>下游：RPC、数据库、缓存、消息等。</li>\n<li>容器：探活、CPU、内存、磁盘等。</li>\n<li>JVM：GC、内存、线程池。</li>\n<li>其他：独立线程池、限流。</li>\n</ul>\n</li>\n<li>业务指标：<ul>\n<li>业务动作：例如下单量。</li>\n</ul>\n</li>\n<li>异常指标：<ul>\n<li>基础异常指标：例如CPU上涨20%。</li>\n<li>业务异常指标：例如下单成交量下跌5%。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>告警响应：<ul>\n<li>告警分级（电话、短信、钉钉），</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>应急止血：<ul>\n<li>应急三角色：止血、定位、同步。</li>\n<li>止血恢复：自动恢复、人工介入恢复。</li>\n<li>定位：交易大盘、工具、排障手册。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h4 id=\"3-练\"><a href=\"#3-练\" class=\"headerlink\" title=\"3 练\"></a>3 练</h4><blockquote>\n<ul>\n<li>练<ul>\n<li>攻防演练</li>\n<li>预案演练：注入</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n","site":{"data":{}},"excerpt":"<pre><code>这是系统稳定性系列的第一篇文章，主要介绍的是一些高可用建设的基础知识。</code></pre><h3 id=\"一、高可用\"><a href=\"#一、高可用\" class=\"headerlink\" title=\"一、高可用\"></a>一、高可用</h3><blockquote>\n<p>“高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。其计算公式是：可用率=（总时间-不可用时间）/总时间。</p>\n</blockquote>\n<p>高可用建设是确保系统在面临各种故障和挑战时仍能持续稳定运行，为用户提供可靠服务的一系列措施。</p>","more":"<p>高可用建设总结归纳成3个方面：防、控、练。</p>\n<h4 id=\"1-防\"><a href=\"#1-防\" class=\"headerlink\" title=\"1 防\"></a>1 防</h4><p>“防” 在高可用建设中代表着通过各种手段预防故障发生、防范风险因素和防止性能下降，为系统的高可用性提供坚实的基础。 可以从架构设计、技术选型、业务风险、容量规划等方面进行。</p>\n<p>⭐️ 架构设计</p>\n<ul>\n<li>通过合理的分布式架构设计，将系统拆分为多个独立的模块或服务，避免单点故障。</li>\n<li>进行冗余设计，对关键组件如数据库、服务器等进行备份，确保在主组件出现故障时，备用组件能够及时接管，保证系统的持续运行。</li>\n</ul>\n<p>⭐️ 风险梳理<br>通过人工梳理或者工具梳理，分析业务流程中的风险点，采取相应的措施进行防范。例如分析交易主链路中的风险点。</p>\n<p>⭐️ 风险治理<br>针对风险梳理出来的问题进行治理，治理方案如下：</p>\n<blockquote>\n<ul>\n<li>强弱依赖：判断强依赖是否可以降成弱依赖。</li>\n<li>隔离建设：<ul>\n<li>限流隔离：分应用隔离、分场景隔离。</li>\n<li>线程池隔离：</li>\n<li>功能隔离：<ul>\n<li>应用分组隔离：例如交易服务可分成导购分组、下单分组。</li>\n<li>应用功能隔离：例如交易的商户订单、用户订单，可做隔离。</li>\n</ul>\n</li>\n<li>资源隔离：例如缓存，针对不同业务，申请不同资源。</li>\n</ul>\n</li>\n<li>限流治理：<ul>\n<li>保护自己</li>\n<li>保护下游</li>\n</ul>\n</li>\n<li>容灾建设：<ul>\n<li>单元化</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h4 id=\"2-控\"><a href=\"#2-控\" class=\"headerlink\" title=\"2 控\"></a>2 控</h4><blockquote>\n<ul>\n<li>控” 意味着对系统的各个关键环节进行持续监控；能够快速发现系统中的异常情况；隔离故障影响；快速恢复服务。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>发现响应：<ul>\n<li>告警配置：<ul>\n<li>基础指标：<ul>\n<li>入口：RPC、消息、定时任务等。</li>\n<li>下游：RPC、数据库、缓存、消息等。</li>\n<li>容器：探活、CPU、内存、磁盘等。</li>\n<li>JVM：GC、内存、线程池。</li>\n<li>其他：独立线程池、限流。</li>\n</ul>\n</li>\n<li>业务指标：<ul>\n<li>业务动作：例如下单量。</li>\n</ul>\n</li>\n<li>异常指标：<ul>\n<li>基础异常指标：例如CPU上涨20%。</li>\n<li>业务异常指标：例如下单成交量下跌5%。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>告警响应：<ul>\n<li>告警分级（电话、短信、钉钉），</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>应急止血：<ul>\n<li>应急三角色：止血、定位、同步。</li>\n<li>止血恢复：自动恢复、人工介入恢复。</li>\n<li>定位：交易大盘、工具、排障手册。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h4 id=\"3-练\"><a href=\"#3-练\" class=\"headerlink\" title=\"3 练\"></a>3 练</h4><blockquote>\n<ul>\n<li>练<ul>\n<li>攻防演练</li>\n<li>预案演练：注入</li>\n</ul>\n</li>\n</ul>\n</blockquote>"},{"title":"《稳定性》订单拉单","date":"2024-06-09T02:00:00.000Z","_content":"\n    这是稳定性系列的第三篇文章，主要介绍的是交易系统高可用建设和线程池隔离的稳定性建设。\n\n### 一、背景\n订单拉单通常是指从外部系统（如电商平台、支付系统等）获取订单数据并导入到自己的系统中进行处理的过程。  \n订单拉单的常见方案：\n- 定时任务：设置定时任务，按照一定的时间间隔（如每分钟、每小时等）主动从外部系统查询并拉取新的订单数据。这种方式适用于外部系统不提供主动推送功能或者对实时性要求不高的情况。\n- 数据库同步：如果外部系统和你的系统可以直接访问同一个数据库，可以通过数据库的同步机制（如触发器、存储过程等）将订单数据同步到你的系统中。这种方式实时性高，但需要确保数据库的安全性和稳定性。\n\n<!-- more -->\n> 交易系统的拉单，采用定时任务方案，作为交易系统高可用建设中的一部分，当消息队列遇到各种故障和异常情况时，能够通过拉单任务创建本地订单，保障持续提供服务的能力。  \n\n执行时序图：\n{% plantuml %}\nparticipant 集团交易\ndatabase metaq\nparticipant schedulerx\nparticipant 本地交易\ndatabase mysql\n\n集团交易->metaq: 订单创建消息\nmetaq->本地交易: 订阅\n本地交易->本地交易: 创建订单、创建拉单任务\n本地交易->mysql:存储数据\nschedulerx->本地交易: 执行定时任务\n本地交易->本地交易:执行拉单任务\n{% endplantuml %}\n\n为什么要进行拉单优化呢？\n- 业务逻辑收口，逻辑统一。\n- 线程池隔离：未隔离，和其他业务耦合。\n- 定时任务会有2小时的停顿问题。\n\n\n### 二、重构前准备\n- 明确目标：\n  - 业务 & 线程池的隔离，并且解决定时任务停顿问题。\n- 评估现状：\n  - 分析拉单任务的创建场景，内部创建及对外暴露的接口。\n  - 线程池的使用情况。\n\n\n### 三、线程池隔离的稳定性建设\n#### 1 评估现状：\n任务创建量、任务执行量、线程池数量：\n- 任务创建量：2000W+/天。\n- 任务执行量：1000/s.\n- 任务执行耗时：40ms\n- 共享线程池数量：50。\n- 任务执行流程如下：分成3级任务。\n```java\n@Component\npublic class PullOrderJobProcessor extends MapJobProcessor {\n\n    @Autowired\n    private XXXService xxxService;\n\n    private final int PAGE_SIZE = 500;\n\n    @Override\n    public ProcessResult process(JobContext context) throws Exception {\n        String taskName = context.getTaskName();\n        Object task = context.getTask();\n        if (isRootTask(context)) {\n            //一级任务：分库分表\n            List<String> tableList = getTableList(dbName);\n            return map(dbList, \"DbTask\");\n        } else if (taskName.equals(\"TableTask\")) {\n            //二级任务：分页查询数据\n            String tableName = (String)task;\n            //分页查询\n            List<PageTask> tasks = pageQuery(tableName, PAGE_SIZE);\n            //任务分发\n            return map(tasks, \"task\");\n        } else if (taskName.equals(\"task\")) {\n            //三级任务：具体的任务执行\n            PageTask pageTask = (PageTask)task;\n            //根据任务ID查询任务\n            Task task = queryRecord(tableName, pageTask.getTaskId());\n            //TODO handle records\n            return new ProcessResult(true);\n        }\n\n        return new ProcessResult(false);\n    }\n\n}\n```\nschedulerx任务平台，会将任务分发到应用的worker服务器（不区分中心、单元），中心和单元的 机器数量：\n- 中心：400台\n  - CPU：16核\n- 单元：400台\n\n#### 3 线程池监控\n[先做线程池监控](http://caohuiwu.github.io/2024/06/09/2024-06-09-%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%9E%84-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/)\n\n#### 4 线程池容量规划\n任务需要1s内执行完成，计算线程数量，公式如下：\n> - 单机理论线程数量=(qps/(总时间/平均耗时))\n> - 1000/(1000/40)=40个线程\n\n因为线程池是使用共享的线程池，不太容易得出线程池的状态数据。先从理论上分析，1000的QPS，会被平均分摊到800台机器上，那每台实际执行的量理论上是1.25个(1000/800) 。\n\n##### 实际解决方案\n通过灰度，将任务流量放入独立线程池，然后通过线程池监控查看线程池的状态，再做相应调整。\n\n##### 更优方案\n可以动态的调整线程池的数据。\n\n参考文章：   \n[Java线程池实现原理及其在美团业务中的实践](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)\n\n\n","source":"_posts/2024-06-09-稳定性-订单拉单.md","raw":"---\ntitle: 《稳定性》订单拉单\ndate: 2024-06-09 10:00:00\ncategories:\n  - [线程池]\n  - [稳定性, 高可用]\n  - [阿里]\ntags:\n- 阿里\n---\n\n    这是稳定性系列的第三篇文章，主要介绍的是交易系统高可用建设和线程池隔离的稳定性建设。\n\n### 一、背景\n订单拉单通常是指从外部系统（如电商平台、支付系统等）获取订单数据并导入到自己的系统中进行处理的过程。  \n订单拉单的常见方案：\n- 定时任务：设置定时任务，按照一定的时间间隔（如每分钟、每小时等）主动从外部系统查询并拉取新的订单数据。这种方式适用于外部系统不提供主动推送功能或者对实时性要求不高的情况。\n- 数据库同步：如果外部系统和你的系统可以直接访问同一个数据库，可以通过数据库的同步机制（如触发器、存储过程等）将订单数据同步到你的系统中。这种方式实时性高，但需要确保数据库的安全性和稳定性。\n\n<!-- more -->\n> 交易系统的拉单，采用定时任务方案，作为交易系统高可用建设中的一部分，当消息队列遇到各种故障和异常情况时，能够通过拉单任务创建本地订单，保障持续提供服务的能力。  \n\n执行时序图：\n{% plantuml %}\nparticipant 集团交易\ndatabase metaq\nparticipant schedulerx\nparticipant 本地交易\ndatabase mysql\n\n集团交易->metaq: 订单创建消息\nmetaq->本地交易: 订阅\n本地交易->本地交易: 创建订单、创建拉单任务\n本地交易->mysql:存储数据\nschedulerx->本地交易: 执行定时任务\n本地交易->本地交易:执行拉单任务\n{% endplantuml %}\n\n为什么要进行拉单优化呢？\n- 业务逻辑收口，逻辑统一。\n- 线程池隔离：未隔离，和其他业务耦合。\n- 定时任务会有2小时的停顿问题。\n\n\n### 二、重构前准备\n- 明确目标：\n  - 业务 & 线程池的隔离，并且解决定时任务停顿问题。\n- 评估现状：\n  - 分析拉单任务的创建场景，内部创建及对外暴露的接口。\n  - 线程池的使用情况。\n\n\n### 三、线程池隔离的稳定性建设\n#### 1 评估现状：\n任务创建量、任务执行量、线程池数量：\n- 任务创建量：2000W+/天。\n- 任务执行量：1000/s.\n- 任务执行耗时：40ms\n- 共享线程池数量：50。\n- 任务执行流程如下：分成3级任务。\n```java\n@Component\npublic class PullOrderJobProcessor extends MapJobProcessor {\n\n    @Autowired\n    private XXXService xxxService;\n\n    private final int PAGE_SIZE = 500;\n\n    @Override\n    public ProcessResult process(JobContext context) throws Exception {\n        String taskName = context.getTaskName();\n        Object task = context.getTask();\n        if (isRootTask(context)) {\n            //一级任务：分库分表\n            List<String> tableList = getTableList(dbName);\n            return map(dbList, \"DbTask\");\n        } else if (taskName.equals(\"TableTask\")) {\n            //二级任务：分页查询数据\n            String tableName = (String)task;\n            //分页查询\n            List<PageTask> tasks = pageQuery(tableName, PAGE_SIZE);\n            //任务分发\n            return map(tasks, \"task\");\n        } else if (taskName.equals(\"task\")) {\n            //三级任务：具体的任务执行\n            PageTask pageTask = (PageTask)task;\n            //根据任务ID查询任务\n            Task task = queryRecord(tableName, pageTask.getTaskId());\n            //TODO handle records\n            return new ProcessResult(true);\n        }\n\n        return new ProcessResult(false);\n    }\n\n}\n```\nschedulerx任务平台，会将任务分发到应用的worker服务器（不区分中心、单元），中心和单元的 机器数量：\n- 中心：400台\n  - CPU：16核\n- 单元：400台\n\n#### 3 线程池监控\n[先做线程池监控](http://caohuiwu.github.io/2024/06/09/2024-06-09-%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%9E%84-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/)\n\n#### 4 线程池容量规划\n任务需要1s内执行完成，计算线程数量，公式如下：\n> - 单机理论线程数量=(qps/(总时间/平均耗时))\n> - 1000/(1000/40)=40个线程\n\n因为线程池是使用共享的线程池，不太容易得出线程池的状态数据。先从理论上分析，1000的QPS，会被平均分摊到800台机器上，那每台实际执行的量理论上是1.25个(1000/800) 。\n\n##### 实际解决方案\n通过灰度，将任务流量放入独立线程池，然后通过线程池监控查看线程池的状态，再做相应调整。\n\n##### 更优方案\n可以动态的调整线程池的数据。\n\n参考文章：   \n[Java线程池实现原理及其在美团业务中的实践](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)\n\n\n","slug":"2024-06-09-稳定性-订单拉单","published":1,"updated":"2024-10-25T08:51:32.956Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny1004qa13ktdoklfpg","content":"<pre><code>这是稳定性系列的第三篇文章，主要介绍的是交易系统高可用建设和线程池隔离的稳定性建设。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>订单拉单通常是指从外部系统（如电商平台、支付系统等）获取订单数据并导入到自己的系统中进行处理的过程。<br>订单拉单的常见方案：</p>\n<ul>\n<li>定时任务：设置定时任务，按照一定的时间间隔（如每分钟、每小时等）主动从外部系统查询并拉取新的订单数据。这种方式适用于外部系统不提供主动推送功能或者对实时性要求不高的情况。</li>\n<li>数据库同步：如果外部系统和你的系统可以直接访问同一个数据库，可以通过数据库的同步机制（如触发器、存储过程等）将订单数据同步到你的系统中。这种方式实时性高，但需要确保数据库的安全性和稳定性。</li>\n</ul>\n<a id=\"more\"></a>\n<blockquote>\n<p>交易系统的拉单，采用定时任务方案，作为交易系统高可用建设中的一部分，当消息队列遇到各种故障和异常情况时，能够通过拉单任务创建本地订单，保障持续提供服务的能力。  </p>\n</blockquote>\n<p>执行时序图：</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHU3cxxUdiHKzsBNasOp9NIc99Ob9YSQf2Rcf9OY5N0PAwukICr9JIdDIY2XJXPtFMF9sp0KDxPN5X3XSNijcwTc0phHHUh5lqj7VgquxPJtVlUhQjurdZUYwmZAuTibbWTIzdj78X2w8hWHW2CV1nGoFKpEvE8FV9xjrFknQYwGOxo-hfsXbFcrOycxhXMUywBeItq0r_rhdynSAUf-jcFPk-3QjfACeXgf7j1W00\">\n\n<p>为什么要进行拉单优化呢？</p>\n<ul>\n<li>业务逻辑收口，逻辑统一。</li>\n<li>线程池隔离：未隔离，和其他业务耦合。</li>\n<li>定时任务会有2小时的停顿问题。</li>\n</ul>\n<h3 id=\"二、重构前准备\"><a href=\"#二、重构前准备\" class=\"headerlink\" title=\"二、重构前准备\"></a>二、重构前准备</h3><ul>\n<li>明确目标：<ul>\n<li>业务 &amp; 线程池的隔离，并且解决定时任务停顿问题。</li>\n</ul>\n</li>\n<li>评估现状：<ul>\n<li>分析拉单任务的创建场景，内部创建及对外暴露的接口。</li>\n<li>线程池的使用情况。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"三、线程池隔离的稳定性建设\"><a href=\"#三、线程池隔离的稳定性建设\" class=\"headerlink\" title=\"三、线程池隔离的稳定性建设\"></a>三、线程池隔离的稳定性建设</h3><h4 id=\"1-评估现状：\"><a href=\"#1-评估现状：\" class=\"headerlink\" title=\"1 评估现状：\"></a>1 评估现状：</h4><p>任务创建量、任务执行量、线程池数量：</p>\n<ul>\n<li>任务创建量：2000W+/天。</li>\n<li>任务执行量：1000/s.</li>\n<li>任务执行耗时：40ms</li>\n<li>共享线程池数量：50。</li>\n<li>任务执行流程如下：分成3级任务。<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PullOrderJobProcessor</span> <span class=\"keyword\">extends</span> <span class=\"title\">MapJobProcessor</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Autowired</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> XXXService xxxService;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> PAGE_SIZE = <span class=\"number\">500</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ProcessResult <span class=\"title\">process</span><span class=\"params\">(JobContext context)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        String taskName = context.getTaskName();</span><br><span class=\"line\">        Object task = context.getTask();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (isRootTask(context)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//一级任务：分库分表</span></span><br><span class=\"line\">            List&lt;String&gt; tableList = getTableList(dbName);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> map(dbList, <span class=\"string\">\"DbTask\"</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (taskName.equals(<span class=\"string\">\"TableTask\"</span>)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//二级任务：分页查询数据</span></span><br><span class=\"line\">            String tableName = (String)task;</span><br><span class=\"line\">            <span class=\"comment\">//分页查询</span></span><br><span class=\"line\">            List&lt;PageTask&gt; tasks = pageQuery(tableName, PAGE_SIZE);</span><br><span class=\"line\">            <span class=\"comment\">//任务分发</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> map(tasks, <span class=\"string\">\"task\"</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (taskName.equals(<span class=\"string\">\"task\"</span>)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//三级任务：具体的任务执行</span></span><br><span class=\"line\">            PageTask pageTask = (PageTask)task;</span><br><span class=\"line\">            <span class=\"comment\">//根据任务ID查询任务</span></span><br><span class=\"line\">            Task task = queryRecord(tableName, pageTask.getTaskId());</span><br><span class=\"line\">            <span class=\"comment\">//TODO handle records</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> ProcessResult(<span class=\"keyword\">true</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> ProcessResult(<span class=\"keyword\">false</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>schedulerx任务平台，会将任务分发到应用的worker服务器（不区分中心、单元），中心和单元的 机器数量：</p>\n<ul>\n<li>中心：400台<ul>\n<li>CPU：16核</li>\n</ul>\n</li>\n<li>单元：400台</li>\n</ul>\n<h4 id=\"3-线程池监控\"><a href=\"#3-线程池监控\" class=\"headerlink\" title=\"3 线程池监控\"></a>3 线程池监控</h4><p><a href=\"http://caohuiwu.github.io/2024/06/09/2024-06-09-%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%9E%84-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/\" target=\"_blank\" rel=\"noopener\">先做线程池监控</a></p>\n<h4 id=\"4-线程池容量规划\"><a href=\"#4-线程池容量规划\" class=\"headerlink\" title=\"4 线程池容量规划\"></a>4 线程池容量规划</h4><p>任务需要1s内执行完成，计算线程数量，公式如下：</p>\n<blockquote>\n<ul>\n<li>单机理论线程数量=(qps/(总时间/平均耗时))</li>\n<li>1000/(1000/40)=40个线程</li>\n</ul>\n</blockquote>\n<p>因为线程池是使用共享的线程池，不太容易得出线程池的状态数据。先从理论上分析，1000的QPS，会被平均分摊到800台机器上，那每台实际执行的量理论上是1.25个(1000/800) 。</p>\n<h5 id=\"实际解决方案\"><a href=\"#实际解决方案\" class=\"headerlink\" title=\"实际解决方案\"></a>实际解决方案</h5><p>通过灰度，将任务流量放入独立线程池，然后通过线程池监控查看线程池的状态，再做相应调整。</p>\n<h5 id=\"更优方案\"><a href=\"#更优方案\" class=\"headerlink\" title=\"更优方案\"></a>更优方案</h5><p>可以动态的调整线程池的数据。</p>\n<p>参考文章：<br><a href=\"https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html\" target=\"_blank\" rel=\"noopener\">Java线程池实现原理及其在美团业务中的实践</a></p>\n","site":{"data":{}},"excerpt":"<pre><code>这是稳定性系列的第三篇文章，主要介绍的是交易系统高可用建设和线程池隔离的稳定性建设。</code></pre><h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>订单拉单通常是指从外部系统（如电商平台、支付系统等）获取订单数据并导入到自己的系统中进行处理的过程。<br>订单拉单的常见方案：</p>\n<ul>\n<li>定时任务：设置定时任务，按照一定的时间间隔（如每分钟、每小时等）主动从外部系统查询并拉取新的订单数据。这种方式适用于外部系统不提供主动推送功能或者对实时性要求不高的情况。</li>\n<li>数据库同步：如果外部系统和你的系统可以直接访问同一个数据库，可以通过数据库的同步机制（如触发器、存储过程等）将订单数据同步到你的系统中。这种方式实时性高，但需要确保数据库的安全性和稳定性。</li>\n</ul>","more":"<blockquote>\n<p>交易系统的拉单，采用定时任务方案，作为交易系统高可用建设中的一部分，当消息队列遇到各种故障和异常情况时，能够通过拉单任务创建本地订单，保障持续提供服务的能力。  </p>\n</blockquote>\n<p>执行时序图：</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHU3cxxUdiHKzsBNasOp9NIc99Ob9YSQf2Rcf9OY5N0PAwukICr9JIdDIY2XJXPtFMF9sp0KDxPN5X3XSNijcwTc0phHHUh5lqj7VgquxPJtVlUhQjurdZUYwmZAuTibbWTIzdj78X2w8hWHW2CV1nGoFKpEvE8FV9xjrFknQYwGOxo-hfsXbFcrOycxhXMUywBeItq0r_rhdynSAUf-jcFPk-3QjfACeXgf7j1W00\">\n\n<p>为什么要进行拉单优化呢？</p>\n<ul>\n<li>业务逻辑收口，逻辑统一。</li>\n<li>线程池隔离：未隔离，和其他业务耦合。</li>\n<li>定时任务会有2小时的停顿问题。</li>\n</ul>\n<h3 id=\"二、重构前准备\"><a href=\"#二、重构前准备\" class=\"headerlink\" title=\"二、重构前准备\"></a>二、重构前准备</h3><ul>\n<li>明确目标：<ul>\n<li>业务 &amp; 线程池的隔离，并且解决定时任务停顿问题。</li>\n</ul>\n</li>\n<li>评估现状：<ul>\n<li>分析拉单任务的创建场景，内部创建及对外暴露的接口。</li>\n<li>线程池的使用情况。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"三、线程池隔离的稳定性建设\"><a href=\"#三、线程池隔离的稳定性建设\" class=\"headerlink\" title=\"三、线程池隔离的稳定性建设\"></a>三、线程池隔离的稳定性建设</h3><h4 id=\"1-评估现状：\"><a href=\"#1-评估现状：\" class=\"headerlink\" title=\"1 评估现状：\"></a>1 评估现状：</h4><p>任务创建量、任务执行量、线程池数量：</p>\n<ul>\n<li>任务创建量：2000W+/天。</li>\n<li>任务执行量：1000/s.</li>\n<li>任务执行耗时：40ms</li>\n<li>共享线程池数量：50。</li>\n<li>任务执行流程如下：分成3级任务。<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PullOrderJobProcessor</span> <span class=\"keyword\">extends</span> <span class=\"title\">MapJobProcessor</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Autowired</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> XXXService xxxService;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> PAGE_SIZE = <span class=\"number\">500</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ProcessResult <span class=\"title\">process</span><span class=\"params\">(JobContext context)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        String taskName = context.getTaskName();</span><br><span class=\"line\">        Object task = context.getTask();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (isRootTask(context)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//一级任务：分库分表</span></span><br><span class=\"line\">            List&lt;String&gt; tableList = getTableList(dbName);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> map(dbList, <span class=\"string\">\"DbTask\"</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (taskName.equals(<span class=\"string\">\"TableTask\"</span>)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//二级任务：分页查询数据</span></span><br><span class=\"line\">            String tableName = (String)task;</span><br><span class=\"line\">            <span class=\"comment\">//分页查询</span></span><br><span class=\"line\">            List&lt;PageTask&gt; tasks = pageQuery(tableName, PAGE_SIZE);</span><br><span class=\"line\">            <span class=\"comment\">//任务分发</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> map(tasks, <span class=\"string\">\"task\"</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (taskName.equals(<span class=\"string\">\"task\"</span>)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//三级任务：具体的任务执行</span></span><br><span class=\"line\">            PageTask pageTask = (PageTask)task;</span><br><span class=\"line\">            <span class=\"comment\">//根据任务ID查询任务</span></span><br><span class=\"line\">            Task task = queryRecord(tableName, pageTask.getTaskId());</span><br><span class=\"line\">            <span class=\"comment\">//TODO handle records</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> ProcessResult(<span class=\"keyword\">true</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> ProcessResult(<span class=\"keyword\">false</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>schedulerx任务平台，会将任务分发到应用的worker服务器（不区分中心、单元），中心和单元的 机器数量：</p>\n<ul>\n<li>中心：400台<ul>\n<li>CPU：16核</li>\n</ul>\n</li>\n<li>单元：400台</li>\n</ul>\n<h4 id=\"3-线程池监控\"><a href=\"#3-线程池监控\" class=\"headerlink\" title=\"3 线程池监控\"></a>3 线程池监控</h4><p><a href=\"http://caohuiwu.github.io/2024/06/09/2024-06-09-%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%9E%84-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/\" target=\"_blank\" rel=\"noopener\">先做线程池监控</a></p>\n<h4 id=\"4-线程池容量规划\"><a href=\"#4-线程池容量规划\" class=\"headerlink\" title=\"4 线程池容量规划\"></a>4 线程池容量规划</h4><p>任务需要1s内执行完成，计算线程数量，公式如下：</p>\n<blockquote>\n<ul>\n<li>单机理论线程数量=(qps/(总时间/平均耗时))</li>\n<li>1000/(1000/40)=40个线程</li>\n</ul>\n</blockquote>\n<p>因为线程池是使用共享的线程池，不太容易得出线程池的状态数据。先从理论上分析，1000的QPS，会被平均分摊到800台机器上，那每台实际执行的量理论上是1.25个(1000/800) 。</p>\n<h5 id=\"实际解决方案\"><a href=\"#实际解决方案\" class=\"headerlink\" title=\"实际解决方案\"></a>实际解决方案</h5><p>通过灰度，将任务流量放入独立线程池，然后通过线程池监控查看线程池的状态，再做相应调整。</p>\n<h5 id=\"更优方案\"><a href=\"#更优方案\" class=\"headerlink\" title=\"更优方案\"></a>更优方案</h5><p>可以动态的调整线程池的数据。</p>\n<p>参考文章：<br><a href=\"https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html\" target=\"_blank\" rel=\"noopener\">Java线程池实现原理及其在美团业务中的实践</a></p>"},{"title":"《稳定性》变更三板斧","date":"2024-06-29T02:00:00.000Z","_content":"\n    这是稳定性系列的第五篇文章，主要介绍的是变更三板斧。\n\n### 一、安全生产之变更三板斧\n在阿里内部运维体系中，有一个常提的概念是\"变更三板斧\":\n- 可监控\n- 可灰度\n- 可回滚\n\n<!-- more -->\n\n#### ⭐️可监控\n上线的过程中，我们的系统要做到可监控，如果没有监控，上线过程中我们对系统的状态是一无所知，是很可怕的。监控什么东西那，其实监控的就是指标。\n![可监控](2024-06-29-稳定性-变更三板斧/可监控.png)\n\n#### ⭐️可灰度\n上线过程中，我们要做到可灰度，通过灰度执行变更以限制爆炸半径，降低影响范围，同时灰度过程要做好兼容。灰度分为不同维度的灰度：机器维度，机房维度，地域维度，业务维度：用户，商家，仓，承运商等。\n> 那具体应该怎么灰度呢？\n> \n> 不同场景，灰度的维度是不一样的，例如从用户维度进行说明：\n> - 灰度比例：确定用户的量级，影响范围，可以分为 0~1000, 0~10000等多种比例进行控制。影响范围大，缩小每次灰度比例。\n>   - 选择初始灰度比例：1/10000，万分之一，开始是一个较为谨慎的选择。\n>   - 设定递增策略：可以计划每隔一段时间（如一周）将灰度比例增加 1%，逐步扩大测试范围。这样可以更细致地观察新功能在不同用户规模下的表现。\n>     - 固定比例递增：\n>       - 每次增加固定百分比；比如每次增加 5%。从 1% 开始，接着是 6%、11%、16% 等\n>       - 以特定比例区间递增：例如先从 1% 开始，然后每次增加 3% 到 5% 之间的随机值。\n>     - 指数递增：\n>       - 缓慢起步后快速增长：开始时以较小的比例递增，比如从 1% 开始，然后按照指数函数的趋势增加比例。例如，接下来是 2%、4%、8%、16% 等。这种方式在初期可以更谨慎地观察新功能的影响，一旦确定相对稳定，就可以快速扩大测试范围，加快上线进度。但需要密切监控，因为后期增长速度较快，可能会带来较大风险。\n>     - 基于阶段的递增：\n>       - 划分不同阶段，每个阶段设定不同的递增幅度：比如将灰度发布分为三个阶段。在第一阶段，从 1% 开始，每次增加 2%，直到达到 10%；在第二阶段，每次增加 5%，从 10% 增长到 30%；在第三阶段，每次增加 10%，直到接近全面发布。这种方式可以根据不同阶段的目标和风险承受能力来调整递增策略，更加灵活地控制灰度发布过程。\n> - 示例：1/10000, 2/10000, 5/10000, 10/10000, 50/10000, 100/10000...\n\n#### ⭐️可回滚\n线上出现问题时，我们应该优先止损，其次才是分析根因。\n> 止损的最快方式就是回滚，回滚分为代码回滚和数据回滚\n> - 代码回滚：有2种方式，开关控制和部署回滚。\n>   - 开关回滚：通过开关控制，操作成本最低，止损最快速。\n>   - 部署回滚：通过发布平台，例如行云将代码回滚到上个稳定运行的版本，耗时长，止损速度慢。\n> - 数据回滚：有时候我们代码回滚完，如果没有做好向前兼容性，系统应用依然有问题，例如上线过程中产生了新数据，回滚完后，代码不能处理新的数据。所以这个时候又涉及到数据的回滚。\n>   - 数据的回滚涉及到修数：将产生的新数据无效掉，或者修改为正确的数据等，当数据量比较大时，数据的回滚一般耗时费力，所以建议做好向前兼容性，直接代码回滚。\n\n参考文章：   \n[万字长文浅谈系统稳定性建设](https://developer.jdcloud.com/article/3894)      \n\n\n\n","source":"_posts/2024-06-29-稳定性-变更三板斧.md","raw":"---\ntitle: 《稳定性》变更三板斧\ndate: 2024-06-29 10:00:00\ncategories:\n  - [稳定性, 安全生产]\n  - [阿里]\ntags:\n- 阿里\n---\n\n    这是稳定性系列的第五篇文章，主要介绍的是变更三板斧。\n\n### 一、安全生产之变更三板斧\n在阿里内部运维体系中，有一个常提的概念是\"变更三板斧\":\n- 可监控\n- 可灰度\n- 可回滚\n\n<!-- more -->\n\n#### ⭐️可监控\n上线的过程中，我们的系统要做到可监控，如果没有监控，上线过程中我们对系统的状态是一无所知，是很可怕的。监控什么东西那，其实监控的就是指标。\n![可监控](2024-06-29-稳定性-变更三板斧/可监控.png)\n\n#### ⭐️可灰度\n上线过程中，我们要做到可灰度，通过灰度执行变更以限制爆炸半径，降低影响范围，同时灰度过程要做好兼容。灰度分为不同维度的灰度：机器维度，机房维度，地域维度，业务维度：用户，商家，仓，承运商等。\n> 那具体应该怎么灰度呢？\n> \n> 不同场景，灰度的维度是不一样的，例如从用户维度进行说明：\n> - 灰度比例：确定用户的量级，影响范围，可以分为 0~1000, 0~10000等多种比例进行控制。影响范围大，缩小每次灰度比例。\n>   - 选择初始灰度比例：1/10000，万分之一，开始是一个较为谨慎的选择。\n>   - 设定递增策略：可以计划每隔一段时间（如一周）将灰度比例增加 1%，逐步扩大测试范围。这样可以更细致地观察新功能在不同用户规模下的表现。\n>     - 固定比例递增：\n>       - 每次增加固定百分比；比如每次增加 5%。从 1% 开始，接着是 6%、11%、16% 等\n>       - 以特定比例区间递增：例如先从 1% 开始，然后每次增加 3% 到 5% 之间的随机值。\n>     - 指数递增：\n>       - 缓慢起步后快速增长：开始时以较小的比例递增，比如从 1% 开始，然后按照指数函数的趋势增加比例。例如，接下来是 2%、4%、8%、16% 等。这种方式在初期可以更谨慎地观察新功能的影响，一旦确定相对稳定，就可以快速扩大测试范围，加快上线进度。但需要密切监控，因为后期增长速度较快，可能会带来较大风险。\n>     - 基于阶段的递增：\n>       - 划分不同阶段，每个阶段设定不同的递增幅度：比如将灰度发布分为三个阶段。在第一阶段，从 1% 开始，每次增加 2%，直到达到 10%；在第二阶段，每次增加 5%，从 10% 增长到 30%；在第三阶段，每次增加 10%，直到接近全面发布。这种方式可以根据不同阶段的目标和风险承受能力来调整递增策略，更加灵活地控制灰度发布过程。\n> - 示例：1/10000, 2/10000, 5/10000, 10/10000, 50/10000, 100/10000...\n\n#### ⭐️可回滚\n线上出现问题时，我们应该优先止损，其次才是分析根因。\n> 止损的最快方式就是回滚，回滚分为代码回滚和数据回滚\n> - 代码回滚：有2种方式，开关控制和部署回滚。\n>   - 开关回滚：通过开关控制，操作成本最低，止损最快速。\n>   - 部署回滚：通过发布平台，例如行云将代码回滚到上个稳定运行的版本，耗时长，止损速度慢。\n> - 数据回滚：有时候我们代码回滚完，如果没有做好向前兼容性，系统应用依然有问题，例如上线过程中产生了新数据，回滚完后，代码不能处理新的数据。所以这个时候又涉及到数据的回滚。\n>   - 数据的回滚涉及到修数：将产生的新数据无效掉，或者修改为正确的数据等，当数据量比较大时，数据的回滚一般耗时费力，所以建议做好向前兼容性，直接代码回滚。\n\n参考文章：   \n[万字长文浅谈系统稳定性建设](https://developer.jdcloud.com/article/3894)      \n\n\n\n","slug":"2024-06-29-稳定性-变更三板斧","published":1,"updated":"2024-10-28T08:55:11.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny3004ua13kq1xzarfm","content":"<pre><code>这是稳定性系列的第五篇文章，主要介绍的是变更三板斧。</code></pre><h3 id=\"一、安全生产之变更三板斧\"><a href=\"#一、安全生产之变更三板斧\" class=\"headerlink\" title=\"一、安全生产之变更三板斧\"></a>一、安全生产之变更三板斧</h3><p>在阿里内部运维体系中，有一个常提的概念是”变更三板斧”:</p>\n<ul>\n<li>可监控</li>\n<li>可灰度</li>\n<li>可回滚</li>\n</ul>\n<a id=\"more\"></a>\n\n<h4 id=\"⭐️可监控\"><a href=\"#⭐️可监控\" class=\"headerlink\" title=\"⭐️可监控\"></a>⭐️可监控</h4><p>上线的过程中，我们的系统要做到可监控，如果没有监控，上线过程中我们对系统的状态是一无所知，是很可怕的。监控什么东西那，其实监控的就是指标。<br><img src=\"/2024/06/29/2024-06-29-稳定性-变更三板斧/%E5%8F%AF%E7%9B%91%E6%8E%A7.png\" alt=\"可监控\"></p>\n<h4 id=\"⭐️可灰度\"><a href=\"#⭐️可灰度\" class=\"headerlink\" title=\"⭐️可灰度\"></a>⭐️可灰度</h4><p>上线过程中，我们要做到可灰度，通过灰度执行变更以限制爆炸半径，降低影响范围，同时灰度过程要做好兼容。灰度分为不同维度的灰度：机器维度，机房维度，地域维度，业务维度：用户，商家，仓，承运商等。</p>\n<blockquote>\n<p>那具体应该怎么灰度呢？</p>\n<p>不同场景，灰度的维度是不一样的，例如从用户维度进行说明：</p>\n<ul>\n<li>灰度比例：确定用户的量级，影响范围，可以分为 0<del>1000, 0</del>10000等多种比例进行控制。影响范围大，缩小每次灰度比例。<ul>\n<li>选择初始灰度比例：1/10000，万分之一，开始是一个较为谨慎的选择。</li>\n<li>设定递增策略：可以计划每隔一段时间（如一周）将灰度比例增加 1%，逐步扩大测试范围。这样可以更细致地观察新功能在不同用户规模下的表现。<ul>\n<li>固定比例递增：<ul>\n<li>每次增加固定百分比；比如每次增加 5%。从 1% 开始，接着是 6%、11%、16% 等</li>\n<li>以特定比例区间递增：例如先从 1% 开始，然后每次增加 3% 到 5% 之间的随机值。</li>\n</ul>\n</li>\n<li>指数递增：<ul>\n<li>缓慢起步后快速增长：开始时以较小的比例递增，比如从 1% 开始，然后按照指数函数的趋势增加比例。例如，接下来是 2%、4%、8%、16% 等。这种方式在初期可以更谨慎地观察新功能的影响，一旦确定相对稳定，就可以快速扩大测试范围，加快上线进度。但需要密切监控，因为后期增长速度较快，可能会带来较大风险。</li>\n</ul>\n</li>\n<li>基于阶段的递增：<ul>\n<li>划分不同阶段，每个阶段设定不同的递增幅度：比如将灰度发布分为三个阶段。在第一阶段，从 1% 开始，每次增加 2%，直到达到 10%；在第二阶段，每次增加 5%，从 10% 增长到 30%；在第三阶段，每次增加 10%，直到接近全面发布。这种方式可以根据不同阶段的目标和风险承受能力来调整递增策略，更加灵活地控制灰度发布过程。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>示例：1/10000, 2/10000, 5/10000, 10/10000, 50/10000, 100/10000…</li>\n</ul>\n</blockquote>\n<h4 id=\"⭐️可回滚\"><a href=\"#⭐️可回滚\" class=\"headerlink\" title=\"⭐️可回滚\"></a>⭐️可回滚</h4><p>线上出现问题时，我们应该优先止损，其次才是分析根因。</p>\n<blockquote>\n<p>止损的最快方式就是回滚，回滚分为代码回滚和数据回滚</p>\n<ul>\n<li>代码回滚：有2种方式，开关控制和部署回滚。<ul>\n<li>开关回滚：通过开关控制，操作成本最低，止损最快速。</li>\n<li>部署回滚：通过发布平台，例如行云将代码回滚到上个稳定运行的版本，耗时长，止损速度慢。</li>\n</ul>\n</li>\n<li>数据回滚：有时候我们代码回滚完，如果没有做好向前兼容性，系统应用依然有问题，例如上线过程中产生了新数据，回滚完后，代码不能处理新的数据。所以这个时候又涉及到数据的回滚。<ul>\n<li>数据的回滚涉及到修数：将产生的新数据无效掉，或者修改为正确的数据等，当数据量比较大时，数据的回滚一般耗时费力，所以建议做好向前兼容性，直接代码回滚。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<p>参考文章：<br><a href=\"https://developer.jdcloud.com/article/3894\" target=\"_blank\" rel=\"noopener\">万字长文浅谈系统稳定性建设</a>      </p>\n","site":{"data":{}},"excerpt":"<pre><code>这是稳定性系列的第五篇文章，主要介绍的是变更三板斧。</code></pre><h3 id=\"一、安全生产之变更三板斧\"><a href=\"#一、安全生产之变更三板斧\" class=\"headerlink\" title=\"一、安全生产之变更三板斧\"></a>一、安全生产之变更三板斧</h3><p>在阿里内部运维体系中，有一个常提的概念是”变更三板斧”:</p>\n<ul>\n<li>可监控</li>\n<li>可灰度</li>\n<li>可回滚</li>\n</ul>","more":"<h4 id=\"⭐️可监控\"><a href=\"#⭐️可监控\" class=\"headerlink\" title=\"⭐️可监控\"></a>⭐️可监控</h4><p>上线的过程中，我们的系统要做到可监控，如果没有监控，上线过程中我们对系统的状态是一无所知，是很可怕的。监控什么东西那，其实监控的就是指标。<br><img src=\"/2024/06/29/2024-06-29-稳定性-变更三板斧/%E5%8F%AF%E7%9B%91%E6%8E%A7.png\" alt=\"可监控\"></p>\n<h4 id=\"⭐️可灰度\"><a href=\"#⭐️可灰度\" class=\"headerlink\" title=\"⭐️可灰度\"></a>⭐️可灰度</h4><p>上线过程中，我们要做到可灰度，通过灰度执行变更以限制爆炸半径，降低影响范围，同时灰度过程要做好兼容。灰度分为不同维度的灰度：机器维度，机房维度，地域维度，业务维度：用户，商家，仓，承运商等。</p>\n<blockquote>\n<p>那具体应该怎么灰度呢？</p>\n<p>不同场景，灰度的维度是不一样的，例如从用户维度进行说明：</p>\n<ul>\n<li>灰度比例：确定用户的量级，影响范围，可以分为 0<del>1000, 0</del>10000等多种比例进行控制。影响范围大，缩小每次灰度比例。<ul>\n<li>选择初始灰度比例：1/10000，万分之一，开始是一个较为谨慎的选择。</li>\n<li>设定递增策略：可以计划每隔一段时间（如一周）将灰度比例增加 1%，逐步扩大测试范围。这样可以更细致地观察新功能在不同用户规模下的表现。<ul>\n<li>固定比例递增：<ul>\n<li>每次增加固定百分比；比如每次增加 5%。从 1% 开始，接着是 6%、11%、16% 等</li>\n<li>以特定比例区间递增：例如先从 1% 开始，然后每次增加 3% 到 5% 之间的随机值。</li>\n</ul>\n</li>\n<li>指数递增：<ul>\n<li>缓慢起步后快速增长：开始时以较小的比例递增，比如从 1% 开始，然后按照指数函数的趋势增加比例。例如，接下来是 2%、4%、8%、16% 等。这种方式在初期可以更谨慎地观察新功能的影响，一旦确定相对稳定，就可以快速扩大测试范围，加快上线进度。但需要密切监控，因为后期增长速度较快，可能会带来较大风险。</li>\n</ul>\n</li>\n<li>基于阶段的递增：<ul>\n<li>划分不同阶段，每个阶段设定不同的递增幅度：比如将灰度发布分为三个阶段。在第一阶段，从 1% 开始，每次增加 2%，直到达到 10%；在第二阶段，每次增加 5%，从 10% 增长到 30%；在第三阶段，每次增加 10%，直到接近全面发布。这种方式可以根据不同阶段的目标和风险承受能力来调整递增策略，更加灵活地控制灰度发布过程。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>示例：1/10000, 2/10000, 5/10000, 10/10000, 50/10000, 100/10000…</li>\n</ul>\n</blockquote>\n<h4 id=\"⭐️可回滚\"><a href=\"#⭐️可回滚\" class=\"headerlink\" title=\"⭐️可回滚\"></a>⭐️可回滚</h4><p>线上出现问题时，我们应该优先止损，其次才是分析根因。</p>\n<blockquote>\n<p>止损的最快方式就是回滚，回滚分为代码回滚和数据回滚</p>\n<ul>\n<li>代码回滚：有2种方式，开关控制和部署回滚。<ul>\n<li>开关回滚：通过开关控制，操作成本最低，止损最快速。</li>\n<li>部署回滚：通过发布平台，例如行云将代码回滚到上个稳定运行的版本，耗时长，止损速度慢。</li>\n</ul>\n</li>\n<li>数据回滚：有时候我们代码回滚完，如果没有做好向前兼容性，系统应用依然有问题，例如上线过程中产生了新数据，回滚完后，代码不能处理新的数据。所以这个时候又涉及到数据的回滚。<ul>\n<li>数据的回滚涉及到修数：将产生的新数据无效掉，或者修改为正确的数据等，当数据量比较大时，数据的回滚一般耗时费力，所以建议做好向前兼容性，直接代码回滚。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<p>参考文章：<br><a href=\"https://developer.jdcloud.com/article/3894\" target=\"_blank\" rel=\"noopener\">万字长文浅谈系统稳定性建设</a>      </p>"},{"title":"《稳定性》单元化概念","date":"2024-07-11T02:00:00.000Z","_content":"\n    这是稳定性系列的第六篇文章，主要介绍的是单元化概念。\n\n### 一、什么是单元化？\n\n单元化简单点我们直接就可以认为是一个机房，在这个单元内能够完成业务的闭环。比如说用户进入APP，浏览商品，选择商品确认订单，下单，支付，查看订单信息，这整个流程都在一个单元中能够完成，并且数据也是存储在这个单元里面。\n<!-- more -->\n![什么是单元化](2024-07-11-稳定性-单元化概念/什么是单元化.png)\n\n#### 1.2 单元化基础术语\n<style>\ntable th:first-of-type {\n    width: 10%;\n}\ntable th:nth-of-type(2) {\n    width: 70%;\n}\n</style>\n\n\n| 术语    | 含义                                                                       |\n|-------|--------------------------------------------------------------------------|\n| gzone | Global Zone，全局区域。部署了不可拆分的数据和服务，这些数据或服务可能会被RZone 依赖。GZone 在全局只有一组，数据仅有一份。 |\n| rzone | Region Zone，最符合理论上单元定义的 Zone，每个 RZone 都是自包含的，拥有自己的数据，能完成所有业务。            |\n| ezone | eleme zone，饿了么每个机房为一个 ezone，一个 ezone 包含了饿了么需要的各种服务。一笔业务能够内聚在一个 ezone 中   |\n\n### 二、单元化的目的\n\n#### ⭐️ 高可用容灾：\n\n- 1、一个IDC机房挂掉了，能把流量直接切到另一个IDC机房（同一个城市），异地容灾是最终解决方案。\n\n#### ⭐️高并发容量问题：\n\n- 1、提高并发能力，加机器是最直接的答案，但是随之而来的瓶颈是数据库连接瓶颈，机房网卡瓶颈等。\n- 2、水平扩展能力，意味着可以按照一定维度来进行分片。\n- 3、单元化在做的事情，就是把数据流量，按照一定维度进行拆分。使得一个单元IDC能够闭环提供完整的服务能力。但是这个服务能力面对的是拆分后的部分数据流量，且只服务这部分流量。\n\n### 三、单元化产品组成\n![单元化产品组成](2024-07-11-稳定性-单元化概念/单元化产品组成.png)\n单元化产品包含以下三大部分：\n- 运行时：单元化流量路由能力，包含统一接入网关、应用层组件和数据层组件。\n- 运维时：跨集群资源管理、发布运维和单元化管控能力，包含单元化应用服务（LHC）。 单元化监控分析能力，包含实时监控组件和分布式链路跟踪组件。\n- 容灾时：巡检诊断、容灾演练和切换能力，包含高可用容灾平台。\n\n#### 3.1、运行时\n##### 1、统一接入网关：\n> 统一接入网关，是将访问流量根据转发规则分发到多台后端服务器的流量分发控制服务。\n> \n> 在单元化场景下，按单元化路由规则（如用户 ID 到单元的映射关系以及单元间权重占比），将用户的 http 请求路由至目标机房和单元，实现流量动态调拨。\n> \n> 统一接入网关的作用如下：\n> - 拦截请求，识别目标应用的单元类型（如是 RZone 应用，还是 GZone 应用） 根据目标类型，进行路由转发，支持跨机房异地转发，实现单元化流量调拨。\n> - GZone 路由：根据路由规则（单元权重占比），将用户 http 请求转发至目标单元的应用服务器中。\n> - RZone 路由：从 cookie 中读取分片字段（如 uid），根据路由规则（用户 ID 到单元的映射关系），将用户 http 请求转发至目标机房的应用服务器中。\n\n##### 2、中间件\n在单元化架构下，中间件从应用层到数据层均提供了单元化流量路由能力。\n![中间件改造](2024-07-11-稳定性-单元化概念/中间件改造.png)\n\nAPIRouter ： 路由分发服务\n> API Router是一个HTTP反向代理和负载均衡器，部署在公有云中作为HTTP API流量的入口，它能识别出流量的归属 shard ，并根据 shard 将流量转发到对应的 ezone。API Router 支持多种路由键，可以是地理位置，也可以是商户ID，订单ID等等，最终由 API Router 映射为统一的 Sharding ID。\n\n服务通信层：RPC\n> 需要支持基于单元化规则的服务路由。需要做到单元的应用可以调用本单元的服务，中心的应用调用中心的服务，从而保证单元的封闭性，减少跨单元的服务（跨单元调用，通常会增加30ms的耗时）。\n\n消息通信层（Notify MQ层）\n> 实现原则，尽量保持单元内部消息在内部投递和消费，同时所有消息会路由到中心，保证没有做单元化部署的业务也能接受到消息\n\n数据库层\n> 用户在各自映射的单元写对应的数据，数据会和中心做双向同步；如买家数据订单\n> - 单元化保护：确保不同单元之间的数据隔离，防止数据泄露和误操作。\n> \n> ![底层数据同步](2024-07-11-稳定性-单元化概念/底层数据同步.png)\n\n### 三、怎么做单元化？\n#### 3.1、面临的问题\n##### 1. 流量调配\n如何进行流量的分配呢？常见的有按buyerId、地理位置。通常会分成交易单元化和导购单元化。\n###### 交易单元化\n交易单元化是将交易过程划分成多个独立的单元，每个单元负责特定的交易环节或功能。通过这种方式，可以提高交易系统的可扩展性、可靠性和性能。\n\n###### 导购单元化\n导购单元化是将导购功能划分成多个独立的单元，每个单元负责特定的导购场景或用户需求。通过这种方式，可以提高导购系统的精准性、个性化和用户体验。可以按照用户行为进行单元划分，例如搜索导购单元、推荐导购单元、品类导购单元等。每个单元根据用户的不同行为和需求，提供相应的导购服务。\n##### 2. 数据拆分\n- 数据的一致性问题\n  - 当数据分布在多个单元中时，确保不同单元之间的数据一致性是一个挑战。例如，在交易单元化中，如果一个用户在多个单元中进行交易，如何保证其账户余额、订单状态等数据的一致性。\n- 数据分区和路由\n  - 单元化通常需要对数据进行分区，并根据特定的规则将数据路由到不同的单元。如果数据分区不合理或路由规则不清晰，可能会导致数据分布不均衡，影响系统性能。\n\n##### 3. 响应延迟\n面临最大的问题就是异地跨机房调用。索引单元化比较核心的点是，一个单元可以提供完整的服务能力，部署完整的应用服务。单元化后，完整的请求链路要求在同一机房内完成。所以单元化也要求整个数据链路层面进行适配，包括rpc请求，MQ消息链路，DAL数据访问层面。\n\n\n\n参考文章：   \n[阿里技术架构演进及过程中遇到的问题](https://juejin.cn/post/7338422591517310991)   \n[饿了么异地多活的数据实施-DRC](https://pic.huodongjia.com/ganhuodocs/2017-08-09/1502263496.67.pdf)    \n[看完这篇异地多活的改造，我决定和架构师battle一下](https://tech.dewu.com/article?id=9)   \n[蚂蚁单元化解决方案白皮书](https://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/160617/AntCloud_zh/1585895792638/%E8%9A%82%E8%9A%81%E5%8D%95%E5%85%83%E5%8C%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%99%BD%E7%9A%AE%E4%B9%A6.pdf)    \n\n\n\n","source":"_posts/2024-07-11-稳定性-单元化概念.md","raw":"---\ntitle: 《稳定性》单元化概念\ndate: 2024-07-11 10:00:00\ncategories:\n  - [ 稳定性, 高可用、单元化]\n  - [ 阿里 ]\ntags:\n  - 阿里\n---\n\n    这是稳定性系列的第六篇文章，主要介绍的是单元化概念。\n\n### 一、什么是单元化？\n\n单元化简单点我们直接就可以认为是一个机房，在这个单元内能够完成业务的闭环。比如说用户进入APP，浏览商品，选择商品确认订单，下单，支付，查看订单信息，这整个流程都在一个单元中能够完成，并且数据也是存储在这个单元里面。\n<!-- more -->\n![什么是单元化](2024-07-11-稳定性-单元化概念/什么是单元化.png)\n\n#### 1.2 单元化基础术语\n<style>\ntable th:first-of-type {\n    width: 10%;\n}\ntable th:nth-of-type(2) {\n    width: 70%;\n}\n</style>\n\n\n| 术语    | 含义                                                                       |\n|-------|--------------------------------------------------------------------------|\n| gzone | Global Zone，全局区域。部署了不可拆分的数据和服务，这些数据或服务可能会被RZone 依赖。GZone 在全局只有一组，数据仅有一份。 |\n| rzone | Region Zone，最符合理论上单元定义的 Zone，每个 RZone 都是自包含的，拥有自己的数据，能完成所有业务。            |\n| ezone | eleme zone，饿了么每个机房为一个 ezone，一个 ezone 包含了饿了么需要的各种服务。一笔业务能够内聚在一个 ezone 中   |\n\n### 二、单元化的目的\n\n#### ⭐️ 高可用容灾：\n\n- 1、一个IDC机房挂掉了，能把流量直接切到另一个IDC机房（同一个城市），异地容灾是最终解决方案。\n\n#### ⭐️高并发容量问题：\n\n- 1、提高并发能力，加机器是最直接的答案，但是随之而来的瓶颈是数据库连接瓶颈，机房网卡瓶颈等。\n- 2、水平扩展能力，意味着可以按照一定维度来进行分片。\n- 3、单元化在做的事情，就是把数据流量，按照一定维度进行拆分。使得一个单元IDC能够闭环提供完整的服务能力。但是这个服务能力面对的是拆分后的部分数据流量，且只服务这部分流量。\n\n### 三、单元化产品组成\n![单元化产品组成](2024-07-11-稳定性-单元化概念/单元化产品组成.png)\n单元化产品包含以下三大部分：\n- 运行时：单元化流量路由能力，包含统一接入网关、应用层组件和数据层组件。\n- 运维时：跨集群资源管理、发布运维和单元化管控能力，包含单元化应用服务（LHC）。 单元化监控分析能力，包含实时监控组件和分布式链路跟踪组件。\n- 容灾时：巡检诊断、容灾演练和切换能力，包含高可用容灾平台。\n\n#### 3.1、运行时\n##### 1、统一接入网关：\n> 统一接入网关，是将访问流量根据转发规则分发到多台后端服务器的流量分发控制服务。\n> \n> 在单元化场景下，按单元化路由规则（如用户 ID 到单元的映射关系以及单元间权重占比），将用户的 http 请求路由至目标机房和单元，实现流量动态调拨。\n> \n> 统一接入网关的作用如下：\n> - 拦截请求，识别目标应用的单元类型（如是 RZone 应用，还是 GZone 应用） 根据目标类型，进行路由转发，支持跨机房异地转发，实现单元化流量调拨。\n> - GZone 路由：根据路由规则（单元权重占比），将用户 http 请求转发至目标单元的应用服务器中。\n> - RZone 路由：从 cookie 中读取分片字段（如 uid），根据路由规则（用户 ID 到单元的映射关系），将用户 http 请求转发至目标机房的应用服务器中。\n\n##### 2、中间件\n在单元化架构下，中间件从应用层到数据层均提供了单元化流量路由能力。\n![中间件改造](2024-07-11-稳定性-单元化概念/中间件改造.png)\n\nAPIRouter ： 路由分发服务\n> API Router是一个HTTP反向代理和负载均衡器，部署在公有云中作为HTTP API流量的入口，它能识别出流量的归属 shard ，并根据 shard 将流量转发到对应的 ezone。API Router 支持多种路由键，可以是地理位置，也可以是商户ID，订单ID等等，最终由 API Router 映射为统一的 Sharding ID。\n\n服务通信层：RPC\n> 需要支持基于单元化规则的服务路由。需要做到单元的应用可以调用本单元的服务，中心的应用调用中心的服务，从而保证单元的封闭性，减少跨单元的服务（跨单元调用，通常会增加30ms的耗时）。\n\n消息通信层（Notify MQ层）\n> 实现原则，尽量保持单元内部消息在内部投递和消费，同时所有消息会路由到中心，保证没有做单元化部署的业务也能接受到消息\n\n数据库层\n> 用户在各自映射的单元写对应的数据，数据会和中心做双向同步；如买家数据订单\n> - 单元化保护：确保不同单元之间的数据隔离，防止数据泄露和误操作。\n> \n> ![底层数据同步](2024-07-11-稳定性-单元化概念/底层数据同步.png)\n\n### 三、怎么做单元化？\n#### 3.1、面临的问题\n##### 1. 流量调配\n如何进行流量的分配呢？常见的有按buyerId、地理位置。通常会分成交易单元化和导购单元化。\n###### 交易单元化\n交易单元化是将交易过程划分成多个独立的单元，每个单元负责特定的交易环节或功能。通过这种方式，可以提高交易系统的可扩展性、可靠性和性能。\n\n###### 导购单元化\n导购单元化是将导购功能划分成多个独立的单元，每个单元负责特定的导购场景或用户需求。通过这种方式，可以提高导购系统的精准性、个性化和用户体验。可以按照用户行为进行单元划分，例如搜索导购单元、推荐导购单元、品类导购单元等。每个单元根据用户的不同行为和需求，提供相应的导购服务。\n##### 2. 数据拆分\n- 数据的一致性问题\n  - 当数据分布在多个单元中时，确保不同单元之间的数据一致性是一个挑战。例如，在交易单元化中，如果一个用户在多个单元中进行交易，如何保证其账户余额、订单状态等数据的一致性。\n- 数据分区和路由\n  - 单元化通常需要对数据进行分区，并根据特定的规则将数据路由到不同的单元。如果数据分区不合理或路由规则不清晰，可能会导致数据分布不均衡，影响系统性能。\n\n##### 3. 响应延迟\n面临最大的问题就是异地跨机房调用。索引单元化比较核心的点是，一个单元可以提供完整的服务能力，部署完整的应用服务。单元化后，完整的请求链路要求在同一机房内完成。所以单元化也要求整个数据链路层面进行适配，包括rpc请求，MQ消息链路，DAL数据访问层面。\n\n\n\n参考文章：   \n[阿里技术架构演进及过程中遇到的问题](https://juejin.cn/post/7338422591517310991)   \n[饿了么异地多活的数据实施-DRC](https://pic.huodongjia.com/ganhuodocs/2017-08-09/1502263496.67.pdf)    \n[看完这篇异地多活的改造，我决定和架构师battle一下](https://tech.dewu.com/article?id=9)   \n[蚂蚁单元化解决方案白皮书](https://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/160617/AntCloud_zh/1585895792638/%E8%9A%82%E8%9A%81%E5%8D%95%E5%85%83%E5%8C%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%99%BD%E7%9A%AE%E4%B9%A6.pdf)    \n\n\n\n","slug":"2024-07-11-稳定性-单元化概念","published":1,"updated":"2024-10-30T08:31:24.403Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny4004xa13kdrbkst6y","content":"<pre><code>这是稳定性系列的第六篇文章，主要介绍的是单元化概念。</code></pre><h3 id=\"一、什么是单元化？\"><a href=\"#一、什么是单元化？\" class=\"headerlink\" title=\"一、什么是单元化？\"></a>一、什么是单元化？</h3><p>单元化简单点我们直接就可以认为是一个机房，在这个单元内能够完成业务的闭环。比如说用户进入APP，浏览商品，选择商品确认订单，下单，支付，查看订单信息，这整个流程都在一个单元中能够完成，并且数据也是存储在这个单元里面。</p>\n<a id=\"more\"></a>\n<p><img src=\"/2024/07/11/2024-07-11-稳定性-单元化概念/%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%95%E5%85%83%E5%8C%96.png\" alt=\"什么是单元化\"></p>\n<h4 id=\"1-2-单元化基础术语\"><a href=\"#1-2-单元化基础术语\" class=\"headerlink\" title=\"1.2 单元化基础术语\"></a>1.2 单元化基础术语</h4><style>\ntable th:first-of-type {\n    width: 10%;\n}\ntable th:nth-of-type(2) {\n    width: 70%;\n}\n</style>\n\n\n<table>\n<thead>\n<tr>\n<th>术语</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>gzone</td>\n<td>Global Zone，全局区域。部署了不可拆分的数据和服务，这些数据或服务可能会被RZone 依赖。GZone 在全局只有一组，数据仅有一份。</td>\n</tr>\n<tr>\n<td>rzone</td>\n<td>Region Zone，最符合理论上单元定义的 Zone，每个 RZone 都是自包含的，拥有自己的数据，能完成所有业务。</td>\n</tr>\n<tr>\n<td>ezone</td>\n<td>eleme zone，饿了么每个机房为一个 ezone，一个 ezone 包含了饿了么需要的各种服务。一笔业务能够内聚在一个 ezone 中</td>\n</tr>\n</tbody></table>\n<h3 id=\"二、单元化的目的\"><a href=\"#二、单元化的目的\" class=\"headerlink\" title=\"二、单元化的目的\"></a>二、单元化的目的</h3><h4 id=\"⭐️-高可用容灾：\"><a href=\"#⭐️-高可用容灾：\" class=\"headerlink\" title=\"⭐️ 高可用容灾：\"></a>⭐️ 高可用容灾：</h4><ul>\n<li>1、一个IDC机房挂掉了，能把流量直接切到另一个IDC机房（同一个城市），异地容灾是最终解决方案。</li>\n</ul>\n<h4 id=\"⭐️高并发容量问题：\"><a href=\"#⭐️高并发容量问题：\" class=\"headerlink\" title=\"⭐️高并发容量问题：\"></a>⭐️高并发容量问题：</h4><ul>\n<li>1、提高并发能力，加机器是最直接的答案，但是随之而来的瓶颈是数据库连接瓶颈，机房网卡瓶颈等。</li>\n<li>2、水平扩展能力，意味着可以按照一定维度来进行分片。</li>\n<li>3、单元化在做的事情，就是把数据流量，按照一定维度进行拆分。使得一个单元IDC能够闭环提供完整的服务能力。但是这个服务能力面对的是拆分后的部分数据流量，且只服务这部分流量。</li>\n</ul>\n<h3 id=\"三、单元化产品组成\"><a href=\"#三、单元化产品组成\" class=\"headerlink\" title=\"三、单元化产品组成\"></a>三、单元化产品组成</h3><p><img src=\"/2024/07/11/2024-07-11-稳定性-单元化概念/%E5%8D%95%E5%85%83%E5%8C%96%E4%BA%A7%E5%93%81%E7%BB%84%E6%88%90.png\" alt=\"单元化产品组成\"><br>单元化产品包含以下三大部分：</p>\n<ul>\n<li>运行时：单元化流量路由能力，包含统一接入网关、应用层组件和数据层组件。</li>\n<li>运维时：跨集群资源管理、发布运维和单元化管控能力，包含单元化应用服务（LHC）。 单元化监控分析能力，包含实时监控组件和分布式链路跟踪组件。</li>\n<li>容灾时：巡检诊断、容灾演练和切换能力，包含高可用容灾平台。</li>\n</ul>\n<h4 id=\"3-1、运行时\"><a href=\"#3-1、运行时\" class=\"headerlink\" title=\"3.1、运行时\"></a>3.1、运行时</h4><h5 id=\"1、统一接入网关：\"><a href=\"#1、统一接入网关：\" class=\"headerlink\" title=\"1、统一接入网关：\"></a>1、统一接入网关：</h5><blockquote>\n<p>统一接入网关，是将访问流量根据转发规则分发到多台后端服务器的流量分发控制服务。</p>\n<p>在单元化场景下，按单元化路由规则（如用户 ID 到单元的映射关系以及单元间权重占比），将用户的 http 请求路由至目标机房和单元，实现流量动态调拨。</p>\n<p>统一接入网关的作用如下：</p>\n<ul>\n<li>拦截请求，识别目标应用的单元类型（如是 RZone 应用，还是 GZone 应用） 根据目标类型，进行路由转发，支持跨机房异地转发，实现单元化流量调拨。</li>\n<li>GZone 路由：根据路由规则（单元权重占比），将用户 http 请求转发至目标单元的应用服务器中。</li>\n<li>RZone 路由：从 cookie 中读取分片字段（如 uid），根据路由规则（用户 ID 到单元的映射关系），将用户 http 请求转发至目标机房的应用服务器中。</li>\n</ul>\n</blockquote>\n<h5 id=\"2、中间件\"><a href=\"#2、中间件\" class=\"headerlink\" title=\"2、中间件\"></a>2、中间件</h5><p>在单元化架构下，中间件从应用层到数据层均提供了单元化流量路由能力。<br><img src=\"/2024/07/11/2024-07-11-稳定性-单元化概念/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%94%B9%E9%80%A0.png\" alt=\"中间件改造\"></p>\n<p>APIRouter ： 路由分发服务</p>\n<blockquote>\n<p>API Router是一个HTTP反向代理和负载均衡器，部署在公有云中作为HTTP API流量的入口，它能识别出流量的归属 shard ，并根据 shard 将流量转发到对应的 ezone。API Router 支持多种路由键，可以是地理位置，也可以是商户ID，订单ID等等，最终由 API Router 映射为统一的 Sharding ID。</p>\n</blockquote>\n<p>服务通信层：RPC</p>\n<blockquote>\n<p>需要支持基于单元化规则的服务路由。需要做到单元的应用可以调用本单元的服务，中心的应用调用中心的服务，从而保证单元的封闭性，减少跨单元的服务（跨单元调用，通常会增加30ms的耗时）。</p>\n</blockquote>\n<p>消息通信层（Notify MQ层）</p>\n<blockquote>\n<p>实现原则，尽量保持单元内部消息在内部投递和消费，同时所有消息会路由到中心，保证没有做单元化部署的业务也能接受到消息</p>\n</blockquote>\n<p>数据库层</p>\n<blockquote>\n<p>用户在各自映射的单元写对应的数据，数据会和中心做双向同步；如买家数据订单</p>\n<ul>\n<li>单元化保护：确保不同单元之间的数据隔离，防止数据泄露和误操作。</li>\n</ul>\n<p><img src=\"/2024/07/11/2024-07-11-稳定性-单元化概念/%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5.png\" alt=\"底层数据同步\"></p>\n</blockquote>\n<h3 id=\"三、怎么做单元化？\"><a href=\"#三、怎么做单元化？\" class=\"headerlink\" title=\"三、怎么做单元化？\"></a>三、怎么做单元化？</h3><h4 id=\"3-1、面临的问题\"><a href=\"#3-1、面临的问题\" class=\"headerlink\" title=\"3.1、面临的问题\"></a>3.1、面临的问题</h4><h5 id=\"1-流量调配\"><a href=\"#1-流量调配\" class=\"headerlink\" title=\"1. 流量调配\"></a>1. 流量调配</h5><p>如何进行流量的分配呢？常见的有按buyerId、地理位置。通常会分成交易单元化和导购单元化。</p>\n<h6 id=\"交易单元化\"><a href=\"#交易单元化\" class=\"headerlink\" title=\"交易单元化\"></a>交易单元化</h6><p>交易单元化是将交易过程划分成多个独立的单元，每个单元负责特定的交易环节或功能。通过这种方式，可以提高交易系统的可扩展性、可靠性和性能。</p>\n<h6 id=\"导购单元化\"><a href=\"#导购单元化\" class=\"headerlink\" title=\"导购单元化\"></a>导购单元化</h6><p>导购单元化是将导购功能划分成多个独立的单元，每个单元负责特定的导购场景或用户需求。通过这种方式，可以提高导购系统的精准性、个性化和用户体验。可以按照用户行为进行单元划分，例如搜索导购单元、推荐导购单元、品类导购单元等。每个单元根据用户的不同行为和需求，提供相应的导购服务。</p>\n<h5 id=\"2-数据拆分\"><a href=\"#2-数据拆分\" class=\"headerlink\" title=\"2. 数据拆分\"></a>2. 数据拆分</h5><ul>\n<li>数据的一致性问题<ul>\n<li>当数据分布在多个单元中时，确保不同单元之间的数据一致性是一个挑战。例如，在交易单元化中，如果一个用户在多个单元中进行交易，如何保证其账户余额、订单状态等数据的一致性。</li>\n</ul>\n</li>\n<li>数据分区和路由<ul>\n<li>单元化通常需要对数据进行分区，并根据特定的规则将数据路由到不同的单元。如果数据分区不合理或路由规则不清晰，可能会导致数据分布不均衡，影响系统性能。</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"3-响应延迟\"><a href=\"#3-响应延迟\" class=\"headerlink\" title=\"3. 响应延迟\"></a>3. 响应延迟</h5><p>面临最大的问题就是异地跨机房调用。索引单元化比较核心的点是，一个单元可以提供完整的服务能力，部署完整的应用服务。单元化后，完整的请求链路要求在同一机房内完成。所以单元化也要求整个数据链路层面进行适配，包括rpc请求，MQ消息链路，DAL数据访问层面。</p>\n<p>参考文章：<br><a href=\"https://juejin.cn/post/7338422591517310991\" target=\"_blank\" rel=\"noopener\">阿里技术架构演进及过程中遇到的问题</a><br><a href=\"https://pic.huodongjia.com/ganhuodocs/2017-08-09/1502263496.67.pdf\" target=\"_blank\" rel=\"noopener\">饿了么异地多活的数据实施-DRC</a><br><a href=\"https://tech.dewu.com/article?id=9\" target=\"_blank\" rel=\"noopener\">看完这篇异地多活的改造，我决定和架构师battle一下</a><br><a href=\"https://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/160617/AntCloud_zh/1585895792638/%E8%9A%82%E8%9A%81%E5%8D%95%E5%85%83%E5%8C%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%99%BD%E7%9A%AE%E4%B9%A6.pdf\" target=\"_blank\" rel=\"noopener\">蚂蚁单元化解决方案白皮书</a>    </p>\n","site":{"data":{}},"excerpt":"<pre><code>这是稳定性系列的第六篇文章，主要介绍的是单元化概念。</code></pre><h3 id=\"一、什么是单元化？\"><a href=\"#一、什么是单元化？\" class=\"headerlink\" title=\"一、什么是单元化？\"></a>一、什么是单元化？</h3><p>单元化简单点我们直接就可以认为是一个机房，在这个单元内能够完成业务的闭环。比如说用户进入APP，浏览商品，选择商品确认订单，下单，支付，查看订单信息，这整个流程都在一个单元中能够完成，并且数据也是存储在这个单元里面。</p>","more":"<p><img src=\"/2024/07/11/2024-07-11-稳定性-单元化概念/%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%95%E5%85%83%E5%8C%96.png\" alt=\"什么是单元化\"></p>\n<h4 id=\"1-2-单元化基础术语\"><a href=\"#1-2-单元化基础术语\" class=\"headerlink\" title=\"1.2 单元化基础术语\"></a>1.2 单元化基础术语</h4><style>\ntable th:first-of-type {\n    width: 10%;\n}\ntable th:nth-of-type(2) {\n    width: 70%;\n}\n</style>\n\n\n<table>\n<thead>\n<tr>\n<th>术语</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>gzone</td>\n<td>Global Zone，全局区域。部署了不可拆分的数据和服务，这些数据或服务可能会被RZone 依赖。GZone 在全局只有一组，数据仅有一份。</td>\n</tr>\n<tr>\n<td>rzone</td>\n<td>Region Zone，最符合理论上单元定义的 Zone，每个 RZone 都是自包含的，拥有自己的数据，能完成所有业务。</td>\n</tr>\n<tr>\n<td>ezone</td>\n<td>eleme zone，饿了么每个机房为一个 ezone，一个 ezone 包含了饿了么需要的各种服务。一笔业务能够内聚在一个 ezone 中</td>\n</tr>\n</tbody></table>\n<h3 id=\"二、单元化的目的\"><a href=\"#二、单元化的目的\" class=\"headerlink\" title=\"二、单元化的目的\"></a>二、单元化的目的</h3><h4 id=\"⭐️-高可用容灾：\"><a href=\"#⭐️-高可用容灾：\" class=\"headerlink\" title=\"⭐️ 高可用容灾：\"></a>⭐️ 高可用容灾：</h4><ul>\n<li>1、一个IDC机房挂掉了，能把流量直接切到另一个IDC机房（同一个城市），异地容灾是最终解决方案。</li>\n</ul>\n<h4 id=\"⭐️高并发容量问题：\"><a href=\"#⭐️高并发容量问题：\" class=\"headerlink\" title=\"⭐️高并发容量问题：\"></a>⭐️高并发容量问题：</h4><ul>\n<li>1、提高并发能力，加机器是最直接的答案，但是随之而来的瓶颈是数据库连接瓶颈，机房网卡瓶颈等。</li>\n<li>2、水平扩展能力，意味着可以按照一定维度来进行分片。</li>\n<li>3、单元化在做的事情，就是把数据流量，按照一定维度进行拆分。使得一个单元IDC能够闭环提供完整的服务能力。但是这个服务能力面对的是拆分后的部分数据流量，且只服务这部分流量。</li>\n</ul>\n<h3 id=\"三、单元化产品组成\"><a href=\"#三、单元化产品组成\" class=\"headerlink\" title=\"三、单元化产品组成\"></a>三、单元化产品组成</h3><p><img src=\"/2024/07/11/2024-07-11-稳定性-单元化概念/%E5%8D%95%E5%85%83%E5%8C%96%E4%BA%A7%E5%93%81%E7%BB%84%E6%88%90.png\" alt=\"单元化产品组成\"><br>单元化产品包含以下三大部分：</p>\n<ul>\n<li>运行时：单元化流量路由能力，包含统一接入网关、应用层组件和数据层组件。</li>\n<li>运维时：跨集群资源管理、发布运维和单元化管控能力，包含单元化应用服务（LHC）。 单元化监控分析能力，包含实时监控组件和分布式链路跟踪组件。</li>\n<li>容灾时：巡检诊断、容灾演练和切换能力，包含高可用容灾平台。</li>\n</ul>\n<h4 id=\"3-1、运行时\"><a href=\"#3-1、运行时\" class=\"headerlink\" title=\"3.1、运行时\"></a>3.1、运行时</h4><h5 id=\"1、统一接入网关：\"><a href=\"#1、统一接入网关：\" class=\"headerlink\" title=\"1、统一接入网关：\"></a>1、统一接入网关：</h5><blockquote>\n<p>统一接入网关，是将访问流量根据转发规则分发到多台后端服务器的流量分发控制服务。</p>\n<p>在单元化场景下，按单元化路由规则（如用户 ID 到单元的映射关系以及单元间权重占比），将用户的 http 请求路由至目标机房和单元，实现流量动态调拨。</p>\n<p>统一接入网关的作用如下：</p>\n<ul>\n<li>拦截请求，识别目标应用的单元类型（如是 RZone 应用，还是 GZone 应用） 根据目标类型，进行路由转发，支持跨机房异地转发，实现单元化流量调拨。</li>\n<li>GZone 路由：根据路由规则（单元权重占比），将用户 http 请求转发至目标单元的应用服务器中。</li>\n<li>RZone 路由：从 cookie 中读取分片字段（如 uid），根据路由规则（用户 ID 到单元的映射关系），将用户 http 请求转发至目标机房的应用服务器中。</li>\n</ul>\n</blockquote>\n<h5 id=\"2、中间件\"><a href=\"#2、中间件\" class=\"headerlink\" title=\"2、中间件\"></a>2、中间件</h5><p>在单元化架构下，中间件从应用层到数据层均提供了单元化流量路由能力。<br><img src=\"/2024/07/11/2024-07-11-稳定性-单元化概念/%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%94%B9%E9%80%A0.png\" alt=\"中间件改造\"></p>\n<p>APIRouter ： 路由分发服务</p>\n<blockquote>\n<p>API Router是一个HTTP反向代理和负载均衡器，部署在公有云中作为HTTP API流量的入口，它能识别出流量的归属 shard ，并根据 shard 将流量转发到对应的 ezone。API Router 支持多种路由键，可以是地理位置，也可以是商户ID，订单ID等等，最终由 API Router 映射为统一的 Sharding ID。</p>\n</blockquote>\n<p>服务通信层：RPC</p>\n<blockquote>\n<p>需要支持基于单元化规则的服务路由。需要做到单元的应用可以调用本单元的服务，中心的应用调用中心的服务，从而保证单元的封闭性，减少跨单元的服务（跨单元调用，通常会增加30ms的耗时）。</p>\n</blockquote>\n<p>消息通信层（Notify MQ层）</p>\n<blockquote>\n<p>实现原则，尽量保持单元内部消息在内部投递和消费，同时所有消息会路由到中心，保证没有做单元化部署的业务也能接受到消息</p>\n</blockquote>\n<p>数据库层</p>\n<blockquote>\n<p>用户在各自映射的单元写对应的数据，数据会和中心做双向同步；如买家数据订单</p>\n<ul>\n<li>单元化保护：确保不同单元之间的数据隔离，防止数据泄露和误操作。</li>\n</ul>\n<p><img src=\"/2024/07/11/2024-07-11-稳定性-单元化概念/%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5.png\" alt=\"底层数据同步\"></p>\n</blockquote>\n<h3 id=\"三、怎么做单元化？\"><a href=\"#三、怎么做单元化？\" class=\"headerlink\" title=\"三、怎么做单元化？\"></a>三、怎么做单元化？</h3><h4 id=\"3-1、面临的问题\"><a href=\"#3-1、面临的问题\" class=\"headerlink\" title=\"3.1、面临的问题\"></a>3.1、面临的问题</h4><h5 id=\"1-流量调配\"><a href=\"#1-流量调配\" class=\"headerlink\" title=\"1. 流量调配\"></a>1. 流量调配</h5><p>如何进行流量的分配呢？常见的有按buyerId、地理位置。通常会分成交易单元化和导购单元化。</p>\n<h6 id=\"交易单元化\"><a href=\"#交易单元化\" class=\"headerlink\" title=\"交易单元化\"></a>交易单元化</h6><p>交易单元化是将交易过程划分成多个独立的单元，每个单元负责特定的交易环节或功能。通过这种方式，可以提高交易系统的可扩展性、可靠性和性能。</p>\n<h6 id=\"导购单元化\"><a href=\"#导购单元化\" class=\"headerlink\" title=\"导购单元化\"></a>导购单元化</h6><p>导购单元化是将导购功能划分成多个独立的单元，每个单元负责特定的导购场景或用户需求。通过这种方式，可以提高导购系统的精准性、个性化和用户体验。可以按照用户行为进行单元划分，例如搜索导购单元、推荐导购单元、品类导购单元等。每个单元根据用户的不同行为和需求，提供相应的导购服务。</p>\n<h5 id=\"2-数据拆分\"><a href=\"#2-数据拆分\" class=\"headerlink\" title=\"2. 数据拆分\"></a>2. 数据拆分</h5><ul>\n<li>数据的一致性问题<ul>\n<li>当数据分布在多个单元中时，确保不同单元之间的数据一致性是一个挑战。例如，在交易单元化中，如果一个用户在多个单元中进行交易，如何保证其账户余额、订单状态等数据的一致性。</li>\n</ul>\n</li>\n<li>数据分区和路由<ul>\n<li>单元化通常需要对数据进行分区，并根据特定的规则将数据路由到不同的单元。如果数据分区不合理或路由规则不清晰，可能会导致数据分布不均衡，影响系统性能。</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"3-响应延迟\"><a href=\"#3-响应延迟\" class=\"headerlink\" title=\"3. 响应延迟\"></a>3. 响应延迟</h5><p>面临最大的问题就是异地跨机房调用。索引单元化比较核心的点是，一个单元可以提供完整的服务能力，部署完整的应用服务。单元化后，完整的请求链路要求在同一机房内完成。所以单元化也要求整个数据链路层面进行适配，包括rpc请求，MQ消息链路，DAL数据访问层面。</p>\n<p>参考文章：<br><a href=\"https://juejin.cn/post/7338422591517310991\" target=\"_blank\" rel=\"noopener\">阿里技术架构演进及过程中遇到的问题</a><br><a href=\"https://pic.huodongjia.com/ganhuodocs/2017-08-09/1502263496.67.pdf\" target=\"_blank\" rel=\"noopener\">饿了么异地多活的数据实施-DRC</a><br><a href=\"https://tech.dewu.com/article?id=9\" target=\"_blank\" rel=\"noopener\">看完这篇异地多活的改造，我决定和架构师battle一下</a><br><a href=\"https://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/160617/AntCloud_zh/1585895792638/%E8%9A%82%E8%9A%81%E5%8D%95%E5%85%83%E5%8C%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%99%BD%E7%9A%AE%E4%B9%A6.pdf\" target=\"_blank\" rel=\"noopener\">蚂蚁单元化解决方案白皮书</a>    </p>"},{"title":"《稳定性》线程池要设置多大","date":"2024-06-15T02:00:00.000Z","_content":"\n    这是稳定性系列的第四篇文章，主要介绍的是线程池的设置。\n\n### 一、理论分析\n**业界的一些线程池参数配置方案：**\n![线程池参数配置方案](2024-06-15-稳定性-线程池要设置多大/线程池参数配置方案.png)\n<!-- more -->\n> 一般思路：会使用第3种计算方式去得到大致的线程池数量。\n>  \n> 示例如下：假设1秒需要执行1000个任务，每个任务执行耗时40ms，那么需要多少个线程？\n> \n> 公式：任务个数/每秒执行个数=线程数量\n> - 1000/(1000/40)=40个线程\n\n**和CPU利用率的关系：**\n> 示例如下：任务执行耗时40ms，其中计算10ms，数据库IO为30ms。\n> \n> CPU利用率=10/40=25%\n\n**线程数量&队列&流量关系：**\n![线程池参数配置方案](2024-06-15-稳定性-线程池要设置多大/队列和流量的关系.png)\n> - **线程处理速度 < 流量：** 导致队列堆积，导致影响业务，极端情况下OOM；\n> - **线程处理速度 = 流量：** 比较稳定的情况，一般不会出现大问题。\n> - **线程处理速度 > 流量：** 有可能是线程数量过多，造成资源浪费。\n\n### 三、实际业务\n在实际业务中，为了系统稳定性，每个业务都会有独立的线程池，所以会存在多个线程池。那如果一个新业务来了，我们应该怎么设置线程池数量呢？这篇文章为订单拉单的后序文章。\n\n#### 3.1、线程预估\n这一步操作还是需要的，基于新业务的特性，根据理论分析，估算出大致的线程数量。预估出来后，我们应该怎么做呢？\n\n#### 3.2、分析影响\n预估出来后，需要分析影响。\n\n增加线程池，有可能会对现有业务造成影响（不管有木有影响，我们还是得去做考虑），应该从哪些方面进行分析呢？\n\n**方面1：业务响应时间 & 吞吐量**        \n为什么需要考虑这个？\n> 新增线程池后，新任务会去抢占CPU的运行时间，造成进程上下文的切换，导致原有业务的执行时间减少，最终体现到响应时间和吞吐量上。\n> - 解决方法：减少线程数量，增大队列，减少上下文切换。实际操作上，无法具体分析出影响范围有多大。\n>   - 最佳实践：采用灰度发布的方式，逐步将新线程池引入现有业务系统；同时对现有业务的监控指标进行观察。\n****\n**方面2：[CPU负载 & CPU利用率：](https://caohuiwu.github.io/2024/06/05/2024-06-05-Linux-CPU%E8%B4%9F%E8%BD%BD%E5%92%8C%E5%88%A9%E7%94%A8%E7%8E%87/#more)**\n> 1. 造成CPU负载的升高：增加线程池，那么会有更多的任务需要处理。例如I/O 密集型任务，这些进程会处于等待 I/O 完成的状态，此时它们并不占用大量的 CPU 资源，但会被计入系统负载中。\n>    1. 解决方法：根据不同的造成因素做不同的处理。\n>    2. 例如应用程序问题，则优化程序；\n>    3. 如果是机器问题，则增加CPU核心数量或升级硬件；\n> 2. 进程频繁上下文切换：\n>    1. 更多的任务，那么会竞争CPU使用资源，就会造成进程频繁上下文切换，会消耗一定的系统资源。\n\n因此我们需要去查看CPU负载 & CPU利用率，保证增加线程池后，两项指标不会升高到预期之外，并且不对其他现有业务造成过大的影响。\n****\n**方面3：内存：**\n> 每开启一个线程都需要内存空间，并且任务堆积情况下，会造成内存消耗，极端情况下造成oom。\n\n#### 3.3、我们应该怎么做？\n> 最佳实践：采用灰度发布的方式，逐步将新线程池引入现有业务系统；同时对现有业务的监控指标进行观察。\n\n\n参考文章：   \n[Java线程池实现原理及其在美团业务中的实践](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)      \n[线程池的数量和线程池中线程数量如何设置-实践篇](https://juejin.cn/post/7067183465224994852#heading-5)\n\n\n","source":"_posts/2024-06-15-稳定性-线程池要设置多大.md","raw":"---\ntitle: 《稳定性》线程池要设置多大\ndate: 2024-06-15 10:00:00\ncategories:\n  - [线程池]\n  - [稳定性]\n  - [阿里]\ntags:\n- 阿里\n---\n\n    这是稳定性系列的第四篇文章，主要介绍的是线程池的设置。\n\n### 一、理论分析\n**业界的一些线程池参数配置方案：**\n![线程池参数配置方案](2024-06-15-稳定性-线程池要设置多大/线程池参数配置方案.png)\n<!-- more -->\n> 一般思路：会使用第3种计算方式去得到大致的线程池数量。\n>  \n> 示例如下：假设1秒需要执行1000个任务，每个任务执行耗时40ms，那么需要多少个线程？\n> \n> 公式：任务个数/每秒执行个数=线程数量\n> - 1000/(1000/40)=40个线程\n\n**和CPU利用率的关系：**\n> 示例如下：任务执行耗时40ms，其中计算10ms，数据库IO为30ms。\n> \n> CPU利用率=10/40=25%\n\n**线程数量&队列&流量关系：**\n![线程池参数配置方案](2024-06-15-稳定性-线程池要设置多大/队列和流量的关系.png)\n> - **线程处理速度 < 流量：** 导致队列堆积，导致影响业务，极端情况下OOM；\n> - **线程处理速度 = 流量：** 比较稳定的情况，一般不会出现大问题。\n> - **线程处理速度 > 流量：** 有可能是线程数量过多，造成资源浪费。\n\n### 三、实际业务\n在实际业务中，为了系统稳定性，每个业务都会有独立的线程池，所以会存在多个线程池。那如果一个新业务来了，我们应该怎么设置线程池数量呢？这篇文章为订单拉单的后序文章。\n\n#### 3.1、线程预估\n这一步操作还是需要的，基于新业务的特性，根据理论分析，估算出大致的线程数量。预估出来后，我们应该怎么做呢？\n\n#### 3.2、分析影响\n预估出来后，需要分析影响。\n\n增加线程池，有可能会对现有业务造成影响（不管有木有影响，我们还是得去做考虑），应该从哪些方面进行分析呢？\n\n**方面1：业务响应时间 & 吞吐量**        \n为什么需要考虑这个？\n> 新增线程池后，新任务会去抢占CPU的运行时间，造成进程上下文的切换，导致原有业务的执行时间减少，最终体现到响应时间和吞吐量上。\n> - 解决方法：减少线程数量，增大队列，减少上下文切换。实际操作上，无法具体分析出影响范围有多大。\n>   - 最佳实践：采用灰度发布的方式，逐步将新线程池引入现有业务系统；同时对现有业务的监控指标进行观察。\n****\n**方面2：[CPU负载 & CPU利用率：](https://caohuiwu.github.io/2024/06/05/2024-06-05-Linux-CPU%E8%B4%9F%E8%BD%BD%E5%92%8C%E5%88%A9%E7%94%A8%E7%8E%87/#more)**\n> 1. 造成CPU负载的升高：增加线程池，那么会有更多的任务需要处理。例如I/O 密集型任务，这些进程会处于等待 I/O 完成的状态，此时它们并不占用大量的 CPU 资源，但会被计入系统负载中。\n>    1. 解决方法：根据不同的造成因素做不同的处理。\n>    2. 例如应用程序问题，则优化程序；\n>    3. 如果是机器问题，则增加CPU核心数量或升级硬件；\n> 2. 进程频繁上下文切换：\n>    1. 更多的任务，那么会竞争CPU使用资源，就会造成进程频繁上下文切换，会消耗一定的系统资源。\n\n因此我们需要去查看CPU负载 & CPU利用率，保证增加线程池后，两项指标不会升高到预期之外，并且不对其他现有业务造成过大的影响。\n****\n**方面3：内存：**\n> 每开启一个线程都需要内存空间，并且任务堆积情况下，会造成内存消耗，极端情况下造成oom。\n\n#### 3.3、我们应该怎么做？\n> 最佳实践：采用灰度发布的方式，逐步将新线程池引入现有业务系统；同时对现有业务的监控指标进行观察。\n\n\n参考文章：   \n[Java线程池实现原理及其在美团业务中的实践](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)      \n[线程池的数量和线程池中线程数量如何设置-实践篇](https://juejin.cn/post/7067183465224994852#heading-5)\n\n\n","slug":"2024-06-15-稳定性-线程池要设置多大","published":1,"updated":"2024-10-28T09:00:48.584Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny50051a13kt3zcmx9f","content":"<pre><code>这是稳定性系列的第四篇文章，主要介绍的是线程池的设置。</code></pre><h3 id=\"一、理论分析\"><a href=\"#一、理论分析\" class=\"headerlink\" title=\"一、理论分析\"></a>一、理论分析</h3><p><strong>业界的一些线程池参数配置方案：</strong><br><img src=\"/2024/06/15/2024-06-15-稳定性-线程池要设置多大/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E6%96%B9%E6%A1%88.png\" alt=\"线程池参数配置方案\"></p>\n<a id=\"more\"></a>\n<blockquote>\n<p>一般思路：会使用第3种计算方式去得到大致的线程池数量。</p>\n<p>示例如下：假设1秒需要执行1000个任务，每个任务执行耗时40ms，那么需要多少个线程？</p>\n<p>公式：任务个数/每秒执行个数=线程数量</p>\n<ul>\n<li>1000/(1000/40)=40个线程</li>\n</ul>\n</blockquote>\n<p><strong>和CPU利用率的关系：</strong></p>\n<blockquote>\n<p>示例如下：任务执行耗时40ms，其中计算10ms，数据库IO为30ms。</p>\n<p>CPU利用率=10/40=25%</p>\n</blockquote>\n<p><strong>线程数量&amp;队列&amp;流量关系：</strong><br><img src=\"/2024/06/15/2024-06-15-稳定性-线程池要设置多大/%E9%98%9F%E5%88%97%E5%92%8C%E6%B5%81%E9%87%8F%E7%9A%84%E5%85%B3%E7%B3%BB.png\" alt=\"线程池参数配置方案\"></p>\n<blockquote>\n<ul>\n<li><strong>线程处理速度 &lt; 流量：</strong> 导致队列堆积，导致影响业务，极端情况下OOM；</li>\n<li><strong>线程处理速度 = 流量：</strong> 比较稳定的情况，一般不会出现大问题。</li>\n<li><strong>线程处理速度 &gt; 流量：</strong> 有可能是线程数量过多，造成资源浪费。</li>\n</ul>\n</blockquote>\n<h3 id=\"三、实际业务\"><a href=\"#三、实际业务\" class=\"headerlink\" title=\"三、实际业务\"></a>三、实际业务</h3><p>在实际业务中，为了系统稳定性，每个业务都会有独立的线程池，所以会存在多个线程池。那如果一个新业务来了，我们应该怎么设置线程池数量呢？这篇文章为订单拉单的后序文章。</p>\n<h4 id=\"3-1、线程预估\"><a href=\"#3-1、线程预估\" class=\"headerlink\" title=\"3.1、线程预估\"></a>3.1、线程预估</h4><p>这一步操作还是需要的，基于新业务的特性，根据理论分析，估算出大致的线程数量。预估出来后，我们应该怎么做呢？</p>\n<h4 id=\"3-2、分析影响\"><a href=\"#3-2、分析影响\" class=\"headerlink\" title=\"3.2、分析影响\"></a>3.2、分析影响</h4><p>预估出来后，需要分析影响。</p>\n<p>增加线程池，有可能会对现有业务造成影响（不管有木有影响，我们还是得去做考虑），应该从哪些方面进行分析呢？</p>\n<p><strong>方面1：业务响应时间 &amp; 吞吐量</strong><br>为什么需要考虑这个？</p>\n<blockquote>\n<p>新增线程池后，新任务会去抢占CPU的运行时间，造成进程上下文的切换，导致原有业务的执行时间减少，最终体现到响应时间和吞吐量上。</p>\n<ul>\n<li>解决方法：减少线程数量，增大队列，减少上下文切换。实际操作上，无法具体分析出影响范围有多大。<ul>\n<li>最佳实践：采用灰度发布的方式，逐步将新线程池引入现有业务系统；同时对现有业务的监控指标进行观察。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<hr>\n<p><strong>方面2：<a href=\"https://caohuiwu.github.io/2024/06/05/2024-06-05-Linux-CPU%E8%B4%9F%E8%BD%BD%E5%92%8C%E5%88%A9%E7%94%A8%E7%8E%87/#more\" target=\"_blank\" rel=\"noopener\">CPU负载 &amp; CPU利用率：</a></strong></p>\n<blockquote>\n<ol>\n<li>造成CPU负载的升高：增加线程池，那么会有更多的任务需要处理。例如I/O 密集型任务，这些进程会处于等待 I/O 完成的状态，此时它们并不占用大量的 CPU 资源，但会被计入系统负载中。<ol>\n<li>解决方法：根据不同的造成因素做不同的处理。</li>\n<li>例如应用程序问题，则优化程序；</li>\n<li>如果是机器问题，则增加CPU核心数量或升级硬件；</li>\n</ol>\n</li>\n<li>进程频繁上下文切换：<ol>\n<li>更多的任务，那么会竞争CPU使用资源，就会造成进程频繁上下文切换，会消耗一定的系统资源。</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>因此我们需要去查看CPU负载 &amp; CPU利用率，保证增加线程池后，两项指标不会升高到预期之外，并且不对其他现有业务造成过大的影响。</p>\n<hr>\n<p><strong>方面3：内存：</strong></p>\n<blockquote>\n<p>每开启一个线程都需要内存空间，并且任务堆积情况下，会造成内存消耗，极端情况下造成oom。</p>\n</blockquote>\n<h4 id=\"3-3、我们应该怎么做？\"><a href=\"#3-3、我们应该怎么做？\" class=\"headerlink\" title=\"3.3、我们应该怎么做？\"></a>3.3、我们应该怎么做？</h4><blockquote>\n<p>最佳实践：采用灰度发布的方式，逐步将新线程池引入现有业务系统；同时对现有业务的监控指标进行观察。</p>\n</blockquote>\n<p>参考文章：<br><a href=\"https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html\" target=\"_blank\" rel=\"noopener\">Java线程池实现原理及其在美团业务中的实践</a><br><a href=\"https://juejin.cn/post/7067183465224994852#heading-5\" target=\"_blank\" rel=\"noopener\">线程池的数量和线程池中线程数量如何设置-实践篇</a></p>\n","site":{"data":{}},"excerpt":"<pre><code>这是稳定性系列的第四篇文章，主要介绍的是线程池的设置。</code></pre><h3 id=\"一、理论分析\"><a href=\"#一、理论分析\" class=\"headerlink\" title=\"一、理论分析\"></a>一、理论分析</h3><p><strong>业界的一些线程池参数配置方案：</strong><br><img src=\"/2024/06/15/2024-06-15-稳定性-线程池要设置多大/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E6%96%B9%E6%A1%88.png\" alt=\"线程池参数配置方案\"></p>","more":"<blockquote>\n<p>一般思路：会使用第3种计算方式去得到大致的线程池数量。</p>\n<p>示例如下：假设1秒需要执行1000个任务，每个任务执行耗时40ms，那么需要多少个线程？</p>\n<p>公式：任务个数/每秒执行个数=线程数量</p>\n<ul>\n<li>1000/(1000/40)=40个线程</li>\n</ul>\n</blockquote>\n<p><strong>和CPU利用率的关系：</strong></p>\n<blockquote>\n<p>示例如下：任务执行耗时40ms，其中计算10ms，数据库IO为30ms。</p>\n<p>CPU利用率=10/40=25%</p>\n</blockquote>\n<p><strong>线程数量&amp;队列&amp;流量关系：</strong><br><img src=\"/2024/06/15/2024-06-15-稳定性-线程池要设置多大/%E9%98%9F%E5%88%97%E5%92%8C%E6%B5%81%E9%87%8F%E7%9A%84%E5%85%B3%E7%B3%BB.png\" alt=\"线程池参数配置方案\"></p>\n<blockquote>\n<ul>\n<li><strong>线程处理速度 &lt; 流量：</strong> 导致队列堆积，导致影响业务，极端情况下OOM；</li>\n<li><strong>线程处理速度 = 流量：</strong> 比较稳定的情况，一般不会出现大问题。</li>\n<li><strong>线程处理速度 &gt; 流量：</strong> 有可能是线程数量过多，造成资源浪费。</li>\n</ul>\n</blockquote>\n<h3 id=\"三、实际业务\"><a href=\"#三、实际业务\" class=\"headerlink\" title=\"三、实际业务\"></a>三、实际业务</h3><p>在实际业务中，为了系统稳定性，每个业务都会有独立的线程池，所以会存在多个线程池。那如果一个新业务来了，我们应该怎么设置线程池数量呢？这篇文章为订单拉单的后序文章。</p>\n<h4 id=\"3-1、线程预估\"><a href=\"#3-1、线程预估\" class=\"headerlink\" title=\"3.1、线程预估\"></a>3.1、线程预估</h4><p>这一步操作还是需要的，基于新业务的特性，根据理论分析，估算出大致的线程数量。预估出来后，我们应该怎么做呢？</p>\n<h4 id=\"3-2、分析影响\"><a href=\"#3-2、分析影响\" class=\"headerlink\" title=\"3.2、分析影响\"></a>3.2、分析影响</h4><p>预估出来后，需要分析影响。</p>\n<p>增加线程池，有可能会对现有业务造成影响（不管有木有影响，我们还是得去做考虑），应该从哪些方面进行分析呢？</p>\n<p><strong>方面1：业务响应时间 &amp; 吞吐量</strong><br>为什么需要考虑这个？</p>\n<blockquote>\n<p>新增线程池后，新任务会去抢占CPU的运行时间，造成进程上下文的切换，导致原有业务的执行时间减少，最终体现到响应时间和吞吐量上。</p>\n<ul>\n<li>解决方法：减少线程数量，增大队列，减少上下文切换。实际操作上，无法具体分析出影响范围有多大。<ul>\n<li>最佳实践：采用灰度发布的方式，逐步将新线程池引入现有业务系统；同时对现有业务的监控指标进行观察。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<hr>\n<p><strong>方面2：<a href=\"https://caohuiwu.github.io/2024/06/05/2024-06-05-Linux-CPU%E8%B4%9F%E8%BD%BD%E5%92%8C%E5%88%A9%E7%94%A8%E7%8E%87/#more\" target=\"_blank\" rel=\"noopener\">CPU负载 &amp; CPU利用率：</a></strong></p>\n<blockquote>\n<ol>\n<li>造成CPU负载的升高：增加线程池，那么会有更多的任务需要处理。例如I/O 密集型任务，这些进程会处于等待 I/O 完成的状态，此时它们并不占用大量的 CPU 资源，但会被计入系统负载中。<ol>\n<li>解决方法：根据不同的造成因素做不同的处理。</li>\n<li>例如应用程序问题，则优化程序；</li>\n<li>如果是机器问题，则增加CPU核心数量或升级硬件；</li>\n</ol>\n</li>\n<li>进程频繁上下文切换：<ol>\n<li>更多的任务，那么会竞争CPU使用资源，就会造成进程频繁上下文切换，会消耗一定的系统资源。</li>\n</ol>\n</li>\n</ol>\n</blockquote>\n<p>因此我们需要去查看CPU负载 &amp; CPU利用率，保证增加线程池后，两项指标不会升高到预期之外，并且不对其他现有业务造成过大的影响。</p>\n<hr>\n<p><strong>方面3：内存：</strong></p>\n<blockquote>\n<p>每开启一个线程都需要内存空间，并且任务堆积情况下，会造成内存消耗，极端情况下造成oom。</p>\n</blockquote>\n<h4 id=\"3-3、我们应该怎么做？\"><a href=\"#3-3、我们应该怎么做？\" class=\"headerlink\" title=\"3.3、我们应该怎么做？\"></a>3.3、我们应该怎么做？</h4><blockquote>\n<p>最佳实践：采用灰度发布的方式，逐步将新线程池引入现有业务系统；同时对现有业务的监控指标进行观察。</p>\n</blockquote>\n<p>参考文章：<br><a href=\"https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html\" target=\"_blank\" rel=\"noopener\">Java线程池实现原理及其在美团业务中的实践</a><br><a href=\"https://juejin.cn/post/7067183465224994852#heading-5\" target=\"_blank\" rel=\"noopener\">线程池的数量和线程池中线程数量如何设置-实践篇</a></p>"},{"title":"《系统重构》如何做数据同步延迟监控？","date":"2024-07-27T02:00:00.000Z","_content":"\n### 一、背景\n在做系统重构或者系统迁移时，都会涉及到数据的同步工作，从老库到新库，那如何监控老库到新库的数据延迟呢？\n<!-- more -->\n### 二、数据同步工作原理\n阿里DTS的数据同步工作原理。\n![数据同步工作原理](2024-07-27-系统重构-如何做数据同步延迟监控/数据同步工作原理.png)\nDTS可以在两个数据源之间同步正在进行的数据变更。数据同步通常用于OLTP到OLAP的数据传输。数据同步包括以下两个阶段：\n1. 同步初始化：DTS先开始收集增量数据，然后将源数据库的结构和存量数据加载到目标数据库。\n2. 数据实时同步：DTS同步正在进行的数据变更，并保持源数据库和目标数据库的同步。\n\n为了同步正在进行的数据变更，DTS使用两个处理事务日志的模块：\n1. 事务日志读取模块：日志读取模块从源实例读取原始数据，经过解析、过滤及标准格式化，最终将数据在本地持久化。日志读取模块通过数据库协议连接并读取源实例的增量日志。如果源数据库为RDS MySQL，那么数据抓取模块通过Binlog dump协议连接源库。\n2. 日志回放模块：日志回放模块从日志读取模块中请求增量数据，并根据用户配置的同步对象进行数据过滤，然后在保证事务时序性及事务一致性的前提下，将日志记录同步到目标实例。\nDTS具备日志读取模块、日志回放模块的高可用，DTS容灾系统一旦检测到链路异常，就会在健康服务节点上断点重启链路，从而有效保证同步链路的高可用。\n\n\n### 三、数据同步延迟\n> 同步延迟是指同步到目标数据库的最新数据的时间戳，与源数据库的当前时间戳之间的差值。 如果同步延迟为0，则源数据库与目标数据库的数据完全同步。\n\nDTS监控未做的很好，导致无法监控数据同步的延迟是多少，从稳定性上进行考虑，需要对数据同步延迟进行监控。\n![数据处理流程](2024-07-27-系统重构-如何做数据同步延迟监控/数据处理流程.png)\n> 延迟可以分为3部分组成：\n> - 源库 -> dts 网络延迟\n> - dts处理延迟\n> - dts -> 目标库 网络延迟\n\n#### 解决方案\n![延迟时间](2024-07-27-系统重构-如何做数据同步延迟监控/延迟时间.png)\n一般做法是在脚本的最后阶段往扩展字段添加当前时间(curTime)，此时间会保存到目标库中，然后再调用RPC接口，打印延迟时间，然后再配置监控。\n\n> tips：当然这个方案也不是完美的，建议在源数据中添加必要的标识，用于校验数据，便于DTS脚本处理，降低延迟，提高同步性能\n\n参考文档：\n[DTS产品架构](https://help.aliyun.com/zh/dts/product-overview/system-architecture-and-design-concepts?spm=a2c4g.11186623.help-menu-26590.d_0_1_3.5f8962efRv5pQE&scm=20140722.H_26598._.OR_help-V_1)","source":"_posts/2024-07-27-系统重构-如何做数据同步延迟监控.md","raw":"---\ntitle: 《系统重构》如何做数据同步延迟监控？\ndate: 2024-07-27 10:00:00\ncategories:\n  - [系统重构]\n---\n\n### 一、背景\n在做系统重构或者系统迁移时，都会涉及到数据的同步工作，从老库到新库，那如何监控老库到新库的数据延迟呢？\n<!-- more -->\n### 二、数据同步工作原理\n阿里DTS的数据同步工作原理。\n![数据同步工作原理](2024-07-27-系统重构-如何做数据同步延迟监控/数据同步工作原理.png)\nDTS可以在两个数据源之间同步正在进行的数据变更。数据同步通常用于OLTP到OLAP的数据传输。数据同步包括以下两个阶段：\n1. 同步初始化：DTS先开始收集增量数据，然后将源数据库的结构和存量数据加载到目标数据库。\n2. 数据实时同步：DTS同步正在进行的数据变更，并保持源数据库和目标数据库的同步。\n\n为了同步正在进行的数据变更，DTS使用两个处理事务日志的模块：\n1. 事务日志读取模块：日志读取模块从源实例读取原始数据，经过解析、过滤及标准格式化，最终将数据在本地持久化。日志读取模块通过数据库协议连接并读取源实例的增量日志。如果源数据库为RDS MySQL，那么数据抓取模块通过Binlog dump协议连接源库。\n2. 日志回放模块：日志回放模块从日志读取模块中请求增量数据，并根据用户配置的同步对象进行数据过滤，然后在保证事务时序性及事务一致性的前提下，将日志记录同步到目标实例。\nDTS具备日志读取模块、日志回放模块的高可用，DTS容灾系统一旦检测到链路异常，就会在健康服务节点上断点重启链路，从而有效保证同步链路的高可用。\n\n\n### 三、数据同步延迟\n> 同步延迟是指同步到目标数据库的最新数据的时间戳，与源数据库的当前时间戳之间的差值。 如果同步延迟为0，则源数据库与目标数据库的数据完全同步。\n\nDTS监控未做的很好，导致无法监控数据同步的延迟是多少，从稳定性上进行考虑，需要对数据同步延迟进行监控。\n![数据处理流程](2024-07-27-系统重构-如何做数据同步延迟监控/数据处理流程.png)\n> 延迟可以分为3部分组成：\n> - 源库 -> dts 网络延迟\n> - dts处理延迟\n> - dts -> 目标库 网络延迟\n\n#### 解决方案\n![延迟时间](2024-07-27-系统重构-如何做数据同步延迟监控/延迟时间.png)\n一般做法是在脚本的最后阶段往扩展字段添加当前时间(curTime)，此时间会保存到目标库中，然后再调用RPC接口，打印延迟时间，然后再配置监控。\n\n> tips：当然这个方案也不是完美的，建议在源数据中添加必要的标识，用于校验数据，便于DTS脚本处理，降低延迟，提高同步性能\n\n参考文档：\n[DTS产品架构](https://help.aliyun.com/zh/dts/product-overview/system-architecture-and-design-concepts?spm=a2c4g.11186623.help-menu-26590.d_0_1_3.5f8962efRv5pQE&scm=20140722.H_26598._.OR_help-V_1)","slug":"2024-07-27-系统重构-如何做数据同步延迟监控","published":1,"updated":"2024-11-08T03:31:44.484Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny60054a13k1xsw7mb8","content":"<h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在做系统重构或者系统迁移时，都会涉及到数据的同步工作，从老库到新库，那如何监控老库到新库的数据延迟呢？</p>\n<a id=\"more\"></a>\n<h3 id=\"二、数据同步工作原理\"><a href=\"#二、数据同步工作原理\" class=\"headerlink\" title=\"二、数据同步工作原理\"></a>二、数据同步工作原理</h3><p>阿里DTS的数据同步工作原理。<br><img src=\"/2024/07/27/2024-07-27-系统重构-如何做数据同步延迟监控/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png\" alt=\"数据同步工作原理\"><br>DTS可以在两个数据源之间同步正在进行的数据变更。数据同步通常用于OLTP到OLAP的数据传输。数据同步包括以下两个阶段：</p>\n<ol>\n<li>同步初始化：DTS先开始收集增量数据，然后将源数据库的结构和存量数据加载到目标数据库。</li>\n<li>数据实时同步：DTS同步正在进行的数据变更，并保持源数据库和目标数据库的同步。</li>\n</ol>\n<p>为了同步正在进行的数据变更，DTS使用两个处理事务日志的模块：</p>\n<ol>\n<li>事务日志读取模块：日志读取模块从源实例读取原始数据，经过解析、过滤及标准格式化，最终将数据在本地持久化。日志读取模块通过数据库协议连接并读取源实例的增量日志。如果源数据库为RDS MySQL，那么数据抓取模块通过Binlog dump协议连接源库。</li>\n<li>日志回放模块：日志回放模块从日志读取模块中请求增量数据，并根据用户配置的同步对象进行数据过滤，然后在保证事务时序性及事务一致性的前提下，将日志记录同步到目标实例。<br>DTS具备日志读取模块、日志回放模块的高可用，DTS容灾系统一旦检测到链路异常，就会在健康服务节点上断点重启链路，从而有效保证同步链路的高可用。</li>\n</ol>\n<h3 id=\"三、数据同步延迟\"><a href=\"#三、数据同步延迟\" class=\"headerlink\" title=\"三、数据同步延迟\"></a>三、数据同步延迟</h3><blockquote>\n<p>同步延迟是指同步到目标数据库的最新数据的时间戳，与源数据库的当前时间戳之间的差值。 如果同步延迟为0，则源数据库与目标数据库的数据完全同步。</p>\n</blockquote>\n<p>DTS监控未做的很好，导致无法监控数据同步的延迟是多少，从稳定性上进行考虑，需要对数据同步延迟进行监控。<br><img src=\"/2024/07/27/2024-07-27-系统重构-如何做数据同步延迟监控/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png\" alt=\"数据处理流程\"></p>\n<blockquote>\n<p>延迟可以分为3部分组成：</p>\n<ul>\n<li>源库 -&gt; dts 网络延迟</li>\n<li>dts处理延迟</li>\n<li>dts -&gt; 目标库 网络延迟</li>\n</ul>\n</blockquote>\n<h4 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h4><p><img src=\"/2024/07/27/2024-07-27-系统重构-如何做数据同步延迟监控/%E5%BB%B6%E8%BF%9F%E6%97%B6%E9%97%B4.png\" alt=\"延迟时间\"><br>一般做法是在脚本的最后阶段往扩展字段添加当前时间(curTime)，此时间会保存到目标库中，然后再调用RPC接口，打印延迟时间，然后再配置监控。</p>\n<blockquote>\n<p>tips：当然这个方案也不是完美的，建议在源数据中添加必要的标识，用于校验数据，便于DTS脚本处理，降低延迟，提高同步性能</p>\n</blockquote>\n<p>参考文档：<br><a href=\"https://help.aliyun.com/zh/dts/product-overview/system-architecture-and-design-concepts?spm=a2c4g.11186623.help-menu-26590.d_0_1_3.5f8962efRv5pQE&scm=20140722.H_26598._.OR_help-V_1\" target=\"_blank\" rel=\"noopener\">DTS产品架构</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、背景\"><a href=\"#一、背景\" class=\"headerlink\" title=\"一、背景\"></a>一、背景</h3><p>在做系统重构或者系统迁移时，都会涉及到数据的同步工作，从老库到新库，那如何监控老库到新库的数据延迟呢？</p>","more":"<h3 id=\"二、数据同步工作原理\"><a href=\"#二、数据同步工作原理\" class=\"headerlink\" title=\"二、数据同步工作原理\"></a>二、数据同步工作原理</h3><p>阿里DTS的数据同步工作原理。<br><img src=\"/2024/07/27/2024-07-27-系统重构-如何做数据同步延迟监控/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png\" alt=\"数据同步工作原理\"><br>DTS可以在两个数据源之间同步正在进行的数据变更。数据同步通常用于OLTP到OLAP的数据传输。数据同步包括以下两个阶段：</p>\n<ol>\n<li>同步初始化：DTS先开始收集增量数据，然后将源数据库的结构和存量数据加载到目标数据库。</li>\n<li>数据实时同步：DTS同步正在进行的数据变更，并保持源数据库和目标数据库的同步。</li>\n</ol>\n<p>为了同步正在进行的数据变更，DTS使用两个处理事务日志的模块：</p>\n<ol>\n<li>事务日志读取模块：日志读取模块从源实例读取原始数据，经过解析、过滤及标准格式化，最终将数据在本地持久化。日志读取模块通过数据库协议连接并读取源实例的增量日志。如果源数据库为RDS MySQL，那么数据抓取模块通过Binlog dump协议连接源库。</li>\n<li>日志回放模块：日志回放模块从日志读取模块中请求增量数据，并根据用户配置的同步对象进行数据过滤，然后在保证事务时序性及事务一致性的前提下，将日志记录同步到目标实例。<br>DTS具备日志读取模块、日志回放模块的高可用，DTS容灾系统一旦检测到链路异常，就会在健康服务节点上断点重启链路，从而有效保证同步链路的高可用。</li>\n</ol>\n<h3 id=\"三、数据同步延迟\"><a href=\"#三、数据同步延迟\" class=\"headerlink\" title=\"三、数据同步延迟\"></a>三、数据同步延迟</h3><blockquote>\n<p>同步延迟是指同步到目标数据库的最新数据的时间戳，与源数据库的当前时间戳之间的差值。 如果同步延迟为0，则源数据库与目标数据库的数据完全同步。</p>\n</blockquote>\n<p>DTS监控未做的很好，导致无法监控数据同步的延迟是多少，从稳定性上进行考虑，需要对数据同步延迟进行监控。<br><img src=\"/2024/07/27/2024-07-27-系统重构-如何做数据同步延迟监控/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png\" alt=\"数据处理流程\"></p>\n<blockquote>\n<p>延迟可以分为3部分组成：</p>\n<ul>\n<li>源库 -&gt; dts 网络延迟</li>\n<li>dts处理延迟</li>\n<li>dts -&gt; 目标库 网络延迟</li>\n</ul>\n</blockquote>\n<h4 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h4><p><img src=\"/2024/07/27/2024-07-27-系统重构-如何做数据同步延迟监控/%E5%BB%B6%E8%BF%9F%E6%97%B6%E9%97%B4.png\" alt=\"延迟时间\"><br>一般做法是在脚本的最后阶段往扩展字段添加当前时间(curTime)，此时间会保存到目标库中，然后再调用RPC接口，打印延迟时间，然后再配置监控。</p>\n<blockquote>\n<p>tips：当然这个方案也不是完美的，建议在源数据中添加必要的标识，用于校验数据，便于DTS脚本处理，降低延迟，提高同步性能</p>\n</blockquote>\n<p>参考文档：<br><a href=\"https://help.aliyun.com/zh/dts/product-overview/system-architecture-and-design-concepts?spm=a2c4g.11186623.help-menu-26590.d_0_1_3.5f8962efRv5pQE&scm=20140722.H_26598._.OR_help-V_1\" target=\"_blank\" rel=\"noopener\">DTS产品架构</a></p>"},{"title":"java-thread","date":"2020-04-11T09:19:31.000Z","_content":"\n# 一、线程状态\n```\npublic enum State {\n    //新建状态，未启动\n    NEW,\n    //就绪状态，在JVM中运行，但是在操作系统中可能是等待执行。\n    RUNNABLE,\n    //阻塞状态，表示线程阻塞于锁\n    BLOCKED,\n    //等待状态，需要等待其他线程做出一些特定动作（通知或中断）\n    WAITING,\n   //超时等待，可以在指定的时间后自行返回\n   TIMED_WAITING,\n   //表示该线程已经执行完毕。\n   TERMINATED;\n}\n```\n![状态流转](2020-04-11-java-thread/线程状态流转.png)\n\nJava线程与Linux进程状态的对应关系：  \n1. new，是Thread对象的状态，此时和Linux的进程还没有关系。\n2. Runnable对应linux的Running。\n3. BLOCKED、WAITING、TIMED_WAITING，对应task_intermptible\n4. TERMINATED 对应task_stoped\n\n<!--more-->  \n\nsleep\n```\nThread类的方法\npublic static native void sleep(long millis)\npublic static native void sleep(long millis, int nanos)//sleep(毫秒, 纳秒)\n\n总结：\n    1.线程暂时停止运行，但是未失去对锁的拥有\n    2.线程等待指定的时间后，该线程不一定会立马/确定运行\n    3.线程等待，进入_EntryList队列中\n```\n\njoin\n```\nWaits at most millis milliseconds for this thread to die. A timeout of 0 means to wait forever.\n\npublic final void join(){\n    join(0);\n}\n\npublic final **synchronized** void join(long millis) throw InterruptException{\n    long base = System.currentTimeMillis();\n    long now = 0;\n    if(millis < 0){\n        throw new IllegalArgumentException();\n    }\n    if(millis == 0){\n        while(isAlive()){//isAlive()，当前线程是否还活着\n            wait(0);//object.wait(0);\n        }\n    }else{\n        while(isAlive()){\n            long delay = millis - now;\n            if(delay <=0 ){\n                break;\n            }\n            wait(delay);\n            now = System.currentTimeMillis() - base;\n        }\n    }\n}\n\njoin总结：\n    1、join方法为synchronized方法，所以当线程执行时，会获取该thread对象的锁\n    2、所以执行join方法就已经获取了thread对象的锁，再执行wait方法，就不会抛出异常了。\n    3、使执行object.join()方法的线程等待\n    4、主线程和子线程之间使用，主线程执行，那么主线程将阻塞等待\n        \n使用\npublic class Join {\n    public static void main(String[] args) {\n        Thread thread = new JoinThread();\n        thread.start();\n        try {\n            //主线程等待thread的业务处理完了之后再向下运行  \n            thread.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        for(int i = 0; i < 5; i++){\n            System.out.println(Thread.currentThread().getName()+\" -- \" + i);\n        }\n    }\n}\n\nclass JoinThread extends Thread{\n    @Override\n    public void run() {\n        for(int i = 0; i < 5; i++){\n            System.out.println(Thread.currentThread().getName() + \" -- \"+i);\n            try {\n                sleep(500);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n//---------------运行结果---------------------\n//主线程等待JoinThread执行完再执行\nThread-0 -- 0\nThread-0 -- 1\nThread-0 -- 2\nThread-0 -- 3\nThread-0 -- 4\nmain -- 0\nmain -- 1\nmain -- 2\nmain -- 3\nmain -- 4\n```\n\nyield\n```\na hint to the scheduler that the current thread is willing to yield its\ncurrent use of a processor. The schedular is free to ignore this hint.\n一个线索、示意调度器当前线程将会放弃他当前的处理器使用权\n\npublic static native void yield();\n总结：\n    yield()方法不会使线程失去资源，只是失去了处理器使用权，但是时机不好把控，取决于操作系统\n    public static void main(String[] args){\n        String object = \"abc\";\n        new Thread(new Runnable(){\n            public void run(){\n                synchronized(object){\n                    System.out.println(\"A1\");\n                    sleep(4000);\n                    System.out.println(\"A3\");\n                    Thread.currrentThread.yield();\n                    System.out.println(\"A4\");\n                }\n            }\n        }).start();\n        \n        new Thread(new Runnable(){\n            public void run(){\n                synchronized(object){\n                    System.out.println(\"a\");\n                }\n            }\n        }).start();\n    }\n\n执行结果：\n    A1\n    A3\n    A4\n    a\n    线程让步，并没有执行其他线程，未释放锁\n\n使用\n    public static void main(String[] args){\n        new Thread(new Runnable(){\n            public void run(){\n                System.out.println(\"A1\");\n                sleep(4000);\n                System.out.println(\"A3\");\n                Thread.currrentThread.yield();\n                System.out.println(\"A4\");\n            }\n        }).start();\n        \n        new Thread(new Runnable(){\n            public void run(){\n                System.out.println(\"a\");\n            }\n        }).start();\n    }\n    \n执行结果\n    例：A1\n        A3\n        a\n        A4\n\n```\n\n# 二、创建线程方式\n\n* 继承Thread类，并复写run方法\n* 实现Runnable接口，复写run方法\n* 创建FutureTask对象，创建Callable子类对象，复写call(相当于run)方法，将其传递给FutureTask对象（相当于一个Runnable）\n* 线程池\n\n## 1、Thread类\n```\npublic class MyThread extends Thread{ \n    @Override \n    public void run() { \n        System.out.println(Thread.currentThread().getName()); \n    }\n}\npublic class MyThreadTest { \n    public static void main(String[] args) { \n        // 创建线程 \n        MyThread thread = new MyThread(); \n        // 启动线程 \n        thread.start(); }\n}\n```\n### 2.1、start和run方法的区别      \n1. new Thread()：此时只是创建了Thread对象，没有实际去创建线程\n2. thread.start()：\n    1. 内部执行native start0()方法\n    2. start0()方法内部会调用OS创建线程的方法\n        * Linux下的pthread函数，创建线程，更新JVM进程内存空间\n    3. start0()方法执行后，会调用run()方法\n3. thread.run()：\n    1. 内部不会创建新的线程\n    2. 由当前线程去执行run方法\n\n## 2、Runnable接口\n```\npublic class MyRunnable implements Runnable{ \n    @Override \n    public void run() { \n        System.out.println(Thread.currentThread().getName()); \n    }\n}\npublic class MyRunnableTest { \n    public static void main(String[] args) { \n        MyRunnable myRunnable = new MyRunnable(); \n        // 创建线程 \n        Thread thread = new Thread(myRunnable); \n        // 启动线程 \n        thread.start(); \n    }\n}\n```\n\n## 3、Callable\n```\npublic class MyCallable implements Callable { \n    @Override \n    public Integer call() throws Exception { \n        System.out.println(Thread.currentThread().getName()); \n        return 99; \n    }\n}\npublic class MyCallableTest { \n    public static void main(String[] args) { \n        FutureTask futureTask = new FutureTask<>(new MyCallable()); \n        // 创建线程 \n        Thread thread = new Thread(futureTask); \n        // 启动线程 \n        thread.start(); \n        // 结果返回 \n        try { \n            Thread.sleep(1000); \n            System.out.println(\"返回的结果是：\" + futureTask.get()); \n        } catch (Exception e) { \n            e.printStackTrace(); \n        } \n    }\n}\n```\n\n## 4、线程池\n```\npublic class MyRunnable implements Runnable{ \n    @Override \n    public void run() { \n        System.out.println(Thread.currentThread().getName()); \n    }\n}\npublic class SingleThreadExecutorTest { \n    public static void main(String[] args) { \n        ExecutorService executorService = Executors.newSingleThreadExecutor(); \n        MyRunnable myRunnable = new MyRunnable(); \n        for(int i = 0; i < 10; i++){ \n            executorService.execute(myRunnable); \n        } \n        System.out.println(\"=======任务开始=======\"); \n        executorService.shutdown(); \n    }\n}\n```\n\n\n# 三、linux进程和java线程\n![线程进程关系](2020-04-11-java-thread/线程进程关系.png)\n\n![jvm-linux](2020-04-11-java-thread/jvm线程-Linux进程.png)\njvm线程对应Linux的一个进程\n\n","source":"_posts/2020-04-11-java-thread.md","raw":"---\ntitle: java-thread\ndate: 2020-04-11 17:19:31\ntags: jvm thread\ncategories: \n   - [java, jvm]\n---\n\n# 一、线程状态\n```\npublic enum State {\n    //新建状态，未启动\n    NEW,\n    //就绪状态，在JVM中运行，但是在操作系统中可能是等待执行。\n    RUNNABLE,\n    //阻塞状态，表示线程阻塞于锁\n    BLOCKED,\n    //等待状态，需要等待其他线程做出一些特定动作（通知或中断）\n    WAITING,\n   //超时等待，可以在指定的时间后自行返回\n   TIMED_WAITING,\n   //表示该线程已经执行完毕。\n   TERMINATED;\n}\n```\n![状态流转](2020-04-11-java-thread/线程状态流转.png)\n\nJava线程与Linux进程状态的对应关系：  \n1. new，是Thread对象的状态，此时和Linux的进程还没有关系。\n2. Runnable对应linux的Running。\n3. BLOCKED、WAITING、TIMED_WAITING，对应task_intermptible\n4. TERMINATED 对应task_stoped\n\n<!--more-->  \n\nsleep\n```\nThread类的方法\npublic static native void sleep(long millis)\npublic static native void sleep(long millis, int nanos)//sleep(毫秒, 纳秒)\n\n总结：\n    1.线程暂时停止运行，但是未失去对锁的拥有\n    2.线程等待指定的时间后，该线程不一定会立马/确定运行\n    3.线程等待，进入_EntryList队列中\n```\n\njoin\n```\nWaits at most millis milliseconds for this thread to die. A timeout of 0 means to wait forever.\n\npublic final void join(){\n    join(0);\n}\n\npublic final **synchronized** void join(long millis) throw InterruptException{\n    long base = System.currentTimeMillis();\n    long now = 0;\n    if(millis < 0){\n        throw new IllegalArgumentException();\n    }\n    if(millis == 0){\n        while(isAlive()){//isAlive()，当前线程是否还活着\n            wait(0);//object.wait(0);\n        }\n    }else{\n        while(isAlive()){\n            long delay = millis - now;\n            if(delay <=0 ){\n                break;\n            }\n            wait(delay);\n            now = System.currentTimeMillis() - base;\n        }\n    }\n}\n\njoin总结：\n    1、join方法为synchronized方法，所以当线程执行时，会获取该thread对象的锁\n    2、所以执行join方法就已经获取了thread对象的锁，再执行wait方法，就不会抛出异常了。\n    3、使执行object.join()方法的线程等待\n    4、主线程和子线程之间使用，主线程执行，那么主线程将阻塞等待\n        \n使用\npublic class Join {\n    public static void main(String[] args) {\n        Thread thread = new JoinThread();\n        thread.start();\n        try {\n            //主线程等待thread的业务处理完了之后再向下运行  \n            thread.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        for(int i = 0; i < 5; i++){\n            System.out.println(Thread.currentThread().getName()+\" -- \" + i);\n        }\n    }\n}\n\nclass JoinThread extends Thread{\n    @Override\n    public void run() {\n        for(int i = 0; i < 5; i++){\n            System.out.println(Thread.currentThread().getName() + \" -- \"+i);\n            try {\n                sleep(500);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n//---------------运行结果---------------------\n//主线程等待JoinThread执行完再执行\nThread-0 -- 0\nThread-0 -- 1\nThread-0 -- 2\nThread-0 -- 3\nThread-0 -- 4\nmain -- 0\nmain -- 1\nmain -- 2\nmain -- 3\nmain -- 4\n```\n\nyield\n```\na hint to the scheduler that the current thread is willing to yield its\ncurrent use of a processor. The schedular is free to ignore this hint.\n一个线索、示意调度器当前线程将会放弃他当前的处理器使用权\n\npublic static native void yield();\n总结：\n    yield()方法不会使线程失去资源，只是失去了处理器使用权，但是时机不好把控，取决于操作系统\n    public static void main(String[] args){\n        String object = \"abc\";\n        new Thread(new Runnable(){\n            public void run(){\n                synchronized(object){\n                    System.out.println(\"A1\");\n                    sleep(4000);\n                    System.out.println(\"A3\");\n                    Thread.currrentThread.yield();\n                    System.out.println(\"A4\");\n                }\n            }\n        }).start();\n        \n        new Thread(new Runnable(){\n            public void run(){\n                synchronized(object){\n                    System.out.println(\"a\");\n                }\n            }\n        }).start();\n    }\n\n执行结果：\n    A1\n    A3\n    A4\n    a\n    线程让步，并没有执行其他线程，未释放锁\n\n使用\n    public static void main(String[] args){\n        new Thread(new Runnable(){\n            public void run(){\n                System.out.println(\"A1\");\n                sleep(4000);\n                System.out.println(\"A3\");\n                Thread.currrentThread.yield();\n                System.out.println(\"A4\");\n            }\n        }).start();\n        \n        new Thread(new Runnable(){\n            public void run(){\n                System.out.println(\"a\");\n            }\n        }).start();\n    }\n    \n执行结果\n    例：A1\n        A3\n        a\n        A4\n\n```\n\n# 二、创建线程方式\n\n* 继承Thread类，并复写run方法\n* 实现Runnable接口，复写run方法\n* 创建FutureTask对象，创建Callable子类对象，复写call(相当于run)方法，将其传递给FutureTask对象（相当于一个Runnable）\n* 线程池\n\n## 1、Thread类\n```\npublic class MyThread extends Thread{ \n    @Override \n    public void run() { \n        System.out.println(Thread.currentThread().getName()); \n    }\n}\npublic class MyThreadTest { \n    public static void main(String[] args) { \n        // 创建线程 \n        MyThread thread = new MyThread(); \n        // 启动线程 \n        thread.start(); }\n}\n```\n### 2.1、start和run方法的区别      \n1. new Thread()：此时只是创建了Thread对象，没有实际去创建线程\n2. thread.start()：\n    1. 内部执行native start0()方法\n    2. start0()方法内部会调用OS创建线程的方法\n        * Linux下的pthread函数，创建线程，更新JVM进程内存空间\n    3. start0()方法执行后，会调用run()方法\n3. thread.run()：\n    1. 内部不会创建新的线程\n    2. 由当前线程去执行run方法\n\n## 2、Runnable接口\n```\npublic class MyRunnable implements Runnable{ \n    @Override \n    public void run() { \n        System.out.println(Thread.currentThread().getName()); \n    }\n}\npublic class MyRunnableTest { \n    public static void main(String[] args) { \n        MyRunnable myRunnable = new MyRunnable(); \n        // 创建线程 \n        Thread thread = new Thread(myRunnable); \n        // 启动线程 \n        thread.start(); \n    }\n}\n```\n\n## 3、Callable\n```\npublic class MyCallable implements Callable { \n    @Override \n    public Integer call() throws Exception { \n        System.out.println(Thread.currentThread().getName()); \n        return 99; \n    }\n}\npublic class MyCallableTest { \n    public static void main(String[] args) { \n        FutureTask futureTask = new FutureTask<>(new MyCallable()); \n        // 创建线程 \n        Thread thread = new Thread(futureTask); \n        // 启动线程 \n        thread.start(); \n        // 结果返回 \n        try { \n            Thread.sleep(1000); \n            System.out.println(\"返回的结果是：\" + futureTask.get()); \n        } catch (Exception e) { \n            e.printStackTrace(); \n        } \n    }\n}\n```\n\n## 4、线程池\n```\npublic class MyRunnable implements Runnable{ \n    @Override \n    public void run() { \n        System.out.println(Thread.currentThread().getName()); \n    }\n}\npublic class SingleThreadExecutorTest { \n    public static void main(String[] args) { \n        ExecutorService executorService = Executors.newSingleThreadExecutor(); \n        MyRunnable myRunnable = new MyRunnable(); \n        for(int i = 0; i < 10; i++){ \n            executorService.execute(myRunnable); \n        } \n        System.out.println(\"=======任务开始=======\"); \n        executorService.shutdown(); \n    }\n}\n```\n\n\n# 三、linux进程和java线程\n![线程进程关系](2020-04-11-java-thread/线程进程关系.png)\n\n![jvm-linux](2020-04-11-java-thread/jvm线程-Linux进程.png)\njvm线程对应Linux的一个进程\n\n","slug":"2020-04-11-java-thread","published":1,"updated":"2024-12-09T03:22:02.679Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny70058a13kdzd21gk5","content":"<h1 id=\"一、线程状态\"><a href=\"#一、线程状态\" class=\"headerlink\" title=\"一、线程状态\"></a>一、线程状态</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public enum State &#123;</span><br><span class=\"line\">    //新建状态，未启动</span><br><span class=\"line\">    NEW,</span><br><span class=\"line\">    //就绪状态，在JVM中运行，但是在操作系统中可能是等待执行。</span><br><span class=\"line\">    RUNNABLE,</span><br><span class=\"line\">    //阻塞状态，表示线程阻塞于锁</span><br><span class=\"line\">    BLOCKED,</span><br><span class=\"line\">    //等待状态，需要等待其他线程做出一些特定动作（通知或中断）</span><br><span class=\"line\">    WAITING,</span><br><span class=\"line\">   //超时等待，可以在指定的时间后自行返回</span><br><span class=\"line\">   TIMED_WAITING,</span><br><span class=\"line\">   //表示该线程已经执行完毕。</span><br><span class=\"line\">   TERMINATED;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2020/04/11/2020-04-11-java-thread/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC.png\" alt=\"状态流转\"></p>\n<p>Java线程与Linux进程状态的对应关系：  </p>\n<ol>\n<li>new，是Thread对象的状态，此时和Linux的进程还没有关系。</li>\n<li>Runnable对应linux的Running。</li>\n<li>BLOCKED、WAITING、TIMED_WAITING，对应task_intermptible</li>\n<li>TERMINATED 对应task_stoped</li>\n</ol>\n<a id=\"more\"></a>  \n\n<p>sleep</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Thread类的方法</span><br><span class=\"line\">public static native void sleep(long millis)</span><br><span class=\"line\">public static native void sleep(long millis, int nanos)//sleep(毫秒, 纳秒)</span><br><span class=\"line\"></span><br><span class=\"line\">总结：</span><br><span class=\"line\">    1.线程暂时停止运行，但是未失去对锁的拥有</span><br><span class=\"line\">    2.线程等待指定的时间后，该线程不一定会立马/确定运行</span><br><span class=\"line\">    3.线程等待，进入_EntryList队列中</span><br></pre></td></tr></table></figure>\n\n<p>join</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Waits at most millis milliseconds for this thread to die. A timeout of 0 means to wait forever.</span><br><span class=\"line\"></span><br><span class=\"line\">public final void join()&#123;</span><br><span class=\"line\">    join(0);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">public final **synchronized** void join(long millis) throw InterruptException&#123;</span><br><span class=\"line\">    long base = System.currentTimeMillis();</span><br><span class=\"line\">    long now = 0;</span><br><span class=\"line\">    if(millis &lt; 0)&#123;</span><br><span class=\"line\">        throw new IllegalArgumentException();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(millis == 0)&#123;</span><br><span class=\"line\">        while(isAlive())&#123;//isAlive()，当前线程是否还活着</span><br><span class=\"line\">            wait(0);//object.wait(0);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;else&#123;</span><br><span class=\"line\">        while(isAlive())&#123;</span><br><span class=\"line\">            long delay = millis - now;</span><br><span class=\"line\">            if(delay &lt;=0 )&#123;</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            wait(delay);</span><br><span class=\"line\">            now = System.currentTimeMillis() - base;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">join总结：</span><br><span class=\"line\">    1、join方法为synchronized方法，所以当线程执行时，会获取该thread对象的锁</span><br><span class=\"line\">    2、所以执行join方法就已经获取了thread对象的锁，再执行wait方法，就不会抛出异常了。</span><br><span class=\"line\">    3、使执行object.join()方法的线程等待</span><br><span class=\"line\">    4、主线程和子线程之间使用，主线程执行，那么主线程将阻塞等待</span><br><span class=\"line\">        </span><br><span class=\"line\">使用</span><br><span class=\"line\">public class Join &#123;</span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        Thread thread = new JoinThread();</span><br><span class=\"line\">        thread.start();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            //主线程等待thread的业务处理完了之后再向下运行  </span><br><span class=\"line\">            thread.join();</span><br><span class=\"line\">        &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        for(int i = 0; i &lt; 5; i++)&#123;</span><br><span class=\"line\">            System.out.println(Thread.currentThread().getName()+&quot; -- &quot; + i);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">class JoinThread extends Thread&#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void run() &#123;</span><br><span class=\"line\">        for(int i = 0; i &lt; 5; i++)&#123;</span><br><span class=\"line\">            System.out.println(Thread.currentThread().getName() + &quot; -- &quot;+i);</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                sleep(500);</span><br><span class=\"line\">            &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">                e.printStackTrace();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//---------------运行结果---------------------</span><br><span class=\"line\">//主线程等待JoinThread执行完再执行</span><br><span class=\"line\">Thread-0 -- 0</span><br><span class=\"line\">Thread-0 -- 1</span><br><span class=\"line\">Thread-0 -- 2</span><br><span class=\"line\">Thread-0 -- 3</span><br><span class=\"line\">Thread-0 -- 4</span><br><span class=\"line\">main -- 0</span><br><span class=\"line\">main -- 1</span><br><span class=\"line\">main -- 2</span><br><span class=\"line\">main -- 3</span><br><span class=\"line\">main -- 4</span><br></pre></td></tr></table></figure>\n\n<p>yield</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a hint to the scheduler that the current thread is willing to yield its</span><br><span class=\"line\">current use of a processor. The schedular is free to ignore this hint.</span><br><span class=\"line\">一个线索、示意调度器当前线程将会放弃他当前的处理器使用权</span><br><span class=\"line\"></span><br><span class=\"line\">public static native void yield();</span><br><span class=\"line\">总结：</span><br><span class=\"line\">    yield()方法不会使线程失去资源，只是失去了处理器使用权，但是时机不好把控，取决于操作系统</span><br><span class=\"line\">    public static void main(String[] args)&#123;</span><br><span class=\"line\">        String object = &quot;abc&quot;;</span><br><span class=\"line\">        new Thread(new Runnable()&#123;</span><br><span class=\"line\">            public void run()&#123;</span><br><span class=\"line\">                synchronized(object)&#123;</span><br><span class=\"line\">                    System.out.println(&quot;A1&quot;);</span><br><span class=\"line\">                    sleep(4000);</span><br><span class=\"line\">                    System.out.println(&quot;A3&quot;);</span><br><span class=\"line\">                    Thread.currrentThread.yield();</span><br><span class=\"line\">                    System.out.println(&quot;A4&quot;);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">        </span><br><span class=\"line\">        new Thread(new Runnable()&#123;</span><br><span class=\"line\">            public void run()&#123;</span><br><span class=\"line\">                synchronized(object)&#123;</span><br><span class=\"line\">                    System.out.println(&quot;a&quot;);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">执行结果：</span><br><span class=\"line\">    A1</span><br><span class=\"line\">    A3</span><br><span class=\"line\">    A4</span><br><span class=\"line\">    a</span><br><span class=\"line\">    线程让步，并没有执行其他线程，未释放锁</span><br><span class=\"line\"></span><br><span class=\"line\">使用</span><br><span class=\"line\">    public static void main(String[] args)&#123;</span><br><span class=\"line\">        new Thread(new Runnable()&#123;</span><br><span class=\"line\">            public void run()&#123;</span><br><span class=\"line\">                System.out.println(&quot;A1&quot;);</span><br><span class=\"line\">                sleep(4000);</span><br><span class=\"line\">                System.out.println(&quot;A3&quot;);</span><br><span class=\"line\">                Thread.currrentThread.yield();</span><br><span class=\"line\">                System.out.println(&quot;A4&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">        </span><br><span class=\"line\">        new Thread(new Runnable()&#123;</span><br><span class=\"line\">            public void run()&#123;</span><br><span class=\"line\">                System.out.println(&quot;a&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">执行结果</span><br><span class=\"line\">    例：A1</span><br><span class=\"line\">        A3</span><br><span class=\"line\">        a</span><br><span class=\"line\">        A4</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、创建线程方式\"><a href=\"#二、创建线程方式\" class=\"headerlink\" title=\"二、创建线程方式\"></a>二、创建线程方式</h1><ul>\n<li>继承Thread类，并复写run方法</li>\n<li>实现Runnable接口，复写run方法</li>\n<li>创建FutureTask对象，创建Callable子类对象，复写call(相当于run)方法，将其传递给FutureTask对象（相当于一个Runnable）</li>\n<li>线程池</li>\n</ul>\n<h2 id=\"1、Thread类\"><a href=\"#1、Thread类\" class=\"headerlink\" title=\"1、Thread类\"></a>1、Thread类</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MyThread extends Thread&#123; </span><br><span class=\"line\">    @Override </span><br><span class=\"line\">    public void run() &#123; </span><br><span class=\"line\">        System.out.println(Thread.currentThread().getName()); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public class MyThreadTest &#123; </span><br><span class=\"line\">    public static void main(String[] args) &#123; </span><br><span class=\"line\">        // 创建线程 </span><br><span class=\"line\">        MyThread thread = new MyThread(); </span><br><span class=\"line\">        // 启动线程 </span><br><span class=\"line\">        thread.start(); &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-1、start和run方法的区别\"><a href=\"#2-1、start和run方法的区别\" class=\"headerlink\" title=\"2.1、start和run方法的区别\"></a>2.1、start和run方法的区别</h3><ol>\n<li>new Thread()：此时只是创建了Thread对象，没有实际去创建线程</li>\n<li>thread.start()：<ol>\n<li>内部执行native start0()方法</li>\n<li>start0()方法内部会调用OS创建线程的方法<ul>\n<li>Linux下的pthread函数，创建线程，更新JVM进程内存空间</li>\n</ul>\n</li>\n<li>start0()方法执行后，会调用run()方法</li>\n</ol>\n</li>\n<li>thread.run()：<ol>\n<li>内部不会创建新的线程</li>\n<li>由当前线程去执行run方法</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"2、Runnable接口\"><a href=\"#2、Runnable接口\" class=\"headerlink\" title=\"2、Runnable接口\"></a>2、Runnable接口</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MyRunnable implements Runnable&#123; </span><br><span class=\"line\">    @Override </span><br><span class=\"line\">    public void run() &#123; </span><br><span class=\"line\">        System.out.println(Thread.currentThread().getName()); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public class MyRunnableTest &#123; </span><br><span class=\"line\">    public static void main(String[] args) &#123; </span><br><span class=\"line\">        MyRunnable myRunnable = new MyRunnable(); </span><br><span class=\"line\">        // 创建线程 </span><br><span class=\"line\">        Thread thread = new Thread(myRunnable); </span><br><span class=\"line\">        // 启动线程 </span><br><span class=\"line\">        thread.start(); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、Callable\"><a href=\"#3、Callable\" class=\"headerlink\" title=\"3、Callable\"></a>3、Callable</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MyCallable implements Callable &#123; </span><br><span class=\"line\">    @Override </span><br><span class=\"line\">    public Integer call() throws Exception &#123; </span><br><span class=\"line\">        System.out.println(Thread.currentThread().getName()); </span><br><span class=\"line\">        return 99; </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public class MyCallableTest &#123; </span><br><span class=\"line\">    public static void main(String[] args) &#123; </span><br><span class=\"line\">        FutureTask futureTask = new FutureTask&lt;&gt;(new MyCallable()); </span><br><span class=\"line\">        // 创建线程 </span><br><span class=\"line\">        Thread thread = new Thread(futureTask); </span><br><span class=\"line\">        // 启动线程 </span><br><span class=\"line\">        thread.start(); </span><br><span class=\"line\">        // 结果返回 </span><br><span class=\"line\">        try &#123; </span><br><span class=\"line\">            Thread.sleep(1000); </span><br><span class=\"line\">            System.out.println(&quot;返回的结果是：&quot; + futureTask.get()); </span><br><span class=\"line\">        &#125; catch (Exception e) &#123; </span><br><span class=\"line\">            e.printStackTrace(); </span><br><span class=\"line\">        &#125; </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4、线程池\"><a href=\"#4、线程池\" class=\"headerlink\" title=\"4、线程池\"></a>4、线程池</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MyRunnable implements Runnable&#123; </span><br><span class=\"line\">    @Override </span><br><span class=\"line\">    public void run() &#123; </span><br><span class=\"line\">        System.out.println(Thread.currentThread().getName()); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public class SingleThreadExecutorTest &#123; </span><br><span class=\"line\">    public static void main(String[] args) &#123; </span><br><span class=\"line\">        ExecutorService executorService = Executors.newSingleThreadExecutor(); </span><br><span class=\"line\">        MyRunnable myRunnable = new MyRunnable(); </span><br><span class=\"line\">        for(int i = 0; i &lt; 10; i++)&#123; </span><br><span class=\"line\">            executorService.execute(myRunnable); </span><br><span class=\"line\">        &#125; </span><br><span class=\"line\">        System.out.println(&quot;=======任务开始=======&quot;); </span><br><span class=\"line\">        executorService.shutdown(); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、linux进程和java线程\"><a href=\"#三、linux进程和java线程\" class=\"headerlink\" title=\"三、linux进程和java线程\"></a>三、linux进程和java线程</h1><p><img src=\"/2020/04/11/2020-04-11-java-thread/%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E5%85%B3%E7%B3%BB.png\" alt=\"线程进程关系\"></p>\n<p><img src=\"/2020/04/11/2020-04-11-java-thread/jvm%E7%BA%BF%E7%A8%8B-Linux%E8%BF%9B%E7%A8%8B.png\" alt=\"jvm-linux\"><br>jvm线程对应Linux的一个进程</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、线程状态\"><a href=\"#一、线程状态\" class=\"headerlink\" title=\"一、线程状态\"></a>一、线程状态</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public enum State &#123;</span><br><span class=\"line\">    //新建状态，未启动</span><br><span class=\"line\">    NEW,</span><br><span class=\"line\">    //就绪状态，在JVM中运行，但是在操作系统中可能是等待执行。</span><br><span class=\"line\">    RUNNABLE,</span><br><span class=\"line\">    //阻塞状态，表示线程阻塞于锁</span><br><span class=\"line\">    BLOCKED,</span><br><span class=\"line\">    //等待状态，需要等待其他线程做出一些特定动作（通知或中断）</span><br><span class=\"line\">    WAITING,</span><br><span class=\"line\">   //超时等待，可以在指定的时间后自行返回</span><br><span class=\"line\">   TIMED_WAITING,</span><br><span class=\"line\">   //表示该线程已经执行完毕。</span><br><span class=\"line\">   TERMINATED;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2020/04/11/2020-04-11-java-thread/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E6%B5%81%E8%BD%AC.png\" alt=\"状态流转\"></p>\n<p>Java线程与Linux进程状态的对应关系：  </p>\n<ol>\n<li>new，是Thread对象的状态，此时和Linux的进程还没有关系。</li>\n<li>Runnable对应linux的Running。</li>\n<li>BLOCKED、WAITING、TIMED_WAITING，对应task_intermptible</li>\n<li>TERMINATED 对应task_stoped</li>\n</ol>","more":"<p>sleep</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Thread类的方法</span><br><span class=\"line\">public static native void sleep(long millis)</span><br><span class=\"line\">public static native void sleep(long millis, int nanos)//sleep(毫秒, 纳秒)</span><br><span class=\"line\"></span><br><span class=\"line\">总结：</span><br><span class=\"line\">    1.线程暂时停止运行，但是未失去对锁的拥有</span><br><span class=\"line\">    2.线程等待指定的时间后，该线程不一定会立马/确定运行</span><br><span class=\"line\">    3.线程等待，进入_EntryList队列中</span><br></pre></td></tr></table></figure>\n\n<p>join</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Waits at most millis milliseconds for this thread to die. A timeout of 0 means to wait forever.</span><br><span class=\"line\"></span><br><span class=\"line\">public final void join()&#123;</span><br><span class=\"line\">    join(0);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">public final **synchronized** void join(long millis) throw InterruptException&#123;</span><br><span class=\"line\">    long base = System.currentTimeMillis();</span><br><span class=\"line\">    long now = 0;</span><br><span class=\"line\">    if(millis &lt; 0)&#123;</span><br><span class=\"line\">        throw new IllegalArgumentException();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if(millis == 0)&#123;</span><br><span class=\"line\">        while(isAlive())&#123;//isAlive()，当前线程是否还活着</span><br><span class=\"line\">            wait(0);//object.wait(0);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;else&#123;</span><br><span class=\"line\">        while(isAlive())&#123;</span><br><span class=\"line\">            long delay = millis - now;</span><br><span class=\"line\">            if(delay &lt;=0 )&#123;</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            wait(delay);</span><br><span class=\"line\">            now = System.currentTimeMillis() - base;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">join总结：</span><br><span class=\"line\">    1、join方法为synchronized方法，所以当线程执行时，会获取该thread对象的锁</span><br><span class=\"line\">    2、所以执行join方法就已经获取了thread对象的锁，再执行wait方法，就不会抛出异常了。</span><br><span class=\"line\">    3、使执行object.join()方法的线程等待</span><br><span class=\"line\">    4、主线程和子线程之间使用，主线程执行，那么主线程将阻塞等待</span><br><span class=\"line\">        </span><br><span class=\"line\">使用</span><br><span class=\"line\">public class Join &#123;</span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        Thread thread = new JoinThread();</span><br><span class=\"line\">        thread.start();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            //主线程等待thread的业务处理完了之后再向下运行  </span><br><span class=\"line\">            thread.join();</span><br><span class=\"line\">        &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        for(int i = 0; i &lt; 5; i++)&#123;</span><br><span class=\"line\">            System.out.println(Thread.currentThread().getName()+&quot; -- &quot; + i);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">class JoinThread extends Thread&#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void run() &#123;</span><br><span class=\"line\">        for(int i = 0; i &lt; 5; i++)&#123;</span><br><span class=\"line\">            System.out.println(Thread.currentThread().getName() + &quot; -- &quot;+i);</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                sleep(500);</span><br><span class=\"line\">            &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">                e.printStackTrace();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//---------------运行结果---------------------</span><br><span class=\"line\">//主线程等待JoinThread执行完再执行</span><br><span class=\"line\">Thread-0 -- 0</span><br><span class=\"line\">Thread-0 -- 1</span><br><span class=\"line\">Thread-0 -- 2</span><br><span class=\"line\">Thread-0 -- 3</span><br><span class=\"line\">Thread-0 -- 4</span><br><span class=\"line\">main -- 0</span><br><span class=\"line\">main -- 1</span><br><span class=\"line\">main -- 2</span><br><span class=\"line\">main -- 3</span><br><span class=\"line\">main -- 4</span><br></pre></td></tr></table></figure>\n\n<p>yield</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a hint to the scheduler that the current thread is willing to yield its</span><br><span class=\"line\">current use of a processor. The schedular is free to ignore this hint.</span><br><span class=\"line\">一个线索、示意调度器当前线程将会放弃他当前的处理器使用权</span><br><span class=\"line\"></span><br><span class=\"line\">public static native void yield();</span><br><span class=\"line\">总结：</span><br><span class=\"line\">    yield()方法不会使线程失去资源，只是失去了处理器使用权，但是时机不好把控，取决于操作系统</span><br><span class=\"line\">    public static void main(String[] args)&#123;</span><br><span class=\"line\">        String object = &quot;abc&quot;;</span><br><span class=\"line\">        new Thread(new Runnable()&#123;</span><br><span class=\"line\">            public void run()&#123;</span><br><span class=\"line\">                synchronized(object)&#123;</span><br><span class=\"line\">                    System.out.println(&quot;A1&quot;);</span><br><span class=\"line\">                    sleep(4000);</span><br><span class=\"line\">                    System.out.println(&quot;A3&quot;);</span><br><span class=\"line\">                    Thread.currrentThread.yield();</span><br><span class=\"line\">                    System.out.println(&quot;A4&quot;);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">        </span><br><span class=\"line\">        new Thread(new Runnable()&#123;</span><br><span class=\"line\">            public void run()&#123;</span><br><span class=\"line\">                synchronized(object)&#123;</span><br><span class=\"line\">                    System.out.println(&quot;a&quot;);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">执行结果：</span><br><span class=\"line\">    A1</span><br><span class=\"line\">    A3</span><br><span class=\"line\">    A4</span><br><span class=\"line\">    a</span><br><span class=\"line\">    线程让步，并没有执行其他线程，未释放锁</span><br><span class=\"line\"></span><br><span class=\"line\">使用</span><br><span class=\"line\">    public static void main(String[] args)&#123;</span><br><span class=\"line\">        new Thread(new Runnable()&#123;</span><br><span class=\"line\">            public void run()&#123;</span><br><span class=\"line\">                System.out.println(&quot;A1&quot;);</span><br><span class=\"line\">                sleep(4000);</span><br><span class=\"line\">                System.out.println(&quot;A3&quot;);</span><br><span class=\"line\">                Thread.currrentThread.yield();</span><br><span class=\"line\">                System.out.println(&quot;A4&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">        </span><br><span class=\"line\">        new Thread(new Runnable()&#123;</span><br><span class=\"line\">            public void run()&#123;</span><br><span class=\"line\">                System.out.println(&quot;a&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">执行结果</span><br><span class=\"line\">    例：A1</span><br><span class=\"line\">        A3</span><br><span class=\"line\">        a</span><br><span class=\"line\">        A4</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"二、创建线程方式\"><a href=\"#二、创建线程方式\" class=\"headerlink\" title=\"二、创建线程方式\"></a>二、创建线程方式</h1><ul>\n<li>继承Thread类，并复写run方法</li>\n<li>实现Runnable接口，复写run方法</li>\n<li>创建FutureTask对象，创建Callable子类对象，复写call(相当于run)方法，将其传递给FutureTask对象（相当于一个Runnable）</li>\n<li>线程池</li>\n</ul>\n<h2 id=\"1、Thread类\"><a href=\"#1、Thread类\" class=\"headerlink\" title=\"1、Thread类\"></a>1、Thread类</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MyThread extends Thread&#123; </span><br><span class=\"line\">    @Override </span><br><span class=\"line\">    public void run() &#123; </span><br><span class=\"line\">        System.out.println(Thread.currentThread().getName()); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public class MyThreadTest &#123; </span><br><span class=\"line\">    public static void main(String[] args) &#123; </span><br><span class=\"line\">        // 创建线程 </span><br><span class=\"line\">        MyThread thread = new MyThread(); </span><br><span class=\"line\">        // 启动线程 </span><br><span class=\"line\">        thread.start(); &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-1、start和run方法的区别\"><a href=\"#2-1、start和run方法的区别\" class=\"headerlink\" title=\"2.1、start和run方法的区别\"></a>2.1、start和run方法的区别</h3><ol>\n<li>new Thread()：此时只是创建了Thread对象，没有实际去创建线程</li>\n<li>thread.start()：<ol>\n<li>内部执行native start0()方法</li>\n<li>start0()方法内部会调用OS创建线程的方法<ul>\n<li>Linux下的pthread函数，创建线程，更新JVM进程内存空间</li>\n</ul>\n</li>\n<li>start0()方法执行后，会调用run()方法</li>\n</ol>\n</li>\n<li>thread.run()：<ol>\n<li>内部不会创建新的线程</li>\n<li>由当前线程去执行run方法</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"2、Runnable接口\"><a href=\"#2、Runnable接口\" class=\"headerlink\" title=\"2、Runnable接口\"></a>2、Runnable接口</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MyRunnable implements Runnable&#123; </span><br><span class=\"line\">    @Override </span><br><span class=\"line\">    public void run() &#123; </span><br><span class=\"line\">        System.out.println(Thread.currentThread().getName()); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public class MyRunnableTest &#123; </span><br><span class=\"line\">    public static void main(String[] args) &#123; </span><br><span class=\"line\">        MyRunnable myRunnable = new MyRunnable(); </span><br><span class=\"line\">        // 创建线程 </span><br><span class=\"line\">        Thread thread = new Thread(myRunnable); </span><br><span class=\"line\">        // 启动线程 </span><br><span class=\"line\">        thread.start(); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、Callable\"><a href=\"#3、Callable\" class=\"headerlink\" title=\"3、Callable\"></a>3、Callable</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MyCallable implements Callable &#123; </span><br><span class=\"line\">    @Override </span><br><span class=\"line\">    public Integer call() throws Exception &#123; </span><br><span class=\"line\">        System.out.println(Thread.currentThread().getName()); </span><br><span class=\"line\">        return 99; </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public class MyCallableTest &#123; </span><br><span class=\"line\">    public static void main(String[] args) &#123; </span><br><span class=\"line\">        FutureTask futureTask = new FutureTask&lt;&gt;(new MyCallable()); </span><br><span class=\"line\">        // 创建线程 </span><br><span class=\"line\">        Thread thread = new Thread(futureTask); </span><br><span class=\"line\">        // 启动线程 </span><br><span class=\"line\">        thread.start(); </span><br><span class=\"line\">        // 结果返回 </span><br><span class=\"line\">        try &#123; </span><br><span class=\"line\">            Thread.sleep(1000); </span><br><span class=\"line\">            System.out.println(&quot;返回的结果是：&quot; + futureTask.get()); </span><br><span class=\"line\">        &#125; catch (Exception e) &#123; </span><br><span class=\"line\">            e.printStackTrace(); </span><br><span class=\"line\">        &#125; </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4、线程池\"><a href=\"#4、线程池\" class=\"headerlink\" title=\"4、线程池\"></a>4、线程池</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MyRunnable implements Runnable&#123; </span><br><span class=\"line\">    @Override </span><br><span class=\"line\">    public void run() &#123; </span><br><span class=\"line\">        System.out.println(Thread.currentThread().getName()); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public class SingleThreadExecutorTest &#123; </span><br><span class=\"line\">    public static void main(String[] args) &#123; </span><br><span class=\"line\">        ExecutorService executorService = Executors.newSingleThreadExecutor(); </span><br><span class=\"line\">        MyRunnable myRunnable = new MyRunnable(); </span><br><span class=\"line\">        for(int i = 0; i &lt; 10; i++)&#123; </span><br><span class=\"line\">            executorService.execute(myRunnable); </span><br><span class=\"line\">        &#125; </span><br><span class=\"line\">        System.out.println(&quot;=======任务开始=======&quot;); </span><br><span class=\"line\">        executorService.shutdown(); </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、linux进程和java线程\"><a href=\"#三、linux进程和java线程\" class=\"headerlink\" title=\"三、linux进程和java线程\"></a>三、linux进程和java线程</h1><p><img src=\"/2020/04/11/2020-04-11-java-thread/%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E5%85%B3%E7%B3%BB.png\" alt=\"线程进程关系\"></p>\n<p><img src=\"/2020/04/11/2020-04-11-java-thread/jvm%E7%BA%BF%E7%A8%8B-Linux%E8%BF%9B%E7%A8%8B.png\" alt=\"jvm-linux\"><br>jvm线程对应Linux的一个进程</p>"},{"title":"《架构》基础知识","date":"2024-08-20T02:00:00.000Z","_content":"\n### 一、什么是架构？\n在软件开发领域，架构可以从2方面进行总结，结构设计和技术选型：\n- 结构设计：模块划分、层次结构和交互方式，能够让人清晰的了解系统的整体架构。例如，一个电商系统可能分为用户界面层、业务逻辑层和数据存储层，各层之间通过明确的接口进行通信。\n- 技术选型：根据项目的需求和特点，选择合适的技术栈。比如，对于高并发的系统，可能会选择分布式架构和高性能的数据库。\n\n<!--more-->\n\n上面的这种理解过于理论化，不是很好理解。通常来说，从架构层面大致可以分为：系统架构和应用架构。\n- 系统架构：所谓的系统架构，包含硬件架构、软件架构、数据架构、网络架构。\n  - 硬件架构：包括服务器、存储设备、网络设备等硬件的选型、配置和连接方式。\n  - 软件架构：主要涉及软件系统的分层、模块划分和接口设计。\n  - 数据架构：侧重于数据的组织、存储和管理方式。包括数据库的设计\n  - 网络架构：描述系统中各个组件之间的网络连接方式，包括网络拓扑结构。例如分布式微服务架构。\n- 应用架构：应用架构是系统架构的一个子集，它主要关注软件应用系统本身的架构设计。具体来说，它描述了一个应用程序从用户界面到数据存储的整个软件结构，包括应用程序的各个功能模块如何划分、这些模块之间如何交互以及它们如何与外部系统（如其他应用程序、数据库、服务等）进行协作。\n  - 代码架构：三层架构、MVC架构。\n\n\n### 二、什么是企业架构？\n企业架构是对企业的业务流程、信息系统、技术基础架构以及人员组织等多方面进行整体规划和设计的一种方法和理念。\n\n企业架构可以分为两大部分：业务架构和IT架构，大部分企业架构方法都是从IT架构发展而来的。\n- 业务架构：是把企业的业务战略转化为日常运作的渠道，业务战略决定业务架构，它包括业务的运营模式、流程体系、组织结构、地域分布等内容\n- IT架构：指导IT投资和设计决策的IT框架，是建立企业信息系统的综合蓝图，包括数据架构、应用架构和技术架构三部分。\n\n#### 2.1、业务架构\n定义企业的业务战略、业务目标、业务流程和业务组织。它明确了企业的核心业务活动、业务之间的关系以及业务流程的流转。\n通过业务架构的设计，可以帮助企业更好地理解自身的业务模式，优化业务流程，提高业务效率和竞争力。\n![业务架构](2024-08-20-架构-架构/业务架构.png)\n#### 2.2、应用架构\n描述企业的应用系统组合，包括各个应用系统的功能、相互之间的集成关系以及与业务流程的对应关系，完成从业务到IT的转换。\n![应用架构](2024-08-20-架构-架构/应用架构.png)\n\n#### 2.3、技术架构\n涉及企业的技术基础设施，包括硬件、软件、网络、安全等方面。它确定了企业所采用的技术标准、技术平台和技术选型。\n![技术架构](2024-08-20-架构-架构/技术架构.png)\n#### 2.4、数据架构\n规划企业的数据资源，包括数据的存储、管理、使用和共享。它确定了企业的数据模型、数据标准、数据质量要求以及数据治理策略。\n![数据架构](2024-08-20-架构-架构/数据架构.png)\n\n\n#### 2.5、软件架构和企业架构的关系\n1. 软件架构需要根据业务需求和性能要求等选择合适的技术，如编程语言、数据库系统、服务器架构等。不同的软件架构可能会采用不同的技术组合。\n2. 企业架构中的技术架构同样要进行技术选型，包括选择企业整体的硬件平台、软件平台、网络设备等。软件架构所选用的具体技术是在企业架构的技术架构所设定的基础技术环境下进行的，要符合企业整体技术架构的要求，以确保技术资源在企业内的统一管理和有效利用。\n\n### 三、软件架构的设计原则\n设计原则是在软件设计过程中需要遵循的一些基本准则，它们旨在帮助开发者创建出更具可维护性、可扩展性、灵活性和可靠性的软件系统。常见的设计原则如下：\n#### 1、开闭原则（Open-Closed Principle，OCP）\n1. 含义：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。即当有新的需求出现时，应通过添加新的代码来实现扩展，而非修改现有的代码。\n2. 示例：如在一个图形绘制系统中，有抽象图形类，要添加新图形类型（如椭圆），可创建椭圆子类继承抽象图形类，无需修改抽象图形类代码，以此保证系统稳定性与可扩展性。\n\n#### 2、里氏替换原则（Liskov Substitution Principle，LSP）\n1. 含义：所有引用基类的地方必须能透明地使用其子类的对象。也就是子类应该能够替换基类而不影响程序的正确性。\n2. 示例：假设有函数接受基类类型参数，当传入子类对象时，函数应能正常工作且无意外结果。例如，动物类是基类，猫类是子类，有个函数是计算动物奔跑速度，当传入猫类对象时，应能正确计算出猫的奔跑速度。\n\n#### 3、依赖倒置原则（Dependence Inversion Principle，DIP）\n1. 含义：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。\n2. 示例：在分层架构系统中，业务逻辑层（高层模块）不应直接依赖数据库访问层（低层模块），而是应依赖抽象的数据访问接口。这样当数据库访问方式改变时，只需修改实现接口的具体类，不影响业务逻辑层代码。\n\n#### 4、单一职责原则（Single Responsibility Principle，SRP）\n1. 含义：一个类应该只有一个引起它变化的原因。即一个类应该只有一个职责，只负责一项功能。\n2. 示例：用户管理类不应既负责用户创建、删除等操作，又负责用户权限管理。应将这两项职责分离到不同类中，以便当其中一个功能变化时，不影响另一个功能的代码。\n\n#### 5、接口隔离原则（Interface Segregation Principle，ISP）\n1. 含义：客户端不应该被迫依赖于它不使用的方法。一个类对另一个类的依赖应该建立在最小的接口上。\n2. 示例：打印机接口若包含扫描、传真等方法，而只需要打印功能的客户端依赖此接口，就会被迫实现不需要的方法。应将接口细分，让客户端只依赖所需接口。\n\n#### 6、合成复用原则（Composite Reuse Principle，CRP）\n1. 含义：尽量使用对象组合，而不是继承来达到复用的目的。继承会导致子类与父类的高度耦合，而对象组合可在运行时动态组合对象，更灵活。\n2. 示例：在图形绘制系统中，要一个可同时绘制圆形和矩形的图形类，可通过组合圆形类和矩形类实现，而非创建继承自圆形类和矩形类的新类。这样添加新图形类型时，只需组合新图形类，不影响现有代码。\n\n#### 7、迪米特法则（Law of Demeter，LoD）\n1. 含义：也称为最少知识原则，一个对象应该对其他对象有尽可能少的了解。只与直接的朋友通信，避免与陌生人通信。\n2. 示例：类 A 的方法若需调用类 B 的方法，应通过类 A 的直接关联对象来调用，而不是直接调用类 B 的方法。这样可降低类之间的耦合度，提高系统可维护性。\n\n### 四、软件开发的设计模式\n设计模式是在软件开发过程中，针对反复出现的设计问题所总结出的通用解决方案。它们是经过实践验证的、可复用的软件设计思路和结构，按照其功能和用途可大致分为以下几类：\n#### 4.1、创建模式\n创建型模式主要用于对象的创建过程，它们将对象的创建和使用分离，使得系统在创建对象时更加灵活和可维护。\n##### 单例模式\n保证一个类仅有一个实例，并提供一个全局访问点。常用于管理系统资源、配置信息等，如数据库连接池通常采用单例模式，确保只有一个数据库连接池实例存在，避免资源浪费和冲突。\n##### 工厂模式\n提供了一种创建对象的方式，通过一个工厂类来负责创建对象，而不是在客户端代码中直接实例化对象。这样可以提高代码的灵活性和可维护性。例如，在一个汽车制造工厂里，有不同类型的汽车（如轿车、SUV 等），可以通过一个汽车工厂类来根据需求创建不同类型的汽车对象。\n##### 抽象工厂模式\n提供了创建一系列相关或相互依赖的对象的方式。与工厂模式相比，它更注重创建一组对象，而不是单个对象。比如在一个游戏开发中，需要创建不同场景下的一系列道具、角色等，就可以采用抽象工厂模式。\n\n#### 4.2、结构模式\n##### 代理模式\n通过代理对象来控制对真实对象的访问。例如，在网络访问中，当用户访问某些网站时，可能会通过代理服务器来进行访问，代理服务器可以对访问进行过滤、限制等操作。在软件设计中，代理模式可用于权限管理、性能优化等方面。\n\n##### 装饰者模式\n- **意图：** 动态地给一个对象添加额外的职责，同时不改变其结构。装饰器模式提供了一种灵活的替代继承方式来扩展功能。\n- **主要解决的问题：** 避免通过继承引入静态特征，特别是在子类数量急剧膨胀的情况下。允许在运行时动态地添加或修改对象的功能。\n- **使用场景：** 当需要在不增加大量子类的情况下扩展类的功能。当需要动态地添加或撤销对象的功能。\n\n动态地添加新的行为或功能到一个对象上，而不需要修改被装饰对象的原始代码。比如，一杯咖啡本身有价格和口味等属性，通过装饰者模式可以给咖啡添加奶油、糖等装饰，并且每添加一种装饰就会改变咖啡的价格和口味，而不需要修改咖啡本身的代码。\n![装饰者模式](2024-08-20-架构-架构/装饰者模式.png)\n- 抽象组件(Component): 定义装饰方法的规范\n- 被装饰者(ConcreteComponent): Component的具体实现，也就是我们要装饰的具体对象。\n- 装饰者组件(Decorator): 持有组件(Component)对象的实例引用，该类的职责就是为了装饰具体组件对象，定义的规范。\n- 具体装饰(ConcreteDecorator): 负责给构件对象装饰附加的功能。\n\n<style>\n.highlight.java {\n    height:400px;\n}\n</style>\n```java\n// 抽象组件：咖啡\nabstract class Coffee {\n    String description = \"未知咖啡\";\n\n    public String getDescription() {\n        return description;\n    }\n\n    public abstract double cost();\n}\n\n// 具体组件：普通咖啡\nclass SimpleCoffee extends Coffee {\n    public SimpleCoffee() {\n        description = \"普通咖啡\";\n    }\n\n    @Override\n    public double cost() {\n        return 5.0;\n    }\n}\n\n// 抽象装饰者：咖啡装饰者\nabstract class CoffeeDecorator extends Coffee {\n    protected Coffee coffee;\n\n    public CoffeeDecorator(Coffee coffee) {\n        this.coffee = coffee;\n    }\n\n    @Override\n    public String getDescription() {\n        return coffee.getDescription();\n    }\n\n    @Override\n    public double cost() {\n        return coffee.cost();\n    }\n}\n\n// 具体装饰者：奶油装饰\nclass CreamDecorator extends CoffeeDecorator {\n    public CreamDecorator(Coffee coffee) {\n        super(coffee);\n    }\n\n    @Override\n    public String getDescription() {\n        return coffee.getDescription() + \", 加了奶油\";\n    }\n\n    @Override\n    public double cost() {\n        return coffee.cost() + 2.0;\n    }\n}\n\n// 具体装饰者：糖装饰\nclass SugarDecorator extends CoffeeDecorator {\n    public SugarDecorator(Coffee coffee) {\n        super(coffee);\n    }\n    @Override\n    public String getDescription() {\n        return coffee.getDescription() + \", 加了糖\";\n    }\n    @Override\n    public double cost() {\n        return coffee.cost() + 1.0;\n    }\n}\n// 测试类\npublic class CoffeeDecoratorTest {\n    public static void main(String[] args) {\n        Coffee coffee = new SimpleCoffee();\n        System.out.println(\"原始咖啡：\" + coffee.getDescription() + \"，价格：\" + coffee.cost());\n        coffee = new CreamDecorator(coffee);\n        System.out.println(\"加了奶油后的咖啡：\" + coffee.getDescription() + \"，价格：\" + coffee.cost());\n        coffee = new SugarDecorator(coffee);\n        System.out.println(\"再加了糖后的咖啡：\" + coffee.getDescription() + \"，价格：\" + coffee.cost());\n    }\n}\n```\n\n\n\n##### 桥接模式\n- **意图：** 将抽象部分与它的实现部分分离，使得它们可以独立变化。例如，在图形绘制系统中，形状是抽象部分，颜色是实现部分，通过桥接模式可以让形状和颜色独立变化，即可以选择不同的形状搭配不同的颜色，而不会相互影响。\n- **主要解决的问题：** 避免使用继承导致的类爆炸问题，提供更灵活的扩展方式。\n- **使用场景：** 当系统可能从多个角度进行分类，且每个角度都可能独立变化时，桥接模式是合适的。例如JDBC驱动程序。\n\n```java\n// 颜色接口\ninterface Color {\n    void applyColor();\n}\n\n// 具体颜色实现类：红色\nclass RedColor implements Color {\n    @Override\n    public void applyColor() {\n        System.out.println(\"Applying red color\");\n    }\n}\n\n// 具体颜色实现类：蓝色\nclass BlueColor implements Color {\n    @Override\n    public void applyColor() {\n        System.out.println(\"Applying blue color\");\n    }\n}\n\n// 形状抽象类，包含对颜色的引用（桥接部分）\nabstract class Shape {\n    protected Color color;\n\n    public Shape(Color color) {\n        this.color = color;\n    }\n\n    abstract void draw();\n}\n\n// 具体形状类：圆形\nclass Circle extends Shape {\n    public Circle(Color color) {\n        super(color);\n    }\n\n    @Override\n    void draw() {\n        System.out.print(\"Drawing a circle. \");\n        color.applyColor();\n    }\n}\n\n// 具体形状类：矩形\nclass Rectangle extends Shape {\n    public Rectangle(Color color) {\n        super(color);\n    }\n\n    @Override\n    void draw() {\n        System.out.print(\"Drawing a rectangle. \");\n        color.applyColor();\n    }\n}\n\n\npublic class BridgePatternExample {\n    public static void main(String[] args) {\n        // 使用红色绘制圆形\n        Shape circleWithRed = new Circle(new RedColor());\n        circleWithRed.draw();\n\n        // 使用蓝色绘制矩形\n        Shape rectangleWithBlue = new Rectangle(new BlueColor());\n        rectangleWithBlue.draw();\n    }\n}\n```\n\n##### 装饰模式和桥接模式\n\n###### 不同点\n1. 设计意图：\n   1. 装饰模式：重点在于动态地添加功能。它是一种 “增强” 对象功能的方式，在运行时可以根据需要灵活地组合装饰器来为对象添加不同的功能。装饰器和被装饰对象通常属于同一个层次结构，**都实现相同的接口或者继承相同的抽象类**。\n   2. 桥接模式：更侧重于将抽象和实现解耦，使它们可以独立地演变。抽象部分和实现部分通常**属于不同的层次结构**，它们通过一个抽象的关联（桥）来进行合作。\n2. 使用场景：\n   1. 装饰模式：适用于在不改变对象基本结构的情况下，动态地添加或修改对象的功能。\n   2. 桥接模式：适合用于当一个类存在两个独立变化的维度，且这两个维度需要灵活组合的时候。\n\n#### 4.3、行为模式\n##### 观察者模式\n- **意图**： 创建了对象间的一种一对多的依赖关系，当一个对象状态改变时，所有依赖于它的对象都会得到通知并自动更新。\n- **主要解决的问题**： 观察者模式解决的是一个对象状态改变时，如何自动通知其他依赖对象的问题，同时保持对象间的低耦合和高协作性。\n- **使用场景**： 当一个对象的状态变化需要同时更新其他对象时。\n\n![观察者模式](2024-08-20-架构-架构/观察者模式.png)\n观察者模式使用2个类\n- Subject：主题，提供了addObserver(), deleteObserver(), notifyObservers()等方法\n- Observer：观察者，用于接收主题发送的通知并更新自身状态。\n\n```java\n//主题\ninterface Subject {\n    void addObserver(Observer observer);\n    void removeObserver(Observer observer);\n    void notifyObservers(String message);\n}\nclass NewsAgency implements Subject {\n    private List<Observer> observers = new ArrayList<>();\n    @Override\n    public void addObserver(Observer observer) {\n        observers.add(observer);\n    }\n    @Override\n    public void removeObserver(Observer observer) {\n        observers.remove(observer);\n    }\n    @Override\n    public void notifyObservers(String message) {\n        for (Observer observer : observers) {\n            observer.update(message);\n        }\n    }\n    public void publishNews(String news) {\n        notifyObservers(news);\n    }\n}\n//观察者\ninterface Observer {\n    void update(String message);\n}\nclass NewsSubscriber implements Observer {\n    private String name;\n    public NewsSubscriber(String name) {\n        this.name = name;\n    }\n    @Override\n    public void update(String message) {\n        System.out.println(name + \" received news: \" + message);\n    }\n}\n\npublic class ObserverPatternExample {\n    public static void main(String[] args) {\n        //定义主题\n        NewsAgency newsAgency = new NewsAgency();\n        //创建订阅者\n        NewsSubscriber subscriber1 = new NewsSubscriber(\"Alice\");\n        NewsSubscriber subscriber2 = new NewsSubscriber(\"Bob\");\n        newsAgency.addObserver(subscriber1);\n        newsAgency.addObserver(subscriber2);\n        newsAgency.publishNews(\"Breaking news: A new discovery!\");\n    }\n}\n```\n\n\n##### 策略模式\n定义了一系列的策略，并且让用户可以根据需要选择不同的策略来执行某项任务。例如，在一个出行应用中，用户可以选择不同的出行策略，如打车、公交、地铁等，每种策略都有不同的费用计算方法和行程安排。\n\n##### 命令模式\n将一个请求封装成一个命令对象，这样可以把请求的发出者和执行者分离，便于管理和控制。比如，在一个餐厅里，顾客点菜的请求可以被封装成命令对象，然后由厨师来执行这些命令，这样可以使点菜过程更加有序和可控。\n\n\n\n参考文章：\n[一文搞懂业务架构、应用架构、技术架构、数据架构！](https://mp.weixin.qq.com/s/YBwEqvo1j0-tYzI6NV58sw)","source":"_posts/2024-08-20-架构-架构.md","raw":"---\ntitle: 《架构》基础知识\ndate: 2024-08-20 10:00:00\ncategories:\n  - [架构, 设计模式]\n---\n\n### 一、什么是架构？\n在软件开发领域，架构可以从2方面进行总结，结构设计和技术选型：\n- 结构设计：模块划分、层次结构和交互方式，能够让人清晰的了解系统的整体架构。例如，一个电商系统可能分为用户界面层、业务逻辑层和数据存储层，各层之间通过明确的接口进行通信。\n- 技术选型：根据项目的需求和特点，选择合适的技术栈。比如，对于高并发的系统，可能会选择分布式架构和高性能的数据库。\n\n<!--more-->\n\n上面的这种理解过于理论化，不是很好理解。通常来说，从架构层面大致可以分为：系统架构和应用架构。\n- 系统架构：所谓的系统架构，包含硬件架构、软件架构、数据架构、网络架构。\n  - 硬件架构：包括服务器、存储设备、网络设备等硬件的选型、配置和连接方式。\n  - 软件架构：主要涉及软件系统的分层、模块划分和接口设计。\n  - 数据架构：侧重于数据的组织、存储和管理方式。包括数据库的设计\n  - 网络架构：描述系统中各个组件之间的网络连接方式，包括网络拓扑结构。例如分布式微服务架构。\n- 应用架构：应用架构是系统架构的一个子集，它主要关注软件应用系统本身的架构设计。具体来说，它描述了一个应用程序从用户界面到数据存储的整个软件结构，包括应用程序的各个功能模块如何划分、这些模块之间如何交互以及它们如何与外部系统（如其他应用程序、数据库、服务等）进行协作。\n  - 代码架构：三层架构、MVC架构。\n\n\n### 二、什么是企业架构？\n企业架构是对企业的业务流程、信息系统、技术基础架构以及人员组织等多方面进行整体规划和设计的一种方法和理念。\n\n企业架构可以分为两大部分：业务架构和IT架构，大部分企业架构方法都是从IT架构发展而来的。\n- 业务架构：是把企业的业务战略转化为日常运作的渠道，业务战略决定业务架构，它包括业务的运营模式、流程体系、组织结构、地域分布等内容\n- IT架构：指导IT投资和设计决策的IT框架，是建立企业信息系统的综合蓝图，包括数据架构、应用架构和技术架构三部分。\n\n#### 2.1、业务架构\n定义企业的业务战略、业务目标、业务流程和业务组织。它明确了企业的核心业务活动、业务之间的关系以及业务流程的流转。\n通过业务架构的设计，可以帮助企业更好地理解自身的业务模式，优化业务流程，提高业务效率和竞争力。\n![业务架构](2024-08-20-架构-架构/业务架构.png)\n#### 2.2、应用架构\n描述企业的应用系统组合，包括各个应用系统的功能、相互之间的集成关系以及与业务流程的对应关系，完成从业务到IT的转换。\n![应用架构](2024-08-20-架构-架构/应用架构.png)\n\n#### 2.3、技术架构\n涉及企业的技术基础设施，包括硬件、软件、网络、安全等方面。它确定了企业所采用的技术标准、技术平台和技术选型。\n![技术架构](2024-08-20-架构-架构/技术架构.png)\n#### 2.4、数据架构\n规划企业的数据资源，包括数据的存储、管理、使用和共享。它确定了企业的数据模型、数据标准、数据质量要求以及数据治理策略。\n![数据架构](2024-08-20-架构-架构/数据架构.png)\n\n\n#### 2.5、软件架构和企业架构的关系\n1. 软件架构需要根据业务需求和性能要求等选择合适的技术，如编程语言、数据库系统、服务器架构等。不同的软件架构可能会采用不同的技术组合。\n2. 企业架构中的技术架构同样要进行技术选型，包括选择企业整体的硬件平台、软件平台、网络设备等。软件架构所选用的具体技术是在企业架构的技术架构所设定的基础技术环境下进行的，要符合企业整体技术架构的要求，以确保技术资源在企业内的统一管理和有效利用。\n\n### 三、软件架构的设计原则\n设计原则是在软件设计过程中需要遵循的一些基本准则，它们旨在帮助开发者创建出更具可维护性、可扩展性、灵活性和可靠性的软件系统。常见的设计原则如下：\n#### 1、开闭原则（Open-Closed Principle，OCP）\n1. 含义：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。即当有新的需求出现时，应通过添加新的代码来实现扩展，而非修改现有的代码。\n2. 示例：如在一个图形绘制系统中，有抽象图形类，要添加新图形类型（如椭圆），可创建椭圆子类继承抽象图形类，无需修改抽象图形类代码，以此保证系统稳定性与可扩展性。\n\n#### 2、里氏替换原则（Liskov Substitution Principle，LSP）\n1. 含义：所有引用基类的地方必须能透明地使用其子类的对象。也就是子类应该能够替换基类而不影响程序的正确性。\n2. 示例：假设有函数接受基类类型参数，当传入子类对象时，函数应能正常工作且无意外结果。例如，动物类是基类，猫类是子类，有个函数是计算动物奔跑速度，当传入猫类对象时，应能正确计算出猫的奔跑速度。\n\n#### 3、依赖倒置原则（Dependence Inversion Principle，DIP）\n1. 含义：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。\n2. 示例：在分层架构系统中，业务逻辑层（高层模块）不应直接依赖数据库访问层（低层模块），而是应依赖抽象的数据访问接口。这样当数据库访问方式改变时，只需修改实现接口的具体类，不影响业务逻辑层代码。\n\n#### 4、单一职责原则（Single Responsibility Principle，SRP）\n1. 含义：一个类应该只有一个引起它变化的原因。即一个类应该只有一个职责，只负责一项功能。\n2. 示例：用户管理类不应既负责用户创建、删除等操作，又负责用户权限管理。应将这两项职责分离到不同类中，以便当其中一个功能变化时，不影响另一个功能的代码。\n\n#### 5、接口隔离原则（Interface Segregation Principle，ISP）\n1. 含义：客户端不应该被迫依赖于它不使用的方法。一个类对另一个类的依赖应该建立在最小的接口上。\n2. 示例：打印机接口若包含扫描、传真等方法，而只需要打印功能的客户端依赖此接口，就会被迫实现不需要的方法。应将接口细分，让客户端只依赖所需接口。\n\n#### 6、合成复用原则（Composite Reuse Principle，CRP）\n1. 含义：尽量使用对象组合，而不是继承来达到复用的目的。继承会导致子类与父类的高度耦合，而对象组合可在运行时动态组合对象，更灵活。\n2. 示例：在图形绘制系统中，要一个可同时绘制圆形和矩形的图形类，可通过组合圆形类和矩形类实现，而非创建继承自圆形类和矩形类的新类。这样添加新图形类型时，只需组合新图形类，不影响现有代码。\n\n#### 7、迪米特法则（Law of Demeter，LoD）\n1. 含义：也称为最少知识原则，一个对象应该对其他对象有尽可能少的了解。只与直接的朋友通信，避免与陌生人通信。\n2. 示例：类 A 的方法若需调用类 B 的方法，应通过类 A 的直接关联对象来调用，而不是直接调用类 B 的方法。这样可降低类之间的耦合度，提高系统可维护性。\n\n### 四、软件开发的设计模式\n设计模式是在软件开发过程中，针对反复出现的设计问题所总结出的通用解决方案。它们是经过实践验证的、可复用的软件设计思路和结构，按照其功能和用途可大致分为以下几类：\n#### 4.1、创建模式\n创建型模式主要用于对象的创建过程，它们将对象的创建和使用分离，使得系统在创建对象时更加灵活和可维护。\n##### 单例模式\n保证一个类仅有一个实例，并提供一个全局访问点。常用于管理系统资源、配置信息等，如数据库连接池通常采用单例模式，确保只有一个数据库连接池实例存在，避免资源浪费和冲突。\n##### 工厂模式\n提供了一种创建对象的方式，通过一个工厂类来负责创建对象，而不是在客户端代码中直接实例化对象。这样可以提高代码的灵活性和可维护性。例如，在一个汽车制造工厂里，有不同类型的汽车（如轿车、SUV 等），可以通过一个汽车工厂类来根据需求创建不同类型的汽车对象。\n##### 抽象工厂模式\n提供了创建一系列相关或相互依赖的对象的方式。与工厂模式相比，它更注重创建一组对象，而不是单个对象。比如在一个游戏开发中，需要创建不同场景下的一系列道具、角色等，就可以采用抽象工厂模式。\n\n#### 4.2、结构模式\n##### 代理模式\n通过代理对象来控制对真实对象的访问。例如，在网络访问中，当用户访问某些网站时，可能会通过代理服务器来进行访问，代理服务器可以对访问进行过滤、限制等操作。在软件设计中，代理模式可用于权限管理、性能优化等方面。\n\n##### 装饰者模式\n- **意图：** 动态地给一个对象添加额外的职责，同时不改变其结构。装饰器模式提供了一种灵活的替代继承方式来扩展功能。\n- **主要解决的问题：** 避免通过继承引入静态特征，特别是在子类数量急剧膨胀的情况下。允许在运行时动态地添加或修改对象的功能。\n- **使用场景：** 当需要在不增加大量子类的情况下扩展类的功能。当需要动态地添加或撤销对象的功能。\n\n动态地添加新的行为或功能到一个对象上，而不需要修改被装饰对象的原始代码。比如，一杯咖啡本身有价格和口味等属性，通过装饰者模式可以给咖啡添加奶油、糖等装饰，并且每添加一种装饰就会改变咖啡的价格和口味，而不需要修改咖啡本身的代码。\n![装饰者模式](2024-08-20-架构-架构/装饰者模式.png)\n- 抽象组件(Component): 定义装饰方法的规范\n- 被装饰者(ConcreteComponent): Component的具体实现，也就是我们要装饰的具体对象。\n- 装饰者组件(Decorator): 持有组件(Component)对象的实例引用，该类的职责就是为了装饰具体组件对象，定义的规范。\n- 具体装饰(ConcreteDecorator): 负责给构件对象装饰附加的功能。\n\n<style>\n.highlight.java {\n    height:400px;\n}\n</style>\n```java\n// 抽象组件：咖啡\nabstract class Coffee {\n    String description = \"未知咖啡\";\n\n    public String getDescription() {\n        return description;\n    }\n\n    public abstract double cost();\n}\n\n// 具体组件：普通咖啡\nclass SimpleCoffee extends Coffee {\n    public SimpleCoffee() {\n        description = \"普通咖啡\";\n    }\n\n    @Override\n    public double cost() {\n        return 5.0;\n    }\n}\n\n// 抽象装饰者：咖啡装饰者\nabstract class CoffeeDecorator extends Coffee {\n    protected Coffee coffee;\n\n    public CoffeeDecorator(Coffee coffee) {\n        this.coffee = coffee;\n    }\n\n    @Override\n    public String getDescription() {\n        return coffee.getDescription();\n    }\n\n    @Override\n    public double cost() {\n        return coffee.cost();\n    }\n}\n\n// 具体装饰者：奶油装饰\nclass CreamDecorator extends CoffeeDecorator {\n    public CreamDecorator(Coffee coffee) {\n        super(coffee);\n    }\n\n    @Override\n    public String getDescription() {\n        return coffee.getDescription() + \", 加了奶油\";\n    }\n\n    @Override\n    public double cost() {\n        return coffee.cost() + 2.0;\n    }\n}\n\n// 具体装饰者：糖装饰\nclass SugarDecorator extends CoffeeDecorator {\n    public SugarDecorator(Coffee coffee) {\n        super(coffee);\n    }\n    @Override\n    public String getDescription() {\n        return coffee.getDescription() + \", 加了糖\";\n    }\n    @Override\n    public double cost() {\n        return coffee.cost() + 1.0;\n    }\n}\n// 测试类\npublic class CoffeeDecoratorTest {\n    public static void main(String[] args) {\n        Coffee coffee = new SimpleCoffee();\n        System.out.println(\"原始咖啡：\" + coffee.getDescription() + \"，价格：\" + coffee.cost());\n        coffee = new CreamDecorator(coffee);\n        System.out.println(\"加了奶油后的咖啡：\" + coffee.getDescription() + \"，价格：\" + coffee.cost());\n        coffee = new SugarDecorator(coffee);\n        System.out.println(\"再加了糖后的咖啡：\" + coffee.getDescription() + \"，价格：\" + coffee.cost());\n    }\n}\n```\n\n\n\n##### 桥接模式\n- **意图：** 将抽象部分与它的实现部分分离，使得它们可以独立变化。例如，在图形绘制系统中，形状是抽象部分，颜色是实现部分，通过桥接模式可以让形状和颜色独立变化，即可以选择不同的形状搭配不同的颜色，而不会相互影响。\n- **主要解决的问题：** 避免使用继承导致的类爆炸问题，提供更灵活的扩展方式。\n- **使用场景：** 当系统可能从多个角度进行分类，且每个角度都可能独立变化时，桥接模式是合适的。例如JDBC驱动程序。\n\n```java\n// 颜色接口\ninterface Color {\n    void applyColor();\n}\n\n// 具体颜色实现类：红色\nclass RedColor implements Color {\n    @Override\n    public void applyColor() {\n        System.out.println(\"Applying red color\");\n    }\n}\n\n// 具体颜色实现类：蓝色\nclass BlueColor implements Color {\n    @Override\n    public void applyColor() {\n        System.out.println(\"Applying blue color\");\n    }\n}\n\n// 形状抽象类，包含对颜色的引用（桥接部分）\nabstract class Shape {\n    protected Color color;\n\n    public Shape(Color color) {\n        this.color = color;\n    }\n\n    abstract void draw();\n}\n\n// 具体形状类：圆形\nclass Circle extends Shape {\n    public Circle(Color color) {\n        super(color);\n    }\n\n    @Override\n    void draw() {\n        System.out.print(\"Drawing a circle. \");\n        color.applyColor();\n    }\n}\n\n// 具体形状类：矩形\nclass Rectangle extends Shape {\n    public Rectangle(Color color) {\n        super(color);\n    }\n\n    @Override\n    void draw() {\n        System.out.print(\"Drawing a rectangle. \");\n        color.applyColor();\n    }\n}\n\n\npublic class BridgePatternExample {\n    public static void main(String[] args) {\n        // 使用红色绘制圆形\n        Shape circleWithRed = new Circle(new RedColor());\n        circleWithRed.draw();\n\n        // 使用蓝色绘制矩形\n        Shape rectangleWithBlue = new Rectangle(new BlueColor());\n        rectangleWithBlue.draw();\n    }\n}\n```\n\n##### 装饰模式和桥接模式\n\n###### 不同点\n1. 设计意图：\n   1. 装饰模式：重点在于动态地添加功能。它是一种 “增强” 对象功能的方式，在运行时可以根据需要灵活地组合装饰器来为对象添加不同的功能。装饰器和被装饰对象通常属于同一个层次结构，**都实现相同的接口或者继承相同的抽象类**。\n   2. 桥接模式：更侧重于将抽象和实现解耦，使它们可以独立地演变。抽象部分和实现部分通常**属于不同的层次结构**，它们通过一个抽象的关联（桥）来进行合作。\n2. 使用场景：\n   1. 装饰模式：适用于在不改变对象基本结构的情况下，动态地添加或修改对象的功能。\n   2. 桥接模式：适合用于当一个类存在两个独立变化的维度，且这两个维度需要灵活组合的时候。\n\n#### 4.3、行为模式\n##### 观察者模式\n- **意图**： 创建了对象间的一种一对多的依赖关系，当一个对象状态改变时，所有依赖于它的对象都会得到通知并自动更新。\n- **主要解决的问题**： 观察者模式解决的是一个对象状态改变时，如何自动通知其他依赖对象的问题，同时保持对象间的低耦合和高协作性。\n- **使用场景**： 当一个对象的状态变化需要同时更新其他对象时。\n\n![观察者模式](2024-08-20-架构-架构/观察者模式.png)\n观察者模式使用2个类\n- Subject：主题，提供了addObserver(), deleteObserver(), notifyObservers()等方法\n- Observer：观察者，用于接收主题发送的通知并更新自身状态。\n\n```java\n//主题\ninterface Subject {\n    void addObserver(Observer observer);\n    void removeObserver(Observer observer);\n    void notifyObservers(String message);\n}\nclass NewsAgency implements Subject {\n    private List<Observer> observers = new ArrayList<>();\n    @Override\n    public void addObserver(Observer observer) {\n        observers.add(observer);\n    }\n    @Override\n    public void removeObserver(Observer observer) {\n        observers.remove(observer);\n    }\n    @Override\n    public void notifyObservers(String message) {\n        for (Observer observer : observers) {\n            observer.update(message);\n        }\n    }\n    public void publishNews(String news) {\n        notifyObservers(news);\n    }\n}\n//观察者\ninterface Observer {\n    void update(String message);\n}\nclass NewsSubscriber implements Observer {\n    private String name;\n    public NewsSubscriber(String name) {\n        this.name = name;\n    }\n    @Override\n    public void update(String message) {\n        System.out.println(name + \" received news: \" + message);\n    }\n}\n\npublic class ObserverPatternExample {\n    public static void main(String[] args) {\n        //定义主题\n        NewsAgency newsAgency = new NewsAgency();\n        //创建订阅者\n        NewsSubscriber subscriber1 = new NewsSubscriber(\"Alice\");\n        NewsSubscriber subscriber2 = new NewsSubscriber(\"Bob\");\n        newsAgency.addObserver(subscriber1);\n        newsAgency.addObserver(subscriber2);\n        newsAgency.publishNews(\"Breaking news: A new discovery!\");\n    }\n}\n```\n\n\n##### 策略模式\n定义了一系列的策略，并且让用户可以根据需要选择不同的策略来执行某项任务。例如，在一个出行应用中，用户可以选择不同的出行策略，如打车、公交、地铁等，每种策略都有不同的费用计算方法和行程安排。\n\n##### 命令模式\n将一个请求封装成一个命令对象，这样可以把请求的发出者和执行者分离，便于管理和控制。比如，在一个餐厅里，顾客点菜的请求可以被封装成命令对象，然后由厨师来执行这些命令，这样可以使点菜过程更加有序和可控。\n\n\n\n参考文章：\n[一文搞懂业务架构、应用架构、技术架构、数据架构！](https://mp.weixin.qq.com/s/YBwEqvo1j0-tYzI6NV58sw)","slug":"2024-08-20-架构-架构","published":1,"updated":"2024-11-21T03:42:11.915Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny8005ba13kncj57a94","content":"<h3 id=\"一、什么是架构？\"><a href=\"#一、什么是架构？\" class=\"headerlink\" title=\"一、什么是架构？\"></a>一、什么是架构？</h3><p>在软件开发领域，架构可以从2方面进行总结，结构设计和技术选型：</p>\n<ul>\n<li>结构设计：模块划分、层次结构和交互方式，能够让人清晰的了解系统的整体架构。例如，一个电商系统可能分为用户界面层、业务逻辑层和数据存储层，各层之间通过明确的接口进行通信。</li>\n<li>技术选型：根据项目的需求和特点，选择合适的技术栈。比如，对于高并发的系统，可能会选择分布式架构和高性能的数据库。</li>\n</ul>\n<a id=\"more\"></a>\n\n<p>上面的这种理解过于理论化，不是很好理解。通常来说，从架构层面大致可以分为：系统架构和应用架构。</p>\n<ul>\n<li>系统架构：所谓的系统架构，包含硬件架构、软件架构、数据架构、网络架构。<ul>\n<li>硬件架构：包括服务器、存储设备、网络设备等硬件的选型、配置和连接方式。</li>\n<li>软件架构：主要涉及软件系统的分层、模块划分和接口设计。</li>\n<li>数据架构：侧重于数据的组织、存储和管理方式。包括数据库的设计</li>\n<li>网络架构：描述系统中各个组件之间的网络连接方式，包括网络拓扑结构。例如分布式微服务架构。</li>\n</ul>\n</li>\n<li>应用架构：应用架构是系统架构的一个子集，它主要关注软件应用系统本身的架构设计。具体来说，它描述了一个应用程序从用户界面到数据存储的整个软件结构，包括应用程序的各个功能模块如何划分、这些模块之间如何交互以及它们如何与外部系统（如其他应用程序、数据库、服务等）进行协作。<ul>\n<li>代码架构：三层架构、MVC架构。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"二、什么是企业架构？\"><a href=\"#二、什么是企业架构？\" class=\"headerlink\" title=\"二、什么是企业架构？\"></a>二、什么是企业架构？</h3><p>企业架构是对企业的业务流程、信息系统、技术基础架构以及人员组织等多方面进行整体规划和设计的一种方法和理念。</p>\n<p>企业架构可以分为两大部分：业务架构和IT架构，大部分企业架构方法都是从IT架构发展而来的。</p>\n<ul>\n<li>业务架构：是把企业的业务战略转化为日常运作的渠道，业务战略决定业务架构，它包括业务的运营模式、流程体系、组织结构、地域分布等内容</li>\n<li>IT架构：指导IT投资和设计决策的IT框架，是建立企业信息系统的综合蓝图，包括数据架构、应用架构和技术架构三部分。</li>\n</ul>\n<h4 id=\"2-1、业务架构\"><a href=\"#2-1、业务架构\" class=\"headerlink\" title=\"2.1、业务架构\"></a>2.1、业务架构</h4><p>定义企业的业务战略、业务目标、业务流程和业务组织。它明确了企业的核心业务活动、业务之间的关系以及业务流程的流转。<br>通过业务架构的设计，可以帮助企业更好地理解自身的业务模式，优化业务流程，提高业务效率和竞争力。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E4%B8%9A%E5%8A%A1%E6%9E%B6%E6%9E%84.png\" alt=\"业务架构\"></p>\n<h4 id=\"2-2、应用架构\"><a href=\"#2-2、应用架构\" class=\"headerlink\" title=\"2.2、应用架构\"></a>2.2、应用架构</h4><p>描述企业的应用系统组合，包括各个应用系统的功能、相互之间的集成关系以及与业务流程的对应关系，完成从业务到IT的转换。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84.png\" alt=\"应用架构\"></p>\n<h4 id=\"2-3、技术架构\"><a href=\"#2-3、技术架构\" class=\"headerlink\" title=\"2.3、技术架构\"></a>2.3、技术架构</h4><p>涉及企业的技术基础设施，包括硬件、软件、网络、安全等方面。它确定了企业所采用的技术标准、技术平台和技术选型。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84.png\" alt=\"技术架构\"></p>\n<h4 id=\"2-4、数据架构\"><a href=\"#2-4、数据架构\" class=\"headerlink\" title=\"2.4、数据架构\"></a>2.4、数据架构</h4><p>规划企业的数据资源，包括数据的存储、管理、使用和共享。它确定了企业的数据模型、数据标准、数据质量要求以及数据治理策略。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84.png\" alt=\"数据架构\"></p>\n<h4 id=\"2-5、软件架构和企业架构的关系\"><a href=\"#2-5、软件架构和企业架构的关系\" class=\"headerlink\" title=\"2.5、软件架构和企业架构的关系\"></a>2.5、软件架构和企业架构的关系</h4><ol>\n<li>软件架构需要根据业务需求和性能要求等选择合适的技术，如编程语言、数据库系统、服务器架构等。不同的软件架构可能会采用不同的技术组合。</li>\n<li>企业架构中的技术架构同样要进行技术选型，包括选择企业整体的硬件平台、软件平台、网络设备等。软件架构所选用的具体技术是在企业架构的技术架构所设定的基础技术环境下进行的，要符合企业整体技术架构的要求，以确保技术资源在企业内的统一管理和有效利用。</li>\n</ol>\n<h3 id=\"三、软件架构的设计原则\"><a href=\"#三、软件架构的设计原则\" class=\"headerlink\" title=\"三、软件架构的设计原则\"></a>三、软件架构的设计原则</h3><p>设计原则是在软件设计过程中需要遵循的一些基本准则，它们旨在帮助开发者创建出更具可维护性、可扩展性、灵活性和可靠性的软件系统。常见的设计原则如下：</p>\n<h4 id=\"1、开闭原则（Open-Closed-Principle，OCP）\"><a href=\"#1、开闭原则（Open-Closed-Principle，OCP）\" class=\"headerlink\" title=\"1、开闭原则（Open-Closed Principle，OCP）\"></a>1、开闭原则（Open-Closed Principle，OCP）</h4><ol>\n<li>含义：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。即当有新的需求出现时，应通过添加新的代码来实现扩展，而非修改现有的代码。</li>\n<li>示例：如在一个图形绘制系统中，有抽象图形类，要添加新图形类型（如椭圆），可创建椭圆子类继承抽象图形类，无需修改抽象图形类代码，以此保证系统稳定性与可扩展性。</li>\n</ol>\n<h4 id=\"2、里氏替换原则（Liskov-Substitution-Principle，LSP）\"><a href=\"#2、里氏替换原则（Liskov-Substitution-Principle，LSP）\" class=\"headerlink\" title=\"2、里氏替换原则（Liskov Substitution Principle，LSP）\"></a>2、里氏替换原则（Liskov Substitution Principle，LSP）</h4><ol>\n<li>含义：所有引用基类的地方必须能透明地使用其子类的对象。也就是子类应该能够替换基类而不影响程序的正确性。</li>\n<li>示例：假设有函数接受基类类型参数，当传入子类对象时，函数应能正常工作且无意外结果。例如，动物类是基类，猫类是子类，有个函数是计算动物奔跑速度，当传入猫类对象时，应能正确计算出猫的奔跑速度。</li>\n</ol>\n<h4 id=\"3、依赖倒置原则（Dependence-Inversion-Principle，DIP）\"><a href=\"#3、依赖倒置原则（Dependence-Inversion-Principle，DIP）\" class=\"headerlink\" title=\"3、依赖倒置原则（Dependence Inversion Principle，DIP）\"></a>3、依赖倒置原则（Dependence Inversion Principle，DIP）</h4><ol>\n<li>含义：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。</li>\n<li>示例：在分层架构系统中，业务逻辑层（高层模块）不应直接依赖数据库访问层（低层模块），而是应依赖抽象的数据访问接口。这样当数据库访问方式改变时，只需修改实现接口的具体类，不影响业务逻辑层代码。</li>\n</ol>\n<h4 id=\"4、单一职责原则（Single-Responsibility-Principle，SRP）\"><a href=\"#4、单一职责原则（Single-Responsibility-Principle，SRP）\" class=\"headerlink\" title=\"4、单一职责原则（Single Responsibility Principle，SRP）\"></a>4、单一职责原则（Single Responsibility Principle，SRP）</h4><ol>\n<li>含义：一个类应该只有一个引起它变化的原因。即一个类应该只有一个职责，只负责一项功能。</li>\n<li>示例：用户管理类不应既负责用户创建、删除等操作，又负责用户权限管理。应将这两项职责分离到不同类中，以便当其中一个功能变化时，不影响另一个功能的代码。</li>\n</ol>\n<h4 id=\"5、接口隔离原则（Interface-Segregation-Principle，ISP）\"><a href=\"#5、接口隔离原则（Interface-Segregation-Principle，ISP）\" class=\"headerlink\" title=\"5、接口隔离原则（Interface Segregation Principle，ISP）\"></a>5、接口隔离原则（Interface Segregation Principle，ISP）</h4><ol>\n<li>含义：客户端不应该被迫依赖于它不使用的方法。一个类对另一个类的依赖应该建立在最小的接口上。</li>\n<li>示例：打印机接口若包含扫描、传真等方法，而只需要打印功能的客户端依赖此接口，就会被迫实现不需要的方法。应将接口细分，让客户端只依赖所需接口。</li>\n</ol>\n<h4 id=\"6、合成复用原则（Composite-Reuse-Principle，CRP）\"><a href=\"#6、合成复用原则（Composite-Reuse-Principle，CRP）\" class=\"headerlink\" title=\"6、合成复用原则（Composite Reuse Principle，CRP）\"></a>6、合成复用原则（Composite Reuse Principle，CRP）</h4><ol>\n<li>含义：尽量使用对象组合，而不是继承来达到复用的目的。继承会导致子类与父类的高度耦合，而对象组合可在运行时动态组合对象，更灵活。</li>\n<li>示例：在图形绘制系统中，要一个可同时绘制圆形和矩形的图形类，可通过组合圆形类和矩形类实现，而非创建继承自圆形类和矩形类的新类。这样添加新图形类型时，只需组合新图形类，不影响现有代码。</li>\n</ol>\n<h4 id=\"7、迪米特法则（Law-of-Demeter，LoD）\"><a href=\"#7、迪米特法则（Law-of-Demeter，LoD）\" class=\"headerlink\" title=\"7、迪米特法则（Law of Demeter，LoD）\"></a>7、迪米特法则（Law of Demeter，LoD）</h4><ol>\n<li>含义：也称为最少知识原则，一个对象应该对其他对象有尽可能少的了解。只与直接的朋友通信，避免与陌生人通信。</li>\n<li>示例：类 A 的方法若需调用类 B 的方法，应通过类 A 的直接关联对象来调用，而不是直接调用类 B 的方法。这样可降低类之间的耦合度，提高系统可维护性。</li>\n</ol>\n<h3 id=\"四、软件开发的设计模式\"><a href=\"#四、软件开发的设计模式\" class=\"headerlink\" title=\"四、软件开发的设计模式\"></a>四、软件开发的设计模式</h3><p>设计模式是在软件开发过程中，针对反复出现的设计问题所总结出的通用解决方案。它们是经过实践验证的、可复用的软件设计思路和结构，按照其功能和用途可大致分为以下几类：</p>\n<h4 id=\"4-1、创建模式\"><a href=\"#4-1、创建模式\" class=\"headerlink\" title=\"4.1、创建模式\"></a>4.1、创建模式</h4><p>创建型模式主要用于对象的创建过程，它们将对象的创建和使用分离，使得系统在创建对象时更加灵活和可维护。</p>\n<h5 id=\"单例模式\"><a href=\"#单例模式\" class=\"headerlink\" title=\"单例模式\"></a>单例模式</h5><p>保证一个类仅有一个实例，并提供一个全局访问点。常用于管理系统资源、配置信息等，如数据库连接池通常采用单例模式，确保只有一个数据库连接池实例存在，避免资源浪费和冲突。</p>\n<h5 id=\"工厂模式\"><a href=\"#工厂模式\" class=\"headerlink\" title=\"工厂模式\"></a>工厂模式</h5><p>提供了一种创建对象的方式，通过一个工厂类来负责创建对象，而不是在客户端代码中直接实例化对象。这样可以提高代码的灵活性和可维护性。例如，在一个汽车制造工厂里，有不同类型的汽车（如轿车、SUV 等），可以通过一个汽车工厂类来根据需求创建不同类型的汽车对象。</p>\n<h5 id=\"抽象工厂模式\"><a href=\"#抽象工厂模式\" class=\"headerlink\" title=\"抽象工厂模式\"></a>抽象工厂模式</h5><p>提供了创建一系列相关或相互依赖的对象的方式。与工厂模式相比，它更注重创建一组对象，而不是单个对象。比如在一个游戏开发中，需要创建不同场景下的一系列道具、角色等，就可以采用抽象工厂模式。</p>\n<h4 id=\"4-2、结构模式\"><a href=\"#4-2、结构模式\" class=\"headerlink\" title=\"4.2、结构模式\"></a>4.2、结构模式</h4><h5 id=\"代理模式\"><a href=\"#代理模式\" class=\"headerlink\" title=\"代理模式\"></a>代理模式</h5><p>通过代理对象来控制对真实对象的访问。例如，在网络访问中，当用户访问某些网站时，可能会通过代理服务器来进行访问，代理服务器可以对访问进行过滤、限制等操作。在软件设计中，代理模式可用于权限管理、性能优化等方面。</p>\n<h5 id=\"装饰者模式\"><a href=\"#装饰者模式\" class=\"headerlink\" title=\"装饰者模式\"></a>装饰者模式</h5><ul>\n<li><strong>意图：</strong> 动态地给一个对象添加额外的职责，同时不改变其结构。装饰器模式提供了一种灵活的替代继承方式来扩展功能。</li>\n<li><strong>主要解决的问题：</strong> 避免通过继承引入静态特征，特别是在子类数量急剧膨胀的情况下。允许在运行时动态地添加或修改对象的功能。</li>\n<li><strong>使用场景：</strong> 当需要在不增加大量子类的情况下扩展类的功能。当需要动态地添加或撤销对象的功能。</li>\n</ul>\n<p>动态地添加新的行为或功能到一个对象上，而不需要修改被装饰对象的原始代码。比如，一杯咖啡本身有价格和口味等属性，通过装饰者模式可以给咖啡添加奶油、糖等装饰，并且每添加一种装饰就会改变咖啡的价格和口味，而不需要修改咖啡本身的代码。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F.png\" alt=\"装饰者模式\"></p>\n<ul>\n<li>抽象组件(Component): 定义装饰方法的规范</li>\n<li>被装饰者(ConcreteComponent): Component的具体实现，也就是我们要装饰的具体对象。</li>\n<li>装饰者组件(Decorator): 持有组件(Component)对象的实例引用，该类的职责就是为了装饰具体组件对象，定义的规范。</li>\n<li>具体装饰(ConcreteDecorator): 负责给构件对象装饰附加的功能。</li>\n</ul>\n<style>\n.highlight.java {\n    height:400px;\n}\n</style>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 抽象组件：咖啡</span></span><br><span class=\"line\"><span class=\"keyword\">abstract</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Coffee</span> </span>&#123;</span><br><span class=\"line\">    String description = <span class=\"string\">\"未知咖啡\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getDescription</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> description;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体组件：普通咖啡</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SimpleCoffee</span> <span class=\"keyword\">extends</span> <span class=\"title\">Coffee</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">SimpleCoffee</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        description = <span class=\"string\">\"普通咖啡\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">5.0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 抽象装饰者：咖啡装饰者</span></span><br><span class=\"line\"><span class=\"keyword\">abstract</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CoffeeDecorator</span> <span class=\"keyword\">extends</span> <span class=\"title\">Coffee</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> Coffee coffee;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">CoffeeDecorator</span><span class=\"params\">(Coffee coffee)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.coffee = coffee;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getDescription</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.getDescription();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.cost();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体装饰者：奶油装饰</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CreamDecorator</span> <span class=\"keyword\">extends</span> <span class=\"title\">CoffeeDecorator</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">CreamDecorator</span><span class=\"params\">(Coffee coffee)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(coffee);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getDescription</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.getDescription() + <span class=\"string\">\", 加了奶油\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.cost() + <span class=\"number\">2.0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体装饰者：糖装饰</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SugarDecorator</span> <span class=\"keyword\">extends</span> <span class=\"title\">CoffeeDecorator</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">SugarDecorator</span><span class=\"params\">(Coffee coffee)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(coffee);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getDescription</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.getDescription() + <span class=\"string\">\", 加了糖\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.cost() + <span class=\"number\">1.0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 测试类</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CoffeeDecoratorTest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Coffee coffee = <span class=\"keyword\">new</span> SimpleCoffee();</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"原始咖啡：\"</span> + coffee.getDescription() + <span class=\"string\">\"，价格：\"</span> + coffee.cost());</span><br><span class=\"line\">        coffee = <span class=\"keyword\">new</span> CreamDecorator(coffee);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"加了奶油后的咖啡：\"</span> + coffee.getDescription() + <span class=\"string\">\"，价格：\"</span> + coffee.cost());</span><br><span class=\"line\">        coffee = <span class=\"keyword\">new</span> SugarDecorator(coffee);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"再加了糖后的咖啡：\"</span> + coffee.getDescription() + <span class=\"string\">\"，价格：\"</span> + coffee.cost());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"桥接模式\"><a href=\"#桥接模式\" class=\"headerlink\" title=\"桥接模式\"></a>桥接模式</h5><ul>\n<li><strong>意图：</strong> 将抽象部分与它的实现部分分离，使得它们可以独立变化。例如，在图形绘制系统中，形状是抽象部分，颜色是实现部分，通过桥接模式可以让形状和颜色独立变化，即可以选择不同的形状搭配不同的颜色，而不会相互影响。</li>\n<li><strong>主要解决的问题：</strong> 避免使用继承导致的类爆炸问题，提供更灵活的扩展方式。</li>\n<li><strong>使用场景：</strong> 当系统可能从多个角度进行分类，且每个角度都可能独立变化时，桥接模式是合适的。例如JDBC驱动程序。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 颜色接口</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Color</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">applyColor</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体颜色实现类：红色</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RedColor</span> <span class=\"keyword\">implements</span> <span class=\"title\">Color</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">applyColor</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Applying red color\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体颜色实现类：蓝色</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BlueColor</span> <span class=\"keyword\">implements</span> <span class=\"title\">Color</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">applyColor</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Applying blue color\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 形状抽象类，包含对颜色的引用（桥接部分）</span></span><br><span class=\"line\"><span class=\"keyword\">abstract</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Shape</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> Color color;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Shape</span><span class=\"params\">(Color color)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.color = color;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">abstract</span> <span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体形状类：圆形</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Circle</span> <span class=\"keyword\">extends</span> <span class=\"title\">Shape</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Circle</span><span class=\"params\">(Color color)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(color);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.print(<span class=\"string\">\"Drawing a circle. \"</span>);</span><br><span class=\"line\">        color.applyColor();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体形状类：矩形</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Rectangle</span> <span class=\"keyword\">extends</span> <span class=\"title\">Shape</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Rectangle</span><span class=\"params\">(Color color)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(color);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.print(<span class=\"string\">\"Drawing a rectangle. \"</span>);</span><br><span class=\"line\">        color.applyColor();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BridgePatternExample</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 使用红色绘制圆形</span></span><br><span class=\"line\">        Shape circleWithRed = <span class=\"keyword\">new</span> Circle(<span class=\"keyword\">new</span> RedColor());</span><br><span class=\"line\">        circleWithRed.draw();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 使用蓝色绘制矩形</span></span><br><span class=\"line\">        Shape rectangleWithBlue = <span class=\"keyword\">new</span> Rectangle(<span class=\"keyword\">new</span> BlueColor());</span><br><span class=\"line\">        rectangleWithBlue.draw();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"装饰模式和桥接模式\"><a href=\"#装饰模式和桥接模式\" class=\"headerlink\" title=\"装饰模式和桥接模式\"></a>装饰模式和桥接模式</h5><h6 id=\"不同点\"><a href=\"#不同点\" class=\"headerlink\" title=\"不同点\"></a>不同点</h6><ol>\n<li>设计意图：<ol>\n<li>装饰模式：重点在于动态地添加功能。它是一种 “增强” 对象功能的方式，在运行时可以根据需要灵活地组合装饰器来为对象添加不同的功能。装饰器和被装饰对象通常属于同一个层次结构，<strong>都实现相同的接口或者继承相同的抽象类</strong>。</li>\n<li>桥接模式：更侧重于将抽象和实现解耦，使它们可以独立地演变。抽象部分和实现部分通常<strong>属于不同的层次结构</strong>，它们通过一个抽象的关联（桥）来进行合作。</li>\n</ol>\n</li>\n<li>使用场景：<ol>\n<li>装饰模式：适用于在不改变对象基本结构的情况下，动态地添加或修改对象的功能。</li>\n<li>桥接模式：适合用于当一个类存在两个独立变化的维度，且这两个维度需要灵活组合的时候。</li>\n</ol>\n</li>\n</ol>\n<h4 id=\"4-3、行为模式\"><a href=\"#4-3、行为模式\" class=\"headerlink\" title=\"4.3、行为模式\"></a>4.3、行为模式</h4><h5 id=\"观察者模式\"><a href=\"#观察者模式\" class=\"headerlink\" title=\"观察者模式\"></a>观察者模式</h5><ul>\n<li><strong>意图</strong>： 创建了对象间的一种一对多的依赖关系，当一个对象状态改变时，所有依赖于它的对象都会得到通知并自动更新。</li>\n<li><strong>主要解决的问题</strong>： 观察者模式解决的是一个对象状态改变时，如何自动通知其他依赖对象的问题，同时保持对象间的低耦合和高协作性。</li>\n<li><strong>使用场景</strong>： 当一个对象的状态变化需要同时更新其他对象时。</li>\n</ul>\n<p><img src=\"/2024/08/20/2024-08-20-架构-架构/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F.png\" alt=\"观察者模式\"><br>观察者模式使用2个类</p>\n<ul>\n<li>Subject：主题，提供了addObserver(), deleteObserver(), notifyObservers()等方法</li>\n<li>Observer：观察者，用于接收主题发送的通知并更新自身状态。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//主题</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Subject</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">addObserver</span><span class=\"params\">(Observer observer)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">removeObserver</span><span class=\"params\">(Observer observer)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">notifyObservers</span><span class=\"params\">(String message)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NewsAgency</span> <span class=\"keyword\">implements</span> <span class=\"title\">Subject</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> List&lt;Observer&gt; observers = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">addObserver</span><span class=\"params\">(Observer observer)</span> </span>&#123;</span><br><span class=\"line\">        observers.add(observer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">removeObserver</span><span class=\"params\">(Observer observer)</span> </span>&#123;</span><br><span class=\"line\">        observers.remove(observer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">notifyObservers</span><span class=\"params\">(String message)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (Observer observer : observers) &#123;</span><br><span class=\"line\">            observer.update(message);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">publishNews</span><span class=\"params\">(String news)</span> </span>&#123;</span><br><span class=\"line\">        notifyObservers(news);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//观察者</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Observer</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">update</span><span class=\"params\">(String message)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NewsSubscriber</span> <span class=\"keyword\">implements</span> <span class=\"title\">Observer</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String name;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">NewsSubscriber</span><span class=\"params\">(String name)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.name = name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">update</span><span class=\"params\">(String message)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(name + <span class=\"string\">\" received news: \"</span> + message);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ObserverPatternExample</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//定义主题</span></span><br><span class=\"line\">        NewsAgency newsAgency = <span class=\"keyword\">new</span> NewsAgency();</span><br><span class=\"line\">        <span class=\"comment\">//创建订阅者</span></span><br><span class=\"line\">        NewsSubscriber subscriber1 = <span class=\"keyword\">new</span> NewsSubscriber(<span class=\"string\">\"Alice\"</span>);</span><br><span class=\"line\">        NewsSubscriber subscriber2 = <span class=\"keyword\">new</span> NewsSubscriber(<span class=\"string\">\"Bob\"</span>);</span><br><span class=\"line\">        newsAgency.addObserver(subscriber1);</span><br><span class=\"line\">        newsAgency.addObserver(subscriber2);</span><br><span class=\"line\">        newsAgency.publishNews(<span class=\"string\">\"Breaking news: A new discovery!\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"策略模式\"><a href=\"#策略模式\" class=\"headerlink\" title=\"策略模式\"></a>策略模式</h5><p>定义了一系列的策略，并且让用户可以根据需要选择不同的策略来执行某项任务。例如，在一个出行应用中，用户可以选择不同的出行策略，如打车、公交、地铁等，每种策略都有不同的费用计算方法和行程安排。</p>\n<h5 id=\"命令模式\"><a href=\"#命令模式\" class=\"headerlink\" title=\"命令模式\"></a>命令模式</h5><p>将一个请求封装成一个命令对象，这样可以把请求的发出者和执行者分离，便于管理和控制。比如，在一个餐厅里，顾客点菜的请求可以被封装成命令对象，然后由厨师来执行这些命令，这样可以使点菜过程更加有序和可控。</p>\n<p>参考文章：<br><a href=\"https://mp.weixin.qq.com/s/YBwEqvo1j0-tYzI6NV58sw\" target=\"_blank\" rel=\"noopener\">一文搞懂业务架构、应用架构、技术架构、数据架构！</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、什么是架构？\"><a href=\"#一、什么是架构？\" class=\"headerlink\" title=\"一、什么是架构？\"></a>一、什么是架构？</h3><p>在软件开发领域，架构可以从2方面进行总结，结构设计和技术选型：</p>\n<ul>\n<li>结构设计：模块划分、层次结构和交互方式，能够让人清晰的了解系统的整体架构。例如，一个电商系统可能分为用户界面层、业务逻辑层和数据存储层，各层之间通过明确的接口进行通信。</li>\n<li>技术选型：根据项目的需求和特点，选择合适的技术栈。比如，对于高并发的系统，可能会选择分布式架构和高性能的数据库。</li>\n</ul>","more":"<p>上面的这种理解过于理论化，不是很好理解。通常来说，从架构层面大致可以分为：系统架构和应用架构。</p>\n<ul>\n<li>系统架构：所谓的系统架构，包含硬件架构、软件架构、数据架构、网络架构。<ul>\n<li>硬件架构：包括服务器、存储设备、网络设备等硬件的选型、配置和连接方式。</li>\n<li>软件架构：主要涉及软件系统的分层、模块划分和接口设计。</li>\n<li>数据架构：侧重于数据的组织、存储和管理方式。包括数据库的设计</li>\n<li>网络架构：描述系统中各个组件之间的网络连接方式，包括网络拓扑结构。例如分布式微服务架构。</li>\n</ul>\n</li>\n<li>应用架构：应用架构是系统架构的一个子集，它主要关注软件应用系统本身的架构设计。具体来说，它描述了一个应用程序从用户界面到数据存储的整个软件结构，包括应用程序的各个功能模块如何划分、这些模块之间如何交互以及它们如何与外部系统（如其他应用程序、数据库、服务等）进行协作。<ul>\n<li>代码架构：三层架构、MVC架构。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"二、什么是企业架构？\"><a href=\"#二、什么是企业架构？\" class=\"headerlink\" title=\"二、什么是企业架构？\"></a>二、什么是企业架构？</h3><p>企业架构是对企业的业务流程、信息系统、技术基础架构以及人员组织等多方面进行整体规划和设计的一种方法和理念。</p>\n<p>企业架构可以分为两大部分：业务架构和IT架构，大部分企业架构方法都是从IT架构发展而来的。</p>\n<ul>\n<li>业务架构：是把企业的业务战略转化为日常运作的渠道，业务战略决定业务架构，它包括业务的运营模式、流程体系、组织结构、地域分布等内容</li>\n<li>IT架构：指导IT投资和设计决策的IT框架，是建立企业信息系统的综合蓝图，包括数据架构、应用架构和技术架构三部分。</li>\n</ul>\n<h4 id=\"2-1、业务架构\"><a href=\"#2-1、业务架构\" class=\"headerlink\" title=\"2.1、业务架构\"></a>2.1、业务架构</h4><p>定义企业的业务战略、业务目标、业务流程和业务组织。它明确了企业的核心业务活动、业务之间的关系以及业务流程的流转。<br>通过业务架构的设计，可以帮助企业更好地理解自身的业务模式，优化业务流程，提高业务效率和竞争力。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E4%B8%9A%E5%8A%A1%E6%9E%B6%E6%9E%84.png\" alt=\"业务架构\"></p>\n<h4 id=\"2-2、应用架构\"><a href=\"#2-2、应用架构\" class=\"headerlink\" title=\"2.2、应用架构\"></a>2.2、应用架构</h4><p>描述企业的应用系统组合，包括各个应用系统的功能、相互之间的集成关系以及与业务流程的对应关系，完成从业务到IT的转换。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84.png\" alt=\"应用架构\"></p>\n<h4 id=\"2-3、技术架构\"><a href=\"#2-3、技术架构\" class=\"headerlink\" title=\"2.3、技术架构\"></a>2.3、技术架构</h4><p>涉及企业的技术基础设施，包括硬件、软件、网络、安全等方面。它确定了企业所采用的技术标准、技术平台和技术选型。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84.png\" alt=\"技术架构\"></p>\n<h4 id=\"2-4、数据架构\"><a href=\"#2-4、数据架构\" class=\"headerlink\" title=\"2.4、数据架构\"></a>2.4、数据架构</h4><p>规划企业的数据资源，包括数据的存储、管理、使用和共享。它确定了企业的数据模型、数据标准、数据质量要求以及数据治理策略。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84.png\" alt=\"数据架构\"></p>\n<h4 id=\"2-5、软件架构和企业架构的关系\"><a href=\"#2-5、软件架构和企业架构的关系\" class=\"headerlink\" title=\"2.5、软件架构和企业架构的关系\"></a>2.5、软件架构和企业架构的关系</h4><ol>\n<li>软件架构需要根据业务需求和性能要求等选择合适的技术，如编程语言、数据库系统、服务器架构等。不同的软件架构可能会采用不同的技术组合。</li>\n<li>企业架构中的技术架构同样要进行技术选型，包括选择企业整体的硬件平台、软件平台、网络设备等。软件架构所选用的具体技术是在企业架构的技术架构所设定的基础技术环境下进行的，要符合企业整体技术架构的要求，以确保技术资源在企业内的统一管理和有效利用。</li>\n</ol>\n<h3 id=\"三、软件架构的设计原则\"><a href=\"#三、软件架构的设计原则\" class=\"headerlink\" title=\"三、软件架构的设计原则\"></a>三、软件架构的设计原则</h3><p>设计原则是在软件设计过程中需要遵循的一些基本准则，它们旨在帮助开发者创建出更具可维护性、可扩展性、灵活性和可靠性的软件系统。常见的设计原则如下：</p>\n<h4 id=\"1、开闭原则（Open-Closed-Principle，OCP）\"><a href=\"#1、开闭原则（Open-Closed-Principle，OCP）\" class=\"headerlink\" title=\"1、开闭原则（Open-Closed Principle，OCP）\"></a>1、开闭原则（Open-Closed Principle，OCP）</h4><ol>\n<li>含义：软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。即当有新的需求出现时，应通过添加新的代码来实现扩展，而非修改现有的代码。</li>\n<li>示例：如在一个图形绘制系统中，有抽象图形类，要添加新图形类型（如椭圆），可创建椭圆子类继承抽象图形类，无需修改抽象图形类代码，以此保证系统稳定性与可扩展性。</li>\n</ol>\n<h4 id=\"2、里氏替换原则（Liskov-Substitution-Principle，LSP）\"><a href=\"#2、里氏替换原则（Liskov-Substitution-Principle，LSP）\" class=\"headerlink\" title=\"2、里氏替换原则（Liskov Substitution Principle，LSP）\"></a>2、里氏替换原则（Liskov Substitution Principle，LSP）</h4><ol>\n<li>含义：所有引用基类的地方必须能透明地使用其子类的对象。也就是子类应该能够替换基类而不影响程序的正确性。</li>\n<li>示例：假设有函数接受基类类型参数，当传入子类对象时，函数应能正常工作且无意外结果。例如，动物类是基类，猫类是子类，有个函数是计算动物奔跑速度，当传入猫类对象时，应能正确计算出猫的奔跑速度。</li>\n</ol>\n<h4 id=\"3、依赖倒置原则（Dependence-Inversion-Principle，DIP）\"><a href=\"#3、依赖倒置原则（Dependence-Inversion-Principle，DIP）\" class=\"headerlink\" title=\"3、依赖倒置原则（Dependence Inversion Principle，DIP）\"></a>3、依赖倒置原则（Dependence Inversion Principle，DIP）</h4><ol>\n<li>含义：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。</li>\n<li>示例：在分层架构系统中，业务逻辑层（高层模块）不应直接依赖数据库访问层（低层模块），而是应依赖抽象的数据访问接口。这样当数据库访问方式改变时，只需修改实现接口的具体类，不影响业务逻辑层代码。</li>\n</ol>\n<h4 id=\"4、单一职责原则（Single-Responsibility-Principle，SRP）\"><a href=\"#4、单一职责原则（Single-Responsibility-Principle，SRP）\" class=\"headerlink\" title=\"4、单一职责原则（Single Responsibility Principle，SRP）\"></a>4、单一职责原则（Single Responsibility Principle，SRP）</h4><ol>\n<li>含义：一个类应该只有一个引起它变化的原因。即一个类应该只有一个职责，只负责一项功能。</li>\n<li>示例：用户管理类不应既负责用户创建、删除等操作，又负责用户权限管理。应将这两项职责分离到不同类中，以便当其中一个功能变化时，不影响另一个功能的代码。</li>\n</ol>\n<h4 id=\"5、接口隔离原则（Interface-Segregation-Principle，ISP）\"><a href=\"#5、接口隔离原则（Interface-Segregation-Principle，ISP）\" class=\"headerlink\" title=\"5、接口隔离原则（Interface Segregation Principle，ISP）\"></a>5、接口隔离原则（Interface Segregation Principle，ISP）</h4><ol>\n<li>含义：客户端不应该被迫依赖于它不使用的方法。一个类对另一个类的依赖应该建立在最小的接口上。</li>\n<li>示例：打印机接口若包含扫描、传真等方法，而只需要打印功能的客户端依赖此接口，就会被迫实现不需要的方法。应将接口细分，让客户端只依赖所需接口。</li>\n</ol>\n<h4 id=\"6、合成复用原则（Composite-Reuse-Principle，CRP）\"><a href=\"#6、合成复用原则（Composite-Reuse-Principle，CRP）\" class=\"headerlink\" title=\"6、合成复用原则（Composite Reuse Principle，CRP）\"></a>6、合成复用原则（Composite Reuse Principle，CRP）</h4><ol>\n<li>含义：尽量使用对象组合，而不是继承来达到复用的目的。继承会导致子类与父类的高度耦合，而对象组合可在运行时动态组合对象，更灵活。</li>\n<li>示例：在图形绘制系统中，要一个可同时绘制圆形和矩形的图形类，可通过组合圆形类和矩形类实现，而非创建继承自圆形类和矩形类的新类。这样添加新图形类型时，只需组合新图形类，不影响现有代码。</li>\n</ol>\n<h4 id=\"7、迪米特法则（Law-of-Demeter，LoD）\"><a href=\"#7、迪米特法则（Law-of-Demeter，LoD）\" class=\"headerlink\" title=\"7、迪米特法则（Law of Demeter，LoD）\"></a>7、迪米特法则（Law of Demeter，LoD）</h4><ol>\n<li>含义：也称为最少知识原则，一个对象应该对其他对象有尽可能少的了解。只与直接的朋友通信，避免与陌生人通信。</li>\n<li>示例：类 A 的方法若需调用类 B 的方法，应通过类 A 的直接关联对象来调用，而不是直接调用类 B 的方法。这样可降低类之间的耦合度，提高系统可维护性。</li>\n</ol>\n<h3 id=\"四、软件开发的设计模式\"><a href=\"#四、软件开发的设计模式\" class=\"headerlink\" title=\"四、软件开发的设计模式\"></a>四、软件开发的设计模式</h3><p>设计模式是在软件开发过程中，针对反复出现的设计问题所总结出的通用解决方案。它们是经过实践验证的、可复用的软件设计思路和结构，按照其功能和用途可大致分为以下几类：</p>\n<h4 id=\"4-1、创建模式\"><a href=\"#4-1、创建模式\" class=\"headerlink\" title=\"4.1、创建模式\"></a>4.1、创建模式</h4><p>创建型模式主要用于对象的创建过程，它们将对象的创建和使用分离，使得系统在创建对象时更加灵活和可维护。</p>\n<h5 id=\"单例模式\"><a href=\"#单例模式\" class=\"headerlink\" title=\"单例模式\"></a>单例模式</h5><p>保证一个类仅有一个实例，并提供一个全局访问点。常用于管理系统资源、配置信息等，如数据库连接池通常采用单例模式，确保只有一个数据库连接池实例存在，避免资源浪费和冲突。</p>\n<h5 id=\"工厂模式\"><a href=\"#工厂模式\" class=\"headerlink\" title=\"工厂模式\"></a>工厂模式</h5><p>提供了一种创建对象的方式，通过一个工厂类来负责创建对象，而不是在客户端代码中直接实例化对象。这样可以提高代码的灵活性和可维护性。例如，在一个汽车制造工厂里，有不同类型的汽车（如轿车、SUV 等），可以通过一个汽车工厂类来根据需求创建不同类型的汽车对象。</p>\n<h5 id=\"抽象工厂模式\"><a href=\"#抽象工厂模式\" class=\"headerlink\" title=\"抽象工厂模式\"></a>抽象工厂模式</h5><p>提供了创建一系列相关或相互依赖的对象的方式。与工厂模式相比，它更注重创建一组对象，而不是单个对象。比如在一个游戏开发中，需要创建不同场景下的一系列道具、角色等，就可以采用抽象工厂模式。</p>\n<h4 id=\"4-2、结构模式\"><a href=\"#4-2、结构模式\" class=\"headerlink\" title=\"4.2、结构模式\"></a>4.2、结构模式</h4><h5 id=\"代理模式\"><a href=\"#代理模式\" class=\"headerlink\" title=\"代理模式\"></a>代理模式</h5><p>通过代理对象来控制对真实对象的访问。例如，在网络访问中，当用户访问某些网站时，可能会通过代理服务器来进行访问，代理服务器可以对访问进行过滤、限制等操作。在软件设计中，代理模式可用于权限管理、性能优化等方面。</p>\n<h5 id=\"装饰者模式\"><a href=\"#装饰者模式\" class=\"headerlink\" title=\"装饰者模式\"></a>装饰者模式</h5><ul>\n<li><strong>意图：</strong> 动态地给一个对象添加额外的职责，同时不改变其结构。装饰器模式提供了一种灵活的替代继承方式来扩展功能。</li>\n<li><strong>主要解决的问题：</strong> 避免通过继承引入静态特征，特别是在子类数量急剧膨胀的情况下。允许在运行时动态地添加或修改对象的功能。</li>\n<li><strong>使用场景：</strong> 当需要在不增加大量子类的情况下扩展类的功能。当需要动态地添加或撤销对象的功能。</li>\n</ul>\n<p>动态地添加新的行为或功能到一个对象上，而不需要修改被装饰对象的原始代码。比如，一杯咖啡本身有价格和口味等属性，通过装饰者模式可以给咖啡添加奶油、糖等装饰，并且每添加一种装饰就会改变咖啡的价格和口味，而不需要修改咖啡本身的代码。<br><img src=\"/2024/08/20/2024-08-20-架构-架构/%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F.png\" alt=\"装饰者模式\"></p>\n<ul>\n<li>抽象组件(Component): 定义装饰方法的规范</li>\n<li>被装饰者(ConcreteComponent): Component的具体实现，也就是我们要装饰的具体对象。</li>\n<li>装饰者组件(Decorator): 持有组件(Component)对象的实例引用，该类的职责就是为了装饰具体组件对象，定义的规范。</li>\n<li>具体装饰(ConcreteDecorator): 负责给构件对象装饰附加的功能。</li>\n</ul>\n<style>\n.highlight.java {\n    height:400px;\n}\n</style>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 抽象组件：咖啡</span></span><br><span class=\"line\"><span class=\"keyword\">abstract</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Coffee</span> </span>&#123;</span><br><span class=\"line\">    String description = <span class=\"string\">\"未知咖啡\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getDescription</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> description;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体组件：普通咖啡</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SimpleCoffee</span> <span class=\"keyword\">extends</span> <span class=\"title\">Coffee</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">SimpleCoffee</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        description = <span class=\"string\">\"普通咖啡\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">5.0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 抽象装饰者：咖啡装饰者</span></span><br><span class=\"line\"><span class=\"keyword\">abstract</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CoffeeDecorator</span> <span class=\"keyword\">extends</span> <span class=\"title\">Coffee</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> Coffee coffee;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">CoffeeDecorator</span><span class=\"params\">(Coffee coffee)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.coffee = coffee;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getDescription</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.getDescription();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.cost();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体装饰者：奶油装饰</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CreamDecorator</span> <span class=\"keyword\">extends</span> <span class=\"title\">CoffeeDecorator</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">CreamDecorator</span><span class=\"params\">(Coffee coffee)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(coffee);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getDescription</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.getDescription() + <span class=\"string\">\", 加了奶油\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.cost() + <span class=\"number\">2.0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体装饰者：糖装饰</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SugarDecorator</span> <span class=\"keyword\">extends</span> <span class=\"title\">CoffeeDecorator</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">SugarDecorator</span><span class=\"params\">(Coffee coffee)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(coffee);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getDescription</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.getDescription() + <span class=\"string\">\", 加了糖\"</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">double</span> <span class=\"title\">cost</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> coffee.cost() + <span class=\"number\">1.0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 测试类</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CoffeeDecoratorTest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Coffee coffee = <span class=\"keyword\">new</span> SimpleCoffee();</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"原始咖啡：\"</span> + coffee.getDescription() + <span class=\"string\">\"，价格：\"</span> + coffee.cost());</span><br><span class=\"line\">        coffee = <span class=\"keyword\">new</span> CreamDecorator(coffee);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"加了奶油后的咖啡：\"</span> + coffee.getDescription() + <span class=\"string\">\"，价格：\"</span> + coffee.cost());</span><br><span class=\"line\">        coffee = <span class=\"keyword\">new</span> SugarDecorator(coffee);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"再加了糖后的咖啡：\"</span> + coffee.getDescription() + <span class=\"string\">\"，价格：\"</span> + coffee.cost());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"桥接模式\"><a href=\"#桥接模式\" class=\"headerlink\" title=\"桥接模式\"></a>桥接模式</h5><ul>\n<li><strong>意图：</strong> 将抽象部分与它的实现部分分离，使得它们可以独立变化。例如，在图形绘制系统中，形状是抽象部分，颜色是实现部分，通过桥接模式可以让形状和颜色独立变化，即可以选择不同的形状搭配不同的颜色，而不会相互影响。</li>\n<li><strong>主要解决的问题：</strong> 避免使用继承导致的类爆炸问题，提供更灵活的扩展方式。</li>\n<li><strong>使用场景：</strong> 当系统可能从多个角度进行分类，且每个角度都可能独立变化时，桥接模式是合适的。例如JDBC驱动程序。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 颜色接口</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Color</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">applyColor</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体颜色实现类：红色</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RedColor</span> <span class=\"keyword\">implements</span> <span class=\"title\">Color</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">applyColor</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Applying red color\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体颜色实现类：蓝色</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BlueColor</span> <span class=\"keyword\">implements</span> <span class=\"title\">Color</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">applyColor</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Applying blue color\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 形状抽象类，包含对颜色的引用（桥接部分）</span></span><br><span class=\"line\"><span class=\"keyword\">abstract</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Shape</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> Color color;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Shape</span><span class=\"params\">(Color color)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.color = color;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">abstract</span> <span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体形状类：圆形</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Circle</span> <span class=\"keyword\">extends</span> <span class=\"title\">Shape</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Circle</span><span class=\"params\">(Color color)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(color);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.print(<span class=\"string\">\"Drawing a circle. \"</span>);</span><br><span class=\"line\">        color.applyColor();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体形状类：矩形</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Rectangle</span> <span class=\"keyword\">extends</span> <span class=\"title\">Shape</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Rectangle</span><span class=\"params\">(Color color)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(color);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.print(<span class=\"string\">\"Drawing a rectangle. \"</span>);</span><br><span class=\"line\">        color.applyColor();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BridgePatternExample</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 使用红色绘制圆形</span></span><br><span class=\"line\">        Shape circleWithRed = <span class=\"keyword\">new</span> Circle(<span class=\"keyword\">new</span> RedColor());</span><br><span class=\"line\">        circleWithRed.draw();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 使用蓝色绘制矩形</span></span><br><span class=\"line\">        Shape rectangleWithBlue = <span class=\"keyword\">new</span> Rectangle(<span class=\"keyword\">new</span> BlueColor());</span><br><span class=\"line\">        rectangleWithBlue.draw();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"装饰模式和桥接模式\"><a href=\"#装饰模式和桥接模式\" class=\"headerlink\" title=\"装饰模式和桥接模式\"></a>装饰模式和桥接模式</h5><h6 id=\"不同点\"><a href=\"#不同点\" class=\"headerlink\" title=\"不同点\"></a>不同点</h6><ol>\n<li>设计意图：<ol>\n<li>装饰模式：重点在于动态地添加功能。它是一种 “增强” 对象功能的方式，在运行时可以根据需要灵活地组合装饰器来为对象添加不同的功能。装饰器和被装饰对象通常属于同一个层次结构，<strong>都实现相同的接口或者继承相同的抽象类</strong>。</li>\n<li>桥接模式：更侧重于将抽象和实现解耦，使它们可以独立地演变。抽象部分和实现部分通常<strong>属于不同的层次结构</strong>，它们通过一个抽象的关联（桥）来进行合作。</li>\n</ol>\n</li>\n<li>使用场景：<ol>\n<li>装饰模式：适用于在不改变对象基本结构的情况下，动态地添加或修改对象的功能。</li>\n<li>桥接模式：适合用于当一个类存在两个独立变化的维度，且这两个维度需要灵活组合的时候。</li>\n</ol>\n</li>\n</ol>\n<h4 id=\"4-3、行为模式\"><a href=\"#4-3、行为模式\" class=\"headerlink\" title=\"4.3、行为模式\"></a>4.3、行为模式</h4><h5 id=\"观察者模式\"><a href=\"#观察者模式\" class=\"headerlink\" title=\"观察者模式\"></a>观察者模式</h5><ul>\n<li><strong>意图</strong>： 创建了对象间的一种一对多的依赖关系，当一个对象状态改变时，所有依赖于它的对象都会得到通知并自动更新。</li>\n<li><strong>主要解决的问题</strong>： 观察者模式解决的是一个对象状态改变时，如何自动通知其他依赖对象的问题，同时保持对象间的低耦合和高协作性。</li>\n<li><strong>使用场景</strong>： 当一个对象的状态变化需要同时更新其他对象时。</li>\n</ul>\n<p><img src=\"/2024/08/20/2024-08-20-架构-架构/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F.png\" alt=\"观察者模式\"><br>观察者模式使用2个类</p>\n<ul>\n<li>Subject：主题，提供了addObserver(), deleteObserver(), notifyObservers()等方法</li>\n<li>Observer：观察者，用于接收主题发送的通知并更新自身状态。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//主题</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Subject</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">addObserver</span><span class=\"params\">(Observer observer)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">removeObserver</span><span class=\"params\">(Observer observer)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">notifyObservers</span><span class=\"params\">(String message)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NewsAgency</span> <span class=\"keyword\">implements</span> <span class=\"title\">Subject</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> List&lt;Observer&gt; observers = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">addObserver</span><span class=\"params\">(Observer observer)</span> </span>&#123;</span><br><span class=\"line\">        observers.add(observer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">removeObserver</span><span class=\"params\">(Observer observer)</span> </span>&#123;</span><br><span class=\"line\">        observers.remove(observer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">notifyObservers</span><span class=\"params\">(String message)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (Observer observer : observers) &#123;</span><br><span class=\"line\">            observer.update(message);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">publishNews</span><span class=\"params\">(String news)</span> </span>&#123;</span><br><span class=\"line\">        notifyObservers(news);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//观察者</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Observer</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">update</span><span class=\"params\">(String message)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NewsSubscriber</span> <span class=\"keyword\">implements</span> <span class=\"title\">Observer</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String name;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">NewsSubscriber</span><span class=\"params\">(String name)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.name = name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">update</span><span class=\"params\">(String message)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(name + <span class=\"string\">\" received news: \"</span> + message);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ObserverPatternExample</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//定义主题</span></span><br><span class=\"line\">        NewsAgency newsAgency = <span class=\"keyword\">new</span> NewsAgency();</span><br><span class=\"line\">        <span class=\"comment\">//创建订阅者</span></span><br><span class=\"line\">        NewsSubscriber subscriber1 = <span class=\"keyword\">new</span> NewsSubscriber(<span class=\"string\">\"Alice\"</span>);</span><br><span class=\"line\">        NewsSubscriber subscriber2 = <span class=\"keyword\">new</span> NewsSubscriber(<span class=\"string\">\"Bob\"</span>);</span><br><span class=\"line\">        newsAgency.addObserver(subscriber1);</span><br><span class=\"line\">        newsAgency.addObserver(subscriber2);</span><br><span class=\"line\">        newsAgency.publishNews(<span class=\"string\">\"Breaking news: A new discovery!\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"策略模式\"><a href=\"#策略模式\" class=\"headerlink\" title=\"策略模式\"></a>策略模式</h5><p>定义了一系列的策略，并且让用户可以根据需要选择不同的策略来执行某项任务。例如，在一个出行应用中，用户可以选择不同的出行策略，如打车、公交、地铁等，每种策略都有不同的费用计算方法和行程安排。</p>\n<h5 id=\"命令模式\"><a href=\"#命令模式\" class=\"headerlink\" title=\"命令模式\"></a>命令模式</h5><p>将一个请求封装成一个命令对象，这样可以把请求的发出者和执行者分离，便于管理和控制。比如，在一个餐厅里，顾客点菜的请求可以被封装成命令对象，然后由厨师来执行这些命令，这样可以使点菜过程更加有序和可控。</p>\n<p>参考文章：<br><a href=\"https://mp.weixin.qq.com/s/YBwEqvo1j0-tYzI6NV58sw\" target=\"_blank\" rel=\"noopener\">一文搞懂业务架构、应用架构、技术架构、数据架构！</a></p>"},{"title":"《系统重构》系统重构&合并总结","date":"2024-08-02T02:00:00.000Z","_content":"\n    这是系统重构系列的总结性文章，总结系统重构的一般流程和经验。\n\n### 一、愿景\n整个开发生涯中，经历了非常多的系统重构、系统合并，也总结了一些经验，记录下来。\n<!-- more -->\n### 二、项目管理流程\n较大型的项目，都会经历如图步骤：\n![项目管理流程](2024-08-02-系统重构-系统重构和合并总结/项目管理流程.png)\n本文主要讲解分析设计过程部分。\n### 三、常见问题及解决方案\n\n#### 3.1、数据一致性问题：\n数据一致性，需要特别关注。可以分为存量数据一致性、增量数据一致性问题和数据一致性保障方案。\n##### 3.1.1、存量数据一致性：\n![数据一致性_存量](2024-08-02-系统重构-系统重构和合并总结/数据一致性_存量.png)\n1. 离线方式：\n   1. 通过全量表+日增表，但是离线表一般是T+1（最快也是小时表），存在数据延迟问题，适用于数据变更频率低场景。\n2. binlog方式：\n   1. 延迟低，可靠性高。\n\n##### 3.1.2、增量数据一致性：\n![数据一致性_增量](2024-08-02-系统重构-系统重构和合并总结/数据一致性_增量.png)\n增量数据，一般是通过接口双写的方式，来保障数据一致性，同时还会通过binlog作为冗余方式，保障高可用。\n\n##### 3.1.3、使用离线表方式，先开双写还是先存量同步？\n如果不得不使用离线表的方式进行数据迁移，应该怎么做？考虑先开双写还是先迁移存量数据？\n###### 先开双写（灰度完成后），再做存量同步\n主要流程：先开双写（灰度完成后），再做一次完整的存量同步操作。\n![先双写后存量](2024-08-02-系统重构-系统重构和合并总结/先双写后存量.png)\n![双写先](2024-08-02-系统重构-系统重构和合并总结/双写先.png)\n1. 存量数据更新时，新库不存在数据，需要回查，性能会有影响。\n   1. 解决办法：前期已旧库为准，新库可以采用异步+稳定性方案，降低影响。\n2. 大批量数据更新，查询旧库，会造成旧库资源的冲击并影响现有业务。\n   1. 解决办法：可以结合灰度计划，控制流量，减少对现有业务的影响。\n\n###### 先存量同步，再开双写\n![先存量后增量](2024-08-02-系统重构-系统重构和合并总结/先存量后增量.png)\n> - 2个任务：\n>   - 存量数据同步：执行一次。\n>   - 增量数据同步：每日执行，直至全部灰度完成，并没有数据差异。\n> - 灰度数据，新库不存在或被更新，需要查询旧库，再做更新。\n> - \n\n###### ⭐️方案对比\n> 先双写，后存量同步：\n> - 方案更简单。\n> \n> 先存量同步，后双写：\n> - 方案更复杂，考虑点较多。\n\n\n##### 3.1.4、数据一致性保障方案\n\n1. 离线核对\n   1. 通过D-1离线表进行全量核对。\n2. 查询异步核对。\n3. 实时核对。\n   1. 可通过MQ的方式，进行数据核对。\n\n#### 3.2、ID问题\n在系统重构迁移时，需要考虑ID的问题。如下示例：将Place系统功能重构到ap内。\n{% plantuml %}\nparticipant 业务\nparticipant ap #ee6f6f\nparticipant place #99FF99\ndatabase placemysql #99FF99\ndatabase apmysql #ee6f6f\n\n== 初始状态 ==\n业务->place : 创建商户\nplace->placemysql: 生成商户ID，增加sequence\nplace-->业务:返回商户ID\n\n== 灰度状态 ==\n业务->ap : 创建商户\nap->place:获取商户ID\nplace->placemysql: 生成商户ID，增加sequence\nplace-->ap:返回商户ID\nap-->业务:返回商户ID\n\n== 最终状态 ==\n业务->ap : 创建商户\nap->apmysql: 生成商户ID，增加sequence\nap-->业务:返回商户ID\n\n{% endplantuml %}\n\nID的生成，在迁移过程中通常会有3个状态：\n1. 初始状态：由原系统生成。\n2. 灰度状态：由新系统调用原系统提供的接口生成（实际上由原系统生成）。\n3. 最终状态：由新系统生成。\n\n这里需要新系统考虑sequence问题，一般做法是新sequence需要抬高到一定值，防止生成的ID和旧ID重复，那需要抬高多少呢？\n1. 抬高值 = 日创建量最高值 * 日期。（例如日最高创建量为10000，灰度时间为30天，这个时间尽量多估算点，那么需要抬高值为 10000 * 30 = 300000）\n\n\n参考文章：[数据迁移方案设计](https://www.cnblogs.com/crazymakercircle/p/17531894.html#%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1)","source":"_posts/2024-08-02-系统重构-系统重构和合并总结.md","raw":"---\ntitle: 《系统重构》系统重构&合并总结\ndate: 2024-08-02 10:00:00\ncategories:\n  - [ 系统重构]\n---\n\n    这是系统重构系列的总结性文章，总结系统重构的一般流程和经验。\n\n### 一、愿景\n整个开发生涯中，经历了非常多的系统重构、系统合并，也总结了一些经验，记录下来。\n<!-- more -->\n### 二、项目管理流程\n较大型的项目，都会经历如图步骤：\n![项目管理流程](2024-08-02-系统重构-系统重构和合并总结/项目管理流程.png)\n本文主要讲解分析设计过程部分。\n### 三、常见问题及解决方案\n\n#### 3.1、数据一致性问题：\n数据一致性，需要特别关注。可以分为存量数据一致性、增量数据一致性问题和数据一致性保障方案。\n##### 3.1.1、存量数据一致性：\n![数据一致性_存量](2024-08-02-系统重构-系统重构和合并总结/数据一致性_存量.png)\n1. 离线方式：\n   1. 通过全量表+日增表，但是离线表一般是T+1（最快也是小时表），存在数据延迟问题，适用于数据变更频率低场景。\n2. binlog方式：\n   1. 延迟低，可靠性高。\n\n##### 3.1.2、增量数据一致性：\n![数据一致性_增量](2024-08-02-系统重构-系统重构和合并总结/数据一致性_增量.png)\n增量数据，一般是通过接口双写的方式，来保障数据一致性，同时还会通过binlog作为冗余方式，保障高可用。\n\n##### 3.1.3、使用离线表方式，先开双写还是先存量同步？\n如果不得不使用离线表的方式进行数据迁移，应该怎么做？考虑先开双写还是先迁移存量数据？\n###### 先开双写（灰度完成后），再做存量同步\n主要流程：先开双写（灰度完成后），再做一次完整的存量同步操作。\n![先双写后存量](2024-08-02-系统重构-系统重构和合并总结/先双写后存量.png)\n![双写先](2024-08-02-系统重构-系统重构和合并总结/双写先.png)\n1. 存量数据更新时，新库不存在数据，需要回查，性能会有影响。\n   1. 解决办法：前期已旧库为准，新库可以采用异步+稳定性方案，降低影响。\n2. 大批量数据更新，查询旧库，会造成旧库资源的冲击并影响现有业务。\n   1. 解决办法：可以结合灰度计划，控制流量，减少对现有业务的影响。\n\n###### 先存量同步，再开双写\n![先存量后增量](2024-08-02-系统重构-系统重构和合并总结/先存量后增量.png)\n> - 2个任务：\n>   - 存量数据同步：执行一次。\n>   - 增量数据同步：每日执行，直至全部灰度完成，并没有数据差异。\n> - 灰度数据，新库不存在或被更新，需要查询旧库，再做更新。\n> - \n\n###### ⭐️方案对比\n> 先双写，后存量同步：\n> - 方案更简单。\n> \n> 先存量同步，后双写：\n> - 方案更复杂，考虑点较多。\n\n\n##### 3.1.4、数据一致性保障方案\n\n1. 离线核对\n   1. 通过D-1离线表进行全量核对。\n2. 查询异步核对。\n3. 实时核对。\n   1. 可通过MQ的方式，进行数据核对。\n\n#### 3.2、ID问题\n在系统重构迁移时，需要考虑ID的问题。如下示例：将Place系统功能重构到ap内。\n{% plantuml %}\nparticipant 业务\nparticipant ap #ee6f6f\nparticipant place #99FF99\ndatabase placemysql #99FF99\ndatabase apmysql #ee6f6f\n\n== 初始状态 ==\n业务->place : 创建商户\nplace->placemysql: 生成商户ID，增加sequence\nplace-->业务:返回商户ID\n\n== 灰度状态 ==\n业务->ap : 创建商户\nap->place:获取商户ID\nplace->placemysql: 生成商户ID，增加sequence\nplace-->ap:返回商户ID\nap-->业务:返回商户ID\n\n== 最终状态 ==\n业务->ap : 创建商户\nap->apmysql: 生成商户ID，增加sequence\nap-->业务:返回商户ID\n\n{% endplantuml %}\n\nID的生成，在迁移过程中通常会有3个状态：\n1. 初始状态：由原系统生成。\n2. 灰度状态：由新系统调用原系统提供的接口生成（实际上由原系统生成）。\n3. 最终状态：由新系统生成。\n\n这里需要新系统考虑sequence问题，一般做法是新sequence需要抬高到一定值，防止生成的ID和旧ID重复，那需要抬高多少呢？\n1. 抬高值 = 日创建量最高值 * 日期。（例如日最高创建量为10000，灰度时间为30天，这个时间尽量多估算点，那么需要抬高值为 10000 * 30 = 300000）\n\n\n参考文章：[数据迁移方案设计](https://www.cnblogs.com/crazymakercircle/p/17531894.html#%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1)","slug":"2024-08-02-系统重构-系统重构和合并总结","published":1,"updated":"2024-11-07T09:23:52.023Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpny9005ea13ke6blwqyl","content":"<pre><code>这是系统重构系列的总结性文章，总结系统重构的一般流程和经验。</code></pre><h3 id=\"一、愿景\"><a href=\"#一、愿景\" class=\"headerlink\" title=\"一、愿景\"></a>一、愿景</h3><p>整个开发生涯中，经历了非常多的系统重构、系统合并，也总结了一些经验，记录下来。</p>\n<a id=\"more\"></a>\n<h3 id=\"二、项目管理流程\"><a href=\"#二、项目管理流程\" class=\"headerlink\" title=\"二、项目管理流程\"></a>二、项目管理流程</h3><p>较大型的项目，都会经历如图步骤：<br><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B.png\" alt=\"项目管理流程\"><br>本文主要讲解分析设计过程部分。</p>\n<h3 id=\"三、常见问题及解决方案\"><a href=\"#三、常见问题及解决方案\" class=\"headerlink\" title=\"三、常见问题及解决方案\"></a>三、常见问题及解决方案</h3><h4 id=\"3-1、数据一致性问题：\"><a href=\"#3-1、数据一致性问题：\" class=\"headerlink\" title=\"3.1、数据一致性问题：\"></a>3.1、数据一致性问题：</h4><p>数据一致性，需要特别关注。可以分为存量数据一致性、增量数据一致性问题和数据一致性保障方案。</p>\n<h5 id=\"3-1-1、存量数据一致性：\"><a href=\"#3-1-1、存量数据一致性：\" class=\"headerlink\" title=\"3.1.1、存量数据一致性：\"></a>3.1.1、存量数据一致性：</h5><p><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7_%E5%AD%98%E9%87%8F.png\" alt=\"数据一致性_存量\"></p>\n<ol>\n<li>离线方式：<ol>\n<li>通过全量表+日增表，但是离线表一般是T+1（最快也是小时表），存在数据延迟问题，适用于数据变更频率低场景。</li>\n</ol>\n</li>\n<li>binlog方式：<ol>\n<li>延迟低，可靠性高。</li>\n</ol>\n</li>\n</ol>\n<h5 id=\"3-1-2、增量数据一致性：\"><a href=\"#3-1-2、增量数据一致性：\" class=\"headerlink\" title=\"3.1.2、增量数据一致性：\"></a>3.1.2、增量数据一致性：</h5><p><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7_%E5%A2%9E%E9%87%8F.png\" alt=\"数据一致性_增量\"><br>增量数据，一般是通过接口双写的方式，来保障数据一致性，同时还会通过binlog作为冗余方式，保障高可用。</p>\n<h5 id=\"3-1-3、使用离线表方式，先开双写还是先存量同步？\"><a href=\"#3-1-3、使用离线表方式，先开双写还是先存量同步？\" class=\"headerlink\" title=\"3.1.3、使用离线表方式，先开双写还是先存量同步？\"></a>3.1.3、使用离线表方式，先开双写还是先存量同步？</h5><p>如果不得不使用离线表的方式进行数据迁移，应该怎么做？考虑先开双写还是先迁移存量数据？</p>\n<h6 id=\"先开双写（灰度完成后），再做存量同步\"><a href=\"#先开双写（灰度完成后），再做存量同步\" class=\"headerlink\" title=\"先开双写（灰度完成后），再做存量同步\"></a>先开双写（灰度完成后），再做存量同步</h6><p>主要流程：先开双写（灰度完成后），再做一次完整的存量同步操作。<br><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E5%85%88%E5%8F%8C%E5%86%99%E5%90%8E%E5%AD%98%E9%87%8F.png\" alt=\"先双写后存量\"><br><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E5%8F%8C%E5%86%99%E5%85%88.png\" alt=\"双写先\"></p>\n<ol>\n<li>存量数据更新时，新库不存在数据，需要回查，性能会有影响。<ol>\n<li>解决办法：前期已旧库为准，新库可以采用异步+稳定性方案，降低影响。</li>\n</ol>\n</li>\n<li>大批量数据更新，查询旧库，会造成旧库资源的冲击并影响现有业务。<ol>\n<li>解决办法：可以结合灰度计划，控制流量，减少对现有业务的影响。</li>\n</ol>\n</li>\n</ol>\n<h6 id=\"先存量同步，再开双写\"><a href=\"#先存量同步，再开双写\" class=\"headerlink\" title=\"先存量同步，再开双写\"></a>先存量同步，再开双写</h6><p><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E5%85%88%E5%AD%98%E9%87%8F%E5%90%8E%E5%A2%9E%E9%87%8F.png\" alt=\"先存量后增量\"></p>\n<blockquote>\n<ul>\n<li>2个任务：<ul>\n<li>存量数据同步：执行一次。</li>\n<li>增量数据同步：每日执行，直至全部灰度完成，并没有数据差异。</li>\n</ul>\n</li>\n<li>灰度数据，新库不存在或被更新，需要查询旧库，再做更新。</li>\n<li></li>\n</ul>\n</blockquote>\n<h6 id=\"⭐️方案对比\"><a href=\"#⭐️方案对比\" class=\"headerlink\" title=\"⭐️方案对比\"></a>⭐️方案对比</h6><blockquote>\n<p>先双写，后存量同步：</p>\n<ul>\n<li>方案更简单。</li>\n</ul>\n<p>先存量同步，后双写：</p>\n<ul>\n<li>方案更复杂，考虑点较多。</li>\n</ul>\n</blockquote>\n<h5 id=\"3-1-4、数据一致性保障方案\"><a href=\"#3-1-4、数据一致性保障方案\" class=\"headerlink\" title=\"3.1.4、数据一致性保障方案\"></a>3.1.4、数据一致性保障方案</h5><ol>\n<li>离线核对<ol>\n<li>通过D-1离线表进行全量核对。</li>\n</ol>\n</li>\n<li>查询异步核对。</li>\n<li>实时核对。<ol>\n<li>可通过MQ的方式，进行数据核对。</li>\n</ol>\n</li>\n</ol>\n<h4 id=\"3-2、ID问题\"><a href=\"#3-2、ID问题\" class=\"headerlink\" title=\"3.2、ID问题\"></a>3.2、ID问题</h4><p>在系统重构迁移时，需要考虑ID的问题。如下示例：将Place系统功能重构到ap内。</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHUB9ZrjEkXLm5I4A91GhAgQbcQMPfAC85EOd9gGhAbfPkRfQMN2c99Ob9YSMf4E7SokB274ovn0Ae1DGuBbjRXQSTSvykxtxUjUrPGwE2hIqNn06wTX3ZhO3oiv_ktlLqQjkpZkrSO46e7DWeAuNdK-O_wvW0aVTqUR-dv-cYUK-x5XId5fQcvYMdGhNesa7CjNgnVyhJsVDWoi4kUDwuuUckPPWk0FeRpVh40gZTLY_wjZ_jdmOtXW9t9HQWkmbe2pxdFflJy7nt1x7EXGOvOVVWiHK0\">\n\n<p>ID的生成，在迁移过程中通常会有3个状态：</p>\n<ol>\n<li>初始状态：由原系统生成。</li>\n<li>灰度状态：由新系统调用原系统提供的接口生成（实际上由原系统生成）。</li>\n<li>最终状态：由新系统生成。</li>\n</ol>\n<p>这里需要新系统考虑sequence问题，一般做法是新sequence需要抬高到一定值，防止生成的ID和旧ID重复，那需要抬高多少呢？</p>\n<ol>\n<li>抬高值 = 日创建量最高值 * 日期。（例如日最高创建量为10000，灰度时间为30天，这个时间尽量多估算点，那么需要抬高值为 10000 * 30 = 300000）</li>\n</ol>\n<p>参考文章：<a href=\"https://www.cnblogs.com/crazymakercircle/p/17531894.html#%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1\" target=\"_blank\" rel=\"noopener\">数据迁移方案设计</a></p>\n","site":{"data":{}},"excerpt":"<pre><code>这是系统重构系列的总结性文章，总结系统重构的一般流程和经验。</code></pre><h3 id=\"一、愿景\"><a href=\"#一、愿景\" class=\"headerlink\" title=\"一、愿景\"></a>一、愿景</h3><p>整个开发生涯中，经历了非常多的系统重构、系统合并，也总结了一些经验，记录下来。</p>","more":"<h3 id=\"二、项目管理流程\"><a href=\"#二、项目管理流程\" class=\"headerlink\" title=\"二、项目管理流程\"></a>二、项目管理流程</h3><p>较大型的项目，都会经历如图步骤：<br><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B.png\" alt=\"项目管理流程\"><br>本文主要讲解分析设计过程部分。</p>\n<h3 id=\"三、常见问题及解决方案\"><a href=\"#三、常见问题及解决方案\" class=\"headerlink\" title=\"三、常见问题及解决方案\"></a>三、常见问题及解决方案</h3><h4 id=\"3-1、数据一致性问题：\"><a href=\"#3-1、数据一致性问题：\" class=\"headerlink\" title=\"3.1、数据一致性问题：\"></a>3.1、数据一致性问题：</h4><p>数据一致性，需要特别关注。可以分为存量数据一致性、增量数据一致性问题和数据一致性保障方案。</p>\n<h5 id=\"3-1-1、存量数据一致性：\"><a href=\"#3-1-1、存量数据一致性：\" class=\"headerlink\" title=\"3.1.1、存量数据一致性：\"></a>3.1.1、存量数据一致性：</h5><p><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7_%E5%AD%98%E9%87%8F.png\" alt=\"数据一致性_存量\"></p>\n<ol>\n<li>离线方式：<ol>\n<li>通过全量表+日增表，但是离线表一般是T+1（最快也是小时表），存在数据延迟问题，适用于数据变更频率低场景。</li>\n</ol>\n</li>\n<li>binlog方式：<ol>\n<li>延迟低，可靠性高。</li>\n</ol>\n</li>\n</ol>\n<h5 id=\"3-1-2、增量数据一致性：\"><a href=\"#3-1-2、增量数据一致性：\" class=\"headerlink\" title=\"3.1.2、增量数据一致性：\"></a>3.1.2、增量数据一致性：</h5><p><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7_%E5%A2%9E%E9%87%8F.png\" alt=\"数据一致性_增量\"><br>增量数据，一般是通过接口双写的方式，来保障数据一致性，同时还会通过binlog作为冗余方式，保障高可用。</p>\n<h5 id=\"3-1-3、使用离线表方式，先开双写还是先存量同步？\"><a href=\"#3-1-3、使用离线表方式，先开双写还是先存量同步？\" class=\"headerlink\" title=\"3.1.3、使用离线表方式，先开双写还是先存量同步？\"></a>3.1.3、使用离线表方式，先开双写还是先存量同步？</h5><p>如果不得不使用离线表的方式进行数据迁移，应该怎么做？考虑先开双写还是先迁移存量数据？</p>\n<h6 id=\"先开双写（灰度完成后），再做存量同步\"><a href=\"#先开双写（灰度完成后），再做存量同步\" class=\"headerlink\" title=\"先开双写（灰度完成后），再做存量同步\"></a>先开双写（灰度完成后），再做存量同步</h6><p>主要流程：先开双写（灰度完成后），再做一次完整的存量同步操作。<br><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E5%85%88%E5%8F%8C%E5%86%99%E5%90%8E%E5%AD%98%E9%87%8F.png\" alt=\"先双写后存量\"><br><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E5%8F%8C%E5%86%99%E5%85%88.png\" alt=\"双写先\"></p>\n<ol>\n<li>存量数据更新时，新库不存在数据，需要回查，性能会有影响。<ol>\n<li>解决办法：前期已旧库为准，新库可以采用异步+稳定性方案，降低影响。</li>\n</ol>\n</li>\n<li>大批量数据更新，查询旧库，会造成旧库资源的冲击并影响现有业务。<ol>\n<li>解决办法：可以结合灰度计划，控制流量，减少对现有业务的影响。</li>\n</ol>\n</li>\n</ol>\n<h6 id=\"先存量同步，再开双写\"><a href=\"#先存量同步，再开双写\" class=\"headerlink\" title=\"先存量同步，再开双写\"></a>先存量同步，再开双写</h6><p><img src=\"/2024/08/02/2024-08-02-系统重构-系统重构和合并总结/%E5%85%88%E5%AD%98%E9%87%8F%E5%90%8E%E5%A2%9E%E9%87%8F.png\" alt=\"先存量后增量\"></p>\n<blockquote>\n<ul>\n<li>2个任务：<ul>\n<li>存量数据同步：执行一次。</li>\n<li>增量数据同步：每日执行，直至全部灰度完成，并没有数据差异。</li>\n</ul>\n</li>\n<li>灰度数据，新库不存在或被更新，需要查询旧库，再做更新。</li>\n<li></li>\n</ul>\n</blockquote>\n<h6 id=\"⭐️方案对比\"><a href=\"#⭐️方案对比\" class=\"headerlink\" title=\"⭐️方案对比\"></a>⭐️方案对比</h6><blockquote>\n<p>先双写，后存量同步：</p>\n<ul>\n<li>方案更简单。</li>\n</ul>\n<p>先存量同步，后双写：</p>\n<ul>\n<li>方案更复杂，考虑点较多。</li>\n</ul>\n</blockquote>\n<h5 id=\"3-1-4、数据一致性保障方案\"><a href=\"#3-1-4、数据一致性保障方案\" class=\"headerlink\" title=\"3.1.4、数据一致性保障方案\"></a>3.1.4、数据一致性保障方案</h5><ol>\n<li>离线核对<ol>\n<li>通过D-1离线表进行全量核对。</li>\n</ol>\n</li>\n<li>查询异步核对。</li>\n<li>实时核对。<ol>\n<li>可通过MQ的方式，进行数据核对。</li>\n</ol>\n</li>\n</ol>\n<h4 id=\"3-2、ID问题\"><a href=\"#3-2、ID问题\" class=\"headerlink\" title=\"3.2、ID问题\"></a>3.2、ID问题</h4><p>在系统重构迁移时，需要考虑ID的问题。如下示例：将Place系统功能重构到ap内。</p>\n<img src=\"http://www.plantuml.com/plantuml/svg/AqWiAibCpYn8p2jHUB9ZrjEkXLm5I4A91GhAgQbcQMPfAC85EOd9gGhAbfPkRfQMN2c99Ob9YSMf4E7SokB274ovn0Ae1DGuBbjRXQSTSvykxtxUjUrPGwE2hIqNn06wTX3ZhO3oiv_ktlLqQjkpZkrSO46e7DWeAuNdK-O_wvW0aVTqUR-dv-cYUK-x5XId5fQcvYMdGhNesa7CjNgnVyhJsVDWoi4kUDwuuUckPPWk0FeRpVh40gZTLY_wjZ_jdmOtXW9t9HQWkmbe2pxdFflJy7nt1x7EXGOvOVVWiHK0\">\n\n<p>ID的生成，在迁移过程中通常会有3个状态：</p>\n<ol>\n<li>初始状态：由原系统生成。</li>\n<li>灰度状态：由新系统调用原系统提供的接口生成（实际上由原系统生成）。</li>\n<li>最终状态：由新系统生成。</li>\n</ol>\n<p>这里需要新系统考虑sequence问题，一般做法是新sequence需要抬高到一定值，防止生成的ID和旧ID重复，那需要抬高多少呢？</p>\n<ol>\n<li>抬高值 = 日创建量最高值 * 日期。（例如日最高创建量为10000，灰度时间为30天，这个时间尽量多估算点，那么需要抬高值为 10000 * 30 = 300000）</li>\n</ol>\n<p>参考文章：<a href=\"https://www.cnblogs.com/crazymakercircle/p/17531894.html#%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1\" target=\"_blank\" rel=\"noopener\">数据迁移方案设计</a></p>"},{"title":"Mybatis","date":"2021-01-10T14:28:51.000Z","_content":"\n# 一、配置\n```\n<!-- MyBatis配置 -->\n<bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n    <!-- 配置数据源 -->\n    <property name=\"dataSource\" ref=\"shardingDataSource\"/>\n    <!-- 配置Mybatis配置文件 -->\n    <property name=\"configLocation\" value=\"classpath:/mybatis/mybatis-config.xml\"/>\n    <!-- 配置别名包路径 -->\n    <property name=\"typeAliasesPackage\" value=\"com.general.trade.entity\"/>\n    <!-- 配置Mapper扫描路径 -->\n    <property name=\"mapperLocations\" value=\"classpath:/mybatis/mapper/**/**Mapper.xml\"/>\n</bean>\n\n<!-- mapper的扫描 -->\n<bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\">\n    <property name=\"basePackage\" value=\"com.order.center.server.dao.mapper\"/>\n    <property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/>\n</bean>\n```\n\n<!--more-->\n\n# 二、启动过程\n\n## 1. SqlSessionFactoryBean实现\nspring启动过程中，会生成SqlSessionFactoryBean对象。\n```\npublic class SqlSessionFactoryBean implements FactoryBean<SqlSessionFactory>, InitializingBean, ApplicationListener<ApplicationEvent> \n```\nSqlSessionFactoryBean实现了InitializingBean接口，在初始化会调用afterPropertiesSet()方法。\n\n## 2. afterPropertiesSet()\n```\npublic void afterPropertiesSet() throws Exception {\n    this.sqlSessionFactory = buildSqlSessionFactory();\n}\n```\n\n## 3. buildSqlSessionFactory()\n> 在SqlSessionFactoryBean的实例化过程中：\n```\nprotected SqlSessionFactory buildSqlSessionFactory() throws IOException {\n    Configuration configuration;\n    //1. 读取文件\n    xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties);\n    //2. 解析mybatis-config.xml文件，解析配置文件的各个节点，解析的结果保存到configuration对象中\n    xmlConfigBuilder.parse();\n}\n```\n\n> 文件的具体解析工作\n```\npublic Configuration parse() {\n    if (parsed) {\n      throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\");\n    }\n    parsed = true;\n    parseConfiguration(parser.evalNode(\"/configuration\"));\n    return configuration;\n  }\n\n  private void parseConfiguration(XNode root) {\n    try {\n      //issue #117 read properties first\n      propertiesElement(root.evalNode(\"properties\"));\n      Properties settings = settingsAsProperties(root.evalNode(\"settings\"));\n      loadCustomVfs(settings);\n      typeAliasesElement(root.evalNode(\"typeAliases\"));\n      pluginElement(root.evalNode(\"plugins\"));\n      objectFactoryElement(root.evalNode(\"objectFactory\"));\n      objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\"));\n      reflectorFactoryElement(root.evalNode(\"reflectorFactory\"));\n      settingsElement(settings);\n      // read it after objectFactory and objectWrapperFactory issue #631\n      environmentsElement(root.evalNode(\"environments\"));\n      databaseIdProviderElement(root.evalNode(\"databaseIdProvider\"));\n      typeHandlerElement(root.evalNode(\"typeHandlers\"));\n      //解析mapper文件\n      mapperElement(root.evalNode(\"mappers\"));\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e);\n    }\n  }\n```\n\n此时所有的配置文件就已经解析完成了，解析内容会放入到Configuration对象内。\n\n> 占位符的替换工作\n```\n//解析文件中的占位符\n//<property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/>\n//<property name=\"url\" value=\"${jdbc.url1}\" />\n//<property name=\"username\" value=\"${jdbc.username1}\" />\n//<property name=\"password\" value=\"${jdbc.password1}\" />\npublic class PropertyParser {\n    public static String parse(String string, Properties variables) {\n        VariableTokenHandler handler = new VariableTokenHandler(variables);\n        GenericTokenParser parser = new GenericTokenParser(\"${\", \"}\", handler);\n        return parser.parse(string);\n    }\n}\n```\n\n# 三、MapperScannerConfigurer扫描过程\n```\npublic class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware {\n\n    //实现BeanDefinitionRegistryPostProcessor，在BeanFactoryPostProcessor初始化执行时会进行调用\n    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) {\n        if (this.processPropertyPlaceHolders) {\n          processPropertyPlaceHolders();\n        }\n        ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry);\n        scanner.setAddToConfig(this.addToConfig);\n        scanner.setAnnotationClass(this.annotationClass);\n        scanner.setMarkerInterface(this.markerInterface);\n        scanner.setSqlSessionFactory(this.sqlSessionFactory);\n        scanner.setSqlSessionTemplate(this.sqlSessionTemplate);\n        scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName);\n        scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName);\n        scanner.setResourceLoader(this.applicationContext);\n        scanner.setBeanNameGenerator(this.nameGenerator);\n        scanner.registerFilters();\n        //进行扫描，扫描指定路径下的接口\n        scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));\n      }\n}\n```\n然后我们看下ClassPathMapperScanner中的关键是如何扫描对应package下的接口的。\n\n```\npublic Set<BeanDefinitionHolder> doScan(String... basePackages) {\n    //扫描路径下的接口生成BeanDefinitionHolder\n    Set<BeanDefinitionHolder> beanDefinitions = super.doScan(basePackages);\n    if (beanDefinitions.isEmpty()) {\n      logger.warn(\"No MyBatis mapper was found in '\" + Arrays.toString(basePackages) + \"' package. Please check your configuration.\");\n    } else {\n        //进行beanDefinition的处理\n        processBeanDefinitions(beanDefinitions);\n    }\n    return beanDefinitions;\n}\n\nprivate void processBeanDefinitions(Set<BeanDefinitionHolder> beanDefinitions) {\n    GenericBeanDefinition definition;\n    for (BeanDefinitionHolder holder : beanDefinitions) {\n        definition = (GenericBeanDefinition) holder.getBeanDefinition();\n        // the mapper interface is the original class of the bean\n        // but, the actual class of the bean is MapperFactoryBean\n        //其实MapperScannerConfigurer的作用也就是将对应的接口的类型改造为MapperFactoryBean，\n        definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); // issue #59\n        definition.setBeanClass(this.mapperFactoryBean.getClass());\n        .....\n    }\n}\n```\n其实MapperScannerConfigurer的作用也就是将对应的接口的类型改造为MapperFactoryBean。\n\n# 四、MapperFactoryBean原理\nMapperFactoryBean继承了SqlSessionDaoSupport类，SqlSessionDaoSupport类继承DaoSupport抽象类，DaoSupport抽象类实现了InitializingBean接口，\n因此实例个MapperFactoryBean的时候，都会调用InitializingBean接口的afterPropertiesSet方法。\n\nDaoSupport的afterPropertiesSet方法：\n```\npublic final void afterPropertiesSet() throws IllegalArgumentException, BeanInitializationException {\n    // Let abstract subclasses check their configuration.\n    checkDaoConfig();\n\n    // Let concrete implementations initialize themselves.\n    try {\n        initDao();\n    }\n    catch (Exception ex) {\n        throw new BeanInitializationException(\"Initialization of DAO failed\", ex);\n    }\n}\n```\n\nMapperFactoryBean重写了checkDaoConfig方法：\n```\nprotected void checkDaoConfig() {\n    super.checkDaoConfig();\n    notNull(this.mapperInterface, \"Property 'mapperInterface' is required\");\n    Configuration configuration = getSqlSession().getConfiguration();\n    if (this.addToConfig && !configuration.hasMapper(this.mapperInterface)) {\n      try {\n        //mapperInterface是否存在configuration内，不存在就放入\n        configuration.addMapper(this.mapperInterface);\n      } catch (Exception e) {\n        logger.error(\"Error while adding the mapper '\" + this.mapperInterface + \"' to configuration.\", e);\n        throw new IllegalArgumentException(e);\n      } finally {\n        ErrorContext.instance().reset();\n      }\n    }\n  }\n```\n\n然后通过spring工厂拿对应的bean的时候：\n```\npublic T getObject() throws Exception {\n    return getSqlSession().getMapper(this.mapperInterface);\n  }\n```\n\n继续往下，DefaultSqlSession\n```\npublic <T> T getMapper(Class<T> type) {\n   return configuration.<T>getMapper(type, this);\n }\n```\n\nMapperRegistry的getMapper方法：\n```\npublic <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n    final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);\n    if (mapperProxyFactory == null) {\n      throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\");\n    }\n    try {\n      return mapperProxyFactory.newInstance(sqlSession);\n    } catch (Exception e) {\n      throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e);\n    }\n}\n```\n\nMapperProxyFactory构造MapperProxy：\n```\nprotected T newInstance(MapperProxy<T> mapperProxy) {\n    return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);\n}\n```\n\n**MapperProxyFactory使用了jdk组带的Proxy完成动态代理。**\n**MapperProxy内部使用了MapperMethod类完成方法的调用**\n\n\nMapperProxy的执行过程：\n```\n//实现了InvocationHandler，说明使用了jdk自带的动态代理。\npublic class MapperProxy<T> implements InvocationHandler, Serializable {\n  private static final long serialVersionUID = -6424540398559729838L;\n  private final SqlSession sqlSession;\n  private final Class<T> mapperInterface;\n  private final Map<Method, MapperMethod> methodCache;\n\n  public MapperProxy(SqlSession sqlSession, Class<T> mapperInterface, Map<Method, MapperMethod> methodCache) {\n    this.sqlSession = sqlSession;\n    this.mapperInterface = mapperInterface;\n    this.methodCache = methodCache;\n  }\n\n  @Override\n  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n    try {\n      if (Object.class.equals(method.getDeclaringClass())) {\n        return method.invoke(this, args);\n      } else if (isDefaultMethod(method)) {\n        return invokeDefaultMethod(proxy, method, args);\n      }\n    } catch (Throwable t) {\n      throw ExceptionUtil.unwrapThrowable(t);\n    }\n    final MapperMethod mapperMethod = cachedMapperMethod(method);\n    return mapperMethod.execute(sqlSession, args);\n  }\n}\n```\n\ninvoke方法的执行：\n```\npublic Object execute(SqlSession sqlSession, Object[] args) {\n    Object result;\n    switch (command.getType()) {\n      case INSERT: {\n    \tObject param = method.convertArgsToSqlCommandParam(args);\n        result = rowCountResult(sqlSession.insert(command.getName(), param));\n        break;\n      }\n      case UPDATE: {\n        Object param = method.convertArgsToSqlCommandParam(args);\n        result = rowCountResult(sqlSession.update(command.getName(), param));\n        break;\n      }\n      case DELETE: {\n        Object param = method.convertArgsToSqlCommandParam(args);\n        result = rowCountResult(sqlSession.delete(command.getName(), param));\n        break;\n      }\n      case SELECT:\n        if (method.returnsVoid() && method.hasResultHandler()) {\n          executeWithResultHandler(sqlSession, args);\n          result = null;\n        } else if (method.returnsMany()) {\n          result = executeForMany(sqlSession, args);\n        } else if (method.returnsMap()) {\n          result = executeForMap(sqlSession, args);\n        } else if (method.returnsCursor()) {\n          result = executeForCursor(sqlSession, args);\n        } else {\n          Object param = method.convertArgsToSqlCommandParam(args);\n          result = sqlSession.selectOne(command.getName(), param);\n        }\n        break;\n      case FLUSH:\n        result = sqlSession.flushStatements();\n        break;\n      default:\n        throw new BindingException(\"Unknown execution method for: \" + command.getName());\n    }\n    if (result == null && method.getReturnType().isPrimitive() && !method.returnsVoid()) {\n      throw new BindingException(\"Mapper method '\" + command.getName() \n          + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\");\n    }\n    return result;\n  }\n```\n\n\n\n\n# 五、使用 \n```\n//获取与数据库相关的会话(实际并未进行连接)\nSqlSession sqlSession = sqlSessionFactory.openSession();//DefaultSqlSessionFactory\n//获取对应的映射接口对象\n//4. 使用SqlSession创建Dao接口的代理对象\nIUserDao userMapper = sqlSession.getMapper(IUserDao.class);\n//5. 使用代理对象执行方法\nList<User> users = userMapper.findAll();\n```\n\n## sqlSessionFactory.openSession()原理\n```\nSqlSessionFactoryBean，此步会将所有的plugins添加到interceptorChain内\nif (!isEmpty(this.plugins)) {\n  for (Interceptor plugin : this.plugins) {\n    configuration.addInterceptor(plugin);\n    if (LOGGER.isDebugEnabled()) {\n      LOGGER.debug(\"Registered plugin: '\" + plugin + \"'\");\n    }\n  }\n}\n\n@Override\npublic SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level) {\n    return openSessionFromDataSource(execType, level, false);\n}\n\nprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {\n    Transaction tx = null;\n    try {\n        final Environment environment = configuration.getEnvironment();\n        final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);\n        tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);\n        //创建执行器\n        final Executor executor = configuration.newExecutor(tx, execType);\n        return new DefaultSqlSession(configuration, executor, autoCommit);\n    } catch (Exception e) {\n        closeTransaction(tx); // may have fetched a connection so lets call close()\n        throw ExceptionFactory.wrapException(\"Error opening session.  Cause: \" + e, e);\n    } finally {\n        ErrorContext.instance().reset();\n    }\n}\n```\n\n## 创建执行器\n```\npublic Executor newExecutor(Transaction transaction, ExecutorType executorType) {\n    executorType = executorType == null ? defaultExecutorType : executorType;\n    executorType = executorType == null ? ExecutorType.SIMPLE : executorType;\n    Executor executor;\n    if (ExecutorType.BATCH == executorType) {\n      executor = new BatchExecutor(this, transaction);\n    } else if (ExecutorType.REUSE == executorType) {\n      executor = new ReuseExecutor(this, transaction);\n    } else {\n      executor = new SimpleExecutor(this, transaction);\n    }\n    if (cacheEnabled) {\n      executor = new CachingExecutor(executor);\n    }\n    //进行interceptorChain的执行\n    executor = (Executor) interceptorChain.pluginAll(executor);\n    return executor;\n  }\n```\n\n\n## 拦截器链的执行\n```  \npublic Object pluginAll(Object target) {\n    for (Interceptor interceptor : interceptors) {\n      target = interceptor.plugin(target);\n    }\n    return target;\n  }  \n  \n自定义分页拦截器\n@Intercepts({ @Signature(type = StatementHandler.class, method = \"prepare\", args = { Connection.class, Integer.class }) })\npublic class PaginationInterceptor implements Interceptor {\n    @Override\n    //需要重写interceptor接口的plugin方法  \n    public Object plugin(Object target) {\n        //Plugin.java 实现了 InvocationHandler 接口，看的出也是 Java 动态代理，调用其静态方法 wrap:\n        return Plugin.wrap(target, this);\n    }\n}\n\n//为statementHandler 对象生成代理对象\npublic static Object wrap(Object target, Interceptor interceptor) {\n    Map<Class<?>, Set<Method>> signatureMap = getSignatureMap(interceptor);\n    Class<?> type = target.getClass();\n    Class<?>[] interfaces = getAllInterfaces(type, signatureMap);\n    if (interfaces.length > 0) {\n      return Proxy.newProxyInstance(\n          type.getClassLoader(),\n          interfaces,\n          new Plugin(target, interceptor, signatureMap));\n    }\n    return target;\n  }\n  \n  \n则为 target 生成代理对象最后当在 DefaultSqlSession 中执行具体执行时，如 selectList 方法中, 此时的 executor 是刚刚生成的代理对象\n  return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);\n  \n  \nexecutor 调用的方法就会执行 Plugin 重写的 invoke 方法：\n@Override\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\ntry {\n  Set<Method> methods = signatureMap.get(method.getDeclaringClass());\n  if (methods != null && methods.contains(method)) {\n    //拦截器的 intercept 方法执行\n    return interceptor.intercept(new Invocation(target, method, args));\n  }\n  //真正的方法执行\n  return method.invoke(target, args);\n} catch (Exception e) {\n  throw ExceptionUtil.unwrapThrowable(e);\n}\n}\n```\n\n总结：实现拦截器，需要实现Interceptor接口，并实现其plugin、和intercept两个方法\n\n\n[参考博客](https://cloud.tencent.com/developer/article/1498525)\n\n\n# 六、#{}和${}的区别是什么\n（1）mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值。\n```\nPreparedStatement ps = conn.prepareStatement(sql);\nps.setInt(1,id);\n```\n（2）mybatis在处理${}时，就是把${}替换成变量的值。\n\n（3）使用#{}可以有效的防止SQL注入，提高系统安全性。原因在于：预编译机制。预编译完成之后，SQL的结构已经固定，即便用户输入非法参数，也不会对SQL的结构产生影响，从而避免了潜在的安全风险。\n\n（4）预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。\n\n\n# 五、","source":"_posts/2021-01-10-Mybatis.md","raw":"---\ntitle: Mybatis\ndate: 2021-01-10 22:28:51\ncategories:\n  - [spring]\n  - [mybatis, 原理]\n---\n\n# 一、配置\n```\n<!-- MyBatis配置 -->\n<bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n    <!-- 配置数据源 -->\n    <property name=\"dataSource\" ref=\"shardingDataSource\"/>\n    <!-- 配置Mybatis配置文件 -->\n    <property name=\"configLocation\" value=\"classpath:/mybatis/mybatis-config.xml\"/>\n    <!-- 配置别名包路径 -->\n    <property name=\"typeAliasesPackage\" value=\"com.general.trade.entity\"/>\n    <!-- 配置Mapper扫描路径 -->\n    <property name=\"mapperLocations\" value=\"classpath:/mybatis/mapper/**/**Mapper.xml\"/>\n</bean>\n\n<!-- mapper的扫描 -->\n<bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\">\n    <property name=\"basePackage\" value=\"com.order.center.server.dao.mapper\"/>\n    <property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/>\n</bean>\n```\n\n<!--more-->\n\n# 二、启动过程\n\n## 1. SqlSessionFactoryBean实现\nspring启动过程中，会生成SqlSessionFactoryBean对象。\n```\npublic class SqlSessionFactoryBean implements FactoryBean<SqlSessionFactory>, InitializingBean, ApplicationListener<ApplicationEvent> \n```\nSqlSessionFactoryBean实现了InitializingBean接口，在初始化会调用afterPropertiesSet()方法。\n\n## 2. afterPropertiesSet()\n```\npublic void afterPropertiesSet() throws Exception {\n    this.sqlSessionFactory = buildSqlSessionFactory();\n}\n```\n\n## 3. buildSqlSessionFactory()\n> 在SqlSessionFactoryBean的实例化过程中：\n```\nprotected SqlSessionFactory buildSqlSessionFactory() throws IOException {\n    Configuration configuration;\n    //1. 读取文件\n    xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties);\n    //2. 解析mybatis-config.xml文件，解析配置文件的各个节点，解析的结果保存到configuration对象中\n    xmlConfigBuilder.parse();\n}\n```\n\n> 文件的具体解析工作\n```\npublic Configuration parse() {\n    if (parsed) {\n      throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\");\n    }\n    parsed = true;\n    parseConfiguration(parser.evalNode(\"/configuration\"));\n    return configuration;\n  }\n\n  private void parseConfiguration(XNode root) {\n    try {\n      //issue #117 read properties first\n      propertiesElement(root.evalNode(\"properties\"));\n      Properties settings = settingsAsProperties(root.evalNode(\"settings\"));\n      loadCustomVfs(settings);\n      typeAliasesElement(root.evalNode(\"typeAliases\"));\n      pluginElement(root.evalNode(\"plugins\"));\n      objectFactoryElement(root.evalNode(\"objectFactory\"));\n      objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\"));\n      reflectorFactoryElement(root.evalNode(\"reflectorFactory\"));\n      settingsElement(settings);\n      // read it after objectFactory and objectWrapperFactory issue #631\n      environmentsElement(root.evalNode(\"environments\"));\n      databaseIdProviderElement(root.evalNode(\"databaseIdProvider\"));\n      typeHandlerElement(root.evalNode(\"typeHandlers\"));\n      //解析mapper文件\n      mapperElement(root.evalNode(\"mappers\"));\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e);\n    }\n  }\n```\n\n此时所有的配置文件就已经解析完成了，解析内容会放入到Configuration对象内。\n\n> 占位符的替换工作\n```\n//解析文件中的占位符\n//<property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/>\n//<property name=\"url\" value=\"${jdbc.url1}\" />\n//<property name=\"username\" value=\"${jdbc.username1}\" />\n//<property name=\"password\" value=\"${jdbc.password1}\" />\npublic class PropertyParser {\n    public static String parse(String string, Properties variables) {\n        VariableTokenHandler handler = new VariableTokenHandler(variables);\n        GenericTokenParser parser = new GenericTokenParser(\"${\", \"}\", handler);\n        return parser.parse(string);\n    }\n}\n```\n\n# 三、MapperScannerConfigurer扫描过程\n```\npublic class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware {\n\n    //实现BeanDefinitionRegistryPostProcessor，在BeanFactoryPostProcessor初始化执行时会进行调用\n    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) {\n        if (this.processPropertyPlaceHolders) {\n          processPropertyPlaceHolders();\n        }\n        ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry);\n        scanner.setAddToConfig(this.addToConfig);\n        scanner.setAnnotationClass(this.annotationClass);\n        scanner.setMarkerInterface(this.markerInterface);\n        scanner.setSqlSessionFactory(this.sqlSessionFactory);\n        scanner.setSqlSessionTemplate(this.sqlSessionTemplate);\n        scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName);\n        scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName);\n        scanner.setResourceLoader(this.applicationContext);\n        scanner.setBeanNameGenerator(this.nameGenerator);\n        scanner.registerFilters();\n        //进行扫描，扫描指定路径下的接口\n        scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));\n      }\n}\n```\n然后我们看下ClassPathMapperScanner中的关键是如何扫描对应package下的接口的。\n\n```\npublic Set<BeanDefinitionHolder> doScan(String... basePackages) {\n    //扫描路径下的接口生成BeanDefinitionHolder\n    Set<BeanDefinitionHolder> beanDefinitions = super.doScan(basePackages);\n    if (beanDefinitions.isEmpty()) {\n      logger.warn(\"No MyBatis mapper was found in '\" + Arrays.toString(basePackages) + \"' package. Please check your configuration.\");\n    } else {\n        //进行beanDefinition的处理\n        processBeanDefinitions(beanDefinitions);\n    }\n    return beanDefinitions;\n}\n\nprivate void processBeanDefinitions(Set<BeanDefinitionHolder> beanDefinitions) {\n    GenericBeanDefinition definition;\n    for (BeanDefinitionHolder holder : beanDefinitions) {\n        definition = (GenericBeanDefinition) holder.getBeanDefinition();\n        // the mapper interface is the original class of the bean\n        // but, the actual class of the bean is MapperFactoryBean\n        //其实MapperScannerConfigurer的作用也就是将对应的接口的类型改造为MapperFactoryBean，\n        definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); // issue #59\n        definition.setBeanClass(this.mapperFactoryBean.getClass());\n        .....\n    }\n}\n```\n其实MapperScannerConfigurer的作用也就是将对应的接口的类型改造为MapperFactoryBean。\n\n# 四、MapperFactoryBean原理\nMapperFactoryBean继承了SqlSessionDaoSupport类，SqlSessionDaoSupport类继承DaoSupport抽象类，DaoSupport抽象类实现了InitializingBean接口，\n因此实例个MapperFactoryBean的时候，都会调用InitializingBean接口的afterPropertiesSet方法。\n\nDaoSupport的afterPropertiesSet方法：\n```\npublic final void afterPropertiesSet() throws IllegalArgumentException, BeanInitializationException {\n    // Let abstract subclasses check their configuration.\n    checkDaoConfig();\n\n    // Let concrete implementations initialize themselves.\n    try {\n        initDao();\n    }\n    catch (Exception ex) {\n        throw new BeanInitializationException(\"Initialization of DAO failed\", ex);\n    }\n}\n```\n\nMapperFactoryBean重写了checkDaoConfig方法：\n```\nprotected void checkDaoConfig() {\n    super.checkDaoConfig();\n    notNull(this.mapperInterface, \"Property 'mapperInterface' is required\");\n    Configuration configuration = getSqlSession().getConfiguration();\n    if (this.addToConfig && !configuration.hasMapper(this.mapperInterface)) {\n      try {\n        //mapperInterface是否存在configuration内，不存在就放入\n        configuration.addMapper(this.mapperInterface);\n      } catch (Exception e) {\n        logger.error(\"Error while adding the mapper '\" + this.mapperInterface + \"' to configuration.\", e);\n        throw new IllegalArgumentException(e);\n      } finally {\n        ErrorContext.instance().reset();\n      }\n    }\n  }\n```\n\n然后通过spring工厂拿对应的bean的时候：\n```\npublic T getObject() throws Exception {\n    return getSqlSession().getMapper(this.mapperInterface);\n  }\n```\n\n继续往下，DefaultSqlSession\n```\npublic <T> T getMapper(Class<T> type) {\n   return configuration.<T>getMapper(type, this);\n }\n```\n\nMapperRegistry的getMapper方法：\n```\npublic <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n    final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);\n    if (mapperProxyFactory == null) {\n      throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\");\n    }\n    try {\n      return mapperProxyFactory.newInstance(sqlSession);\n    } catch (Exception e) {\n      throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e);\n    }\n}\n```\n\nMapperProxyFactory构造MapperProxy：\n```\nprotected T newInstance(MapperProxy<T> mapperProxy) {\n    return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);\n}\n```\n\n**MapperProxyFactory使用了jdk组带的Proxy完成动态代理。**\n**MapperProxy内部使用了MapperMethod类完成方法的调用**\n\n\nMapperProxy的执行过程：\n```\n//实现了InvocationHandler，说明使用了jdk自带的动态代理。\npublic class MapperProxy<T> implements InvocationHandler, Serializable {\n  private static final long serialVersionUID = -6424540398559729838L;\n  private final SqlSession sqlSession;\n  private final Class<T> mapperInterface;\n  private final Map<Method, MapperMethod> methodCache;\n\n  public MapperProxy(SqlSession sqlSession, Class<T> mapperInterface, Map<Method, MapperMethod> methodCache) {\n    this.sqlSession = sqlSession;\n    this.mapperInterface = mapperInterface;\n    this.methodCache = methodCache;\n  }\n\n  @Override\n  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n    try {\n      if (Object.class.equals(method.getDeclaringClass())) {\n        return method.invoke(this, args);\n      } else if (isDefaultMethod(method)) {\n        return invokeDefaultMethod(proxy, method, args);\n      }\n    } catch (Throwable t) {\n      throw ExceptionUtil.unwrapThrowable(t);\n    }\n    final MapperMethod mapperMethod = cachedMapperMethod(method);\n    return mapperMethod.execute(sqlSession, args);\n  }\n}\n```\n\ninvoke方法的执行：\n```\npublic Object execute(SqlSession sqlSession, Object[] args) {\n    Object result;\n    switch (command.getType()) {\n      case INSERT: {\n    \tObject param = method.convertArgsToSqlCommandParam(args);\n        result = rowCountResult(sqlSession.insert(command.getName(), param));\n        break;\n      }\n      case UPDATE: {\n        Object param = method.convertArgsToSqlCommandParam(args);\n        result = rowCountResult(sqlSession.update(command.getName(), param));\n        break;\n      }\n      case DELETE: {\n        Object param = method.convertArgsToSqlCommandParam(args);\n        result = rowCountResult(sqlSession.delete(command.getName(), param));\n        break;\n      }\n      case SELECT:\n        if (method.returnsVoid() && method.hasResultHandler()) {\n          executeWithResultHandler(sqlSession, args);\n          result = null;\n        } else if (method.returnsMany()) {\n          result = executeForMany(sqlSession, args);\n        } else if (method.returnsMap()) {\n          result = executeForMap(sqlSession, args);\n        } else if (method.returnsCursor()) {\n          result = executeForCursor(sqlSession, args);\n        } else {\n          Object param = method.convertArgsToSqlCommandParam(args);\n          result = sqlSession.selectOne(command.getName(), param);\n        }\n        break;\n      case FLUSH:\n        result = sqlSession.flushStatements();\n        break;\n      default:\n        throw new BindingException(\"Unknown execution method for: \" + command.getName());\n    }\n    if (result == null && method.getReturnType().isPrimitive() && !method.returnsVoid()) {\n      throw new BindingException(\"Mapper method '\" + command.getName() \n          + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\");\n    }\n    return result;\n  }\n```\n\n\n\n\n# 五、使用 \n```\n//获取与数据库相关的会话(实际并未进行连接)\nSqlSession sqlSession = sqlSessionFactory.openSession();//DefaultSqlSessionFactory\n//获取对应的映射接口对象\n//4. 使用SqlSession创建Dao接口的代理对象\nIUserDao userMapper = sqlSession.getMapper(IUserDao.class);\n//5. 使用代理对象执行方法\nList<User> users = userMapper.findAll();\n```\n\n## sqlSessionFactory.openSession()原理\n```\nSqlSessionFactoryBean，此步会将所有的plugins添加到interceptorChain内\nif (!isEmpty(this.plugins)) {\n  for (Interceptor plugin : this.plugins) {\n    configuration.addInterceptor(plugin);\n    if (LOGGER.isDebugEnabled()) {\n      LOGGER.debug(\"Registered plugin: '\" + plugin + \"'\");\n    }\n  }\n}\n\n@Override\npublic SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level) {\n    return openSessionFromDataSource(execType, level, false);\n}\n\nprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {\n    Transaction tx = null;\n    try {\n        final Environment environment = configuration.getEnvironment();\n        final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);\n        tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);\n        //创建执行器\n        final Executor executor = configuration.newExecutor(tx, execType);\n        return new DefaultSqlSession(configuration, executor, autoCommit);\n    } catch (Exception e) {\n        closeTransaction(tx); // may have fetched a connection so lets call close()\n        throw ExceptionFactory.wrapException(\"Error opening session.  Cause: \" + e, e);\n    } finally {\n        ErrorContext.instance().reset();\n    }\n}\n```\n\n## 创建执行器\n```\npublic Executor newExecutor(Transaction transaction, ExecutorType executorType) {\n    executorType = executorType == null ? defaultExecutorType : executorType;\n    executorType = executorType == null ? ExecutorType.SIMPLE : executorType;\n    Executor executor;\n    if (ExecutorType.BATCH == executorType) {\n      executor = new BatchExecutor(this, transaction);\n    } else if (ExecutorType.REUSE == executorType) {\n      executor = new ReuseExecutor(this, transaction);\n    } else {\n      executor = new SimpleExecutor(this, transaction);\n    }\n    if (cacheEnabled) {\n      executor = new CachingExecutor(executor);\n    }\n    //进行interceptorChain的执行\n    executor = (Executor) interceptorChain.pluginAll(executor);\n    return executor;\n  }\n```\n\n\n## 拦截器链的执行\n```  \npublic Object pluginAll(Object target) {\n    for (Interceptor interceptor : interceptors) {\n      target = interceptor.plugin(target);\n    }\n    return target;\n  }  \n  \n自定义分页拦截器\n@Intercepts({ @Signature(type = StatementHandler.class, method = \"prepare\", args = { Connection.class, Integer.class }) })\npublic class PaginationInterceptor implements Interceptor {\n    @Override\n    //需要重写interceptor接口的plugin方法  \n    public Object plugin(Object target) {\n        //Plugin.java 实现了 InvocationHandler 接口，看的出也是 Java 动态代理，调用其静态方法 wrap:\n        return Plugin.wrap(target, this);\n    }\n}\n\n//为statementHandler 对象生成代理对象\npublic static Object wrap(Object target, Interceptor interceptor) {\n    Map<Class<?>, Set<Method>> signatureMap = getSignatureMap(interceptor);\n    Class<?> type = target.getClass();\n    Class<?>[] interfaces = getAllInterfaces(type, signatureMap);\n    if (interfaces.length > 0) {\n      return Proxy.newProxyInstance(\n          type.getClassLoader(),\n          interfaces,\n          new Plugin(target, interceptor, signatureMap));\n    }\n    return target;\n  }\n  \n  \n则为 target 生成代理对象最后当在 DefaultSqlSession 中执行具体执行时，如 selectList 方法中, 此时的 executor 是刚刚生成的代理对象\n  return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);\n  \n  \nexecutor 调用的方法就会执行 Plugin 重写的 invoke 方法：\n@Override\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\ntry {\n  Set<Method> methods = signatureMap.get(method.getDeclaringClass());\n  if (methods != null && methods.contains(method)) {\n    //拦截器的 intercept 方法执行\n    return interceptor.intercept(new Invocation(target, method, args));\n  }\n  //真正的方法执行\n  return method.invoke(target, args);\n} catch (Exception e) {\n  throw ExceptionUtil.unwrapThrowable(e);\n}\n}\n```\n\n总结：实现拦截器，需要实现Interceptor接口，并实现其plugin、和intercept两个方法\n\n\n[参考博客](https://cloud.tencent.com/developer/article/1498525)\n\n\n# 六、#{}和${}的区别是什么\n（1）mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值。\n```\nPreparedStatement ps = conn.prepareStatement(sql);\nps.setInt(1,id);\n```\n（2）mybatis在处理${}时，就是把${}替换成变量的值。\n\n（3）使用#{}可以有效的防止SQL注入，提高系统安全性。原因在于：预编译机制。预编译完成之后，SQL的结构已经固定，即便用户输入非法参数，也不会对SQL的结构产生影响，从而避免了潜在的安全风险。\n\n（4）预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。\n\n\n# 五、","slug":"2021-01-10-Mybatis","published":1,"updated":"2024-10-18T01:53:52.179Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnya005ha13ko9590szt","content":"<h1 id=\"一、配置\"><a href=\"#一、配置\" class=\"headerlink\" title=\"一、配置\"></a>一、配置</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!-- MyBatis配置 --&gt;</span><br><span class=\"line\">&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;</span><br><span class=\"line\">    &lt;!-- 配置数据源 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;dataSource&quot; ref=&quot;shardingDataSource&quot;/&gt;</span><br><span class=\"line\">    &lt;!-- 配置Mybatis配置文件 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;configLocation&quot; value=&quot;classpath:/mybatis/mybatis-config.xml&quot;/&gt;</span><br><span class=\"line\">    &lt;!-- 配置别名包路径 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.general.trade.entity&quot;/&gt;</span><br><span class=\"line\">    &lt;!-- 配置Mapper扫描路径 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:/mybatis/mapper/**/**Mapper.xml&quot;/&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!-- mapper的扫描 --&gt;</span><br><span class=\"line\">&lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;</span><br><span class=\"line\">    &lt;property name=&quot;basePackage&quot; value=&quot;com.order.center.server.dao.mapper&quot;/&gt;</span><br><span class=\"line\">    &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure>\n\n<a id=\"more\"></a>\n\n<h1 id=\"二、启动过程\"><a href=\"#二、启动过程\" class=\"headerlink\" title=\"二、启动过程\"></a>二、启动过程</h1><h2 id=\"1-SqlSessionFactoryBean实现\"><a href=\"#1-SqlSessionFactoryBean实现\" class=\"headerlink\" title=\"1. SqlSessionFactoryBean实现\"></a>1. SqlSessionFactoryBean实现</h2><p>spring启动过程中，会生成SqlSessionFactoryBean对象。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt;</span><br></pre></td></tr></table></figure>\n\n<p>SqlSessionFactoryBean实现了InitializingBean接口，在初始化会调用afterPropertiesSet()方法。</p>\n<h2 id=\"2-afterPropertiesSet\"><a href=\"#2-afterPropertiesSet\" class=\"headerlink\" title=\"2. afterPropertiesSet()\"></a>2. afterPropertiesSet()</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void afterPropertiesSet() throws Exception &#123;</span><br><span class=\"line\">    this.sqlSessionFactory = buildSqlSessionFactory();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-buildSqlSessionFactory\"><a href=\"#3-buildSqlSessionFactory\" class=\"headerlink\" title=\"3. buildSqlSessionFactory()\"></a>3. buildSqlSessionFactory()</h2><blockquote>\n<p>在SqlSessionFactoryBean的实例化过程中：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected SqlSessionFactory buildSqlSessionFactory() throws IOException &#123;</span><br><span class=\"line\">    Configuration configuration;</span><br><span class=\"line\">    //1. 读取文件</span><br><span class=\"line\">    xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties);</span><br><span class=\"line\">    //2. 解析mybatis-config.xml文件，解析配置文件的各个节点，解析的结果保存到configuration对象中</span><br><span class=\"line\">    xmlConfigBuilder.parse();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>文件的具体解析工作</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Configuration parse() &#123;</span><br><span class=\"line\">    if (parsed) &#123;</span><br><span class=\"line\">      throw new BuilderException(&quot;Each XMLConfigBuilder can only be used once.&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    parsed = true;</span><br><span class=\"line\">    parseConfiguration(parser.evalNode(&quot;/configuration&quot;));</span><br><span class=\"line\">    return configuration;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  private void parseConfiguration(XNode root) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">      //issue #117 read properties first</span><br><span class=\"line\">      propertiesElement(root.evalNode(&quot;properties&quot;));</span><br><span class=\"line\">      Properties settings = settingsAsProperties(root.evalNode(&quot;settings&quot;));</span><br><span class=\"line\">      loadCustomVfs(settings);</span><br><span class=\"line\">      typeAliasesElement(root.evalNode(&quot;typeAliases&quot;));</span><br><span class=\"line\">      pluginElement(root.evalNode(&quot;plugins&quot;));</span><br><span class=\"line\">      objectFactoryElement(root.evalNode(&quot;objectFactory&quot;));</span><br><span class=\"line\">      objectWrapperFactoryElement(root.evalNode(&quot;objectWrapperFactory&quot;));</span><br><span class=\"line\">      reflectorFactoryElement(root.evalNode(&quot;reflectorFactory&quot;));</span><br><span class=\"line\">      settingsElement(settings);</span><br><span class=\"line\">      // read it after objectFactory and objectWrapperFactory issue #631</span><br><span class=\"line\">      environmentsElement(root.evalNode(&quot;environments&quot;));</span><br><span class=\"line\">      databaseIdProviderElement(root.evalNode(&quot;databaseIdProvider&quot;));</span><br><span class=\"line\">      typeHandlerElement(root.evalNode(&quot;typeHandlers&quot;));</span><br><span class=\"line\">      //解析mapper文件</span><br><span class=\"line\">      mapperElement(root.evalNode(&quot;mappers&quot;));</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">      throw new BuilderException(&quot;Error parsing SQL Mapper Configuration. Cause: &quot; + e, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>此时所有的配置文件就已经解析完成了，解析内容会放入到Configuration对象内。</p>\n<blockquote>\n<p>占位符的替换工作</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//解析文件中的占位符</span><br><span class=\"line\">//&lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;</span><br><span class=\"line\">//&lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url1&#125;&quot; /&gt;</span><br><span class=\"line\">//&lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username1&#125;&quot; /&gt;</span><br><span class=\"line\">//&lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password1&#125;&quot; /&gt;</span><br><span class=\"line\">public class PropertyParser &#123;</span><br><span class=\"line\">    public static String parse(String string, Properties variables) &#123;</span><br><span class=\"line\">        VariableTokenHandler handler = new VariableTokenHandler(variables);</span><br><span class=\"line\">        GenericTokenParser parser = new GenericTokenParser(&quot;$&#123;&quot;, &quot;&#125;&quot;, handler);</span><br><span class=\"line\">        return parser.parse(string);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、MapperScannerConfigurer扫描过程\"><a href=\"#三、MapperScannerConfigurer扫描过程\" class=\"headerlink\" title=\"三、MapperScannerConfigurer扫描过程\"></a>三、MapperScannerConfigurer扫描过程</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    //实现BeanDefinitionRegistryPostProcessor，在BeanFactoryPostProcessor初始化执行时会进行调用</span><br><span class=\"line\">    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123;</span><br><span class=\"line\">        if (this.processPropertyPlaceHolders) &#123;</span><br><span class=\"line\">          processPropertyPlaceHolders();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry);</span><br><span class=\"line\">        scanner.setAddToConfig(this.addToConfig);</span><br><span class=\"line\">        scanner.setAnnotationClass(this.annotationClass);</span><br><span class=\"line\">        scanner.setMarkerInterface(this.markerInterface);</span><br><span class=\"line\">        scanner.setSqlSessionFactory(this.sqlSessionFactory);</span><br><span class=\"line\">        scanner.setSqlSessionTemplate(this.sqlSessionTemplate);</span><br><span class=\"line\">        scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName);</span><br><span class=\"line\">        scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName);</span><br><span class=\"line\">        scanner.setResourceLoader(this.applicationContext);</span><br><span class=\"line\">        scanner.setBeanNameGenerator(this.nameGenerator);</span><br><span class=\"line\">        scanner.registerFilters();</span><br><span class=\"line\">        //进行扫描，扫描指定路径下的接口</span><br><span class=\"line\">        scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后我们看下ClassPathMapperScanner中的关键是如何扫描对应package下的接口的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123;</span><br><span class=\"line\">    //扫描路径下的接口生成BeanDefinitionHolder</span><br><span class=\"line\">    Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages);</span><br><span class=\"line\">    if (beanDefinitions.isEmpty()) &#123;</span><br><span class=\"line\">      logger.warn(&quot;No MyBatis mapper was found in &apos;&quot; + Arrays.toString(basePackages) + &quot;&apos; package. Please check your configuration.&quot;);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        //进行beanDefinition的处理</span><br><span class=\"line\">        processBeanDefinitions(beanDefinitions);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return beanDefinitions;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123;</span><br><span class=\"line\">    GenericBeanDefinition definition;</span><br><span class=\"line\">    for (BeanDefinitionHolder holder : beanDefinitions) &#123;</span><br><span class=\"line\">        definition = (GenericBeanDefinition) holder.getBeanDefinition();</span><br><span class=\"line\">        // the mapper interface is the original class of the bean</span><br><span class=\"line\">        // but, the actual class of the bean is MapperFactoryBean</span><br><span class=\"line\">        //其实MapperScannerConfigurer的作用也就是将对应的接口的类型改造为MapperFactoryBean，</span><br><span class=\"line\">        definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); // issue #59</span><br><span class=\"line\">        definition.setBeanClass(this.mapperFactoryBean.getClass());</span><br><span class=\"line\">        .....</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>其实MapperScannerConfigurer的作用也就是将对应的接口的类型改造为MapperFactoryBean。</p>\n<h1 id=\"四、MapperFactoryBean原理\"><a href=\"#四、MapperFactoryBean原理\" class=\"headerlink\" title=\"四、MapperFactoryBean原理\"></a>四、MapperFactoryBean原理</h1><p>MapperFactoryBean继承了SqlSessionDaoSupport类，SqlSessionDaoSupport类继承DaoSupport抽象类，DaoSupport抽象类实现了InitializingBean接口，<br>因此实例个MapperFactoryBean的时候，都会调用InitializingBean接口的afterPropertiesSet方法。</p>\n<p>DaoSupport的afterPropertiesSet方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public final void afterPropertiesSet() throws IllegalArgumentException, BeanInitializationException &#123;</span><br><span class=\"line\">    // Let abstract subclasses check their configuration.</span><br><span class=\"line\">    checkDaoConfig();</span><br><span class=\"line\"></span><br><span class=\"line\">    // Let concrete implementations initialize themselves.</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        initDao();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    catch (Exception ex) &#123;</span><br><span class=\"line\">        throw new BeanInitializationException(&quot;Initialization of DAO failed&quot;, ex);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>MapperFactoryBean重写了checkDaoConfig方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void checkDaoConfig() &#123;</span><br><span class=\"line\">    super.checkDaoConfig();</span><br><span class=\"line\">    notNull(this.mapperInterface, &quot;Property &apos;mapperInterface&apos; is required&quot;);</span><br><span class=\"line\">    Configuration configuration = getSqlSession().getConfiguration();</span><br><span class=\"line\">    if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) &#123;</span><br><span class=\"line\">      try &#123;</span><br><span class=\"line\">        //mapperInterface是否存在configuration内，不存在就放入</span><br><span class=\"line\">        configuration.addMapper(this.mapperInterface);</span><br><span class=\"line\">      &#125; catch (Exception e) &#123;</span><br><span class=\"line\">        logger.error(&quot;Error while adding the mapper &apos;&quot; + this.mapperInterface + &quot;&apos; to configuration.&quot;, e);</span><br><span class=\"line\">        throw new IllegalArgumentException(e);</span><br><span class=\"line\">      &#125; finally &#123;</span><br><span class=\"line\">        ErrorContext.instance().reset();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后通过spring工厂拿对应的bean的时候：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public T getObject() throws Exception &#123;</span><br><span class=\"line\">    return getSqlSession().getMapper(this.mapperInterface);</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>继续往下，DefaultSqlSession</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123;</span><br><span class=\"line\">   return configuration.&lt;T&gt;getMapper(type, this);</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n\n<p>MapperRegistry的getMapper方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123;</span><br><span class=\"line\">    final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type);</span><br><span class=\"line\">    if (mapperProxyFactory == null) &#123;</span><br><span class=\"line\">      throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">      return mapperProxyFactory.newInstance(sqlSession);</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">      throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>MapperProxyFactory构造MapperProxy：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123;</span><br><span class=\"line\">    return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>MapperProxyFactory使用了jdk组带的Proxy完成动态代理。</strong><br><strong>MapperProxy内部使用了MapperMethod类完成方法的调用</strong></p>\n<p>MapperProxy的执行过程：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//实现了InvocationHandler，说明使用了jdk自带的动态代理。</span><br><span class=\"line\">public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123;</span><br><span class=\"line\">  private static final long serialVersionUID = -6424540398559729838L;</span><br><span class=\"line\">  private final SqlSession sqlSession;</span><br><span class=\"line\">  private final Class&lt;T&gt; mapperInterface;</span><br><span class=\"line\">  private final Map&lt;Method, MapperMethod&gt; methodCache;</span><br><span class=\"line\"></span><br><span class=\"line\">  public MapperProxy(SqlSession sqlSession, Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123;</span><br><span class=\"line\">    this.sqlSession = sqlSession;</span><br><span class=\"line\">    this.mapperInterface = mapperInterface;</span><br><span class=\"line\">    this.methodCache = methodCache;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  @Override</span><br><span class=\"line\">  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">      if (Object.class.equals(method.getDeclaringClass())) &#123;</span><br><span class=\"line\">        return method.invoke(this, args);</span><br><span class=\"line\">      &#125; else if (isDefaultMethod(method)) &#123;</span><br><span class=\"line\">        return invokeDefaultMethod(proxy, method, args);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">      throw ExceptionUtil.unwrapThrowable(t);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    final MapperMethod mapperMethod = cachedMapperMethod(method);</span><br><span class=\"line\">    return mapperMethod.execute(sqlSession, args);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>invoke方法的执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Object execute(SqlSession sqlSession, Object[] args) &#123;</span><br><span class=\"line\">    Object result;</span><br><span class=\"line\">    switch (command.getType()) &#123;</span><br><span class=\"line\">      case INSERT: &#123;</span><br><span class=\"line\">    \tObject param = method.convertArgsToSqlCommandParam(args);</span><br><span class=\"line\">        result = rowCountResult(sqlSession.insert(command.getName(), param));</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      case UPDATE: &#123;</span><br><span class=\"line\">        Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class=\"line\">        result = rowCountResult(sqlSession.update(command.getName(), param));</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      case DELETE: &#123;</span><br><span class=\"line\">        Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class=\"line\">        result = rowCountResult(sqlSession.delete(command.getName(), param));</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      case SELECT:</span><br><span class=\"line\">        if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123;</span><br><span class=\"line\">          executeWithResultHandler(sqlSession, args);</span><br><span class=\"line\">          result = null;</span><br><span class=\"line\">        &#125; else if (method.returnsMany()) &#123;</span><br><span class=\"line\">          result = executeForMany(sqlSession, args);</span><br><span class=\"line\">        &#125; else if (method.returnsMap()) &#123;</span><br><span class=\"line\">          result = executeForMap(sqlSession, args);</span><br><span class=\"line\">        &#125; else if (method.returnsCursor()) &#123;</span><br><span class=\"line\">          result = executeForCursor(sqlSession, args);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">          Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class=\"line\">          result = sqlSession.selectOne(command.getName(), param);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case FLUSH:</span><br><span class=\"line\">        result = sqlSession.flushStatements();</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      default:</span><br><span class=\"line\">        throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123;</span><br><span class=\"line\">      throw new BindingException(&quot;Mapper method &apos;&quot; + command.getName() </span><br><span class=\"line\">          + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return result;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"五、使用\"><a href=\"#五、使用\" class=\"headerlink\" title=\"五、使用\"></a>五、使用</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//获取与数据库相关的会话(实际并未进行连接)</span><br><span class=\"line\">SqlSession sqlSession = sqlSessionFactory.openSession();//DefaultSqlSessionFactory</span><br><span class=\"line\">//获取对应的映射接口对象</span><br><span class=\"line\">//4. 使用SqlSession创建Dao接口的代理对象</span><br><span class=\"line\">IUserDao userMapper = sqlSession.getMapper(IUserDao.class);</span><br><span class=\"line\">//5. 使用代理对象执行方法</span><br><span class=\"line\">List&lt;User&gt; users = userMapper.findAll();</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"sqlSessionFactory-openSession-原理\"><a href=\"#sqlSessionFactory-openSession-原理\" class=\"headerlink\" title=\"sqlSessionFactory.openSession()原理\"></a>sqlSessionFactory.openSession()原理</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SqlSessionFactoryBean，此步会将所有的plugins添加到interceptorChain内</span><br><span class=\"line\">if (!isEmpty(this.plugins)) &#123;</span><br><span class=\"line\">  for (Interceptor plugin : this.plugins) &#123;</span><br><span class=\"line\">    configuration.addInterceptor(plugin);</span><br><span class=\"line\">    if (LOGGER.isDebugEnabled()) &#123;</span><br><span class=\"line\">      LOGGER.debug(&quot;Registered plugin: &apos;&quot; + plugin + &quot;&apos;&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@Override</span><br><span class=\"line\">public SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level) &#123;</span><br><span class=\"line\">    return openSessionFromDataSource(execType, level, false);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123;</span><br><span class=\"line\">    Transaction tx = null;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        final Environment environment = configuration.getEnvironment();</span><br><span class=\"line\">        final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);</span><br><span class=\"line\">        tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);</span><br><span class=\"line\">        //创建执行器</span><br><span class=\"line\">        final Executor executor = configuration.newExecutor(tx, execType);</span><br><span class=\"line\">        return new DefaultSqlSession(configuration, executor, autoCommit);</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">        closeTransaction(tx); // may have fetched a connection so lets call close()</span><br><span class=\"line\">        throw ExceptionFactory.wrapException(&quot;Error opening session.  Cause: &quot; + e, e);</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        ErrorContext.instance().reset();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"创建执行器\"><a href=\"#创建执行器\" class=\"headerlink\" title=\"创建执行器\"></a>创建执行器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123;</span><br><span class=\"line\">    executorType = executorType == null ? defaultExecutorType : executorType;</span><br><span class=\"line\">    executorType = executorType == null ? ExecutorType.SIMPLE : executorType;</span><br><span class=\"line\">    Executor executor;</span><br><span class=\"line\">    if (ExecutorType.BATCH == executorType) &#123;</span><br><span class=\"line\">      executor = new BatchExecutor(this, transaction);</span><br><span class=\"line\">    &#125; else if (ExecutorType.REUSE == executorType) &#123;</span><br><span class=\"line\">      executor = new ReuseExecutor(this, transaction);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      executor = new SimpleExecutor(this, transaction);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (cacheEnabled) &#123;</span><br><span class=\"line\">      executor = new CachingExecutor(executor);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //进行interceptorChain的执行</span><br><span class=\"line\">    executor = (Executor) interceptorChain.pluginAll(executor);</span><br><span class=\"line\">    return executor;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"拦截器链的执行\"><a href=\"#拦截器链的执行\" class=\"headerlink\" title=\"拦截器链的执行\"></a>拦截器链的执行</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Object pluginAll(Object target) &#123;</span><br><span class=\"line\">    for (Interceptor interceptor : interceptors) &#123;</span><br><span class=\"line\">      target = interceptor.plugin(target);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return target;</span><br><span class=\"line\">  &#125;  </span><br><span class=\"line\">  </span><br><span class=\"line\">自定义分页拦截器</span><br><span class=\"line\">@Intercepts(&#123; @Signature(type = StatementHandler.class, method = &quot;prepare&quot;, args = &#123; Connection.class, Integer.class &#125;) &#125;)</span><br><span class=\"line\">public class PaginationInterceptor implements Interceptor &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    //需要重写interceptor接口的plugin方法  </span><br><span class=\"line\">    public Object plugin(Object target) &#123;</span><br><span class=\"line\">        //Plugin.java 实现了 InvocationHandler 接口，看的出也是 Java 动态代理，调用其静态方法 wrap:</span><br><span class=\"line\">        return Plugin.wrap(target, this);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//为statementHandler 对象生成代理对象</span><br><span class=\"line\">public static Object wrap(Object target, Interceptor interceptor) &#123;</span><br><span class=\"line\">    Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor);</span><br><span class=\"line\">    Class&lt;?&gt; type = target.getClass();</span><br><span class=\"line\">    Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap);</span><br><span class=\"line\">    if (interfaces.length &gt; 0) &#123;</span><br><span class=\"line\">      return Proxy.newProxyInstance(</span><br><span class=\"line\">          type.getClassLoader(),</span><br><span class=\"line\">          interfaces,</span><br><span class=\"line\">          new Plugin(target, interceptor, signatureMap));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return target;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\">则为 target 生成代理对象最后当在 DefaultSqlSession 中执行具体执行时，如 selectList 方法中, 此时的 executor 是刚刚生成的代理对象</span><br><span class=\"line\">  return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\">executor 调用的方法就会执行 Plugin 重写的 invoke 方法：</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;</span><br><span class=\"line\">try &#123;</span><br><span class=\"line\">  Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass());</span><br><span class=\"line\">  if (methods != null &amp;&amp; methods.contains(method)) &#123;</span><br><span class=\"line\">    //拦截器的 intercept 方法执行</span><br><span class=\"line\">    return interceptor.intercept(new Invocation(target, method, args));</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  //真正的方法执行</span><br><span class=\"line\">  return method.invoke(target, args);</span><br><span class=\"line\">&#125; catch (Exception e) &#123;</span><br><span class=\"line\">  throw ExceptionUtil.unwrapThrowable(e);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>总结：实现拦截器，需要实现Interceptor接口，并实现其plugin、和intercept两个方法</p>\n<p><a href=\"https://cloud.tencent.com/developer/article/1498525\" target=\"_blank\" rel=\"noopener\">参考博客</a></p>\n<h1 id=\"六、-和-的区别是什么\"><a href=\"#六、-和-的区别是什么\" class=\"headerlink\" title=\"六、#{}和${}的区别是什么\"></a>六、#{}和${}的区别是什么</h1><p>（1）mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PreparedStatement ps = conn.prepareStatement(sql);</span><br><span class=\"line\">ps.setInt(1,id);</span><br></pre></td></tr></table></figure>\n\n<p>（2）mybatis在处理${}时，就是把${}替换成变量的值。</p>\n<p>（3）使用#{}可以有效的防止SQL注入，提高系统安全性。原因在于：预编译机制。预编译完成之后，SQL的结构已经固定，即便用户输入非法参数，也不会对SQL的结构产生影响，从而避免了潜在的安全风险。</p>\n<p>（4）预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。</p>\n<h1 id=\"五、\"><a href=\"#五、\" class=\"headerlink\" title=\"五、\"></a>五、</h1>","site":{"data":{}},"excerpt":"<h1 id=\"一、配置\"><a href=\"#一、配置\" class=\"headerlink\" title=\"一、配置\"></a>一、配置</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;!-- MyBatis配置 --&gt;</span><br><span class=\"line\">&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;</span><br><span class=\"line\">    &lt;!-- 配置数据源 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;dataSource&quot; ref=&quot;shardingDataSource&quot;/&gt;</span><br><span class=\"line\">    &lt;!-- 配置Mybatis配置文件 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;configLocation&quot; value=&quot;classpath:/mybatis/mybatis-config.xml&quot;/&gt;</span><br><span class=\"line\">    &lt;!-- 配置别名包路径 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.general.trade.entity&quot;/&gt;</span><br><span class=\"line\">    &lt;!-- 配置Mapper扫描路径 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:/mybatis/mapper/**/**Mapper.xml&quot;/&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;!-- mapper的扫描 --&gt;</span><br><span class=\"line\">&lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;</span><br><span class=\"line\">    &lt;property name=&quot;basePackage&quot; value=&quot;com.order.center.server.dao.mapper&quot;/&gt;</span><br><span class=\"line\">    &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure>","more":"<h1 id=\"二、启动过程\"><a href=\"#二、启动过程\" class=\"headerlink\" title=\"二、启动过程\"></a>二、启动过程</h1><h2 id=\"1-SqlSessionFactoryBean实现\"><a href=\"#1-SqlSessionFactoryBean实现\" class=\"headerlink\" title=\"1. SqlSessionFactoryBean实现\"></a>1. SqlSessionFactoryBean实现</h2><p>spring启动过程中，会生成SqlSessionFactoryBean对象。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt;</span><br></pre></td></tr></table></figure>\n\n<p>SqlSessionFactoryBean实现了InitializingBean接口，在初始化会调用afterPropertiesSet()方法。</p>\n<h2 id=\"2-afterPropertiesSet\"><a href=\"#2-afterPropertiesSet\" class=\"headerlink\" title=\"2. afterPropertiesSet()\"></a>2. afterPropertiesSet()</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void afterPropertiesSet() throws Exception &#123;</span><br><span class=\"line\">    this.sqlSessionFactory = buildSqlSessionFactory();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-buildSqlSessionFactory\"><a href=\"#3-buildSqlSessionFactory\" class=\"headerlink\" title=\"3. buildSqlSessionFactory()\"></a>3. buildSqlSessionFactory()</h2><blockquote>\n<p>在SqlSessionFactoryBean的实例化过程中：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected SqlSessionFactory buildSqlSessionFactory() throws IOException &#123;</span><br><span class=\"line\">    Configuration configuration;</span><br><span class=\"line\">    //1. 读取文件</span><br><span class=\"line\">    xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties);</span><br><span class=\"line\">    //2. 解析mybatis-config.xml文件，解析配置文件的各个节点，解析的结果保存到configuration对象中</span><br><span class=\"line\">    xmlConfigBuilder.parse();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>文件的具体解析工作</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Configuration parse() &#123;</span><br><span class=\"line\">    if (parsed) &#123;</span><br><span class=\"line\">      throw new BuilderException(&quot;Each XMLConfigBuilder can only be used once.&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    parsed = true;</span><br><span class=\"line\">    parseConfiguration(parser.evalNode(&quot;/configuration&quot;));</span><br><span class=\"line\">    return configuration;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  private void parseConfiguration(XNode root) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">      //issue #117 read properties first</span><br><span class=\"line\">      propertiesElement(root.evalNode(&quot;properties&quot;));</span><br><span class=\"line\">      Properties settings = settingsAsProperties(root.evalNode(&quot;settings&quot;));</span><br><span class=\"line\">      loadCustomVfs(settings);</span><br><span class=\"line\">      typeAliasesElement(root.evalNode(&quot;typeAliases&quot;));</span><br><span class=\"line\">      pluginElement(root.evalNode(&quot;plugins&quot;));</span><br><span class=\"line\">      objectFactoryElement(root.evalNode(&quot;objectFactory&quot;));</span><br><span class=\"line\">      objectWrapperFactoryElement(root.evalNode(&quot;objectWrapperFactory&quot;));</span><br><span class=\"line\">      reflectorFactoryElement(root.evalNode(&quot;reflectorFactory&quot;));</span><br><span class=\"line\">      settingsElement(settings);</span><br><span class=\"line\">      // read it after objectFactory and objectWrapperFactory issue #631</span><br><span class=\"line\">      environmentsElement(root.evalNode(&quot;environments&quot;));</span><br><span class=\"line\">      databaseIdProviderElement(root.evalNode(&quot;databaseIdProvider&quot;));</span><br><span class=\"line\">      typeHandlerElement(root.evalNode(&quot;typeHandlers&quot;));</span><br><span class=\"line\">      //解析mapper文件</span><br><span class=\"line\">      mapperElement(root.evalNode(&quot;mappers&quot;));</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">      throw new BuilderException(&quot;Error parsing SQL Mapper Configuration. Cause: &quot; + e, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>此时所有的配置文件就已经解析完成了，解析内容会放入到Configuration对象内。</p>\n<blockquote>\n<p>占位符的替换工作</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//解析文件中的占位符</span><br><span class=\"line\">//&lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;</span><br><span class=\"line\">//&lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url1&#125;&quot; /&gt;</span><br><span class=\"line\">//&lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username1&#125;&quot; /&gt;</span><br><span class=\"line\">//&lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password1&#125;&quot; /&gt;</span><br><span class=\"line\">public class PropertyParser &#123;</span><br><span class=\"line\">    public static String parse(String string, Properties variables) &#123;</span><br><span class=\"line\">        VariableTokenHandler handler = new VariableTokenHandler(variables);</span><br><span class=\"line\">        GenericTokenParser parser = new GenericTokenParser(&quot;$&#123;&quot;, &quot;&#125;&quot;, handler);</span><br><span class=\"line\">        return parser.parse(string);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"三、MapperScannerConfigurer扫描过程\"><a href=\"#三、MapperScannerConfigurer扫描过程\" class=\"headerlink\" title=\"三、MapperScannerConfigurer扫描过程\"></a>三、MapperScannerConfigurer扫描过程</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    //实现BeanDefinitionRegistryPostProcessor，在BeanFactoryPostProcessor初始化执行时会进行调用</span><br><span class=\"line\">    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123;</span><br><span class=\"line\">        if (this.processPropertyPlaceHolders) &#123;</span><br><span class=\"line\">          processPropertyPlaceHolders();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry);</span><br><span class=\"line\">        scanner.setAddToConfig(this.addToConfig);</span><br><span class=\"line\">        scanner.setAnnotationClass(this.annotationClass);</span><br><span class=\"line\">        scanner.setMarkerInterface(this.markerInterface);</span><br><span class=\"line\">        scanner.setSqlSessionFactory(this.sqlSessionFactory);</span><br><span class=\"line\">        scanner.setSqlSessionTemplate(this.sqlSessionTemplate);</span><br><span class=\"line\">        scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName);</span><br><span class=\"line\">        scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName);</span><br><span class=\"line\">        scanner.setResourceLoader(this.applicationContext);</span><br><span class=\"line\">        scanner.setBeanNameGenerator(this.nameGenerator);</span><br><span class=\"line\">        scanner.registerFilters();</span><br><span class=\"line\">        //进行扫描，扫描指定路径下的接口</span><br><span class=\"line\">        scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后我们看下ClassPathMapperScanner中的关键是如何扫描对应package下的接口的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123;</span><br><span class=\"line\">    //扫描路径下的接口生成BeanDefinitionHolder</span><br><span class=\"line\">    Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages);</span><br><span class=\"line\">    if (beanDefinitions.isEmpty()) &#123;</span><br><span class=\"line\">      logger.warn(&quot;No MyBatis mapper was found in &apos;&quot; + Arrays.toString(basePackages) + &quot;&apos; package. Please check your configuration.&quot;);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        //进行beanDefinition的处理</span><br><span class=\"line\">        processBeanDefinitions(beanDefinitions);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return beanDefinitions;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123;</span><br><span class=\"line\">    GenericBeanDefinition definition;</span><br><span class=\"line\">    for (BeanDefinitionHolder holder : beanDefinitions) &#123;</span><br><span class=\"line\">        definition = (GenericBeanDefinition) holder.getBeanDefinition();</span><br><span class=\"line\">        // the mapper interface is the original class of the bean</span><br><span class=\"line\">        // but, the actual class of the bean is MapperFactoryBean</span><br><span class=\"line\">        //其实MapperScannerConfigurer的作用也就是将对应的接口的类型改造为MapperFactoryBean，</span><br><span class=\"line\">        definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); // issue #59</span><br><span class=\"line\">        definition.setBeanClass(this.mapperFactoryBean.getClass());</span><br><span class=\"line\">        .....</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>其实MapperScannerConfigurer的作用也就是将对应的接口的类型改造为MapperFactoryBean。</p>\n<h1 id=\"四、MapperFactoryBean原理\"><a href=\"#四、MapperFactoryBean原理\" class=\"headerlink\" title=\"四、MapperFactoryBean原理\"></a>四、MapperFactoryBean原理</h1><p>MapperFactoryBean继承了SqlSessionDaoSupport类，SqlSessionDaoSupport类继承DaoSupport抽象类，DaoSupport抽象类实现了InitializingBean接口，<br>因此实例个MapperFactoryBean的时候，都会调用InitializingBean接口的afterPropertiesSet方法。</p>\n<p>DaoSupport的afterPropertiesSet方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public final void afterPropertiesSet() throws IllegalArgumentException, BeanInitializationException &#123;</span><br><span class=\"line\">    // Let abstract subclasses check their configuration.</span><br><span class=\"line\">    checkDaoConfig();</span><br><span class=\"line\"></span><br><span class=\"line\">    // Let concrete implementations initialize themselves.</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        initDao();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    catch (Exception ex) &#123;</span><br><span class=\"line\">        throw new BeanInitializationException(&quot;Initialization of DAO failed&quot;, ex);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>MapperFactoryBean重写了checkDaoConfig方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void checkDaoConfig() &#123;</span><br><span class=\"line\">    super.checkDaoConfig();</span><br><span class=\"line\">    notNull(this.mapperInterface, &quot;Property &apos;mapperInterface&apos; is required&quot;);</span><br><span class=\"line\">    Configuration configuration = getSqlSession().getConfiguration();</span><br><span class=\"line\">    if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) &#123;</span><br><span class=\"line\">      try &#123;</span><br><span class=\"line\">        //mapperInterface是否存在configuration内，不存在就放入</span><br><span class=\"line\">        configuration.addMapper(this.mapperInterface);</span><br><span class=\"line\">      &#125; catch (Exception e) &#123;</span><br><span class=\"line\">        logger.error(&quot;Error while adding the mapper &apos;&quot; + this.mapperInterface + &quot;&apos; to configuration.&quot;, e);</span><br><span class=\"line\">        throw new IllegalArgumentException(e);</span><br><span class=\"line\">      &#125; finally &#123;</span><br><span class=\"line\">        ErrorContext.instance().reset();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>然后通过spring工厂拿对应的bean的时候：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public T getObject() throws Exception &#123;</span><br><span class=\"line\">    return getSqlSession().getMapper(this.mapperInterface);</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>继续往下，DefaultSqlSession</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123;</span><br><span class=\"line\">   return configuration.&lt;T&gt;getMapper(type, this);</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n\n<p>MapperRegistry的getMapper方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123;</span><br><span class=\"line\">    final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type);</span><br><span class=\"line\">    if (mapperProxyFactory == null) &#123;</span><br><span class=\"line\">      throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">      return mapperProxyFactory.newInstance(sqlSession);</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">      throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>MapperProxyFactory构造MapperProxy：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123;</span><br><span class=\"line\">    return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>MapperProxyFactory使用了jdk组带的Proxy完成动态代理。</strong><br><strong>MapperProxy内部使用了MapperMethod类完成方法的调用</strong></p>\n<p>MapperProxy的执行过程：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//实现了InvocationHandler，说明使用了jdk自带的动态代理。</span><br><span class=\"line\">public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123;</span><br><span class=\"line\">  private static final long serialVersionUID = -6424540398559729838L;</span><br><span class=\"line\">  private final SqlSession sqlSession;</span><br><span class=\"line\">  private final Class&lt;T&gt; mapperInterface;</span><br><span class=\"line\">  private final Map&lt;Method, MapperMethod&gt; methodCache;</span><br><span class=\"line\"></span><br><span class=\"line\">  public MapperProxy(SqlSession sqlSession, Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123;</span><br><span class=\"line\">    this.sqlSession = sqlSession;</span><br><span class=\"line\">    this.mapperInterface = mapperInterface;</span><br><span class=\"line\">    this.methodCache = methodCache;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  @Override</span><br><span class=\"line\">  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">      if (Object.class.equals(method.getDeclaringClass())) &#123;</span><br><span class=\"line\">        return method.invoke(this, args);</span><br><span class=\"line\">      &#125; else if (isDefaultMethod(method)) &#123;</span><br><span class=\"line\">        return invokeDefaultMethod(proxy, method, args);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">      throw ExceptionUtil.unwrapThrowable(t);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    final MapperMethod mapperMethod = cachedMapperMethod(method);</span><br><span class=\"line\">    return mapperMethod.execute(sqlSession, args);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>invoke方法的执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Object execute(SqlSession sqlSession, Object[] args) &#123;</span><br><span class=\"line\">    Object result;</span><br><span class=\"line\">    switch (command.getType()) &#123;</span><br><span class=\"line\">      case INSERT: &#123;</span><br><span class=\"line\">    \tObject param = method.convertArgsToSqlCommandParam(args);</span><br><span class=\"line\">        result = rowCountResult(sqlSession.insert(command.getName(), param));</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      case UPDATE: &#123;</span><br><span class=\"line\">        Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class=\"line\">        result = rowCountResult(sqlSession.update(command.getName(), param));</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      case DELETE: &#123;</span><br><span class=\"line\">        Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class=\"line\">        result = rowCountResult(sqlSession.delete(command.getName(), param));</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      case SELECT:</span><br><span class=\"line\">        if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123;</span><br><span class=\"line\">          executeWithResultHandler(sqlSession, args);</span><br><span class=\"line\">          result = null;</span><br><span class=\"line\">        &#125; else if (method.returnsMany()) &#123;</span><br><span class=\"line\">          result = executeForMany(sqlSession, args);</span><br><span class=\"line\">        &#125; else if (method.returnsMap()) &#123;</span><br><span class=\"line\">          result = executeForMap(sqlSession, args);</span><br><span class=\"line\">        &#125; else if (method.returnsCursor()) &#123;</span><br><span class=\"line\">          result = executeForCursor(sqlSession, args);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">          Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class=\"line\">          result = sqlSession.selectOne(command.getName(), param);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case FLUSH:</span><br><span class=\"line\">        result = sqlSession.flushStatements();</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      default:</span><br><span class=\"line\">        throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123;</span><br><span class=\"line\">      throw new BindingException(&quot;Mapper method &apos;&quot; + command.getName() </span><br><span class=\"line\">          + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return result;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"五、使用\"><a href=\"#五、使用\" class=\"headerlink\" title=\"五、使用\"></a>五、使用</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//获取与数据库相关的会话(实际并未进行连接)</span><br><span class=\"line\">SqlSession sqlSession = sqlSessionFactory.openSession();//DefaultSqlSessionFactory</span><br><span class=\"line\">//获取对应的映射接口对象</span><br><span class=\"line\">//4. 使用SqlSession创建Dao接口的代理对象</span><br><span class=\"line\">IUserDao userMapper = sqlSession.getMapper(IUserDao.class);</span><br><span class=\"line\">//5. 使用代理对象执行方法</span><br><span class=\"line\">List&lt;User&gt; users = userMapper.findAll();</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"sqlSessionFactory-openSession-原理\"><a href=\"#sqlSessionFactory-openSession-原理\" class=\"headerlink\" title=\"sqlSessionFactory.openSession()原理\"></a>sqlSessionFactory.openSession()原理</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SqlSessionFactoryBean，此步会将所有的plugins添加到interceptorChain内</span><br><span class=\"line\">if (!isEmpty(this.plugins)) &#123;</span><br><span class=\"line\">  for (Interceptor plugin : this.plugins) &#123;</span><br><span class=\"line\">    configuration.addInterceptor(plugin);</span><br><span class=\"line\">    if (LOGGER.isDebugEnabled()) &#123;</span><br><span class=\"line\">      LOGGER.debug(&quot;Registered plugin: &apos;&quot; + plugin + &quot;&apos;&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@Override</span><br><span class=\"line\">public SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level) &#123;</span><br><span class=\"line\">    return openSessionFromDataSource(execType, level, false);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123;</span><br><span class=\"line\">    Transaction tx = null;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        final Environment environment = configuration.getEnvironment();</span><br><span class=\"line\">        final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);</span><br><span class=\"line\">        tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);</span><br><span class=\"line\">        //创建执行器</span><br><span class=\"line\">        final Executor executor = configuration.newExecutor(tx, execType);</span><br><span class=\"line\">        return new DefaultSqlSession(configuration, executor, autoCommit);</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">        closeTransaction(tx); // may have fetched a connection so lets call close()</span><br><span class=\"line\">        throw ExceptionFactory.wrapException(&quot;Error opening session.  Cause: &quot; + e, e);</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        ErrorContext.instance().reset();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"创建执行器\"><a href=\"#创建执行器\" class=\"headerlink\" title=\"创建执行器\"></a>创建执行器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123;</span><br><span class=\"line\">    executorType = executorType == null ? defaultExecutorType : executorType;</span><br><span class=\"line\">    executorType = executorType == null ? ExecutorType.SIMPLE : executorType;</span><br><span class=\"line\">    Executor executor;</span><br><span class=\"line\">    if (ExecutorType.BATCH == executorType) &#123;</span><br><span class=\"line\">      executor = new BatchExecutor(this, transaction);</span><br><span class=\"line\">    &#125; else if (ExecutorType.REUSE == executorType) &#123;</span><br><span class=\"line\">      executor = new ReuseExecutor(this, transaction);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      executor = new SimpleExecutor(this, transaction);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (cacheEnabled) &#123;</span><br><span class=\"line\">      executor = new CachingExecutor(executor);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //进行interceptorChain的执行</span><br><span class=\"line\">    executor = (Executor) interceptorChain.pluginAll(executor);</span><br><span class=\"line\">    return executor;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"拦截器链的执行\"><a href=\"#拦截器链的执行\" class=\"headerlink\" title=\"拦截器链的执行\"></a>拦截器链的执行</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Object pluginAll(Object target) &#123;</span><br><span class=\"line\">    for (Interceptor interceptor : interceptors) &#123;</span><br><span class=\"line\">      target = interceptor.plugin(target);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return target;</span><br><span class=\"line\">  &#125;  </span><br><span class=\"line\">  </span><br><span class=\"line\">自定义分页拦截器</span><br><span class=\"line\">@Intercepts(&#123; @Signature(type = StatementHandler.class, method = &quot;prepare&quot;, args = &#123; Connection.class, Integer.class &#125;) &#125;)</span><br><span class=\"line\">public class PaginationInterceptor implements Interceptor &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    //需要重写interceptor接口的plugin方法  </span><br><span class=\"line\">    public Object plugin(Object target) &#123;</span><br><span class=\"line\">        //Plugin.java 实现了 InvocationHandler 接口，看的出也是 Java 动态代理，调用其静态方法 wrap:</span><br><span class=\"line\">        return Plugin.wrap(target, this);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//为statementHandler 对象生成代理对象</span><br><span class=\"line\">public static Object wrap(Object target, Interceptor interceptor) &#123;</span><br><span class=\"line\">    Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor);</span><br><span class=\"line\">    Class&lt;?&gt; type = target.getClass();</span><br><span class=\"line\">    Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap);</span><br><span class=\"line\">    if (interfaces.length &gt; 0) &#123;</span><br><span class=\"line\">      return Proxy.newProxyInstance(</span><br><span class=\"line\">          type.getClassLoader(),</span><br><span class=\"line\">          interfaces,</span><br><span class=\"line\">          new Plugin(target, interceptor, signatureMap));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return target;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\">则为 target 生成代理对象最后当在 DefaultSqlSession 中执行具体执行时，如 selectList 方法中, 此时的 executor 是刚刚生成的代理对象</span><br><span class=\"line\">  return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\">executor 调用的方法就会执行 Plugin 重写的 invoke 方法：</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;</span><br><span class=\"line\">try &#123;</span><br><span class=\"line\">  Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass());</span><br><span class=\"line\">  if (methods != null &amp;&amp; methods.contains(method)) &#123;</span><br><span class=\"line\">    //拦截器的 intercept 方法执行</span><br><span class=\"line\">    return interceptor.intercept(new Invocation(target, method, args));</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  //真正的方法执行</span><br><span class=\"line\">  return method.invoke(target, args);</span><br><span class=\"line\">&#125; catch (Exception e) &#123;</span><br><span class=\"line\">  throw ExceptionUtil.unwrapThrowable(e);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>总结：实现拦截器，需要实现Interceptor接口，并实现其plugin、和intercept两个方法</p>\n<p><a href=\"https://cloud.tencent.com/developer/article/1498525\" target=\"_blank\" rel=\"noopener\">参考博客</a></p>\n<h1 id=\"六、-和-的区别是什么\"><a href=\"#六、-和-的区别是什么\" class=\"headerlink\" title=\"六、#{}和${}的区别是什么\"></a>六、#{}和${}的区别是什么</h1><p>（1）mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PreparedStatement ps = conn.prepareStatement(sql);</span><br><span class=\"line\">ps.setInt(1,id);</span><br></pre></td></tr></table></figure>\n\n<p>（2）mybatis在处理${}时，就是把${}替换成变量的值。</p>\n<p>（3）使用#{}可以有效的防止SQL注入，提高系统安全性。原因在于：预编译机制。预编译完成之后，SQL的结构已经固定，即便用户输入非法参数，也不会对SQL的结构产生影响，从而避免了潜在的安全风险。</p>\n<p>（4）预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。</p>\n<h1 id=\"五、\"><a href=\"#五、\" class=\"headerlink\" title=\"五、\"></a>五、</h1>"},{"title":"《架构》常见架构","date":"2024-08-25T02:00:00.000Z","_content":"\n### 一、常见系统架构模式\n\n#### 1.1、单体架构\n单体架构比较初级，典型的三级架构，前端+中间业务逻辑层+数据库层。这是一种典型的Java Spring mvc框架的应用。其架构图如下所示：\n![系统架构-单体架构](2024-08-25-架构-常见架构/系统架构-单体架构.png)\n\n<!--more-->\n#### 1.2、分布式架构\n是单体架构的并发扩展，将一个大的系统划分为多个业务模块，业务模块分别部署在不同的服务器上，各个业务模块之间通过接口进行数据交互。\n![系统架构-分布式架构](2024-08-25-架构-常见架构/系统架构-分布式架构.png)\n结构特点：\n- 服务拆分：系统被分解为多个独立的服务，每个服务专注于特定的业务功能。\n- 数据拆分：\n- 网络通信：服务之间通过网络进行通信，常见的通信协议包括 RESTful API（基于 HTTP）、RPC（远程过程调用）、消息队列等。\n\n#### 1.3、微服务架构\n微服务架构是一种将单块应用程序拆分成一组小型服务的架构风格。\n\n> Tips:分布式架构和微服务架构有什么区别呢？\n> - 联系：\n>   - 架构理念相似：都强调将系统的功能进行拆分，通过多个组件的协作来完成系统的功能。\n>   - 都涉及网络通信\n>   - 都注重系统的可扩展性\n> - 区别：\n>   - 拆分程度和粒度：\n>     - 分布式架构：拆分的程度相对较粗，可能是将系统按照功能模块、业务领域或者物理部署环境等方式进行划分。\n>     - 微服务架构：拆分的粒度更细，强调每个微服务专注于单一的业务功能。\n>   - 服务独立性和自治性：\n>     - 分布式架构：虽然各个分布式组件之间是相互独立的，但在某些情况下可能还会共享一些资源或者依赖关系。例如，分布式系统中的多个组件可能共享一个数据库，或者某个组件的运行可能依赖于另一个组件的特定状态。\n>     - 微服务架构：微服务具有更高的独立性和自治性。每个微服务有自己独立的业务逻辑、数据存储和开发团队，它们之间的耦合度更低。\n>   - 架构复杂度和管理难度：\n>     - 分布式架构：复杂度主要体现在分布式系统的基础设施方面，如网络通信、数据分布和一致性、节点故障处理等。\n>     - 微服务架构：除了面临分布式系统的一般问题外，还增加了服务治理的复杂性。需要解决微服务之间的服务发现、配置管理、负载均衡等问题。\n\n#### 1.4、Serverless\n\n\n### 二、常见应用架构模式\n\n#### 2.1、MVC\nMVC模式最主要精神之一就是Model与View的分离，这两者之间的分离可使网页设计人员和程序开发人员能够独立工作、互不影响，从而提高了开发效率和维护效率。除此之外，将模型层的数据处理建立成许多组件，增加了程序的可复用性、增进了系统功能的可扩展性；将业务流程集中在控制层，增强了程序流程的清晰度.\n\n##### 2.1.1、View (视图） 层\n为用户提供使用界面，与用户直接进行交互。\n\n<!--more-->\n\n##### 2.1.2、Model（模型） 层\n代表一个存取数据的对象或 JAVA POJO（Plain Old Java Object，简单java对象）。它也可以带有逻辑，主要用于承载数据，并对用户提交请求进行计算的模块。模型分为两类，一类称为数据承载 Bean，一类称为业务处理Bean。所谓数据承载 Bean 是指实体类（如：User类），专门为用户承载业务数据的；而业务处理 Bean 则是指Service 或 Dao 对象， 专门用于处理用户提交请求的。\n\n##### 2.1.3、Controller（控制器） 层\n用于将用户请求转发给相应的 Model 进行处理，并根据 Model 的计算结果向用户提供相应响应。它使视图与模型分离。\n\n![MVC架构工作流程](2024-08-25-架构-常见架构/MVC架构工作流程.png)\n常见的前后端分离架构就是采用MVC架构（但是后端应用一般还会和三层架构组合一起）。\n\n### 2.2、三层架构\n我们常说的三层架构是由JavaWeb提出的，也就是说这是JavaWeb独有的！ 所谓三层是表现层（WEB层）、业务逻辑层（Business Logic），以及数据访问层（Data Access）。 开发中更多的是用到三层架构。\n\n三层架构就是为了符合“高内聚，低耦合”思想，把各个功能模块划分为表示层（UI）、业务逻辑层（BLL）和数据访问层（DAL）三层架构。\n![三层架构](2024-08-25-架构-常见架构/三层架构.png)\n这个就是我们开发过程中常见的架构模式。\n\n### 2.3、MVC和三层架构的联系与区别\n![MVC和三层架构的联系与区别](2024-08-25-架构-常见架构/MVC和三层架构的联系与区别.png)\n\n\n三层架构的缺点：\n- 业务逻辑分散： 在三层架构中，业务逻辑往往分散在不同的层中，导致业务流程难以理清，影响了代码的可读性和可维护性。\n- 领域模型贫血： 三层架构中，领域逻辑和数据存储混合在一起，导致领域模型的业务方法受限，难以表达复杂的业务规则。\n- 过度依赖数据存储： 不同层之间对数据存储的依赖紧密，当切换数据存储介质时，需要大量修改代码。\n\n随着业务的不断复杂化，service层变得越来越庞大，服务之间的引用也变得越来越混乱，这为项目带来了风险和不确定性。","source":"_posts/2024-08-25-架构-常见架构.md","raw":"---\ntitle: 《架构》常见架构\ndate: 2024-08-25 10:00:00\ncategories:\n  - [架构]\n---\n\n### 一、常见系统架构模式\n\n#### 1.1、单体架构\n单体架构比较初级，典型的三级架构，前端+中间业务逻辑层+数据库层。这是一种典型的Java Spring mvc框架的应用。其架构图如下所示：\n![系统架构-单体架构](2024-08-25-架构-常见架构/系统架构-单体架构.png)\n\n<!--more-->\n#### 1.2、分布式架构\n是单体架构的并发扩展，将一个大的系统划分为多个业务模块，业务模块分别部署在不同的服务器上，各个业务模块之间通过接口进行数据交互。\n![系统架构-分布式架构](2024-08-25-架构-常见架构/系统架构-分布式架构.png)\n结构特点：\n- 服务拆分：系统被分解为多个独立的服务，每个服务专注于特定的业务功能。\n- 数据拆分：\n- 网络通信：服务之间通过网络进行通信，常见的通信协议包括 RESTful API（基于 HTTP）、RPC（远程过程调用）、消息队列等。\n\n#### 1.3、微服务架构\n微服务架构是一种将单块应用程序拆分成一组小型服务的架构风格。\n\n> Tips:分布式架构和微服务架构有什么区别呢？\n> - 联系：\n>   - 架构理念相似：都强调将系统的功能进行拆分，通过多个组件的协作来完成系统的功能。\n>   - 都涉及网络通信\n>   - 都注重系统的可扩展性\n> - 区别：\n>   - 拆分程度和粒度：\n>     - 分布式架构：拆分的程度相对较粗，可能是将系统按照功能模块、业务领域或者物理部署环境等方式进行划分。\n>     - 微服务架构：拆分的粒度更细，强调每个微服务专注于单一的业务功能。\n>   - 服务独立性和自治性：\n>     - 分布式架构：虽然各个分布式组件之间是相互独立的，但在某些情况下可能还会共享一些资源或者依赖关系。例如，分布式系统中的多个组件可能共享一个数据库，或者某个组件的运行可能依赖于另一个组件的特定状态。\n>     - 微服务架构：微服务具有更高的独立性和自治性。每个微服务有自己独立的业务逻辑、数据存储和开发团队，它们之间的耦合度更低。\n>   - 架构复杂度和管理难度：\n>     - 分布式架构：复杂度主要体现在分布式系统的基础设施方面，如网络通信、数据分布和一致性、节点故障处理等。\n>     - 微服务架构：除了面临分布式系统的一般问题外，还增加了服务治理的复杂性。需要解决微服务之间的服务发现、配置管理、负载均衡等问题。\n\n#### 1.4、Serverless\n\n\n### 二、常见应用架构模式\n\n#### 2.1、MVC\nMVC模式最主要精神之一就是Model与View的分离，这两者之间的分离可使网页设计人员和程序开发人员能够独立工作、互不影响，从而提高了开发效率和维护效率。除此之外，将模型层的数据处理建立成许多组件，增加了程序的可复用性、增进了系统功能的可扩展性；将业务流程集中在控制层，增强了程序流程的清晰度.\n\n##### 2.1.1、View (视图） 层\n为用户提供使用界面，与用户直接进行交互。\n\n<!--more-->\n\n##### 2.1.2、Model（模型） 层\n代表一个存取数据的对象或 JAVA POJO（Plain Old Java Object，简单java对象）。它也可以带有逻辑，主要用于承载数据，并对用户提交请求进行计算的模块。模型分为两类，一类称为数据承载 Bean，一类称为业务处理Bean。所谓数据承载 Bean 是指实体类（如：User类），专门为用户承载业务数据的；而业务处理 Bean 则是指Service 或 Dao 对象， 专门用于处理用户提交请求的。\n\n##### 2.1.3、Controller（控制器） 层\n用于将用户请求转发给相应的 Model 进行处理，并根据 Model 的计算结果向用户提供相应响应。它使视图与模型分离。\n\n![MVC架构工作流程](2024-08-25-架构-常见架构/MVC架构工作流程.png)\n常见的前后端分离架构就是采用MVC架构（但是后端应用一般还会和三层架构组合一起）。\n\n### 2.2、三层架构\n我们常说的三层架构是由JavaWeb提出的，也就是说这是JavaWeb独有的！ 所谓三层是表现层（WEB层）、业务逻辑层（Business Logic），以及数据访问层（Data Access）。 开发中更多的是用到三层架构。\n\n三层架构就是为了符合“高内聚，低耦合”思想，把各个功能模块划分为表示层（UI）、业务逻辑层（BLL）和数据访问层（DAL）三层架构。\n![三层架构](2024-08-25-架构-常见架构/三层架构.png)\n这个就是我们开发过程中常见的架构模式。\n\n### 2.3、MVC和三层架构的联系与区别\n![MVC和三层架构的联系与区别](2024-08-25-架构-常见架构/MVC和三层架构的联系与区别.png)\n\n\n三层架构的缺点：\n- 业务逻辑分散： 在三层架构中，业务逻辑往往分散在不同的层中，导致业务流程难以理清，影响了代码的可读性和可维护性。\n- 领域模型贫血： 三层架构中，领域逻辑和数据存储混合在一起，导致领域模型的业务方法受限，难以表达复杂的业务规则。\n- 过度依赖数据存储： 不同层之间对数据存储的依赖紧密，当切换数据存储介质时，需要大量修改代码。\n\n随着业务的不断复杂化，service层变得越来越庞大，服务之间的引用也变得越来越混乱，这为项目带来了风险和不确定性。","slug":"2024-08-25-架构-常见架构","published":1,"updated":"2024-11-29T09:24:51.709Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyb005ka13ka1bax7a0","content":"<h3 id=\"一、常见系统架构模式\"><a href=\"#一、常见系统架构模式\" class=\"headerlink\" title=\"一、常见系统架构模式\"></a>一、常见系统架构模式</h3><h4 id=\"1-1、单体架构\"><a href=\"#1-1、单体架构\" class=\"headerlink\" title=\"1.1、单体架构\"></a>1.1、单体架构</h4><p>单体架构比较初级，典型的三级架构，前端+中间业务逻辑层+数据库层。这是一种典型的Java Spring mvc框架的应用。其架构图如下所示：<br><img src=\"/2024/08/25/2024-08-25-架构-常见架构/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84-%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84.png\" alt=\"系统架构-单体架构\"></p>\n<a id=\"more\"></a>\n<h4 id=\"1-2、分布式架构\"><a href=\"#1-2、分布式架构\" class=\"headerlink\" title=\"1.2、分布式架构\"></a>1.2、分布式架构</h4><p>是单体架构的并发扩展，将一个大的系统划分为多个业务模块，业务模块分别部署在不同的服务器上，各个业务模块之间通过接口进行数据交互。<br><img src=\"/2024/08/25/2024-08-25-架构-常见架构/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.png\" alt=\"系统架构-分布式架构\"><br>结构特点：</p>\n<ul>\n<li>服务拆分：系统被分解为多个独立的服务，每个服务专注于特定的业务功能。</li>\n<li>数据拆分：</li>\n<li>网络通信：服务之间通过网络进行通信，常见的通信协议包括 RESTful API（基于 HTTP）、RPC（远程过程调用）、消息队列等。</li>\n</ul>\n<h4 id=\"1-3、微服务架构\"><a href=\"#1-3、微服务架构\" class=\"headerlink\" title=\"1.3、微服务架构\"></a>1.3、微服务架构</h4><p>微服务架构是一种将单块应用程序拆分成一组小型服务的架构风格。</p>\n<blockquote>\n<p>Tips:分布式架构和微服务架构有什么区别呢？</p>\n<ul>\n<li>联系：<ul>\n<li>架构理念相似：都强调将系统的功能进行拆分，通过多个组件的协作来完成系统的功能。</li>\n<li>都涉及网络通信</li>\n<li>都注重系统的可扩展性</li>\n</ul>\n</li>\n<li>区别：<ul>\n<li>拆分程度和粒度：<ul>\n<li>分布式架构：拆分的程度相对较粗，可能是将系统按照功能模块、业务领域或者物理部署环境等方式进行划分。</li>\n<li>微服务架构：拆分的粒度更细，强调每个微服务专注于单一的业务功能。</li>\n</ul>\n</li>\n<li>服务独立性和自治性：<ul>\n<li>分布式架构：虽然各个分布式组件之间是相互独立的，但在某些情况下可能还会共享一些资源或者依赖关系。例如，分布式系统中的多个组件可能共享一个数据库，或者某个组件的运行可能依赖于另一个组件的特定状态。</li>\n<li>微服务架构：微服务具有更高的独立性和自治性。每个微服务有自己独立的业务逻辑、数据存储和开发团队，它们之间的耦合度更低。</li>\n</ul>\n</li>\n<li>架构复杂度和管理难度：<ul>\n<li>分布式架构：复杂度主要体现在分布式系统的基础设施方面，如网络通信、数据分布和一致性、节点故障处理等。</li>\n<li>微服务架构：除了面临分布式系统的一般问题外，还增加了服务治理的复杂性。需要解决微服务之间的服务发现、配置管理、负载均衡等问题。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h4 id=\"1-4、Serverless\"><a href=\"#1-4、Serverless\" class=\"headerlink\" title=\"1.4、Serverless\"></a>1.4、Serverless</h4><h3 id=\"二、常见应用架构模式\"><a href=\"#二、常见应用架构模式\" class=\"headerlink\" title=\"二、常见应用架构模式\"></a>二、常见应用架构模式</h3><h4 id=\"2-1、MVC\"><a href=\"#2-1、MVC\" class=\"headerlink\" title=\"2.1、MVC\"></a>2.1、MVC</h4><p>MVC模式最主要精神之一就是Model与View的分离，这两者之间的分离可使网页设计人员和程序开发人员能够独立工作、互不影响，从而提高了开发效率和维护效率。除此之外，将模型层的数据处理建立成许多组件，增加了程序的可复用性、增进了系统功能的可扩展性；将业务流程集中在控制层，增强了程序流程的清晰度.</p>\n<h5 id=\"2-1-1、View-视图）-层\"><a href=\"#2-1-1、View-视图）-层\" class=\"headerlink\" title=\"2.1.1、View (视图） 层\"></a>2.1.1、View (视图） 层</h5><p>为用户提供使用界面，与用户直接进行交互。</p>\n<!--more-->\n\n<h5 id=\"2-1-2、Model（模型）-层\"><a href=\"#2-1-2、Model（模型）-层\" class=\"headerlink\" title=\"2.1.2、Model（模型） 层\"></a>2.1.2、Model（模型） 层</h5><p>代表一个存取数据的对象或 JAVA POJO（Plain Old Java Object，简单java对象）。它也可以带有逻辑，主要用于承载数据，并对用户提交请求进行计算的模块。模型分为两类，一类称为数据承载 Bean，一类称为业务处理Bean。所谓数据承载 Bean 是指实体类（如：User类），专门为用户承载业务数据的；而业务处理 Bean 则是指Service 或 Dao 对象， 专门用于处理用户提交请求的。</p>\n<h5 id=\"2-1-3、Controller（控制器）-层\"><a href=\"#2-1-3、Controller（控制器）-层\" class=\"headerlink\" title=\"2.1.3、Controller（控制器） 层\"></a>2.1.3、Controller（控制器） 层</h5><p>用于将用户请求转发给相应的 Model 进行处理，并根据 Model 的计算结果向用户提供相应响应。它使视图与模型分离。</p>\n<p><img src=\"/2024/08/25/2024-08-25-架构-常见架构/MVC%E6%9E%B6%E6%9E%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png\" alt=\"MVC架构工作流程\"><br>常见的前后端分离架构就是采用MVC架构（但是后端应用一般还会和三层架构组合一起）。</p>\n<h3 id=\"2-2、三层架构\"><a href=\"#2-2、三层架构\" class=\"headerlink\" title=\"2.2、三层架构\"></a>2.2、三层架构</h3><p>我们常说的三层架构是由JavaWeb提出的，也就是说这是JavaWeb独有的！ 所谓三层是表现层（WEB层）、业务逻辑层（Business Logic），以及数据访问层（Data Access）。 开发中更多的是用到三层架构。</p>\n<p>三层架构就是为了符合“高内聚，低耦合”思想，把各个功能模块划分为表示层（UI）、业务逻辑层（BLL）和数据访问层（DAL）三层架构。<br><img src=\"/2024/08/25/2024-08-25-架构-常见架构/%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84.png\" alt=\"三层架构\"><br>这个就是我们开发过程中常见的架构模式。</p>\n<h3 id=\"2-3、MVC和三层架构的联系与区别\"><a href=\"#2-3、MVC和三层架构的联系与区别\" class=\"headerlink\" title=\"2.3、MVC和三层架构的联系与区别\"></a>2.3、MVC和三层架构的联系与区别</h3><p><img src=\"/2024/08/25/2024-08-25-架构-常见架构/MVC%E5%92%8C%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84%E7%9A%84%E8%81%94%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB.png\" alt=\"MVC和三层架构的联系与区别\"></p>\n<p>三层架构的缺点：</p>\n<ul>\n<li>业务逻辑分散： 在三层架构中，业务逻辑往往分散在不同的层中，导致业务流程难以理清，影响了代码的可读性和可维护性。</li>\n<li>领域模型贫血： 三层架构中，领域逻辑和数据存储混合在一起，导致领域模型的业务方法受限，难以表达复杂的业务规则。</li>\n<li>过度依赖数据存储： 不同层之间对数据存储的依赖紧密，当切换数据存储介质时，需要大量修改代码。</li>\n</ul>\n<p>随着业务的不断复杂化，service层变得越来越庞大，服务之间的引用也变得越来越混乱，这为项目带来了风险和不确定性。</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、常见系统架构模式\"><a href=\"#一、常见系统架构模式\" class=\"headerlink\" title=\"一、常见系统架构模式\"></a>一、常见系统架构模式</h3><h4 id=\"1-1、单体架构\"><a href=\"#1-1、单体架构\" class=\"headerlink\" title=\"1.1、单体架构\"></a>1.1、单体架构</h4><p>单体架构比较初级，典型的三级架构，前端+中间业务逻辑层+数据库层。这是一种典型的Java Spring mvc框架的应用。其架构图如下所示：<br><img src=\"/2024/08/25/2024-08-25-架构-常见架构/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84-%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84.png\" alt=\"系统架构-单体架构\"></p>","more":"<h4 id=\"1-2、分布式架构\"><a href=\"#1-2、分布式架构\" class=\"headerlink\" title=\"1.2、分布式架构\"></a>1.2、分布式架构</h4><p>是单体架构的并发扩展，将一个大的系统划分为多个业务模块，业务模块分别部署在不同的服务器上，各个业务模块之间通过接口进行数据交互。<br><img src=\"/2024/08/25/2024-08-25-架构-常见架构/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.png\" alt=\"系统架构-分布式架构\"><br>结构特点：</p>\n<ul>\n<li>服务拆分：系统被分解为多个独立的服务，每个服务专注于特定的业务功能。</li>\n<li>数据拆分：</li>\n<li>网络通信：服务之间通过网络进行通信，常见的通信协议包括 RESTful API（基于 HTTP）、RPC（远程过程调用）、消息队列等。</li>\n</ul>\n<h4 id=\"1-3、微服务架构\"><a href=\"#1-3、微服务架构\" class=\"headerlink\" title=\"1.3、微服务架构\"></a>1.3、微服务架构</h4><p>微服务架构是一种将单块应用程序拆分成一组小型服务的架构风格。</p>\n<blockquote>\n<p>Tips:分布式架构和微服务架构有什么区别呢？</p>\n<ul>\n<li>联系：<ul>\n<li>架构理念相似：都强调将系统的功能进行拆分，通过多个组件的协作来完成系统的功能。</li>\n<li>都涉及网络通信</li>\n<li>都注重系统的可扩展性</li>\n</ul>\n</li>\n<li>区别：<ul>\n<li>拆分程度和粒度：<ul>\n<li>分布式架构：拆分的程度相对较粗，可能是将系统按照功能模块、业务领域或者物理部署环境等方式进行划分。</li>\n<li>微服务架构：拆分的粒度更细，强调每个微服务专注于单一的业务功能。</li>\n</ul>\n</li>\n<li>服务独立性和自治性：<ul>\n<li>分布式架构：虽然各个分布式组件之间是相互独立的，但在某些情况下可能还会共享一些资源或者依赖关系。例如，分布式系统中的多个组件可能共享一个数据库，或者某个组件的运行可能依赖于另一个组件的特定状态。</li>\n<li>微服务架构：微服务具有更高的独立性和自治性。每个微服务有自己独立的业务逻辑、数据存储和开发团队，它们之间的耦合度更低。</li>\n</ul>\n</li>\n<li>架构复杂度和管理难度：<ul>\n<li>分布式架构：复杂度主要体现在分布式系统的基础设施方面，如网络通信、数据分布和一致性、节点故障处理等。</li>\n<li>微服务架构：除了面临分布式系统的一般问题外，还增加了服务治理的复杂性。需要解决微服务之间的服务发现、配置管理、负载均衡等问题。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h4 id=\"1-4、Serverless\"><a href=\"#1-4、Serverless\" class=\"headerlink\" title=\"1.4、Serverless\"></a>1.4、Serverless</h4><h3 id=\"二、常见应用架构模式\"><a href=\"#二、常见应用架构模式\" class=\"headerlink\" title=\"二、常见应用架构模式\"></a>二、常见应用架构模式</h3><h4 id=\"2-1、MVC\"><a href=\"#2-1、MVC\" class=\"headerlink\" title=\"2.1、MVC\"></a>2.1、MVC</h4><p>MVC模式最主要精神之一就是Model与View的分离，这两者之间的分离可使网页设计人员和程序开发人员能够独立工作、互不影响，从而提高了开发效率和维护效率。除此之外，将模型层的数据处理建立成许多组件，增加了程序的可复用性、增进了系统功能的可扩展性；将业务流程集中在控制层，增强了程序流程的清晰度.</p>\n<h5 id=\"2-1-1、View-视图）-层\"><a href=\"#2-1-1、View-视图）-层\" class=\"headerlink\" title=\"2.1.1、View (视图） 层\"></a>2.1.1、View (视图） 层</h5><p>为用户提供使用界面，与用户直接进行交互。</p>\n<!--more-->\n\n<h5 id=\"2-1-2、Model（模型）-层\"><a href=\"#2-1-2、Model（模型）-层\" class=\"headerlink\" title=\"2.1.2、Model（模型） 层\"></a>2.1.2、Model（模型） 层</h5><p>代表一个存取数据的对象或 JAVA POJO（Plain Old Java Object，简单java对象）。它也可以带有逻辑，主要用于承载数据，并对用户提交请求进行计算的模块。模型分为两类，一类称为数据承载 Bean，一类称为业务处理Bean。所谓数据承载 Bean 是指实体类（如：User类），专门为用户承载业务数据的；而业务处理 Bean 则是指Service 或 Dao 对象， 专门用于处理用户提交请求的。</p>\n<h5 id=\"2-1-3、Controller（控制器）-层\"><a href=\"#2-1-3、Controller（控制器）-层\" class=\"headerlink\" title=\"2.1.3、Controller（控制器） 层\"></a>2.1.3、Controller（控制器） 层</h5><p>用于将用户请求转发给相应的 Model 进行处理，并根据 Model 的计算结果向用户提供相应响应。它使视图与模型分离。</p>\n<p><img src=\"/2024/08/25/2024-08-25-架构-常见架构/MVC%E6%9E%B6%E6%9E%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png\" alt=\"MVC架构工作流程\"><br>常见的前后端分离架构就是采用MVC架构（但是后端应用一般还会和三层架构组合一起）。</p>\n<h3 id=\"2-2、三层架构\"><a href=\"#2-2、三层架构\" class=\"headerlink\" title=\"2.2、三层架构\"></a>2.2、三层架构</h3><p>我们常说的三层架构是由JavaWeb提出的，也就是说这是JavaWeb独有的！ 所谓三层是表现层（WEB层）、业务逻辑层（Business Logic），以及数据访问层（Data Access）。 开发中更多的是用到三层架构。</p>\n<p>三层架构就是为了符合“高内聚，低耦合”思想，把各个功能模块划分为表示层（UI）、业务逻辑层（BLL）和数据访问层（DAL）三层架构。<br><img src=\"/2024/08/25/2024-08-25-架构-常见架构/%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84.png\" alt=\"三层架构\"><br>这个就是我们开发过程中常见的架构模式。</p>\n<h3 id=\"2-3、MVC和三层架构的联系与区别\"><a href=\"#2-3、MVC和三层架构的联系与区别\" class=\"headerlink\" title=\"2.3、MVC和三层架构的联系与区别\"></a>2.3、MVC和三层架构的联系与区别</h3><p><img src=\"/2024/08/25/2024-08-25-架构-常见架构/MVC%E5%92%8C%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84%E7%9A%84%E8%81%94%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB.png\" alt=\"MVC和三层架构的联系与区别\"></p>\n<p>三层架构的缺点：</p>\n<ul>\n<li>业务逻辑分散： 在三层架构中，业务逻辑往往分散在不同的层中，导致业务流程难以理清，影响了代码的可读性和可维护性。</li>\n<li>领域模型贫血： 三层架构中，领域逻辑和数据存储混合在一起，导致领域模型的业务方法受限，难以表达复杂的业务规则。</li>\n<li>过度依赖数据存储： 不同层之间对数据存储的依赖紧密，当切换数据存储介质时，需要大量修改代码。</li>\n</ul>\n<p>随着业务的不断复杂化，service层变得越来越庞大，服务之间的引用也变得越来越混乱，这为项目带来了风险和不确定性。</p>"},{"title":"《架构》DDD实施过程","date":"2024-09-10T02:00:00.000Z","_content":"\n### 一、DDD实施过程？\n\n![DDD完整设计流程](2024-09-10-架构-DDD实施过程/DDD完整设计流程.png)\n\n<!--more-->\n\n1. 首先第一步，根据业务诉求， 提炼出整体的业务流程 ，同时拆解出里面的关键事件，角色，参与者等核心实例。\n   1. 整个拆解和梳理的方法论：目前业界有一些比较成熟的，比如事件风暴，四色建模法等，后面单独讲。\n2. 提炼完整个业务流程后，进入战略设计阶段，这个阶段主要是从全局和顶层的视角， 把整个业务语义转换为结构化分层 。通过领域和子域的划分，同时结合通用域、支撑域、限界上下文等设计，分解问题复杂度，其实就是前面说到的“分而治之”的思想。\n3. 接下来就会到具体的战术设计阶段，通过前面的战略设计阶段，已经把整个领域、边界、上下文等关键模块都梳理完成，现在就是从各个域中再次拆解更细粒度的模块，去指导最终的编码实现，这些更细粒度的模块包括实体、聚合、聚合根等。\n4. 最后就到了编码实现阶段，DDD有一个关键价值，叫做“ 设计即实现 ”，所以在战术阶段的设计，理论上是可以直接作用于代码的分层结构，如果架构和战术阶段有出入，说明之前的设计有问题，可以复盘重新推演。\n\n#### 步骤1：提炼业务流程\n通用语言（Ubiquitous language）是指在软件设计中，业务人员和开发人员需要使用无歧义的统一语言来对话。\n\n这些语言包括对概念的统一理解和定义，以及业务人员参与到软件建模中，否则业务的变化会造成软件巨大的变化。\n\n方法论：\n- 事件风暴\n- 四色建模法\n\n#### 步骤2：战略设计\n侧重于高层次、宏观上去划分和集成限界上下文。\n\n战略建模（包含概念）：领域（Domain）、核心域、子域、界限上下文（Bounded Context）、上下文映射图（Context Mapping）。\n\n战略设计结果**示例**如下：\n![商品领域](2024-09-10-架构-DDD实施过程/商品领域.png)\n> 首先，在商品领域中，商品是核心域，并对应一个商品上下文，库存被设计为一个通用子域，因为以后交易的业务场景会被用到，并对应一个库存上下文，品牌通用子域也一样，业务场景可能会对品牌的单独处理（比如品牌街，这是和商品不想关的），所以设计成通用子域会相对好些，分类支撑子域和属性子域相对复杂点，其实这里的分类和属性都是相对于商品而言的，你可以成为商品分类和商品属性，独立于商品之外，分类和属性是没有任何存在的业务意义的，所以，把它们设计为商品领域的支撑子域会比较好些。\n\n\n#### 步骤3：战术设计\n梳理清楚上下文之间的关系后，细化上下文，我们需要从战术层面上剖析上下文内部的组织关系，进行建模。首先看下DDD中的一些定义。\n\n战术建模（包含概念）：聚合（Aggregate）、实体（Entity）、值对象（Value Objects）、资源库（Repository）、领域服务（Domain Services）、领域事件（Domain Events）、模块（Modules）。\n\n战术设计结果示例如下：\n![商品数据模型图](2024-09-10-架构-DDD实施过程/商品数据模型图.png)\n\n**示例 ：** 最后得到的结果可以是如下的：\n![战略战术结果](2024-09-10-架构-DDD实施过程/战略战术结果.png)\n\n\n#### 步骤4：编码实现阶段\nDDD工程实现，在对上下文进行细化后，我们开始在工程中真正落地DDD。\n\n##### 4.1、确定代码的分层架构\n传统架构上，我们一般会使用MVC+三层架构，进行构建应用的代码结构。随着代码和业务的复杂度增加，三层结构存在业务逻辑分散问题，可以通过分层架构、清晰架构来解决业务逻辑分散问题。\n\n![分层架构_代码指示](2024-09-10-架构-DDD实施过程/分层架构_代码指示.png)\n\n\n### 二、总结\n![实施总结](2024-09-10-架构-DDD实施过程/实施总结.png)\n\n\n\n参考文章：\n[DDD 概念参考](https://domain-driven-design.org/zh/ddd-concept-reference.html)        \n[DDD领域驱动设计理论](https://tech.dewu.com/article?id=113)      \n","source":"_posts/2024-09-10-架构-DDD实施过程.md","raw":"---\ntitle: 《架构》DDD实施过程\ndate: 2024-09-10 10:00:00\ncategories:\n  - [架构, DDD]\n---\n\n### 一、DDD实施过程？\n\n![DDD完整设计流程](2024-09-10-架构-DDD实施过程/DDD完整设计流程.png)\n\n<!--more-->\n\n1. 首先第一步，根据业务诉求， 提炼出整体的业务流程 ，同时拆解出里面的关键事件，角色，参与者等核心实例。\n   1. 整个拆解和梳理的方法论：目前业界有一些比较成熟的，比如事件风暴，四色建模法等，后面单独讲。\n2. 提炼完整个业务流程后，进入战略设计阶段，这个阶段主要是从全局和顶层的视角， 把整个业务语义转换为结构化分层 。通过领域和子域的划分，同时结合通用域、支撑域、限界上下文等设计，分解问题复杂度，其实就是前面说到的“分而治之”的思想。\n3. 接下来就会到具体的战术设计阶段，通过前面的战略设计阶段，已经把整个领域、边界、上下文等关键模块都梳理完成，现在就是从各个域中再次拆解更细粒度的模块，去指导最终的编码实现，这些更细粒度的模块包括实体、聚合、聚合根等。\n4. 最后就到了编码实现阶段，DDD有一个关键价值，叫做“ 设计即实现 ”，所以在战术阶段的设计，理论上是可以直接作用于代码的分层结构，如果架构和战术阶段有出入，说明之前的设计有问题，可以复盘重新推演。\n\n#### 步骤1：提炼业务流程\n通用语言（Ubiquitous language）是指在软件设计中，业务人员和开发人员需要使用无歧义的统一语言来对话。\n\n这些语言包括对概念的统一理解和定义，以及业务人员参与到软件建模中，否则业务的变化会造成软件巨大的变化。\n\n方法论：\n- 事件风暴\n- 四色建模法\n\n#### 步骤2：战略设计\n侧重于高层次、宏观上去划分和集成限界上下文。\n\n战略建模（包含概念）：领域（Domain）、核心域、子域、界限上下文（Bounded Context）、上下文映射图（Context Mapping）。\n\n战略设计结果**示例**如下：\n![商品领域](2024-09-10-架构-DDD实施过程/商品领域.png)\n> 首先，在商品领域中，商品是核心域，并对应一个商品上下文，库存被设计为一个通用子域，因为以后交易的业务场景会被用到，并对应一个库存上下文，品牌通用子域也一样，业务场景可能会对品牌的单独处理（比如品牌街，这是和商品不想关的），所以设计成通用子域会相对好些，分类支撑子域和属性子域相对复杂点，其实这里的分类和属性都是相对于商品而言的，你可以成为商品分类和商品属性，独立于商品之外，分类和属性是没有任何存在的业务意义的，所以，把它们设计为商品领域的支撑子域会比较好些。\n\n\n#### 步骤3：战术设计\n梳理清楚上下文之间的关系后，细化上下文，我们需要从战术层面上剖析上下文内部的组织关系，进行建模。首先看下DDD中的一些定义。\n\n战术建模（包含概念）：聚合（Aggregate）、实体（Entity）、值对象（Value Objects）、资源库（Repository）、领域服务（Domain Services）、领域事件（Domain Events）、模块（Modules）。\n\n战术设计结果示例如下：\n![商品数据模型图](2024-09-10-架构-DDD实施过程/商品数据模型图.png)\n\n**示例 ：** 最后得到的结果可以是如下的：\n![战略战术结果](2024-09-10-架构-DDD实施过程/战略战术结果.png)\n\n\n#### 步骤4：编码实现阶段\nDDD工程实现，在对上下文进行细化后，我们开始在工程中真正落地DDD。\n\n##### 4.1、确定代码的分层架构\n传统架构上，我们一般会使用MVC+三层架构，进行构建应用的代码结构。随着代码和业务的复杂度增加，三层结构存在业务逻辑分散问题，可以通过分层架构、清晰架构来解决业务逻辑分散问题。\n\n![分层架构_代码指示](2024-09-10-架构-DDD实施过程/分层架构_代码指示.png)\n\n\n### 二、总结\n![实施总结](2024-09-10-架构-DDD实施过程/实施总结.png)\n\n\n\n参考文章：\n[DDD 概念参考](https://domain-driven-design.org/zh/ddd-concept-reference.html)        \n[DDD领域驱动设计理论](https://tech.dewu.com/article?id=113)      \n","slug":"2024-09-10-架构-DDD实施过程","published":1,"updated":"2024-12-03T03:13:55.191Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyb005na13ksd8qmmff","content":"<h3 id=\"一、DDD实施过程？\"><a href=\"#一、DDD实施过程？\" class=\"headerlink\" title=\"一、DDD实施过程？\"></a>一、DDD实施过程？</h3><p><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/DDD%E5%AE%8C%E6%95%B4%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B.png\" alt=\"DDD完整设计流程\"></p>\n<a id=\"more\"></a>\n\n<ol>\n<li>首先第一步，根据业务诉求， 提炼出整体的业务流程 ，同时拆解出里面的关键事件，角色，参与者等核心实例。<ol>\n<li>整个拆解和梳理的方法论：目前业界有一些比较成熟的，比如事件风暴，四色建模法等，后面单独讲。</li>\n</ol>\n</li>\n<li>提炼完整个业务流程后，进入战略设计阶段，这个阶段主要是从全局和顶层的视角， 把整个业务语义转换为结构化分层 。通过领域和子域的划分，同时结合通用域、支撑域、限界上下文等设计，分解问题复杂度，其实就是前面说到的“分而治之”的思想。</li>\n<li>接下来就会到具体的战术设计阶段，通过前面的战略设计阶段，已经把整个领域、边界、上下文等关键模块都梳理完成，现在就是从各个域中再次拆解更细粒度的模块，去指导最终的编码实现，这些更细粒度的模块包括实体、聚合、聚合根等。</li>\n<li>最后就到了编码实现阶段，DDD有一个关键价值，叫做“ 设计即实现 ”，所以在战术阶段的设计，理论上是可以直接作用于代码的分层结构，如果架构和战术阶段有出入，说明之前的设计有问题，可以复盘重新推演。</li>\n</ol>\n<h4 id=\"步骤1：提炼业务流程\"><a href=\"#步骤1：提炼业务流程\" class=\"headerlink\" title=\"步骤1：提炼业务流程\"></a>步骤1：提炼业务流程</h4><p>通用语言（Ubiquitous language）是指在软件设计中，业务人员和开发人员需要使用无歧义的统一语言来对话。</p>\n<p>这些语言包括对概念的统一理解和定义，以及业务人员参与到软件建模中，否则业务的变化会造成软件巨大的变化。</p>\n<p>方法论：</p>\n<ul>\n<li>事件风暴</li>\n<li>四色建模法</li>\n</ul>\n<h4 id=\"步骤2：战略设计\"><a href=\"#步骤2：战略设计\" class=\"headerlink\" title=\"步骤2：战略设计\"></a>步骤2：战略设计</h4><p>侧重于高层次、宏观上去划分和集成限界上下文。</p>\n<p>战略建模（包含概念）：领域（Domain）、核心域、子域、界限上下文（Bounded Context）、上下文映射图（Context Mapping）。</p>\n<p>战略设计结果<strong>示例</strong>如下：<br><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E5%95%86%E5%93%81%E9%A2%86%E5%9F%9F.png\" alt=\"商品领域\"></p>\n<blockquote>\n<p>首先，在商品领域中，商品是核心域，并对应一个商品上下文，库存被设计为一个通用子域，因为以后交易的业务场景会被用到，并对应一个库存上下文，品牌通用子域也一样，业务场景可能会对品牌的单独处理（比如品牌街，这是和商品不想关的），所以设计成通用子域会相对好些，分类支撑子域和属性子域相对复杂点，其实这里的分类和属性都是相对于商品而言的，你可以成为商品分类和商品属性，独立于商品之外，分类和属性是没有任何存在的业务意义的，所以，把它们设计为商品领域的支撑子域会比较好些。</p>\n</blockquote>\n<h4 id=\"步骤3：战术设计\"><a href=\"#步骤3：战术设计\" class=\"headerlink\" title=\"步骤3：战术设计\"></a>步骤3：战术设计</h4><p>梳理清楚上下文之间的关系后，细化上下文，我们需要从战术层面上剖析上下文内部的组织关系，进行建模。首先看下DDD中的一些定义。</p>\n<p>战术建模（包含概念）：聚合（Aggregate）、实体（Entity）、值对象（Value Objects）、资源库（Repository）、领域服务（Domain Services）、领域事件（Domain Events）、模块（Modules）。</p>\n<p>战术设计结果示例如下：<br><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E5%95%86%E5%93%81%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%9B%BE.png\" alt=\"商品数据模型图\"></p>\n<p><strong>示例 ：</strong> 最后得到的结果可以是如下的：<br><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E6%88%98%E7%95%A5%E6%88%98%E6%9C%AF%E7%BB%93%E6%9E%9C.png\" alt=\"战略战术结果\"></p>\n<h4 id=\"步骤4：编码实现阶段\"><a href=\"#步骤4：编码实现阶段\" class=\"headerlink\" title=\"步骤4：编码实现阶段\"></a>步骤4：编码实现阶段</h4><p>DDD工程实现，在对上下文进行细化后，我们开始在工程中真正落地DDD。</p>\n<h5 id=\"4-1、确定代码的分层架构\"><a href=\"#4-1、确定代码的分层架构\" class=\"headerlink\" title=\"4.1、确定代码的分层架构\"></a>4.1、确定代码的分层架构</h5><p>传统架构上，我们一般会使用MVC+三层架构，进行构建应用的代码结构。随着代码和业务的复杂度增加，三层结构存在业务逻辑分散问题，可以通过分层架构、清晰架构来解决业务逻辑分散问题。</p>\n<p><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84_%E4%BB%A3%E7%A0%81%E6%8C%87%E7%A4%BA.png\" alt=\"分层架构_代码指示\"></p>\n<h3 id=\"二、总结\"><a href=\"#二、总结\" class=\"headerlink\" title=\"二、总结\"></a>二、总结</h3><p><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E5%AE%9E%E6%96%BD%E6%80%BB%E7%BB%93.png\" alt=\"实施总结\"></p>\n<p>参考文章：<br><a href=\"https://domain-driven-design.org/zh/ddd-concept-reference.html\" target=\"_blank\" rel=\"noopener\">DDD 概念参考</a><br><a href=\"https://tech.dewu.com/article?id=113\" target=\"_blank\" rel=\"noopener\">DDD领域驱动设计理论</a>      </p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、DDD实施过程？\"><a href=\"#一、DDD实施过程？\" class=\"headerlink\" title=\"一、DDD实施过程？\"></a>一、DDD实施过程？</h3><p><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/DDD%E5%AE%8C%E6%95%B4%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B.png\" alt=\"DDD完整设计流程\"></p>","more":"<ol>\n<li>首先第一步，根据业务诉求， 提炼出整体的业务流程 ，同时拆解出里面的关键事件，角色，参与者等核心实例。<ol>\n<li>整个拆解和梳理的方法论：目前业界有一些比较成熟的，比如事件风暴，四色建模法等，后面单独讲。</li>\n</ol>\n</li>\n<li>提炼完整个业务流程后，进入战略设计阶段，这个阶段主要是从全局和顶层的视角， 把整个业务语义转换为结构化分层 。通过领域和子域的划分，同时结合通用域、支撑域、限界上下文等设计，分解问题复杂度，其实就是前面说到的“分而治之”的思想。</li>\n<li>接下来就会到具体的战术设计阶段，通过前面的战略设计阶段，已经把整个领域、边界、上下文等关键模块都梳理完成，现在就是从各个域中再次拆解更细粒度的模块，去指导最终的编码实现，这些更细粒度的模块包括实体、聚合、聚合根等。</li>\n<li>最后就到了编码实现阶段，DDD有一个关键价值，叫做“ 设计即实现 ”，所以在战术阶段的设计，理论上是可以直接作用于代码的分层结构，如果架构和战术阶段有出入，说明之前的设计有问题，可以复盘重新推演。</li>\n</ol>\n<h4 id=\"步骤1：提炼业务流程\"><a href=\"#步骤1：提炼业务流程\" class=\"headerlink\" title=\"步骤1：提炼业务流程\"></a>步骤1：提炼业务流程</h4><p>通用语言（Ubiquitous language）是指在软件设计中，业务人员和开发人员需要使用无歧义的统一语言来对话。</p>\n<p>这些语言包括对概念的统一理解和定义，以及业务人员参与到软件建模中，否则业务的变化会造成软件巨大的变化。</p>\n<p>方法论：</p>\n<ul>\n<li>事件风暴</li>\n<li>四色建模法</li>\n</ul>\n<h4 id=\"步骤2：战略设计\"><a href=\"#步骤2：战略设计\" class=\"headerlink\" title=\"步骤2：战略设计\"></a>步骤2：战略设计</h4><p>侧重于高层次、宏观上去划分和集成限界上下文。</p>\n<p>战略建模（包含概念）：领域（Domain）、核心域、子域、界限上下文（Bounded Context）、上下文映射图（Context Mapping）。</p>\n<p>战略设计结果<strong>示例</strong>如下：<br><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E5%95%86%E5%93%81%E9%A2%86%E5%9F%9F.png\" alt=\"商品领域\"></p>\n<blockquote>\n<p>首先，在商品领域中，商品是核心域，并对应一个商品上下文，库存被设计为一个通用子域，因为以后交易的业务场景会被用到，并对应一个库存上下文，品牌通用子域也一样，业务场景可能会对品牌的单独处理（比如品牌街，这是和商品不想关的），所以设计成通用子域会相对好些，分类支撑子域和属性子域相对复杂点，其实这里的分类和属性都是相对于商品而言的，你可以成为商品分类和商品属性，独立于商品之外，分类和属性是没有任何存在的业务意义的，所以，把它们设计为商品领域的支撑子域会比较好些。</p>\n</blockquote>\n<h4 id=\"步骤3：战术设计\"><a href=\"#步骤3：战术设计\" class=\"headerlink\" title=\"步骤3：战术设计\"></a>步骤3：战术设计</h4><p>梳理清楚上下文之间的关系后，细化上下文，我们需要从战术层面上剖析上下文内部的组织关系，进行建模。首先看下DDD中的一些定义。</p>\n<p>战术建模（包含概念）：聚合（Aggregate）、实体（Entity）、值对象（Value Objects）、资源库（Repository）、领域服务（Domain Services）、领域事件（Domain Events）、模块（Modules）。</p>\n<p>战术设计结果示例如下：<br><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E5%95%86%E5%93%81%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%9B%BE.png\" alt=\"商品数据模型图\"></p>\n<p><strong>示例 ：</strong> 最后得到的结果可以是如下的：<br><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E6%88%98%E7%95%A5%E6%88%98%E6%9C%AF%E7%BB%93%E6%9E%9C.png\" alt=\"战略战术结果\"></p>\n<h4 id=\"步骤4：编码实现阶段\"><a href=\"#步骤4：编码实现阶段\" class=\"headerlink\" title=\"步骤4：编码实现阶段\"></a>步骤4：编码实现阶段</h4><p>DDD工程实现，在对上下文进行细化后，我们开始在工程中真正落地DDD。</p>\n<h5 id=\"4-1、确定代码的分层架构\"><a href=\"#4-1、确定代码的分层架构\" class=\"headerlink\" title=\"4.1、确定代码的分层架构\"></a>4.1、确定代码的分层架构</h5><p>传统架构上，我们一般会使用MVC+三层架构，进行构建应用的代码结构。随着代码和业务的复杂度增加，三层结构存在业务逻辑分散问题，可以通过分层架构、清晰架构来解决业务逻辑分散问题。</p>\n<p><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84_%E4%BB%A3%E7%A0%81%E6%8C%87%E7%A4%BA.png\" alt=\"分层架构_代码指示\"></p>\n<h3 id=\"二、总结\"><a href=\"#二、总结\" class=\"headerlink\" title=\"二、总结\"></a>二、总结</h3><p><img src=\"/2024/09/10/2024-09-10-架构-DDD实施过程/%E5%AE%9E%E6%96%BD%E6%80%BB%E7%BB%93.png\" alt=\"实施总结\"></p>\n<p>参考文章：<br><a href=\"https://domain-driven-design.org/zh/ddd-concept-reference.html\" target=\"_blank\" rel=\"noopener\">DDD 概念参考</a><br><a href=\"https://tech.dewu.com/article?id=113\" target=\"_blank\" rel=\"noopener\">DDD领域驱动设计理论</a>      </p>"},{"title":"《架构》基础知识（三高）","date":"2024-08-21T02:00:00.000Z","_content":"\n### 一、基础概念\n在软件设计中，“三高” 是高并发（High - Concurrency）、高性能（High - Performance）、高可用（High - Availability），它们是构建高质量软件系统的关键目标。\n<!--more-->\n\n#### 1.1、高并发（High - Concurrency）\n高并发(High Concurrency)通常是指系统能够同时并行处理很多请求。一般用响应时间、并发吞吐量TPS, 并发用户数等指标来衡量。\n\n<details style=\"background-color: #dbdbdb;padding: 10px;\">\n<summary>▲ 点击查看“并发&并行”相关定义</summary>\n\n##### 什么是并发？\n并发是指在<font color=#e98787>**一段时间内**</font>，多个任务交替执行。\n> 并发的关键在于 “同时处理多个任务” 的外在表现，但在计算机系统的实际执行层面，特别是在**单核处理器**环境下，由于物理资源的限制（同一时刻只有一个核心能够执行指令），这些任务无法真正在同一时刻被执行。所以，通过操作系统的调度机制，让这些任务在一段时间内看起来像是同时在执行，这就形成了交替运行的情况。\n\n##### 什么是并行？\n并行是指在<font color=#e98787>**同一时刻**</font>，多个任务真正地同时执行。\n\n**并发&并行的区别与联系**\n- 区别\n  - **执行时间：** 并发是多个任务在一段时间内交替执行，同一时刻只有一个任务在执行；而并行是多个任务在同一时刻真正地同时执行。例如，并发的多个任务就像在单车道的道路上多辆车交替行驶；而并行的多个任务则像在多车道的高速公路上多辆车同时行驶。\n  - **硬件要求：** 并发可以在单处理器（CPU）系统中实现，通过操作系统的调度机制来实现任务的交替执行；而并行需要多个处理器（CPU）或多核处理器来支持，每个任务在不同的处理器或核心上运行。\n  - **性能提升方式：** 并发主要是通过充分利用等待时间（如 I/O 等待）来提高系统的整体效率；并行则是通过同时利用多个计算资源来加速任务的完成。例如，并发在处理 I/O 密集型任务时效果显著；而并行在处理计算密集型任务时优势明显。\n- 联系\n  - **目的相同：** 并发和并行的目的都是为了提高系统的处理能力和效率，以应对多个任务同时存在的情况。\n  - **可以结合使用：** 在实际的系统设计中，常常会将并发和并行结合使用。例如，在一个多核服务器上，通过多线程并发地处理多个任务，并且每个线程在不同的核心上实现并行执行，从而最大限度地发挥系统的性能。\n</details>\n\n##### 1.1.1、高并发的度量指标\n并发的指标一般有QPS、TPS、IOPS，这几个指标都是可归为系统吞吐率，QPS越高系统能hold住的请求数越多，但光关注这几个指标不够，我们还需要关注RT，即响应时间，也就是从发出request到收到response的时延，这个指标跟吞吐往往是此消彼长的，我们追求的是一定时延下的高吞吐。\n![并发度公式](2024-08-21-架构-三高/并发度公式.png)\n比如有100万次请求，99万次请求都在10毫秒内响应，其他次数10秒才响应，平均时延不高，但时延高的用户受不了，所以，就有了TP90/TP99指标，这个指标不是求平均，而是把时延从小到大排序，取排名90%/99%的时延，**这个指标越大，对慢请求越敏感。**\n\n> TP90: 表示在所有的请求响应时间数据中，按照响应时间从小到大排序后，取排在 90% 位置的响应时间值。例如，有 100 个请求的响应时间数据，将它们排序后，第 90 个数据对应的响应时间就是 TP90。\n\n##### 1.1.2、高并发的设计思路\n高并发的设计思路有两个方向：\n1. 垂直方向扩展，也叫竖向扩展\n2. 水平方向扩展，也叫横向扩展\n\n**垂直方向：** 提升单机能力（提升单机处理能力又可分为硬件和软件两个方面）\n- 硬件方向，很好理解，花钱升级机器，更多核更高主频更大存储空间更多带宽\n- 软件方向，包括用各快的数据结构，改进架构，应用多线程、协程，以及上性能优化各种手段，但这玩意儿天花板低，就像提升个人产出一样，996、007、最多24 X 7。\n\n**水平方向：** 分布式集群\n- 为了解决分布式系统的复杂性问题，一般会用到架构分层和服务拆分，通过分层做隔离，通过微服务解耦。\n  这个理论上没有上限，只要做好层次和服务划分，加机器扩容就能满足需求，但实际上并非如此，一方面分布式会增加系统复杂性，另一方面集群规模上去之后，也会引入一堆AIOps、服务发现、服务治理的新问题。\n  因为垂直向的限制，所以，我们通常更关注水平扩展，高并发系统的实施也主要围绕水平方向展开。\n\n##### 1.1.3、高并发的关键技术\n###### 集群化：负载均衡\n负载均衡就是把负载（request）均衡分配到不同的服务实例，利用集群的能力去对抗高并发，负载均衡是服务集群化的实施要素，它分3种：\n1. **DNS负载均衡，** 客户端通过URL发起网络服务请求的时候，会去DNS服务器做域名解释，DNS会按一定的策略（比如就近策略）把URL转换成IP地址，同一个URL会被解释成不同的IP地址，这便是DNS负载均衡，它是一种粗粒度的负载均衡，它只用URL前半部分，因为DNS负载均衡一般采用就近原则，所以通常能降低时延，但DNS有cache，所以也会更新不及时的问题。\n2. **硬件负载均衡，** 通过布置特殊的负载均衡设备到机房做负载均衡，比如F5，这种设备贵，性能高，可以支撑每秒百万并发，还能做一些安全防护，比如防火墙。\n3. **软件负载均衡，** 根据工作在ISO 7层网络模型的层次，可分为四层负载均衡（比如章文嵩博士的LVS）和七层负载均衡（NGINX），软件负载均衡配置灵活，扩展性强，阿某云的SLB作为服务对外售卖，Nginx可以对URL的后半部做解释承担API网关的职责。\n\n###### 数据库层面：分库分表+读写分离\n负载均衡解决了无状态服务的水平扩展问题，但我们的系统不全是无状态的，后面通常还有有状态的数据库，所以解决了前面的问题，存储有可能成为系统的瓶颈，我们需要对**有状态存储做分片路由。**\n\n数据库的单机QPS一般不高，也就几千，显然满足不了高并发的要求。\n\n所以，我们需要做分库分表 + 读写分离。\n\n就是把一个库分成多个库，部署在多个数据库服务上，主库承载写请求，从库承载读请求。从库可以挂载多个，因为很多场景写的请求远少于读的请求，这样就把对单个库的压力降下来了。\n\n如果写的请求上升就继续分库分表，如果读的请求上升就挂更多的从库，但数据库天生不是很适合高并发，而且数据库对机器配置的要求一般很高，导致单位服务成本高，所以，这样加机器抗压力成本太高，还得另外想招。\n\n###### 读多写少：缓存\n缓存的理论依据是局部性原理。\n\n一般系统的写入请求远少于读请求，针对写少读多的场景，很适合引入缓存集群。\n\n在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求，因为缓存集群很容易做到高性能，所以，这样的话，通过缓存集群，就可以用更少的机器资源承载更高的并发。\n\n缓存的命中率一般能做到很高，而且速度很快，处理能力也强（单机很容易做到几万并发），是理想的解决方案。\n\nCDN本质上就是缓存，被用户大量访问的静态资源缓存在CDN中是目前的通用做法。\n\n**缓存也有很多需要谨慎处理的问题：**\n1. 一致性问题：(a)更新db成功+更新cache失败 -> 不一致 (b)更新db失败+更新cache成功 -> 不一致 ©更新db成功+淘汰缓存失败 -> 不一致\n2. 缓存穿透：查询一定不存在的数据，会穿透缓存直接压到数据库，从而导致缓存失去作用，如果有人利用这个漏洞，大量查询一定不存在的数据，会对数据库造成压力，甚至打挂数据库。解决方案：布隆过滤器 或者 简单的方案，查询不存在的key，也把空结果写入缓存（设置较短的过期淘汰时间），从而降低命失\n3. 缓存雪崩：如果大量缓存在一个时刻同时失效，则请求会转到DB，则对DB形成压迫，导致雪崩。简单的解决方案是为缓存失效时间添加随机值，降低同一时间点失效淘汰缓存数，避免集体失效事件发生\n\n但缓存是针对读，如果写的压力很大，怎么办？\n\n###### 高写入：消息中间件\n通过跟主库加机器，耗费的机器资源是很大的，这个就是数据库系统的特点所决定的。\n\n相同的资源下，数据库系统太重太复杂，所以并发承载能力就在几千/s的量级，所以此时你需要引入别的一些技术。\n\n比如说消息中间件技术，也就是MQ集群，它是非常好的做写请求异步化处理，实现削峰填谷的效果。\n\n消息队列能做解耦，在只需要最终一致性的场景下，很适合用来配合做流控。\n\n假如说，每秒是1万次写请求，其中比如5千次请求是必须请求过来立马写入数据库中的，但是另外5千次写请求是可以允许异步化等待个几十秒，甚至几分钟后才落入数据库内的。\n\n那么此时完全可以引入消息中间件集群，把允许异步化的每秒5千次请求写入MQ，然后基于MQ做一个削峰填谷。比如就以平稳的1000/s的速度消费出来然后落入数据库中即可，此时就会大幅度降低数据库的写入压力。\n\n消息队列本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是很合适的，比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。\n\n\n###### 避免挤兑：流控\n再强大的系统，也怕流量短事件内集中爆发，就像银行怕挤兑一样，所以，高并发另一个必不可少的模块就是流控。\n\n流控的关键是流控算法，有4种常见的流控算法。\n1. **计数器算法（固定窗口）：** 计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略，下一个周期开始时，进行清零，重新计数，实现简单。计数器算法方式限流对于周期比较长的限流，存在很大的弊端，有严重的临界问题。\n2. **滑动窗口算法：** 将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。此算法可以很好的解决固定窗口算法的临界问题。\n3. **漏桶算法：** 访问请求到达时直接放入漏桶，如当前容量已达到上限（限流值），则进行丢弃（触发限流策略）。漏桶以固定的速率进行释放访问请求（即请求通过），直到漏桶为空。分布式环境下实施难度高。\n4. **令牌桶算法：** 程序以r（r=时间周期/限流值）的速度向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，如获取到令牌则通过请求，否则触发限流策略。分布式环境下实施难度高。\n\n\n#### 1.2、高性能（High - Performance）\n高性能是指程序处理速度非常快，所占内存少，CPU占用率低。**高性能的指标经常和高并发的指标紧密相关，想要提高性能，那么就要提高系统发并发能力。**\n\n##### 1.2.1、高性能的衡量指标\n性能的常用的衡量指标包括响应时间RT（完成一个请求所花费的时间）、资源利用率（如 CPU 使用率、内存占用率等）、每秒事务处理量（TPS）等。例如，一个高性能的数据库系统，其查询响应时间可能在毫秒级别，CPU 使用率能够维持在一个合理的范围内，并且每秒能够处理大量的事务。\n\n##### 1.2.2、高性能的设计思路\n可以从计算机体系结构的底层原理去思考，系统优化离不开计算性能(CPU)和存储性能(IO)两个维度，每次谈到高性能设计，经常会面临几个名词：IO多路复用、零拷贝、线程池、冗余等等，总结如下方法：\n\n**如何设计高性能计算(CPU)**\n- 减少计算成本：代码优化计算的时间复杂度O(N^2)->O(N)，合理使用同步/异步、限流减少请求次数等；\n- 让更多的核参与计算：多线程代替单线程、集群代替单机等等；\n\n**如何提升系统IO**\n- 加快IO速度：顺序读写代替随机读写、硬件上SSD提升等；\n- 减少IO次数：索引/分布式计算代替全表扫描、零拷贝减少IO复制次数、DB批量读写、分库分表增加连接数等；\n- 减少IO存储：数据过期策略、合理使用内存、缓存、DB等中间件，做好消息压缩等；\n\n##### 1.2.3、高性能的关键技术\n高性能的关键技术，包含高并发的关键技术，例如缓存、分库分表、读写分离。\n\n###### 算法和数据结构优化\n选择高效的算法 & 优化数据结构。\n\n###### 硬件资源优化与适配\n根据系统的负载特点选择服务器的硬件配置。对于计算密集型的应用，优先考虑配置高性能的 CPU 和足够的内存。例如，一个进行 3D 图形渲染的服务器，需要配备多核、高频的 CPU 和大容量的高速内存，以满足复杂图形计算的需求。\n\n###### 代码优化与性能调优\n减少不必要的计算和操作：     \n在代码编写过程中，避免重复计算和不必要的循环嵌套。例如，将可以提前计算的结果放在循环体外进行计算，减少循环内部的计算量。对于复杂的条件判断，可以通过调整判断顺序来减少不必要的计算。\n\n优化数据库访问代码：    \n减少数据库查询的次数。例如，通过使用连接查询或子查询来一次性获取需要的数据，而不是多次执行简单的查询。对于频繁查询的数据库字段，合理地添加索引可以提高查询速度，但要注意避免过度索引导致的数据更新和存储成本增加。\n\n###### 异步处理与并行处理\n异步处理机制应用：   \n通过异步处理可以提高系统的整体性能，特别是对于一些不需要立即返回结果的操作。例如，在 Web 应用中，用户提交表单后，可以先返回一个确认信息给用户，然后在后台异步地进行数据验证、存储等操作。可以使用消息队列（如 RabbitMQ 或 Kafka）来实现异步处理，将任务放入消息队列后，由专门的消费者进程或线程在后台进行处理。\n\n\n#### 1.3、高性能 & 高并发 的区别\n高性能和高并发确实有一些相似之处，但他们也有明显的区别：\n\n相似点：\n- **目标导向有重合：** 高并发和高性能的最终目标都是为了让系统能够更好地应对各种请求，提供优质的服务。在当今互联网应用场景下，如电商平台的促销活动、热门社交媒体的信息发布时段等，**高并发场景往往也要求系统具备高性能，这样才能在大量请求涌入时依然保证系统的流畅运行，为用户提供良好的体验。**\n- **部分优化策略重叠：** 为了实现高并发和高性能，都可能会采用一些相同的技术手段。例如，缓存技术在两者中都经常被使用。在高性能系统中，缓存可以减少数据查询和处理的时间，提高系统的响应速度；在高并发系统中，缓存能够减轻后端服务器的压力，使得系统在大量请求下依然能够快速响应，避免反复从数据源获取相同的数据。\n\n不同点：\n- 侧重点不同：\n  - 高并发：侧重于系统同时处理大量请求的能力。它更关注系统在多任务环境下的架构设计和资源分配，要确保系统在大量并发请求到来时不会崩溃，并且能够合理地调度资源，让各个请求都能得到及时处理。\n  - 高性能：更强调系统的处理效率和资源利用率。高性能系统追求的是在给定的资源条件下（如 CPU、内存、磁盘 I/O、网络带宽等），能够以最短的时间完成单个请求的处理，并且尽可能地充分利用资源，避免浪费。\n- 衡量指标不同：\n  - 高并发：主要通过系统能够同时处理的请求数量、请求队列长度、吞吐量（单位时间内处理的请求数量）等指标来衡量。\n  - 高性能：常用的衡量指标包括响应时间（完成一个请求所花费的时间）、资源利用率（如 CPU 使用率、内存占用率等）、每秒事务处理量（TPS）等。例如，一个高性能的数据库系统，其查询响应时间可能在毫秒级别，CPU 使用率能够维持在一个合理的范围内，并且每秒能够处理大量的事务。\n- 实现策略的重点不同：\n  - 高并发：\n    - 架构层面：重点在于采用分布式架构、微服务架构等方式将系统进行拆分，通过负载均衡将请求均匀分配到多个节点或服务实例上，同时利用消息队列等异步处理机制来缓解系统压力。\n    - 资源管理层面：需要关注资源的竞争和协调，例如数据库连接池的合理设置，避免过多的请求同时占用数据库连接导致系统阻塞。同时，对服务器资源进行动态调整和扩展，以适应不同并发水平的需求。\n  - 高性能：\n    - 算法和数据结构优化：选择高效的算法和数据结构是高性能的关键。例如，在数据搜索场景中，使用哈希表可以实现快速的数据查找，相比简单的线性查找算法，能够大大提高系统的性能。\n    - 硬件优化和适配：根据系统的需求合理选择硬件设备，并进行优化配置。例如，对于计算密集型的高性能应用，可以选择高性能的 CPU 和 GPU，同时优化服务器的内存和存储系统，以提高数据读写速度。\n    - 代码层面的精细优化：编写高效的代码，减少不必要的计算、内存分配和释放操作等。例如，在循环中避免重复计算，优化函数调用，减少对象的创建和销毁次数等，这些细节优化能够有效提高系统的性能。\n\n#### 1.4、高可用（High - Availability）\n高可用(High Availability，HA)核心目标是保障业务的连续性，从用户视角来看，业务永远是正常稳定的对外提供服务，业界一般用几个9来衡量系统的可用性。通常采用一系列专门的设计(冗余、去单点等)，减少业务的停工时间，从而保持其核心服务的高度可用性。\n\nCAP理论和BASE理论、通过集群来提高系统整体稳定性、超时和重试机制、应对接口级故障：降级、熔断、限流、排队。我们在很多开源组件的文档中看到的 HA 方案就是提升组件可用性，让系统免于宕机无法服务的方案。\n\n##### 1.4.1、高可用的衡量指标\n可用性是一个抽象的概念，你需要知道要如何来度量它，与之相关的概念是： MTBF 和 MTTR。\n- **MTBF（Mean Time Between Failure）** 是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。\n- **MTTR（Mean Time To Repair）** 表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。\n\n可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：\n> Availability = MTBF / (MTBF + MTTR)\n\n这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。\n![高可用衡量指标](2024-08-21-架构-三高/高可用衡量指标.png)\n\n##### 1.4.2、高可用的设计思路\n![高可用设计](2024-08-21-架构-三高/高可用设计.png)\n###### 冗余设计\n通过冗余的硬件设备和软件组件，提高系统的可靠性。\n- 硬件冗余\n  - 服务器冗余：采用多台服务器来提供相同的服务，例如在 Web 服务中，使用负载均衡器将用户请求分配到多个 Web 服务器上。如果其中一台服务器出现故障，负载均衡器会将请求转发到其他正常的服务器，确保服务不中断。在一些关键业务场景中，甚至可以采用双机热备（Active - Active 或 Active - Standby）的方式，两台服务器同时运行相同的服务或一台处于备用状态，实时同步数据，当主服务器出现故障时，备用服务器能立即接管工作。\n  - 存储设备冗余：对于存储系统，使用磁盘阵列（RAID）技术来实现存储冗余。不同的 RAID 级别提供不同程度的冗余和性能。例如，RAID 1 通过镜像技术将数据同时写入两块磁盘，当一块磁盘出现故障时，另一块磁盘的数据仍然可用；RAID 5 则是通过奇偶校验信息分布在多个磁盘上，允许一块磁盘故障后通过奇偶校验恢复数据，这种方式在提供一定冗余的同时也兼顾了存储效率。\n- 软件组件冗余\n  - 服务实例冗余：在微服务架构中，每个微服务可以部署多个实例。例如，订单服务部署多个实例并分布在不同的服务器上，通过服务注册与发现机制，当一个实例出现故障时，其他实例可以继续处理请求。同时，使用熔断器（Circuit Breaker）模式，当某个服务实例频繁出现故障时，暂时切断对该实例的请求，避免故障扩散，直到该实例恢复正常。\n  - 数据备份与冗余存储：定期对数据进行备份，并且将备份数据存储在不同的地理位置或存储介质上。除了本地备份外，还可以使用云存储服务进行异地备份。在数据丢失或损坏的情况下，可以从备份数据中恢复。对于分布式系统中的数据，采用多副本策略，如在分布式数据库中，数据会在多个节点上保存副本，通过一致性算法（如 Paxos、Raft）来保证副本之间的数据一致性。\n    \n###### 故障检测与自动恢复\n监控和预警：实时监控系统的运行状态，及时发现问题并发出预警。\n- 健康检查机制\n  - 服务器健康检查：通过心跳检测、端口扫描、服务响应检查等方式来监测服务器的健康状态。例如，负载均衡器每隔一段时间向后端服务器发送心跳包，如果在规定时间内没有收到服务器的响应，就认为该服务器出现故障，将其从服务列表中移除。在容器化环境（如 Docker、Kubernetes）中，容器编排工具也会定期检查容器的健康状态，当容器出现问题时，会自动重启或重新调度。\n  - 服务健康检查：对于每个服务实例，检查其提供的接口是否能够正常响应。可以通过发送模拟请求或调用服务的健康检查接口来实现。例如，一个支付服务可以提供一个健康检查端点，该端点返回服务的状态信息，监控系统定期访问这个端点，如果返回的状态异常，就采取相应的恢复措施。\n- 自动恢复策略\n  - 服务器自动重启：当检测到服务器出现故障（如系统崩溃、软件故障等）时，自动重启服务器。在一些云服务环境中，云平台会自动检测到虚拟机或容器的故障，并自动重启它们。同时，为了避免频繁重启导致的问题，可以设置重启的次数限制和时间间隔。\n  - 服务自动切换和重新部署：当一个服务实例出现故障时，自动切换到其他正常的服务实例。对于微服务架构，服务发现工具可以动态地更新服务实例列表，将请求导向可用的实例。在某些情况下，还可以自动触发服务的重新部署，例如，当检测到某个服务的代码更新后出现故障，可以回滚到之前的稳定版本或者重新部署经过修复的版本。\n\n###### 负载均衡与流量控制\n- 负载均衡策略\n  - 硬件负载均衡器：如 F5 Big - IP 等硬件设备，可以根据服务器的负载情况（如 CPU 使用率、内存使用率、连接数等）将流量均匀地分配到多个服务器上。这种方式性能高、可靠性强，适用于对流量处理要求较高的大型企业网络或数据中心。\n  - 软件负载均衡：例如 Nginx、HAProxy 等开源软件负载均衡器，它们可以在软件层面实现类似的功能。通过配置不同的负载均衡算法（如轮询、加权轮询、IP 哈希等），将请求合理地分配到后端服务器。在云环境中，云服务提供商的负载均衡服务（如 AWS Elastic Load Balancing）也可以根据用户的需求灵活地配置负载均衡策略。\n- 流量控制与限流\n  - 入口流量控制：在系统的入口处设置流量限制，防止大量突发流量涌入导致系统崩溃。可以根据系统的处理能力和资源情况，设定每秒允许进入的请求数量上限。例如，通过 API 网关对外部 API 请求进行限流，当请求数量超过阈值时，返回错误信息或引导用户稍后重试。\n  - 服务间流量控制：在微服务架构中，为了防止某个微服务被过多的请求淹没，对服务间的调用进行限流。可以使用令牌桶算法或漏桶算法来实现限流。例如，当订单服务调用库存服务时，库存服务可以根据自己的处理能力设置限流策略，确保自身的稳定性。\n\n###### 数据一致性与可靠性保障\n- 数据一致性策略\n  - 强一致性模型：在某些对数据准确性要求极高的场景下，如金融交易系统，采用强一致性模型。这通常需要通过分布式事务协议（如两阶段提交、三阶段提交）来保证所有副本的数据在任何时刻都是完全一致的。但这种方式会带来一定的性能开销，因为需要等待所有节点的数据更新完成才能返回结果。\n  - 最终一致性模型：对于大多数互联网应用等对实时一致性要求不是特别严格的场景，采用最终一致性模型。例如，在分布式缓存系统中，数据更新后可能需要一段时间才能在所有副本中完全一致，但最终所有副本会达到一致状态。可以通过异步复制、版本号控制等方式来实现最终一致性。\n- 数据可靠性措施\n  - 数据校验与纠错：在数据存储和传输过程中，采用数据校验机制（如 CRC 校验、哈希校验等）来检测数据是否出现错误。如果发现错误，可以尝试通过纠错码（如汉明码）或重新获取数据来纠正错误。例如，在存储系统中，每次写入数据后计算数据的校验和，在读取数据时再次计算校验和并与之前的结果进行比较，如果不一致，则采取相应的纠错措施。\n  - 数据存储可靠性保障：除了前面提到的存储设备冗余外，还可以通过数据加密、访问控制等方式来保障数据的存储安全。例如，对敏感数据进行加密存储，只有经过授权的用户才能解密和访问数据，防止数据泄露和篡改。\n\n\n\n\n参考文章：\n[软件系统“三高”的高并发，你了解吗？](https://bbs.huaweicloud.com/blogs/194361#H22)      \n[系统怎样做到高可用？](https://zq99299.github.io/note-architect/hc/01/04.html#%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BA%A6%E9%87%8F)","source":"_posts/2024-08-21-架构-三高.md","raw":"---\ntitle: 《架构》基础知识（三高）\ndate: 2024-08-21 10:00:00\ncategories:\n  - [架构, 三高]\n---\n\n### 一、基础概念\n在软件设计中，“三高” 是高并发（High - Concurrency）、高性能（High - Performance）、高可用（High - Availability），它们是构建高质量软件系统的关键目标。\n<!--more-->\n\n#### 1.1、高并发（High - Concurrency）\n高并发(High Concurrency)通常是指系统能够同时并行处理很多请求。一般用响应时间、并发吞吐量TPS, 并发用户数等指标来衡量。\n\n<details style=\"background-color: #dbdbdb;padding: 10px;\">\n<summary>▲ 点击查看“并发&并行”相关定义</summary>\n\n##### 什么是并发？\n并发是指在<font color=#e98787>**一段时间内**</font>，多个任务交替执行。\n> 并发的关键在于 “同时处理多个任务” 的外在表现，但在计算机系统的实际执行层面，特别是在**单核处理器**环境下，由于物理资源的限制（同一时刻只有一个核心能够执行指令），这些任务无法真正在同一时刻被执行。所以，通过操作系统的调度机制，让这些任务在一段时间内看起来像是同时在执行，这就形成了交替运行的情况。\n\n##### 什么是并行？\n并行是指在<font color=#e98787>**同一时刻**</font>，多个任务真正地同时执行。\n\n**并发&并行的区别与联系**\n- 区别\n  - **执行时间：** 并发是多个任务在一段时间内交替执行，同一时刻只有一个任务在执行；而并行是多个任务在同一时刻真正地同时执行。例如，并发的多个任务就像在单车道的道路上多辆车交替行驶；而并行的多个任务则像在多车道的高速公路上多辆车同时行驶。\n  - **硬件要求：** 并发可以在单处理器（CPU）系统中实现，通过操作系统的调度机制来实现任务的交替执行；而并行需要多个处理器（CPU）或多核处理器来支持，每个任务在不同的处理器或核心上运行。\n  - **性能提升方式：** 并发主要是通过充分利用等待时间（如 I/O 等待）来提高系统的整体效率；并行则是通过同时利用多个计算资源来加速任务的完成。例如，并发在处理 I/O 密集型任务时效果显著；而并行在处理计算密集型任务时优势明显。\n- 联系\n  - **目的相同：** 并发和并行的目的都是为了提高系统的处理能力和效率，以应对多个任务同时存在的情况。\n  - **可以结合使用：** 在实际的系统设计中，常常会将并发和并行结合使用。例如，在一个多核服务器上，通过多线程并发地处理多个任务，并且每个线程在不同的核心上实现并行执行，从而最大限度地发挥系统的性能。\n</details>\n\n##### 1.1.1、高并发的度量指标\n并发的指标一般有QPS、TPS、IOPS，这几个指标都是可归为系统吞吐率，QPS越高系统能hold住的请求数越多，但光关注这几个指标不够，我们还需要关注RT，即响应时间，也就是从发出request到收到response的时延，这个指标跟吞吐往往是此消彼长的，我们追求的是一定时延下的高吞吐。\n![并发度公式](2024-08-21-架构-三高/并发度公式.png)\n比如有100万次请求，99万次请求都在10毫秒内响应，其他次数10秒才响应，平均时延不高，但时延高的用户受不了，所以，就有了TP90/TP99指标，这个指标不是求平均，而是把时延从小到大排序，取排名90%/99%的时延，**这个指标越大，对慢请求越敏感。**\n\n> TP90: 表示在所有的请求响应时间数据中，按照响应时间从小到大排序后，取排在 90% 位置的响应时间值。例如，有 100 个请求的响应时间数据，将它们排序后，第 90 个数据对应的响应时间就是 TP90。\n\n##### 1.1.2、高并发的设计思路\n高并发的设计思路有两个方向：\n1. 垂直方向扩展，也叫竖向扩展\n2. 水平方向扩展，也叫横向扩展\n\n**垂直方向：** 提升单机能力（提升单机处理能力又可分为硬件和软件两个方面）\n- 硬件方向，很好理解，花钱升级机器，更多核更高主频更大存储空间更多带宽\n- 软件方向，包括用各快的数据结构，改进架构，应用多线程、协程，以及上性能优化各种手段，但这玩意儿天花板低，就像提升个人产出一样，996、007、最多24 X 7。\n\n**水平方向：** 分布式集群\n- 为了解决分布式系统的复杂性问题，一般会用到架构分层和服务拆分，通过分层做隔离，通过微服务解耦。\n  这个理论上没有上限，只要做好层次和服务划分，加机器扩容就能满足需求，但实际上并非如此，一方面分布式会增加系统复杂性，另一方面集群规模上去之后，也会引入一堆AIOps、服务发现、服务治理的新问题。\n  因为垂直向的限制，所以，我们通常更关注水平扩展，高并发系统的实施也主要围绕水平方向展开。\n\n##### 1.1.3、高并发的关键技术\n###### 集群化：负载均衡\n负载均衡就是把负载（request）均衡分配到不同的服务实例，利用集群的能力去对抗高并发，负载均衡是服务集群化的实施要素，它分3种：\n1. **DNS负载均衡，** 客户端通过URL发起网络服务请求的时候，会去DNS服务器做域名解释，DNS会按一定的策略（比如就近策略）把URL转换成IP地址，同一个URL会被解释成不同的IP地址，这便是DNS负载均衡，它是一种粗粒度的负载均衡，它只用URL前半部分，因为DNS负载均衡一般采用就近原则，所以通常能降低时延，但DNS有cache，所以也会更新不及时的问题。\n2. **硬件负载均衡，** 通过布置特殊的负载均衡设备到机房做负载均衡，比如F5，这种设备贵，性能高，可以支撑每秒百万并发，还能做一些安全防护，比如防火墙。\n3. **软件负载均衡，** 根据工作在ISO 7层网络模型的层次，可分为四层负载均衡（比如章文嵩博士的LVS）和七层负载均衡（NGINX），软件负载均衡配置灵活，扩展性强，阿某云的SLB作为服务对外售卖，Nginx可以对URL的后半部做解释承担API网关的职责。\n\n###### 数据库层面：分库分表+读写分离\n负载均衡解决了无状态服务的水平扩展问题，但我们的系统不全是无状态的，后面通常还有有状态的数据库，所以解决了前面的问题，存储有可能成为系统的瓶颈，我们需要对**有状态存储做分片路由。**\n\n数据库的单机QPS一般不高，也就几千，显然满足不了高并发的要求。\n\n所以，我们需要做分库分表 + 读写分离。\n\n就是把一个库分成多个库，部署在多个数据库服务上，主库承载写请求，从库承载读请求。从库可以挂载多个，因为很多场景写的请求远少于读的请求，这样就把对单个库的压力降下来了。\n\n如果写的请求上升就继续分库分表，如果读的请求上升就挂更多的从库，但数据库天生不是很适合高并发，而且数据库对机器配置的要求一般很高，导致单位服务成本高，所以，这样加机器抗压力成本太高，还得另外想招。\n\n###### 读多写少：缓存\n缓存的理论依据是局部性原理。\n\n一般系统的写入请求远少于读请求，针对写少读多的场景，很适合引入缓存集群。\n\n在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求，因为缓存集群很容易做到高性能，所以，这样的话，通过缓存集群，就可以用更少的机器资源承载更高的并发。\n\n缓存的命中率一般能做到很高，而且速度很快，处理能力也强（单机很容易做到几万并发），是理想的解决方案。\n\nCDN本质上就是缓存，被用户大量访问的静态资源缓存在CDN中是目前的通用做法。\n\n**缓存也有很多需要谨慎处理的问题：**\n1. 一致性问题：(a)更新db成功+更新cache失败 -> 不一致 (b)更新db失败+更新cache成功 -> 不一致 ©更新db成功+淘汰缓存失败 -> 不一致\n2. 缓存穿透：查询一定不存在的数据，会穿透缓存直接压到数据库，从而导致缓存失去作用，如果有人利用这个漏洞，大量查询一定不存在的数据，会对数据库造成压力，甚至打挂数据库。解决方案：布隆过滤器 或者 简单的方案，查询不存在的key，也把空结果写入缓存（设置较短的过期淘汰时间），从而降低命失\n3. 缓存雪崩：如果大量缓存在一个时刻同时失效，则请求会转到DB，则对DB形成压迫，导致雪崩。简单的解决方案是为缓存失效时间添加随机值，降低同一时间点失效淘汰缓存数，避免集体失效事件发生\n\n但缓存是针对读，如果写的压力很大，怎么办？\n\n###### 高写入：消息中间件\n通过跟主库加机器，耗费的机器资源是很大的，这个就是数据库系统的特点所决定的。\n\n相同的资源下，数据库系统太重太复杂，所以并发承载能力就在几千/s的量级，所以此时你需要引入别的一些技术。\n\n比如说消息中间件技术，也就是MQ集群，它是非常好的做写请求异步化处理，实现削峰填谷的效果。\n\n消息队列能做解耦，在只需要最终一致性的场景下，很适合用来配合做流控。\n\n假如说，每秒是1万次写请求，其中比如5千次请求是必须请求过来立马写入数据库中的，但是另外5千次写请求是可以允许异步化等待个几十秒，甚至几分钟后才落入数据库内的。\n\n那么此时完全可以引入消息中间件集群，把允许异步化的每秒5千次请求写入MQ，然后基于MQ做一个削峰填谷。比如就以平稳的1000/s的速度消费出来然后落入数据库中即可，此时就会大幅度降低数据库的写入压力。\n\n消息队列本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是很合适的，比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。\n\n\n###### 避免挤兑：流控\n再强大的系统，也怕流量短事件内集中爆发，就像银行怕挤兑一样，所以，高并发另一个必不可少的模块就是流控。\n\n流控的关键是流控算法，有4种常见的流控算法。\n1. **计数器算法（固定窗口）：** 计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略，下一个周期开始时，进行清零，重新计数，实现简单。计数器算法方式限流对于周期比较长的限流，存在很大的弊端，有严重的临界问题。\n2. **滑动窗口算法：** 将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。此算法可以很好的解决固定窗口算法的临界问题。\n3. **漏桶算法：** 访问请求到达时直接放入漏桶，如当前容量已达到上限（限流值），则进行丢弃（触发限流策略）。漏桶以固定的速率进行释放访问请求（即请求通过），直到漏桶为空。分布式环境下实施难度高。\n4. **令牌桶算法：** 程序以r（r=时间周期/限流值）的速度向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，如获取到令牌则通过请求，否则触发限流策略。分布式环境下实施难度高。\n\n\n#### 1.2、高性能（High - Performance）\n高性能是指程序处理速度非常快，所占内存少，CPU占用率低。**高性能的指标经常和高并发的指标紧密相关，想要提高性能，那么就要提高系统发并发能力。**\n\n##### 1.2.1、高性能的衡量指标\n性能的常用的衡量指标包括响应时间RT（完成一个请求所花费的时间）、资源利用率（如 CPU 使用率、内存占用率等）、每秒事务处理量（TPS）等。例如，一个高性能的数据库系统，其查询响应时间可能在毫秒级别，CPU 使用率能够维持在一个合理的范围内，并且每秒能够处理大量的事务。\n\n##### 1.2.2、高性能的设计思路\n可以从计算机体系结构的底层原理去思考，系统优化离不开计算性能(CPU)和存储性能(IO)两个维度，每次谈到高性能设计，经常会面临几个名词：IO多路复用、零拷贝、线程池、冗余等等，总结如下方法：\n\n**如何设计高性能计算(CPU)**\n- 减少计算成本：代码优化计算的时间复杂度O(N^2)->O(N)，合理使用同步/异步、限流减少请求次数等；\n- 让更多的核参与计算：多线程代替单线程、集群代替单机等等；\n\n**如何提升系统IO**\n- 加快IO速度：顺序读写代替随机读写、硬件上SSD提升等；\n- 减少IO次数：索引/分布式计算代替全表扫描、零拷贝减少IO复制次数、DB批量读写、分库分表增加连接数等；\n- 减少IO存储：数据过期策略、合理使用内存、缓存、DB等中间件，做好消息压缩等；\n\n##### 1.2.3、高性能的关键技术\n高性能的关键技术，包含高并发的关键技术，例如缓存、分库分表、读写分离。\n\n###### 算法和数据结构优化\n选择高效的算法 & 优化数据结构。\n\n###### 硬件资源优化与适配\n根据系统的负载特点选择服务器的硬件配置。对于计算密集型的应用，优先考虑配置高性能的 CPU 和足够的内存。例如，一个进行 3D 图形渲染的服务器，需要配备多核、高频的 CPU 和大容量的高速内存，以满足复杂图形计算的需求。\n\n###### 代码优化与性能调优\n减少不必要的计算和操作：     \n在代码编写过程中，避免重复计算和不必要的循环嵌套。例如，将可以提前计算的结果放在循环体外进行计算，减少循环内部的计算量。对于复杂的条件判断，可以通过调整判断顺序来减少不必要的计算。\n\n优化数据库访问代码：    \n减少数据库查询的次数。例如，通过使用连接查询或子查询来一次性获取需要的数据，而不是多次执行简单的查询。对于频繁查询的数据库字段，合理地添加索引可以提高查询速度，但要注意避免过度索引导致的数据更新和存储成本增加。\n\n###### 异步处理与并行处理\n异步处理机制应用：   \n通过异步处理可以提高系统的整体性能，特别是对于一些不需要立即返回结果的操作。例如，在 Web 应用中，用户提交表单后，可以先返回一个确认信息给用户，然后在后台异步地进行数据验证、存储等操作。可以使用消息队列（如 RabbitMQ 或 Kafka）来实现异步处理，将任务放入消息队列后，由专门的消费者进程或线程在后台进行处理。\n\n\n#### 1.3、高性能 & 高并发 的区别\n高性能和高并发确实有一些相似之处，但他们也有明显的区别：\n\n相似点：\n- **目标导向有重合：** 高并发和高性能的最终目标都是为了让系统能够更好地应对各种请求，提供优质的服务。在当今互联网应用场景下，如电商平台的促销活动、热门社交媒体的信息发布时段等，**高并发场景往往也要求系统具备高性能，这样才能在大量请求涌入时依然保证系统的流畅运行，为用户提供良好的体验。**\n- **部分优化策略重叠：** 为了实现高并发和高性能，都可能会采用一些相同的技术手段。例如，缓存技术在两者中都经常被使用。在高性能系统中，缓存可以减少数据查询和处理的时间，提高系统的响应速度；在高并发系统中，缓存能够减轻后端服务器的压力，使得系统在大量请求下依然能够快速响应，避免反复从数据源获取相同的数据。\n\n不同点：\n- 侧重点不同：\n  - 高并发：侧重于系统同时处理大量请求的能力。它更关注系统在多任务环境下的架构设计和资源分配，要确保系统在大量并发请求到来时不会崩溃，并且能够合理地调度资源，让各个请求都能得到及时处理。\n  - 高性能：更强调系统的处理效率和资源利用率。高性能系统追求的是在给定的资源条件下（如 CPU、内存、磁盘 I/O、网络带宽等），能够以最短的时间完成单个请求的处理，并且尽可能地充分利用资源，避免浪费。\n- 衡量指标不同：\n  - 高并发：主要通过系统能够同时处理的请求数量、请求队列长度、吞吐量（单位时间内处理的请求数量）等指标来衡量。\n  - 高性能：常用的衡量指标包括响应时间（完成一个请求所花费的时间）、资源利用率（如 CPU 使用率、内存占用率等）、每秒事务处理量（TPS）等。例如，一个高性能的数据库系统，其查询响应时间可能在毫秒级别，CPU 使用率能够维持在一个合理的范围内，并且每秒能够处理大量的事务。\n- 实现策略的重点不同：\n  - 高并发：\n    - 架构层面：重点在于采用分布式架构、微服务架构等方式将系统进行拆分，通过负载均衡将请求均匀分配到多个节点或服务实例上，同时利用消息队列等异步处理机制来缓解系统压力。\n    - 资源管理层面：需要关注资源的竞争和协调，例如数据库连接池的合理设置，避免过多的请求同时占用数据库连接导致系统阻塞。同时，对服务器资源进行动态调整和扩展，以适应不同并发水平的需求。\n  - 高性能：\n    - 算法和数据结构优化：选择高效的算法和数据结构是高性能的关键。例如，在数据搜索场景中，使用哈希表可以实现快速的数据查找，相比简单的线性查找算法，能够大大提高系统的性能。\n    - 硬件优化和适配：根据系统的需求合理选择硬件设备，并进行优化配置。例如，对于计算密集型的高性能应用，可以选择高性能的 CPU 和 GPU，同时优化服务器的内存和存储系统，以提高数据读写速度。\n    - 代码层面的精细优化：编写高效的代码，减少不必要的计算、内存分配和释放操作等。例如，在循环中避免重复计算，优化函数调用，减少对象的创建和销毁次数等，这些细节优化能够有效提高系统的性能。\n\n#### 1.4、高可用（High - Availability）\n高可用(High Availability，HA)核心目标是保障业务的连续性，从用户视角来看，业务永远是正常稳定的对外提供服务，业界一般用几个9来衡量系统的可用性。通常采用一系列专门的设计(冗余、去单点等)，减少业务的停工时间，从而保持其核心服务的高度可用性。\n\nCAP理论和BASE理论、通过集群来提高系统整体稳定性、超时和重试机制、应对接口级故障：降级、熔断、限流、排队。我们在很多开源组件的文档中看到的 HA 方案就是提升组件可用性，让系统免于宕机无法服务的方案。\n\n##### 1.4.1、高可用的衡量指标\n可用性是一个抽象的概念，你需要知道要如何来度量它，与之相关的概念是： MTBF 和 MTTR。\n- **MTBF（Mean Time Between Failure）** 是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。\n- **MTTR（Mean Time To Repair）** 表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。\n\n可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：\n> Availability = MTBF / (MTBF + MTTR)\n\n这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。\n![高可用衡量指标](2024-08-21-架构-三高/高可用衡量指标.png)\n\n##### 1.4.2、高可用的设计思路\n![高可用设计](2024-08-21-架构-三高/高可用设计.png)\n###### 冗余设计\n通过冗余的硬件设备和软件组件，提高系统的可靠性。\n- 硬件冗余\n  - 服务器冗余：采用多台服务器来提供相同的服务，例如在 Web 服务中，使用负载均衡器将用户请求分配到多个 Web 服务器上。如果其中一台服务器出现故障，负载均衡器会将请求转发到其他正常的服务器，确保服务不中断。在一些关键业务场景中，甚至可以采用双机热备（Active - Active 或 Active - Standby）的方式，两台服务器同时运行相同的服务或一台处于备用状态，实时同步数据，当主服务器出现故障时，备用服务器能立即接管工作。\n  - 存储设备冗余：对于存储系统，使用磁盘阵列（RAID）技术来实现存储冗余。不同的 RAID 级别提供不同程度的冗余和性能。例如，RAID 1 通过镜像技术将数据同时写入两块磁盘，当一块磁盘出现故障时，另一块磁盘的数据仍然可用；RAID 5 则是通过奇偶校验信息分布在多个磁盘上，允许一块磁盘故障后通过奇偶校验恢复数据，这种方式在提供一定冗余的同时也兼顾了存储效率。\n- 软件组件冗余\n  - 服务实例冗余：在微服务架构中，每个微服务可以部署多个实例。例如，订单服务部署多个实例并分布在不同的服务器上，通过服务注册与发现机制，当一个实例出现故障时，其他实例可以继续处理请求。同时，使用熔断器（Circuit Breaker）模式，当某个服务实例频繁出现故障时，暂时切断对该实例的请求，避免故障扩散，直到该实例恢复正常。\n  - 数据备份与冗余存储：定期对数据进行备份，并且将备份数据存储在不同的地理位置或存储介质上。除了本地备份外，还可以使用云存储服务进行异地备份。在数据丢失或损坏的情况下，可以从备份数据中恢复。对于分布式系统中的数据，采用多副本策略，如在分布式数据库中，数据会在多个节点上保存副本，通过一致性算法（如 Paxos、Raft）来保证副本之间的数据一致性。\n    \n###### 故障检测与自动恢复\n监控和预警：实时监控系统的运行状态，及时发现问题并发出预警。\n- 健康检查机制\n  - 服务器健康检查：通过心跳检测、端口扫描、服务响应检查等方式来监测服务器的健康状态。例如，负载均衡器每隔一段时间向后端服务器发送心跳包，如果在规定时间内没有收到服务器的响应，就认为该服务器出现故障，将其从服务列表中移除。在容器化环境（如 Docker、Kubernetes）中，容器编排工具也会定期检查容器的健康状态，当容器出现问题时，会自动重启或重新调度。\n  - 服务健康检查：对于每个服务实例，检查其提供的接口是否能够正常响应。可以通过发送模拟请求或调用服务的健康检查接口来实现。例如，一个支付服务可以提供一个健康检查端点，该端点返回服务的状态信息，监控系统定期访问这个端点，如果返回的状态异常，就采取相应的恢复措施。\n- 自动恢复策略\n  - 服务器自动重启：当检测到服务器出现故障（如系统崩溃、软件故障等）时，自动重启服务器。在一些云服务环境中，云平台会自动检测到虚拟机或容器的故障，并自动重启它们。同时，为了避免频繁重启导致的问题，可以设置重启的次数限制和时间间隔。\n  - 服务自动切换和重新部署：当一个服务实例出现故障时，自动切换到其他正常的服务实例。对于微服务架构，服务发现工具可以动态地更新服务实例列表，将请求导向可用的实例。在某些情况下，还可以自动触发服务的重新部署，例如，当检测到某个服务的代码更新后出现故障，可以回滚到之前的稳定版本或者重新部署经过修复的版本。\n\n###### 负载均衡与流量控制\n- 负载均衡策略\n  - 硬件负载均衡器：如 F5 Big - IP 等硬件设备，可以根据服务器的负载情况（如 CPU 使用率、内存使用率、连接数等）将流量均匀地分配到多个服务器上。这种方式性能高、可靠性强，适用于对流量处理要求较高的大型企业网络或数据中心。\n  - 软件负载均衡：例如 Nginx、HAProxy 等开源软件负载均衡器，它们可以在软件层面实现类似的功能。通过配置不同的负载均衡算法（如轮询、加权轮询、IP 哈希等），将请求合理地分配到后端服务器。在云环境中，云服务提供商的负载均衡服务（如 AWS Elastic Load Balancing）也可以根据用户的需求灵活地配置负载均衡策略。\n- 流量控制与限流\n  - 入口流量控制：在系统的入口处设置流量限制，防止大量突发流量涌入导致系统崩溃。可以根据系统的处理能力和资源情况，设定每秒允许进入的请求数量上限。例如，通过 API 网关对外部 API 请求进行限流，当请求数量超过阈值时，返回错误信息或引导用户稍后重试。\n  - 服务间流量控制：在微服务架构中，为了防止某个微服务被过多的请求淹没，对服务间的调用进行限流。可以使用令牌桶算法或漏桶算法来实现限流。例如，当订单服务调用库存服务时，库存服务可以根据自己的处理能力设置限流策略，确保自身的稳定性。\n\n###### 数据一致性与可靠性保障\n- 数据一致性策略\n  - 强一致性模型：在某些对数据准确性要求极高的场景下，如金融交易系统，采用强一致性模型。这通常需要通过分布式事务协议（如两阶段提交、三阶段提交）来保证所有副本的数据在任何时刻都是完全一致的。但这种方式会带来一定的性能开销，因为需要等待所有节点的数据更新完成才能返回结果。\n  - 最终一致性模型：对于大多数互联网应用等对实时一致性要求不是特别严格的场景，采用最终一致性模型。例如，在分布式缓存系统中，数据更新后可能需要一段时间才能在所有副本中完全一致，但最终所有副本会达到一致状态。可以通过异步复制、版本号控制等方式来实现最终一致性。\n- 数据可靠性措施\n  - 数据校验与纠错：在数据存储和传输过程中，采用数据校验机制（如 CRC 校验、哈希校验等）来检测数据是否出现错误。如果发现错误，可以尝试通过纠错码（如汉明码）或重新获取数据来纠正错误。例如，在存储系统中，每次写入数据后计算数据的校验和，在读取数据时再次计算校验和并与之前的结果进行比较，如果不一致，则采取相应的纠错措施。\n  - 数据存储可靠性保障：除了前面提到的存储设备冗余外，还可以通过数据加密、访问控制等方式来保障数据的存储安全。例如，对敏感数据进行加密存储，只有经过授权的用户才能解密和访问数据，防止数据泄露和篡改。\n\n\n\n\n参考文章：\n[软件系统“三高”的高并发，你了解吗？](https://bbs.huaweicloud.com/blogs/194361#H22)      \n[系统怎样做到高可用？](https://zq99299.github.io/note-architect/hc/01/04.html#%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BA%A6%E9%87%8F)","slug":"2024-08-21-架构-三高","published":1,"updated":"2024-11-26T02:59:48.793Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyd005qa13kvob13rrw","content":"<h3 id=\"一、基础概念\"><a href=\"#一、基础概念\" class=\"headerlink\" title=\"一、基础概念\"></a>一、基础概念</h3><p>在软件设计中，“三高” 是高并发（High - Concurrency）、高性能（High - Performance）、高可用（High - Availability），它们是构建高质量软件系统的关键目标。</p>\n<a id=\"more\"></a>\n\n<h4 id=\"1-1、高并发（High-Concurrency）\"><a href=\"#1-1、高并发（High-Concurrency）\" class=\"headerlink\" title=\"1.1、高并发（High - Concurrency）\"></a>1.1、高并发（High - Concurrency）</h4><p>高并发(High Concurrency)通常是指系统能够同时并行处理很多请求。一般用响应时间、并发吞吐量TPS, 并发用户数等指标来衡量。</p>\n<details style=\"background-color: #dbdbdb;padding: 10px;\">\n<summary>▲ 点击查看“并发&并行”相关定义</summary>\n\n<h5 id=\"什么是并发？\"><a href=\"#什么是并发？\" class=\"headerlink\" title=\"什么是并发？\"></a>什么是并发？</h5><p>并发是指在<font color=\"#e98787\"><strong>一段时间内</strong></font>，多个任务交替执行。</p>\n<blockquote>\n<p>并发的关键在于 “同时处理多个任务” 的外在表现，但在计算机系统的实际执行层面，特别是在<strong>单核处理器</strong>环境下，由于物理资源的限制（同一时刻只有一个核心能够执行指令），这些任务无法真正在同一时刻被执行。所以，通过操作系统的调度机制，让这些任务在一段时间内看起来像是同时在执行，这就形成了交替运行的情况。</p>\n</blockquote>\n<h5 id=\"什么是并行？\"><a href=\"#什么是并行？\" class=\"headerlink\" title=\"什么是并行？\"></a>什么是并行？</h5><p>并行是指在<font color=\"#e98787\"><strong>同一时刻</strong></font>，多个任务真正地同时执行。</p>\n<p><strong>并发&amp;并行的区别与联系</strong></p>\n<ul>\n<li>区别<ul>\n<li><strong>执行时间：</strong> 并发是多个任务在一段时间内交替执行，同一时刻只有一个任务在执行；而并行是多个任务在同一时刻真正地同时执行。例如，并发的多个任务就像在单车道的道路上多辆车交替行驶；而并行的多个任务则像在多车道的高速公路上多辆车同时行驶。</li>\n<li><strong>硬件要求：</strong> 并发可以在单处理器（CPU）系统中实现，通过操作系统的调度机制来实现任务的交替执行；而并行需要多个处理器（CPU）或多核处理器来支持，每个任务在不同的处理器或核心上运行。</li>\n<li><strong>性能提升方式：</strong> 并发主要是通过充分利用等待时间（如 I/O 等待）来提高系统的整体效率；并行则是通过同时利用多个计算资源来加速任务的完成。例如，并发在处理 I/O 密集型任务时效果显著；而并行在处理计算密集型任务时优势明显。</li>\n</ul>\n</li>\n<li>联系<ul>\n<li><strong>目的相同：</strong> 并发和并行的目的都是为了提高系统的处理能力和效率，以应对多个任务同时存在的情况。</li>\n<li><strong>可以结合使用：</strong> 在实际的系统设计中，常常会将并发和并行结合使用。例如，在一个多核服务器上，通过多线程并发地处理多个任务，并且每个线程在不同的核心上实现并行执行，从而最大限度地发挥系统的性能。</li></ul></li></ul></details>\n\n\n\n\n\n<h5 id=\"1-1-1、高并发的度量指标\"><a href=\"#1-1-1、高并发的度量指标\" class=\"headerlink\" title=\"1.1.1、高并发的度量指标\"></a>1.1.1、高并发的度量指标</h5><p>并发的指标一般有QPS、TPS、IOPS，这几个指标都是可归为系统吞吐率，QPS越高系统能hold住的请求数越多，但光关注这几个指标不够，我们还需要关注RT，即响应时间，也就是从发出request到收到response的时延，这个指标跟吞吐往往是此消彼长的，我们追求的是一定时延下的高吞吐。<br><img src=\"/2024/08/21/2024-08-21-架构-三高/%E5%B9%B6%E5%8F%91%E5%BA%A6%E5%85%AC%E5%BC%8F.png\" alt=\"并发度公式\"><br>比如有100万次请求，99万次请求都在10毫秒内响应，其他次数10秒才响应，平均时延不高，但时延高的用户受不了，所以，就有了TP90/TP99指标，这个指标不是求平均，而是把时延从小到大排序，取排名90%/99%的时延，<strong>这个指标越大，对慢请求越敏感。</strong></p>\n<blockquote>\n<p>TP90: 表示在所有的请求响应时间数据中，按照响应时间从小到大排序后，取排在 90% 位置的响应时间值。例如，有 100 个请求的响应时间数据，将它们排序后，第 90 个数据对应的响应时间就是 TP90。</p>\n</blockquote>\n<h5 id=\"1-1-2、高并发的设计思路\"><a href=\"#1-1-2、高并发的设计思路\" class=\"headerlink\" title=\"1.1.2、高并发的设计思路\"></a>1.1.2、高并发的设计思路</h5><p>高并发的设计思路有两个方向：</p>\n<ol>\n<li>垂直方向扩展，也叫竖向扩展</li>\n<li>水平方向扩展，也叫横向扩展</li>\n</ol>\n<p><strong>垂直方向：</strong> 提升单机能力（提升单机处理能力又可分为硬件和软件两个方面）</p>\n<ul>\n<li>硬件方向，很好理解，花钱升级机器，更多核更高主频更大存储空间更多带宽</li>\n<li>软件方向，包括用各快的数据结构，改进架构，应用多线程、协程，以及上性能优化各种手段，但这玩意儿天花板低，就像提升个人产出一样，996、007、最多24 X 7。</li>\n</ul>\n<p><strong>水平方向：</strong> 分布式集群</p>\n<ul>\n<li>为了解决分布式系统的复杂性问题，一般会用到架构分层和服务拆分，通过分层做隔离，通过微服务解耦。<br>这个理论上没有上限，只要做好层次和服务划分，加机器扩容就能满足需求，但实际上并非如此，一方面分布式会增加系统复杂性，另一方面集群规模上去之后，也会引入一堆AIOps、服务发现、服务治理的新问题。<br>因为垂直向的限制，所以，我们通常更关注水平扩展，高并发系统的实施也主要围绕水平方向展开。</li>\n</ul>\n<h5 id=\"1-1-3、高并发的关键技术\"><a href=\"#1-1-3、高并发的关键技术\" class=\"headerlink\" title=\"1.1.3、高并发的关键技术\"></a>1.1.3、高并发的关键技术</h5><h6 id=\"集群化：负载均衡\"><a href=\"#集群化：负载均衡\" class=\"headerlink\" title=\"集群化：负载均衡\"></a>集群化：负载均衡</h6><p>负载均衡就是把负载（request）均衡分配到不同的服务实例，利用集群的能力去对抗高并发，负载均衡是服务集群化的实施要素，它分3种：</p>\n<ol>\n<li><strong>DNS负载均衡，</strong> 客户端通过URL发起网络服务请求的时候，会去DNS服务器做域名解释，DNS会按一定的策略（比如就近策略）把URL转换成IP地址，同一个URL会被解释成不同的IP地址，这便是DNS负载均衡，它是一种粗粒度的负载均衡，它只用URL前半部分，因为DNS负载均衡一般采用就近原则，所以通常能降低时延，但DNS有cache，所以也会更新不及时的问题。</li>\n<li><strong>硬件负载均衡，</strong> 通过布置特殊的负载均衡设备到机房做负载均衡，比如F5，这种设备贵，性能高，可以支撑每秒百万并发，还能做一些安全防护，比如防火墙。</li>\n<li><strong>软件负载均衡，</strong> 根据工作在ISO 7层网络模型的层次，可分为四层负载均衡（比如章文嵩博士的LVS）和七层负载均衡（NGINX），软件负载均衡配置灵活，扩展性强，阿某云的SLB作为服务对外售卖，Nginx可以对URL的后半部做解释承担API网关的职责。</li>\n</ol>\n<h6 id=\"数据库层面：分库分表-读写分离\"><a href=\"#数据库层面：分库分表-读写分离\" class=\"headerlink\" title=\"数据库层面：分库分表+读写分离\"></a>数据库层面：分库分表+读写分离</h6><p>负载均衡解决了无状态服务的水平扩展问题，但我们的系统不全是无状态的，后面通常还有有状态的数据库，所以解决了前面的问题，存储有可能成为系统的瓶颈，我们需要对<strong>有状态存储做分片路由。</strong></p>\n<p>数据库的单机QPS一般不高，也就几千，显然满足不了高并发的要求。</p>\n<p>所以，我们需要做分库分表 + 读写分离。</p>\n<p>就是把一个库分成多个库，部署在多个数据库服务上，主库承载写请求，从库承载读请求。从库可以挂载多个，因为很多场景写的请求远少于读的请求，这样就把对单个库的压力降下来了。</p>\n<p>如果写的请求上升就继续分库分表，如果读的请求上升就挂更多的从库，但数据库天生不是很适合高并发，而且数据库对机器配置的要求一般很高，导致单位服务成本高，所以，这样加机器抗压力成本太高，还得另外想招。</p>\n<h6 id=\"读多写少：缓存\"><a href=\"#读多写少：缓存\" class=\"headerlink\" title=\"读多写少：缓存\"></a>读多写少：缓存</h6><p>缓存的理论依据是局部性原理。</p>\n<p>一般系统的写入请求远少于读请求，针对写少读多的场景，很适合引入缓存集群。</p>\n<p>在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求，因为缓存集群很容易做到高性能，所以，这样的话，通过缓存集群，就可以用更少的机器资源承载更高的并发。</p>\n<p>缓存的命中率一般能做到很高，而且速度很快，处理能力也强（单机很容易做到几万并发），是理想的解决方案。</p>\n<p>CDN本质上就是缓存，被用户大量访问的静态资源缓存在CDN中是目前的通用做法。</p>\n<p><strong>缓存也有很多需要谨慎处理的问题：</strong></p>\n<ol>\n<li>一致性问题：(a)更新db成功+更新cache失败 -&gt; 不一致 (b)更新db失败+更新cache成功 -&gt; 不一致 ©更新db成功+淘汰缓存失败 -&gt; 不一致</li>\n<li>缓存穿透：查询一定不存在的数据，会穿透缓存直接压到数据库，从而导致缓存失去作用，如果有人利用这个漏洞，大量查询一定不存在的数据，会对数据库造成压力，甚至打挂数据库。解决方案：布隆过滤器 或者 简单的方案，查询不存在的key，也把空结果写入缓存（设置较短的过期淘汰时间），从而降低命失</li>\n<li>缓存雪崩：如果大量缓存在一个时刻同时失效，则请求会转到DB，则对DB形成压迫，导致雪崩。简单的解决方案是为缓存失效时间添加随机值，降低同一时间点失效淘汰缓存数，避免集体失效事件发生</li>\n</ol>\n<p>但缓存是针对读，如果写的压力很大，怎么办？</p>\n<h6 id=\"高写入：消息中间件\"><a href=\"#高写入：消息中间件\" class=\"headerlink\" title=\"高写入：消息中间件\"></a>高写入：消息中间件</h6><p>通过跟主库加机器，耗费的机器资源是很大的，这个就是数据库系统的特点所决定的。</p>\n<p>相同的资源下，数据库系统太重太复杂，所以并发承载能力就在几千/s的量级，所以此时你需要引入别的一些技术。</p>\n<p>比如说消息中间件技术，也就是MQ集群，它是非常好的做写请求异步化处理，实现削峰填谷的效果。</p>\n<p>消息队列能做解耦，在只需要最终一致性的场景下，很适合用来配合做流控。</p>\n<p>假如说，每秒是1万次写请求，其中比如5千次请求是必须请求过来立马写入数据库中的，但是另外5千次写请求是可以允许异步化等待个几十秒，甚至几分钟后才落入数据库内的。</p>\n<p>那么此时完全可以引入消息中间件集群，把允许异步化的每秒5千次请求写入MQ，然后基于MQ做一个削峰填谷。比如就以平稳的1000/s的速度消费出来然后落入数据库中即可，此时就会大幅度降低数据库的写入压力。</p>\n<p>消息队列本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是很合适的，比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。</p>\n<h6 id=\"避免挤兑：流控\"><a href=\"#避免挤兑：流控\" class=\"headerlink\" title=\"避免挤兑：流控\"></a>避免挤兑：流控</h6><p>再强大的系统，也怕流量短事件内集中爆发，就像银行怕挤兑一样，所以，高并发另一个必不可少的模块就是流控。</p>\n<p>流控的关键是流控算法，有4种常见的流控算法。</p>\n<ol>\n<li><strong>计数器算法（固定窗口）：</strong> 计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略，下一个周期开始时，进行清零，重新计数，实现简单。计数器算法方式限流对于周期比较长的限流，存在很大的弊端，有严重的临界问题。</li>\n<li><strong>滑动窗口算法：</strong> 将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。此算法可以很好的解决固定窗口算法的临界问题。</li>\n<li><strong>漏桶算法：</strong> 访问请求到达时直接放入漏桶，如当前容量已达到上限（限流值），则进行丢弃（触发限流策略）。漏桶以固定的速率进行释放访问请求（即请求通过），直到漏桶为空。分布式环境下实施难度高。</li>\n<li><strong>令牌桶算法：</strong> 程序以r（r=时间周期/限流值）的速度向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，如获取到令牌则通过请求，否则触发限流策略。分布式环境下实施难度高。</li>\n</ol>\n<h4 id=\"1-2、高性能（High-Performance）\"><a href=\"#1-2、高性能（High-Performance）\" class=\"headerlink\" title=\"1.2、高性能（High - Performance）\"></a>1.2、高性能（High - Performance）</h4><p>高性能是指程序处理速度非常快，所占内存少，CPU占用率低。<strong>高性能的指标经常和高并发的指标紧密相关，想要提高性能，那么就要提高系统发并发能力。</strong></p>\n<h5 id=\"1-2-1、高性能的衡量指标\"><a href=\"#1-2-1、高性能的衡量指标\" class=\"headerlink\" title=\"1.2.1、高性能的衡量指标\"></a>1.2.1、高性能的衡量指标</h5><p>性能的常用的衡量指标包括响应时间RT（完成一个请求所花费的时间）、资源利用率（如 CPU 使用率、内存占用率等）、每秒事务处理量（TPS）等。例如，一个高性能的数据库系统，其查询响应时间可能在毫秒级别，CPU 使用率能够维持在一个合理的范围内，并且每秒能够处理大量的事务。</p>\n<h5 id=\"1-2-2、高性能的设计思路\"><a href=\"#1-2-2、高性能的设计思路\" class=\"headerlink\" title=\"1.2.2、高性能的设计思路\"></a>1.2.2、高性能的设计思路</h5><p>可以从计算机体系结构的底层原理去思考，系统优化离不开计算性能(CPU)和存储性能(IO)两个维度，每次谈到高性能设计，经常会面临几个名词：IO多路复用、零拷贝、线程池、冗余等等，总结如下方法：</p>\n<p><strong>如何设计高性能计算(CPU)</strong></p>\n<ul>\n<li>减少计算成本：代码优化计算的时间复杂度O(N^2)-&gt;O(N)，合理使用同步/异步、限流减少请求次数等；</li>\n<li>让更多的核参与计算：多线程代替单线程、集群代替单机等等；</li>\n</ul>\n<p><strong>如何提升系统IO</strong></p>\n<ul>\n<li>加快IO速度：顺序读写代替随机读写、硬件上SSD提升等；</li>\n<li>减少IO次数：索引/分布式计算代替全表扫描、零拷贝减少IO复制次数、DB批量读写、分库分表增加连接数等；</li>\n<li>减少IO存储：数据过期策略、合理使用内存、缓存、DB等中间件，做好消息压缩等；</li>\n</ul>\n<h5 id=\"1-2-3、高性能的关键技术\"><a href=\"#1-2-3、高性能的关键技术\" class=\"headerlink\" title=\"1.2.3、高性能的关键技术\"></a>1.2.3、高性能的关键技术</h5><p>高性能的关键技术，包含高并发的关键技术，例如缓存、分库分表、读写分离。</p>\n<h6 id=\"算法和数据结构优化\"><a href=\"#算法和数据结构优化\" class=\"headerlink\" title=\"算法和数据结构优化\"></a>算法和数据结构优化</h6><p>选择高效的算法 &amp; 优化数据结构。</p>\n<h6 id=\"硬件资源优化与适配\"><a href=\"#硬件资源优化与适配\" class=\"headerlink\" title=\"硬件资源优化与适配\"></a>硬件资源优化与适配</h6><p>根据系统的负载特点选择服务器的硬件配置。对于计算密集型的应用，优先考虑配置高性能的 CPU 和足够的内存。例如，一个进行 3D 图形渲染的服务器，需要配备多核、高频的 CPU 和大容量的高速内存，以满足复杂图形计算的需求。</p>\n<h6 id=\"代码优化与性能调优\"><a href=\"#代码优化与性能调优\" class=\"headerlink\" title=\"代码优化与性能调优\"></a>代码优化与性能调优</h6><p>减少不必要的计算和操作：<br>在代码编写过程中，避免重复计算和不必要的循环嵌套。例如，将可以提前计算的结果放在循环体外进行计算，减少循环内部的计算量。对于复杂的条件判断，可以通过调整判断顺序来减少不必要的计算。</p>\n<p>优化数据库访问代码：<br>减少数据库查询的次数。例如，通过使用连接查询或子查询来一次性获取需要的数据，而不是多次执行简单的查询。对于频繁查询的数据库字段，合理地添加索引可以提高查询速度，但要注意避免过度索引导致的数据更新和存储成本增加。</p>\n<h6 id=\"异步处理与并行处理\"><a href=\"#异步处理与并行处理\" class=\"headerlink\" title=\"异步处理与并行处理\"></a>异步处理与并行处理</h6><p>异步处理机制应用：<br>通过异步处理可以提高系统的整体性能，特别是对于一些不需要立即返回结果的操作。例如，在 Web 应用中，用户提交表单后，可以先返回一个确认信息给用户，然后在后台异步地进行数据验证、存储等操作。可以使用消息队列（如 RabbitMQ 或 Kafka）来实现异步处理，将任务放入消息队列后，由专门的消费者进程或线程在后台进行处理。</p>\n<h4 id=\"1-3、高性能-amp-高并发-的区别\"><a href=\"#1-3、高性能-amp-高并发-的区别\" class=\"headerlink\" title=\"1.3、高性能 &amp; 高并发 的区别\"></a>1.3、高性能 &amp; 高并发 的区别</h4><p>高性能和高并发确实有一些相似之处，但他们也有明显的区别：</p>\n<p>相似点：</p>\n<ul>\n<li><strong>目标导向有重合：</strong> 高并发和高性能的最终目标都是为了让系统能够更好地应对各种请求，提供优质的服务。在当今互联网应用场景下，如电商平台的促销活动、热门社交媒体的信息发布时段等，<strong>高并发场景往往也要求系统具备高性能，这样才能在大量请求涌入时依然保证系统的流畅运行，为用户提供良好的体验。</strong></li>\n<li><strong>部分优化策略重叠：</strong> 为了实现高并发和高性能，都可能会采用一些相同的技术手段。例如，缓存技术在两者中都经常被使用。在高性能系统中，缓存可以减少数据查询和处理的时间，提高系统的响应速度；在高并发系统中，缓存能够减轻后端服务器的压力，使得系统在大量请求下依然能够快速响应，避免反复从数据源获取相同的数据。</li>\n</ul>\n<p>不同点：</p>\n<ul>\n<li>侧重点不同：<ul>\n<li>高并发：侧重于系统同时处理大量请求的能力。它更关注系统在多任务环境下的架构设计和资源分配，要确保系统在大量并发请求到来时不会崩溃，并且能够合理地调度资源，让各个请求都能得到及时处理。</li>\n<li>高性能：更强调系统的处理效率和资源利用率。高性能系统追求的是在给定的资源条件下（如 CPU、内存、磁盘 I/O、网络带宽等），能够以最短的时间完成单个请求的处理，并且尽可能地充分利用资源，避免浪费。</li>\n</ul>\n</li>\n<li>衡量指标不同：<ul>\n<li>高并发：主要通过系统能够同时处理的请求数量、请求队列长度、吞吐量（单位时间内处理的请求数量）等指标来衡量。</li>\n<li>高性能：常用的衡量指标包括响应时间（完成一个请求所花费的时间）、资源利用率（如 CPU 使用率、内存占用率等）、每秒事务处理量（TPS）等。例如，一个高性能的数据库系统，其查询响应时间可能在毫秒级别，CPU 使用率能够维持在一个合理的范围内，并且每秒能够处理大量的事务。</li>\n</ul>\n</li>\n<li>实现策略的重点不同：<ul>\n<li>高并发：<ul>\n<li>架构层面：重点在于采用分布式架构、微服务架构等方式将系统进行拆分，通过负载均衡将请求均匀分配到多个节点或服务实例上，同时利用消息队列等异步处理机制来缓解系统压力。</li>\n<li>资源管理层面：需要关注资源的竞争和协调，例如数据库连接池的合理设置，避免过多的请求同时占用数据库连接导致系统阻塞。同时，对服务器资源进行动态调整和扩展，以适应不同并发水平的需求。</li>\n</ul>\n</li>\n<li>高性能：<ul>\n<li>算法和数据结构优化：选择高效的算法和数据结构是高性能的关键。例如，在数据搜索场景中，使用哈希表可以实现快速的数据查找，相比简单的线性查找算法，能够大大提高系统的性能。</li>\n<li>硬件优化和适配：根据系统的需求合理选择硬件设备，并进行优化配置。例如，对于计算密集型的高性能应用，可以选择高性能的 CPU 和 GPU，同时优化服务器的内存和存储系统，以提高数据读写速度。</li>\n<li>代码层面的精细优化：编写高效的代码，减少不必要的计算、内存分配和释放操作等。例如，在循环中避免重复计算，优化函数调用，减少对象的创建和销毁次数等，这些细节优化能够有效提高系统的性能。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"1-4、高可用（High-Availability）\"><a href=\"#1-4、高可用（High-Availability）\" class=\"headerlink\" title=\"1.4、高可用（High - Availability）\"></a>1.4、高可用（High - Availability）</h4><p>高可用(High Availability，HA)核心目标是保障业务的连续性，从用户视角来看，业务永远是正常稳定的对外提供服务，业界一般用几个9来衡量系统的可用性。通常采用一系列专门的设计(冗余、去单点等)，减少业务的停工时间，从而保持其核心服务的高度可用性。</p>\n<p>CAP理论和BASE理论、通过集群来提高系统整体稳定性、超时和重试机制、应对接口级故障：降级、熔断、限流、排队。我们在很多开源组件的文档中看到的 HA 方案就是提升组件可用性，让系统免于宕机无法服务的方案。</p>\n<h5 id=\"1-4-1、高可用的衡量指标\"><a href=\"#1-4-1、高可用的衡量指标\" class=\"headerlink\" title=\"1.4.1、高可用的衡量指标\"></a>1.4.1、高可用的衡量指标</h5><p>可用性是一个抽象的概念，你需要知道要如何来度量它，与之相关的概念是： MTBF 和 MTTR。</p>\n<ul>\n<li><strong>MTBF（Mean Time Between Failure）</strong> 是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。</li>\n<li><strong>MTTR（Mean Time To Repair）</strong> 表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。</li>\n</ul>\n<p>可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：</p>\n<blockquote>\n<p>Availability = MTBF / (MTBF + MTTR)</p>\n</blockquote>\n<p>这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。<br><img src=\"/2024/08/21/2024-08-21-架构-三高/%E9%AB%98%E5%8F%AF%E7%94%A8%E8%A1%A1%E9%87%8F%E6%8C%87%E6%A0%87.png\" alt=\"高可用衡量指标\"></p>\n<h5 id=\"1-4-2、高可用的设计思路\"><a href=\"#1-4-2、高可用的设计思路\" class=\"headerlink\" title=\"1.4.2、高可用的设计思路\"></a>1.4.2、高可用的设计思路</h5><p><img src=\"/2024/08/21/2024-08-21-架构-三高/%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AE%BE%E8%AE%A1.png\" alt=\"高可用设计\"></p>\n<h6 id=\"冗余设计\"><a href=\"#冗余设计\" class=\"headerlink\" title=\"冗余设计\"></a>冗余设计</h6><p>通过冗余的硬件设备和软件组件，提高系统的可靠性。</p>\n<ul>\n<li>硬件冗余<ul>\n<li>服务器冗余：采用多台服务器来提供相同的服务，例如在 Web 服务中，使用负载均衡器将用户请求分配到多个 Web 服务器上。如果其中一台服务器出现故障，负载均衡器会将请求转发到其他正常的服务器，确保服务不中断。在一些关键业务场景中，甚至可以采用双机热备（Active - Active 或 Active - Standby）的方式，两台服务器同时运行相同的服务或一台处于备用状态，实时同步数据，当主服务器出现故障时，备用服务器能立即接管工作。</li>\n<li>存储设备冗余：对于存储系统，使用磁盘阵列（RAID）技术来实现存储冗余。不同的 RAID 级别提供不同程度的冗余和性能。例如，RAID 1 通过镜像技术将数据同时写入两块磁盘，当一块磁盘出现故障时，另一块磁盘的数据仍然可用；RAID 5 则是通过奇偶校验信息分布在多个磁盘上，允许一块磁盘故障后通过奇偶校验恢复数据，这种方式在提供一定冗余的同时也兼顾了存储效率。</li>\n</ul>\n</li>\n<li>软件组件冗余<ul>\n<li>服务实例冗余：在微服务架构中，每个微服务可以部署多个实例。例如，订单服务部署多个实例并分布在不同的服务器上，通过服务注册与发现机制，当一个实例出现故障时，其他实例可以继续处理请求。同时，使用熔断器（Circuit Breaker）模式，当某个服务实例频繁出现故障时，暂时切断对该实例的请求，避免故障扩散，直到该实例恢复正常。</li>\n<li>数据备份与冗余存储：定期对数据进行备份，并且将备份数据存储在不同的地理位置或存储介质上。除了本地备份外，还可以使用云存储服务进行异地备份。在数据丢失或损坏的情况下，可以从备份数据中恢复。对于分布式系统中的数据，采用多副本策略，如在分布式数据库中，数据会在多个节点上保存副本，通过一致性算法（如 Paxos、Raft）来保证副本之间的数据一致性。</li>\n</ul>\n</li>\n</ul>\n<h6 id=\"故障检测与自动恢复\"><a href=\"#故障检测与自动恢复\" class=\"headerlink\" title=\"故障检测与自动恢复\"></a>故障检测与自动恢复</h6><p>监控和预警：实时监控系统的运行状态，及时发现问题并发出预警。</p>\n<ul>\n<li>健康检查机制<ul>\n<li>服务器健康检查：通过心跳检测、端口扫描、服务响应检查等方式来监测服务器的健康状态。例如，负载均衡器每隔一段时间向后端服务器发送心跳包，如果在规定时间内没有收到服务器的响应，就认为该服务器出现故障，将其从服务列表中移除。在容器化环境（如 Docker、Kubernetes）中，容器编排工具也会定期检查容器的健康状态，当容器出现问题时，会自动重启或重新调度。</li>\n<li>服务健康检查：对于每个服务实例，检查其提供的接口是否能够正常响应。可以通过发送模拟请求或调用服务的健康检查接口来实现。例如，一个支付服务可以提供一个健康检查端点，该端点返回服务的状态信息，监控系统定期访问这个端点，如果返回的状态异常，就采取相应的恢复措施。</li>\n</ul>\n</li>\n<li>自动恢复策略<ul>\n<li>服务器自动重启：当检测到服务器出现故障（如系统崩溃、软件故障等）时，自动重启服务器。在一些云服务环境中，云平台会自动检测到虚拟机或容器的故障，并自动重启它们。同时，为了避免频繁重启导致的问题，可以设置重启的次数限制和时间间隔。</li>\n<li>服务自动切换和重新部署：当一个服务实例出现故障时，自动切换到其他正常的服务实例。对于微服务架构，服务发现工具可以动态地更新服务实例列表，将请求导向可用的实例。在某些情况下，还可以自动触发服务的重新部署，例如，当检测到某个服务的代码更新后出现故障，可以回滚到之前的稳定版本或者重新部署经过修复的版本。</li>\n</ul>\n</li>\n</ul>\n<h6 id=\"负载均衡与流量控制\"><a href=\"#负载均衡与流量控制\" class=\"headerlink\" title=\"负载均衡与流量控制\"></a>负载均衡与流量控制</h6><ul>\n<li>负载均衡策略<ul>\n<li>硬件负载均衡器：如 F5 Big - IP 等硬件设备，可以根据服务器的负载情况（如 CPU 使用率、内存使用率、连接数等）将流量均匀地分配到多个服务器上。这种方式性能高、可靠性强，适用于对流量处理要求较高的大型企业网络或数据中心。</li>\n<li>软件负载均衡：例如 Nginx、HAProxy 等开源软件负载均衡器，它们可以在软件层面实现类似的功能。通过配置不同的负载均衡算法（如轮询、加权轮询、IP 哈希等），将请求合理地分配到后端服务器。在云环境中，云服务提供商的负载均衡服务（如 AWS Elastic Load Balancing）也可以根据用户的需求灵活地配置负载均衡策略。</li>\n</ul>\n</li>\n<li>流量控制与限流<ul>\n<li>入口流量控制：在系统的入口处设置流量限制，防止大量突发流量涌入导致系统崩溃。可以根据系统的处理能力和资源情况，设定每秒允许进入的请求数量上限。例如，通过 API 网关对外部 API 请求进行限流，当请求数量超过阈值时，返回错误信息或引导用户稍后重试。</li>\n<li>服务间流量控制：在微服务架构中，为了防止某个微服务被过多的请求淹没，对服务间的调用进行限流。可以使用令牌桶算法或漏桶算法来实现限流。例如，当订单服务调用库存服务时，库存服务可以根据自己的处理能力设置限流策略，确保自身的稳定性。</li>\n</ul>\n</li>\n</ul>\n<h6 id=\"数据一致性与可靠性保障\"><a href=\"#数据一致性与可靠性保障\" class=\"headerlink\" title=\"数据一致性与可靠性保障\"></a>数据一致性与可靠性保障</h6><ul>\n<li>数据一致性策略<ul>\n<li>强一致性模型：在某些对数据准确性要求极高的场景下，如金融交易系统，采用强一致性模型。这通常需要通过分布式事务协议（如两阶段提交、三阶段提交）来保证所有副本的数据在任何时刻都是完全一致的。但这种方式会带来一定的性能开销，因为需要等待所有节点的数据更新完成才能返回结果。</li>\n<li>最终一致性模型：对于大多数互联网应用等对实时一致性要求不是特别严格的场景，采用最终一致性模型。例如，在分布式缓存系统中，数据更新后可能需要一段时间才能在所有副本中完全一致，但最终所有副本会达到一致状态。可以通过异步复制、版本号控制等方式来实现最终一致性。</li>\n</ul>\n</li>\n<li>数据可靠性措施<ul>\n<li>数据校验与纠错：在数据存储和传输过程中，采用数据校验机制（如 CRC 校验、哈希校验等）来检测数据是否出现错误。如果发现错误，可以尝试通过纠错码（如汉明码）或重新获取数据来纠正错误。例如，在存储系统中，每次写入数据后计算数据的校验和，在读取数据时再次计算校验和并与之前的结果进行比较，如果不一致，则采取相应的纠错措施。</li>\n<li>数据存储可靠性保障：除了前面提到的存储设备冗余外，还可以通过数据加密、访问控制等方式来保障数据的存储安全。例如，对敏感数据进行加密存储，只有经过授权的用户才能解密和访问数据，防止数据泄露和篡改。</li>\n</ul>\n</li>\n</ul>\n<p>参考文章：<br><a href=\"https://bbs.huaweicloud.com/blogs/194361#H22\" target=\"_blank\" rel=\"noopener\">软件系统“三高”的高并发，你了解吗？</a><br><a href=\"https://zq99299.github.io/note-architect/hc/01/04.html#%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BA%A6%E9%87%8F\" target=\"_blank\" rel=\"noopener\">系统怎样做到高可用？</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、基础概念\"><a href=\"#一、基础概念\" class=\"headerlink\" title=\"一、基础概念\"></a>一、基础概念</h3><p>在软件设计中，“三高” 是高并发（High - Concurrency）、高性能（High - Performance）、高可用（High - Availability），它们是构建高质量软件系统的关键目标。</p>","more":"<h4 id=\"1-1、高并发（High-Concurrency）\"><a href=\"#1-1、高并发（High-Concurrency）\" class=\"headerlink\" title=\"1.1、高并发（High - Concurrency）\"></a>1.1、高并发（High - Concurrency）</h4><p>高并发(High Concurrency)通常是指系统能够同时并行处理很多请求。一般用响应时间、并发吞吐量TPS, 并发用户数等指标来衡量。</p>\n<details style=\"background-color: #dbdbdb;padding: 10px;\">\n<summary>▲ 点击查看“并发&并行”相关定义</summary>\n\n<h5 id=\"什么是并发？\"><a href=\"#什么是并发？\" class=\"headerlink\" title=\"什么是并发？\"></a>什么是并发？</h5><p>并发是指在<font color=\"#e98787\"><strong>一段时间内</strong></font>，多个任务交替执行。</p>\n<blockquote>\n<p>并发的关键在于 “同时处理多个任务” 的外在表现，但在计算机系统的实际执行层面，特别是在<strong>单核处理器</strong>环境下，由于物理资源的限制（同一时刻只有一个核心能够执行指令），这些任务无法真正在同一时刻被执行。所以，通过操作系统的调度机制，让这些任务在一段时间内看起来像是同时在执行，这就形成了交替运行的情况。</p>\n</blockquote>\n<h5 id=\"什么是并行？\"><a href=\"#什么是并行？\" class=\"headerlink\" title=\"什么是并行？\"></a>什么是并行？</h5><p>并行是指在<font color=\"#e98787\"><strong>同一时刻</strong></font>，多个任务真正地同时执行。</p>\n<p><strong>并发&amp;并行的区别与联系</strong></p>\n<ul>\n<li>区别<ul>\n<li><strong>执行时间：</strong> 并发是多个任务在一段时间内交替执行，同一时刻只有一个任务在执行；而并行是多个任务在同一时刻真正地同时执行。例如，并发的多个任务就像在单车道的道路上多辆车交替行驶；而并行的多个任务则像在多车道的高速公路上多辆车同时行驶。</li>\n<li><strong>硬件要求：</strong> 并发可以在单处理器（CPU）系统中实现，通过操作系统的调度机制来实现任务的交替执行；而并行需要多个处理器（CPU）或多核处理器来支持，每个任务在不同的处理器或核心上运行。</li>\n<li><strong>性能提升方式：</strong> 并发主要是通过充分利用等待时间（如 I/O 等待）来提高系统的整体效率；并行则是通过同时利用多个计算资源来加速任务的完成。例如，并发在处理 I/O 密集型任务时效果显著；而并行在处理计算密集型任务时优势明显。</li>\n</ul>\n</li>\n<li>联系<ul>\n<li><strong>目的相同：</strong> 并发和并行的目的都是为了提高系统的处理能力和效率，以应对多个任务同时存在的情况。</li>\n<li><strong>可以结合使用：</strong> 在实际的系统设计中，常常会将并发和并行结合使用。例如，在一个多核服务器上，通过多线程并发地处理多个任务，并且每个线程在不同的核心上实现并行执行，从而最大限度地发挥系统的性能。</li></ul></li></ul></details>\n\n\n\n\n\n<h5 id=\"1-1-1、高并发的度量指标\"><a href=\"#1-1-1、高并发的度量指标\" class=\"headerlink\" title=\"1.1.1、高并发的度量指标\"></a>1.1.1、高并发的度量指标</h5><p>并发的指标一般有QPS、TPS、IOPS，这几个指标都是可归为系统吞吐率，QPS越高系统能hold住的请求数越多，但光关注这几个指标不够，我们还需要关注RT，即响应时间，也就是从发出request到收到response的时延，这个指标跟吞吐往往是此消彼长的，我们追求的是一定时延下的高吞吐。<br><img src=\"/2024/08/21/2024-08-21-架构-三高/%E5%B9%B6%E5%8F%91%E5%BA%A6%E5%85%AC%E5%BC%8F.png\" alt=\"并发度公式\"><br>比如有100万次请求，99万次请求都在10毫秒内响应，其他次数10秒才响应，平均时延不高，但时延高的用户受不了，所以，就有了TP90/TP99指标，这个指标不是求平均，而是把时延从小到大排序，取排名90%/99%的时延，<strong>这个指标越大，对慢请求越敏感。</strong></p>\n<blockquote>\n<p>TP90: 表示在所有的请求响应时间数据中，按照响应时间从小到大排序后，取排在 90% 位置的响应时间值。例如，有 100 个请求的响应时间数据，将它们排序后，第 90 个数据对应的响应时间就是 TP90。</p>\n</blockquote>\n<h5 id=\"1-1-2、高并发的设计思路\"><a href=\"#1-1-2、高并发的设计思路\" class=\"headerlink\" title=\"1.1.2、高并发的设计思路\"></a>1.1.2、高并发的设计思路</h5><p>高并发的设计思路有两个方向：</p>\n<ol>\n<li>垂直方向扩展，也叫竖向扩展</li>\n<li>水平方向扩展，也叫横向扩展</li>\n</ol>\n<p><strong>垂直方向：</strong> 提升单机能力（提升单机处理能力又可分为硬件和软件两个方面）</p>\n<ul>\n<li>硬件方向，很好理解，花钱升级机器，更多核更高主频更大存储空间更多带宽</li>\n<li>软件方向，包括用各快的数据结构，改进架构，应用多线程、协程，以及上性能优化各种手段，但这玩意儿天花板低，就像提升个人产出一样，996、007、最多24 X 7。</li>\n</ul>\n<p><strong>水平方向：</strong> 分布式集群</p>\n<ul>\n<li>为了解决分布式系统的复杂性问题，一般会用到架构分层和服务拆分，通过分层做隔离，通过微服务解耦。<br>这个理论上没有上限，只要做好层次和服务划分，加机器扩容就能满足需求，但实际上并非如此，一方面分布式会增加系统复杂性，另一方面集群规模上去之后，也会引入一堆AIOps、服务发现、服务治理的新问题。<br>因为垂直向的限制，所以，我们通常更关注水平扩展，高并发系统的实施也主要围绕水平方向展开。</li>\n</ul>\n<h5 id=\"1-1-3、高并发的关键技术\"><a href=\"#1-1-3、高并发的关键技术\" class=\"headerlink\" title=\"1.1.3、高并发的关键技术\"></a>1.1.3、高并发的关键技术</h5><h6 id=\"集群化：负载均衡\"><a href=\"#集群化：负载均衡\" class=\"headerlink\" title=\"集群化：负载均衡\"></a>集群化：负载均衡</h6><p>负载均衡就是把负载（request）均衡分配到不同的服务实例，利用集群的能力去对抗高并发，负载均衡是服务集群化的实施要素，它分3种：</p>\n<ol>\n<li><strong>DNS负载均衡，</strong> 客户端通过URL发起网络服务请求的时候，会去DNS服务器做域名解释，DNS会按一定的策略（比如就近策略）把URL转换成IP地址，同一个URL会被解释成不同的IP地址，这便是DNS负载均衡，它是一种粗粒度的负载均衡，它只用URL前半部分，因为DNS负载均衡一般采用就近原则，所以通常能降低时延，但DNS有cache，所以也会更新不及时的问题。</li>\n<li><strong>硬件负载均衡，</strong> 通过布置特殊的负载均衡设备到机房做负载均衡，比如F5，这种设备贵，性能高，可以支撑每秒百万并发，还能做一些安全防护，比如防火墙。</li>\n<li><strong>软件负载均衡，</strong> 根据工作在ISO 7层网络模型的层次，可分为四层负载均衡（比如章文嵩博士的LVS）和七层负载均衡（NGINX），软件负载均衡配置灵活，扩展性强，阿某云的SLB作为服务对外售卖，Nginx可以对URL的后半部做解释承担API网关的职责。</li>\n</ol>\n<h6 id=\"数据库层面：分库分表-读写分离\"><a href=\"#数据库层面：分库分表-读写分离\" class=\"headerlink\" title=\"数据库层面：分库分表+读写分离\"></a>数据库层面：分库分表+读写分离</h6><p>负载均衡解决了无状态服务的水平扩展问题，但我们的系统不全是无状态的，后面通常还有有状态的数据库，所以解决了前面的问题，存储有可能成为系统的瓶颈，我们需要对<strong>有状态存储做分片路由。</strong></p>\n<p>数据库的单机QPS一般不高，也就几千，显然满足不了高并发的要求。</p>\n<p>所以，我们需要做分库分表 + 读写分离。</p>\n<p>就是把一个库分成多个库，部署在多个数据库服务上，主库承载写请求，从库承载读请求。从库可以挂载多个，因为很多场景写的请求远少于读的请求，这样就把对单个库的压力降下来了。</p>\n<p>如果写的请求上升就继续分库分表，如果读的请求上升就挂更多的从库，但数据库天生不是很适合高并发，而且数据库对机器配置的要求一般很高，导致单位服务成本高，所以，这样加机器抗压力成本太高，还得另外想招。</p>\n<h6 id=\"读多写少：缓存\"><a href=\"#读多写少：缓存\" class=\"headerlink\" title=\"读多写少：缓存\"></a>读多写少：缓存</h6><p>缓存的理论依据是局部性原理。</p>\n<p>一般系统的写入请求远少于读请求，针对写少读多的场景，很适合引入缓存集群。</p>\n<p>在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求，因为缓存集群很容易做到高性能，所以，这样的话，通过缓存集群，就可以用更少的机器资源承载更高的并发。</p>\n<p>缓存的命中率一般能做到很高，而且速度很快，处理能力也强（单机很容易做到几万并发），是理想的解决方案。</p>\n<p>CDN本质上就是缓存，被用户大量访问的静态资源缓存在CDN中是目前的通用做法。</p>\n<p><strong>缓存也有很多需要谨慎处理的问题：</strong></p>\n<ol>\n<li>一致性问题：(a)更新db成功+更新cache失败 -&gt; 不一致 (b)更新db失败+更新cache成功 -&gt; 不一致 ©更新db成功+淘汰缓存失败 -&gt; 不一致</li>\n<li>缓存穿透：查询一定不存在的数据，会穿透缓存直接压到数据库，从而导致缓存失去作用，如果有人利用这个漏洞，大量查询一定不存在的数据，会对数据库造成压力，甚至打挂数据库。解决方案：布隆过滤器 或者 简单的方案，查询不存在的key，也把空结果写入缓存（设置较短的过期淘汰时间），从而降低命失</li>\n<li>缓存雪崩：如果大量缓存在一个时刻同时失效，则请求会转到DB，则对DB形成压迫，导致雪崩。简单的解决方案是为缓存失效时间添加随机值，降低同一时间点失效淘汰缓存数，避免集体失效事件发生</li>\n</ol>\n<p>但缓存是针对读，如果写的压力很大，怎么办？</p>\n<h6 id=\"高写入：消息中间件\"><a href=\"#高写入：消息中间件\" class=\"headerlink\" title=\"高写入：消息中间件\"></a>高写入：消息中间件</h6><p>通过跟主库加机器，耗费的机器资源是很大的，这个就是数据库系统的特点所决定的。</p>\n<p>相同的资源下，数据库系统太重太复杂，所以并发承载能力就在几千/s的量级，所以此时你需要引入别的一些技术。</p>\n<p>比如说消息中间件技术，也就是MQ集群，它是非常好的做写请求异步化处理，实现削峰填谷的效果。</p>\n<p>消息队列能做解耦，在只需要最终一致性的场景下，很适合用来配合做流控。</p>\n<p>假如说，每秒是1万次写请求，其中比如5千次请求是必须请求过来立马写入数据库中的，但是另外5千次写请求是可以允许异步化等待个几十秒，甚至几分钟后才落入数据库内的。</p>\n<p>那么此时完全可以引入消息中间件集群，把允许异步化的每秒5千次请求写入MQ，然后基于MQ做一个削峰填谷。比如就以平稳的1000/s的速度消费出来然后落入数据库中即可，此时就会大幅度降低数据库的写入压力。</p>\n<p>消息队列本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是很合适的，比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。</p>\n<h6 id=\"避免挤兑：流控\"><a href=\"#避免挤兑：流控\" class=\"headerlink\" title=\"避免挤兑：流控\"></a>避免挤兑：流控</h6><p>再强大的系统，也怕流量短事件内集中爆发，就像银行怕挤兑一样，所以，高并发另一个必不可少的模块就是流控。</p>\n<p>流控的关键是流控算法，有4种常见的流控算法。</p>\n<ol>\n<li><strong>计数器算法（固定窗口）：</strong> 计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略，下一个周期开始时，进行清零，重新计数，实现简单。计数器算法方式限流对于周期比较长的限流，存在很大的弊端，有严重的临界问题。</li>\n<li><strong>滑动窗口算法：</strong> 将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。此算法可以很好的解决固定窗口算法的临界问题。</li>\n<li><strong>漏桶算法：</strong> 访问请求到达时直接放入漏桶，如当前容量已达到上限（限流值），则进行丢弃（触发限流策略）。漏桶以固定的速率进行释放访问请求（即请求通过），直到漏桶为空。分布式环境下实施难度高。</li>\n<li><strong>令牌桶算法：</strong> 程序以r（r=时间周期/限流值）的速度向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，如获取到令牌则通过请求，否则触发限流策略。分布式环境下实施难度高。</li>\n</ol>\n<h4 id=\"1-2、高性能（High-Performance）\"><a href=\"#1-2、高性能（High-Performance）\" class=\"headerlink\" title=\"1.2、高性能（High - Performance）\"></a>1.2、高性能（High - Performance）</h4><p>高性能是指程序处理速度非常快，所占内存少，CPU占用率低。<strong>高性能的指标经常和高并发的指标紧密相关，想要提高性能，那么就要提高系统发并发能力。</strong></p>\n<h5 id=\"1-2-1、高性能的衡量指标\"><a href=\"#1-2-1、高性能的衡量指标\" class=\"headerlink\" title=\"1.2.1、高性能的衡量指标\"></a>1.2.1、高性能的衡量指标</h5><p>性能的常用的衡量指标包括响应时间RT（完成一个请求所花费的时间）、资源利用率（如 CPU 使用率、内存占用率等）、每秒事务处理量（TPS）等。例如，一个高性能的数据库系统，其查询响应时间可能在毫秒级别，CPU 使用率能够维持在一个合理的范围内，并且每秒能够处理大量的事务。</p>\n<h5 id=\"1-2-2、高性能的设计思路\"><a href=\"#1-2-2、高性能的设计思路\" class=\"headerlink\" title=\"1.2.2、高性能的设计思路\"></a>1.2.2、高性能的设计思路</h5><p>可以从计算机体系结构的底层原理去思考，系统优化离不开计算性能(CPU)和存储性能(IO)两个维度，每次谈到高性能设计，经常会面临几个名词：IO多路复用、零拷贝、线程池、冗余等等，总结如下方法：</p>\n<p><strong>如何设计高性能计算(CPU)</strong></p>\n<ul>\n<li>减少计算成本：代码优化计算的时间复杂度O(N^2)-&gt;O(N)，合理使用同步/异步、限流减少请求次数等；</li>\n<li>让更多的核参与计算：多线程代替单线程、集群代替单机等等；</li>\n</ul>\n<p><strong>如何提升系统IO</strong></p>\n<ul>\n<li>加快IO速度：顺序读写代替随机读写、硬件上SSD提升等；</li>\n<li>减少IO次数：索引/分布式计算代替全表扫描、零拷贝减少IO复制次数、DB批量读写、分库分表增加连接数等；</li>\n<li>减少IO存储：数据过期策略、合理使用内存、缓存、DB等中间件，做好消息压缩等；</li>\n</ul>\n<h5 id=\"1-2-3、高性能的关键技术\"><a href=\"#1-2-3、高性能的关键技术\" class=\"headerlink\" title=\"1.2.3、高性能的关键技术\"></a>1.2.3、高性能的关键技术</h5><p>高性能的关键技术，包含高并发的关键技术，例如缓存、分库分表、读写分离。</p>\n<h6 id=\"算法和数据结构优化\"><a href=\"#算法和数据结构优化\" class=\"headerlink\" title=\"算法和数据结构优化\"></a>算法和数据结构优化</h6><p>选择高效的算法 &amp; 优化数据结构。</p>\n<h6 id=\"硬件资源优化与适配\"><a href=\"#硬件资源优化与适配\" class=\"headerlink\" title=\"硬件资源优化与适配\"></a>硬件资源优化与适配</h6><p>根据系统的负载特点选择服务器的硬件配置。对于计算密集型的应用，优先考虑配置高性能的 CPU 和足够的内存。例如，一个进行 3D 图形渲染的服务器，需要配备多核、高频的 CPU 和大容量的高速内存，以满足复杂图形计算的需求。</p>\n<h6 id=\"代码优化与性能调优\"><a href=\"#代码优化与性能调优\" class=\"headerlink\" title=\"代码优化与性能调优\"></a>代码优化与性能调优</h6><p>减少不必要的计算和操作：<br>在代码编写过程中，避免重复计算和不必要的循环嵌套。例如，将可以提前计算的结果放在循环体外进行计算，减少循环内部的计算量。对于复杂的条件判断，可以通过调整判断顺序来减少不必要的计算。</p>\n<p>优化数据库访问代码：<br>减少数据库查询的次数。例如，通过使用连接查询或子查询来一次性获取需要的数据，而不是多次执行简单的查询。对于频繁查询的数据库字段，合理地添加索引可以提高查询速度，但要注意避免过度索引导致的数据更新和存储成本增加。</p>\n<h6 id=\"异步处理与并行处理\"><a href=\"#异步处理与并行处理\" class=\"headerlink\" title=\"异步处理与并行处理\"></a>异步处理与并行处理</h6><p>异步处理机制应用：<br>通过异步处理可以提高系统的整体性能，特别是对于一些不需要立即返回结果的操作。例如，在 Web 应用中，用户提交表单后，可以先返回一个确认信息给用户，然后在后台异步地进行数据验证、存储等操作。可以使用消息队列（如 RabbitMQ 或 Kafka）来实现异步处理，将任务放入消息队列后，由专门的消费者进程或线程在后台进行处理。</p>\n<h4 id=\"1-3、高性能-amp-高并发-的区别\"><a href=\"#1-3、高性能-amp-高并发-的区别\" class=\"headerlink\" title=\"1.3、高性能 &amp; 高并发 的区别\"></a>1.3、高性能 &amp; 高并发 的区别</h4><p>高性能和高并发确实有一些相似之处，但他们也有明显的区别：</p>\n<p>相似点：</p>\n<ul>\n<li><strong>目标导向有重合：</strong> 高并发和高性能的最终目标都是为了让系统能够更好地应对各种请求，提供优质的服务。在当今互联网应用场景下，如电商平台的促销活动、热门社交媒体的信息发布时段等，<strong>高并发场景往往也要求系统具备高性能，这样才能在大量请求涌入时依然保证系统的流畅运行，为用户提供良好的体验。</strong></li>\n<li><strong>部分优化策略重叠：</strong> 为了实现高并发和高性能，都可能会采用一些相同的技术手段。例如，缓存技术在两者中都经常被使用。在高性能系统中，缓存可以减少数据查询和处理的时间，提高系统的响应速度；在高并发系统中，缓存能够减轻后端服务器的压力，使得系统在大量请求下依然能够快速响应，避免反复从数据源获取相同的数据。</li>\n</ul>\n<p>不同点：</p>\n<ul>\n<li>侧重点不同：<ul>\n<li>高并发：侧重于系统同时处理大量请求的能力。它更关注系统在多任务环境下的架构设计和资源分配，要确保系统在大量并发请求到来时不会崩溃，并且能够合理地调度资源，让各个请求都能得到及时处理。</li>\n<li>高性能：更强调系统的处理效率和资源利用率。高性能系统追求的是在给定的资源条件下（如 CPU、内存、磁盘 I/O、网络带宽等），能够以最短的时间完成单个请求的处理，并且尽可能地充分利用资源，避免浪费。</li>\n</ul>\n</li>\n<li>衡量指标不同：<ul>\n<li>高并发：主要通过系统能够同时处理的请求数量、请求队列长度、吞吐量（单位时间内处理的请求数量）等指标来衡量。</li>\n<li>高性能：常用的衡量指标包括响应时间（完成一个请求所花费的时间）、资源利用率（如 CPU 使用率、内存占用率等）、每秒事务处理量（TPS）等。例如，一个高性能的数据库系统，其查询响应时间可能在毫秒级别，CPU 使用率能够维持在一个合理的范围内，并且每秒能够处理大量的事务。</li>\n</ul>\n</li>\n<li>实现策略的重点不同：<ul>\n<li>高并发：<ul>\n<li>架构层面：重点在于采用分布式架构、微服务架构等方式将系统进行拆分，通过负载均衡将请求均匀分配到多个节点或服务实例上，同时利用消息队列等异步处理机制来缓解系统压力。</li>\n<li>资源管理层面：需要关注资源的竞争和协调，例如数据库连接池的合理设置，避免过多的请求同时占用数据库连接导致系统阻塞。同时，对服务器资源进行动态调整和扩展，以适应不同并发水平的需求。</li>\n</ul>\n</li>\n<li>高性能：<ul>\n<li>算法和数据结构优化：选择高效的算法和数据结构是高性能的关键。例如，在数据搜索场景中，使用哈希表可以实现快速的数据查找，相比简单的线性查找算法，能够大大提高系统的性能。</li>\n<li>硬件优化和适配：根据系统的需求合理选择硬件设备，并进行优化配置。例如，对于计算密集型的高性能应用，可以选择高性能的 CPU 和 GPU，同时优化服务器的内存和存储系统，以提高数据读写速度。</li>\n<li>代码层面的精细优化：编写高效的代码，减少不必要的计算、内存分配和释放操作等。例如，在循环中避免重复计算，优化函数调用，减少对象的创建和销毁次数等，这些细节优化能够有效提高系统的性能。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"1-4、高可用（High-Availability）\"><a href=\"#1-4、高可用（High-Availability）\" class=\"headerlink\" title=\"1.4、高可用（High - Availability）\"></a>1.4、高可用（High - Availability）</h4><p>高可用(High Availability，HA)核心目标是保障业务的连续性，从用户视角来看，业务永远是正常稳定的对外提供服务，业界一般用几个9来衡量系统的可用性。通常采用一系列专门的设计(冗余、去单点等)，减少业务的停工时间，从而保持其核心服务的高度可用性。</p>\n<p>CAP理论和BASE理论、通过集群来提高系统整体稳定性、超时和重试机制、应对接口级故障：降级、熔断、限流、排队。我们在很多开源组件的文档中看到的 HA 方案就是提升组件可用性，让系统免于宕机无法服务的方案。</p>\n<h5 id=\"1-4-1、高可用的衡量指标\"><a href=\"#1-4-1、高可用的衡量指标\" class=\"headerlink\" title=\"1.4.1、高可用的衡量指标\"></a>1.4.1、高可用的衡量指标</h5><p>可用性是一个抽象的概念，你需要知道要如何来度量它，与之相关的概念是： MTBF 和 MTTR。</p>\n<ul>\n<li><strong>MTBF（Mean Time Between Failure）</strong> 是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。</li>\n<li><strong>MTTR（Mean Time To Repair）</strong> 表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。</li>\n</ul>\n<p>可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：</p>\n<blockquote>\n<p>Availability = MTBF / (MTBF + MTTR)</p>\n</blockquote>\n<p>这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。<br><img src=\"/2024/08/21/2024-08-21-架构-三高/%E9%AB%98%E5%8F%AF%E7%94%A8%E8%A1%A1%E9%87%8F%E6%8C%87%E6%A0%87.png\" alt=\"高可用衡量指标\"></p>\n<h5 id=\"1-4-2、高可用的设计思路\"><a href=\"#1-4-2、高可用的设计思路\" class=\"headerlink\" title=\"1.4.2、高可用的设计思路\"></a>1.4.2、高可用的设计思路</h5><p><img src=\"/2024/08/21/2024-08-21-架构-三高/%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AE%BE%E8%AE%A1.png\" alt=\"高可用设计\"></p>\n<h6 id=\"冗余设计\"><a href=\"#冗余设计\" class=\"headerlink\" title=\"冗余设计\"></a>冗余设计</h6><p>通过冗余的硬件设备和软件组件，提高系统的可靠性。</p>\n<ul>\n<li>硬件冗余<ul>\n<li>服务器冗余：采用多台服务器来提供相同的服务，例如在 Web 服务中，使用负载均衡器将用户请求分配到多个 Web 服务器上。如果其中一台服务器出现故障，负载均衡器会将请求转发到其他正常的服务器，确保服务不中断。在一些关键业务场景中，甚至可以采用双机热备（Active - Active 或 Active - Standby）的方式，两台服务器同时运行相同的服务或一台处于备用状态，实时同步数据，当主服务器出现故障时，备用服务器能立即接管工作。</li>\n<li>存储设备冗余：对于存储系统，使用磁盘阵列（RAID）技术来实现存储冗余。不同的 RAID 级别提供不同程度的冗余和性能。例如，RAID 1 通过镜像技术将数据同时写入两块磁盘，当一块磁盘出现故障时，另一块磁盘的数据仍然可用；RAID 5 则是通过奇偶校验信息分布在多个磁盘上，允许一块磁盘故障后通过奇偶校验恢复数据，这种方式在提供一定冗余的同时也兼顾了存储效率。</li>\n</ul>\n</li>\n<li>软件组件冗余<ul>\n<li>服务实例冗余：在微服务架构中，每个微服务可以部署多个实例。例如，订单服务部署多个实例并分布在不同的服务器上，通过服务注册与发现机制，当一个实例出现故障时，其他实例可以继续处理请求。同时，使用熔断器（Circuit Breaker）模式，当某个服务实例频繁出现故障时，暂时切断对该实例的请求，避免故障扩散，直到该实例恢复正常。</li>\n<li>数据备份与冗余存储：定期对数据进行备份，并且将备份数据存储在不同的地理位置或存储介质上。除了本地备份外，还可以使用云存储服务进行异地备份。在数据丢失或损坏的情况下，可以从备份数据中恢复。对于分布式系统中的数据，采用多副本策略，如在分布式数据库中，数据会在多个节点上保存副本，通过一致性算法（如 Paxos、Raft）来保证副本之间的数据一致性。</li>\n</ul>\n</li>\n</ul>\n<h6 id=\"故障检测与自动恢复\"><a href=\"#故障检测与自动恢复\" class=\"headerlink\" title=\"故障检测与自动恢复\"></a>故障检测与自动恢复</h6><p>监控和预警：实时监控系统的运行状态，及时发现问题并发出预警。</p>\n<ul>\n<li>健康检查机制<ul>\n<li>服务器健康检查：通过心跳检测、端口扫描、服务响应检查等方式来监测服务器的健康状态。例如，负载均衡器每隔一段时间向后端服务器发送心跳包，如果在规定时间内没有收到服务器的响应，就认为该服务器出现故障，将其从服务列表中移除。在容器化环境（如 Docker、Kubernetes）中，容器编排工具也会定期检查容器的健康状态，当容器出现问题时，会自动重启或重新调度。</li>\n<li>服务健康检查：对于每个服务实例，检查其提供的接口是否能够正常响应。可以通过发送模拟请求或调用服务的健康检查接口来实现。例如，一个支付服务可以提供一个健康检查端点，该端点返回服务的状态信息，监控系统定期访问这个端点，如果返回的状态异常，就采取相应的恢复措施。</li>\n</ul>\n</li>\n<li>自动恢复策略<ul>\n<li>服务器自动重启：当检测到服务器出现故障（如系统崩溃、软件故障等）时，自动重启服务器。在一些云服务环境中，云平台会自动检测到虚拟机或容器的故障，并自动重启它们。同时，为了避免频繁重启导致的问题，可以设置重启的次数限制和时间间隔。</li>\n<li>服务自动切换和重新部署：当一个服务实例出现故障时，自动切换到其他正常的服务实例。对于微服务架构，服务发现工具可以动态地更新服务实例列表，将请求导向可用的实例。在某些情况下，还可以自动触发服务的重新部署，例如，当检测到某个服务的代码更新后出现故障，可以回滚到之前的稳定版本或者重新部署经过修复的版本。</li>\n</ul>\n</li>\n</ul>\n<h6 id=\"负载均衡与流量控制\"><a href=\"#负载均衡与流量控制\" class=\"headerlink\" title=\"负载均衡与流量控制\"></a>负载均衡与流量控制</h6><ul>\n<li>负载均衡策略<ul>\n<li>硬件负载均衡器：如 F5 Big - IP 等硬件设备，可以根据服务器的负载情况（如 CPU 使用率、内存使用率、连接数等）将流量均匀地分配到多个服务器上。这种方式性能高、可靠性强，适用于对流量处理要求较高的大型企业网络或数据中心。</li>\n<li>软件负载均衡：例如 Nginx、HAProxy 等开源软件负载均衡器，它们可以在软件层面实现类似的功能。通过配置不同的负载均衡算法（如轮询、加权轮询、IP 哈希等），将请求合理地分配到后端服务器。在云环境中，云服务提供商的负载均衡服务（如 AWS Elastic Load Balancing）也可以根据用户的需求灵活地配置负载均衡策略。</li>\n</ul>\n</li>\n<li>流量控制与限流<ul>\n<li>入口流量控制：在系统的入口处设置流量限制，防止大量突发流量涌入导致系统崩溃。可以根据系统的处理能力和资源情况，设定每秒允许进入的请求数量上限。例如，通过 API 网关对外部 API 请求进行限流，当请求数量超过阈值时，返回错误信息或引导用户稍后重试。</li>\n<li>服务间流量控制：在微服务架构中，为了防止某个微服务被过多的请求淹没，对服务间的调用进行限流。可以使用令牌桶算法或漏桶算法来实现限流。例如，当订单服务调用库存服务时，库存服务可以根据自己的处理能力设置限流策略，确保自身的稳定性。</li>\n</ul>\n</li>\n</ul>\n<h6 id=\"数据一致性与可靠性保障\"><a href=\"#数据一致性与可靠性保障\" class=\"headerlink\" title=\"数据一致性与可靠性保障\"></a>数据一致性与可靠性保障</h6><ul>\n<li>数据一致性策略<ul>\n<li>强一致性模型：在某些对数据准确性要求极高的场景下，如金融交易系统，采用强一致性模型。这通常需要通过分布式事务协议（如两阶段提交、三阶段提交）来保证所有副本的数据在任何时刻都是完全一致的。但这种方式会带来一定的性能开销，因为需要等待所有节点的数据更新完成才能返回结果。</li>\n<li>最终一致性模型：对于大多数互联网应用等对实时一致性要求不是特别严格的场景，采用最终一致性模型。例如，在分布式缓存系统中，数据更新后可能需要一段时间才能在所有副本中完全一致，但最终所有副本会达到一致状态。可以通过异步复制、版本号控制等方式来实现最终一致性。</li>\n</ul>\n</li>\n<li>数据可靠性措施<ul>\n<li>数据校验与纠错：在数据存储和传输过程中，采用数据校验机制（如 CRC 校验、哈希校验等）来检测数据是否出现错误。如果发现错误，可以尝试通过纠错码（如汉明码）或重新获取数据来纠正错误。例如，在存储系统中，每次写入数据后计算数据的校验和，在读取数据时再次计算校验和并与之前的结果进行比较，如果不一致，则采取相应的纠错措施。</li>\n<li>数据存储可靠性保障：除了前面提到的存储设备冗余外，还可以通过数据加密、访问控制等方式来保障数据的存储安全。例如，对敏感数据进行加密存储，只有经过授权的用户才能解密和访问数据，防止数据泄露和篡改。</li>\n</ul>\n</li>\n</ul>\n<p>参考文章：<br><a href=\"https://bbs.huaweicloud.com/blogs/194361#H22\" target=\"_blank\" rel=\"noopener\">软件系统“三高”的高并发，你了解吗？</a><br><a href=\"https://zq99299.github.io/note-architect/hc/01/04.html#%E5%8F%AF%E7%94%A8%E6%80%A7%E7%9A%84%E5%BA%A6%E9%87%8F\" target=\"_blank\" rel=\"noopener\">系统怎样做到高可用？</a></p>"},{"title":"《架构》DDD应用架构","date":"2024-09-03T02:00:00.000Z","_content":"\n### 一、DDD的应用架构\n领域驱动设计（DDD）主要包含以下几种应用架构：\n- 分层架构\n- 六边形架构\n- 洋葱架构\n- 整洁架构\n- 清晰架构\n\n<!--more-->\n\n### 二、分层架构\nDDD 的分层架构在不断发展。最早是传统的四层架构；后来四层架构有了进一步的优化，实现了各层对基础层的解耦；再后来领域层和应用层之间增加了上下文环境（Context）层，五层架构（DCI）就此形成了。\n![传统4层架构](2024-09-01-架构-DDD分层架构/传统4层架构.png)\n我们看一下上面这张图，在最早的传统四层架构中，**基础层是被其它层依赖的，它位于最核心的位置** ，那按照分层架构的思想，它应该就是核心，但实际上领域层才是软件的核心，所以这种依赖是有问题的。后来我们采用了依赖倒置（Dependency inversion principle,DIP）的设计，优化了传统的四层架构，实现了各层对基础层的解耦。\n\n#### 2.1、分层说明\n我们今天讲的 DDD 分层架构就是优化后的四层架构。在下面这张图中，从上到下依次是：用户接口层、应用层、领域层和基础层。那 DDD 各层的主要职责是什么呢？下面我来逐一介绍一下。\n![分层架构](2024-09-01-架构-DDD分层架构/分层架构.png)\n##### 用户接口层\n用户接口层负责向用户显示信息和解释用户指令。这里的用户可能是：用户、程序、自动化测试和批处理脚本等等。\n\n##### 应用层\n只负责业务流程的串联，对不同领域的服务调用进行编排。          \n事务控制一般在Application层， 在该层我们可以进行安全认证，权限校验，持久化事务控制，或者向其他系统发生基于事件的消息通知，也是作为领域层和用户接口层的桥梁。\n命名规范：command入参为XxxCmdRequest，query入参为XxxQueryRequest\n\nApplicationService的接口入参只能是一个Command、Query或Event对象，CQE对象需要能代表当前方法的业务语意。 ApplicationService集中罗列系统核心的业务用例(Command)。读写（Command和Query）建议分开，放到不同的Service。\n> 是协调领域层和其他外部系统的中间层。它不包含业务逻辑的核心部分，而是负责组织和调用领域层的服务来完成业务操作。例如，在电商系统的订单处理中，应用层会协调领域层的 “订单服务”、“库存服务” 和 “支付服务” 等来完成一个完整的下单流程。它起到了一个流程编排的作用，确保业务操作按照正确的顺序和规则进行。\n\n##### 领域层\n领域层的作用是实现企业核心业务逻辑，通过各种校验手段保证业务的正确性。领域层主要体现领域模型的业务能力，它用来表达业务概念、业务状态和业务规则。\n\n领域层包含聚合根、实体、值对象、领域服务等领域模型中的领域对象。\n\n这里我要特别解释一下其中几个领域对象的关系，以便你在设计领域层的时候能更加清楚。首先，领域模型的业务逻辑主要是由实体和领域服务来实现的，其中实体会采用充血模型来实现所有与之相关的业务功能。其次，你要知道，实体和领域对象在实现业务逻辑上不是同级的，当领域中的某些功能，单一实体（或者值对象）不能实现时，领域服务就会出马，它可以组合聚合内的多个实体（或者值对象），实现复杂的业务逻辑。\n> 例如，在信贷系统中，领域层的 “信用评估服务” 会根据 “客户” 模型和 “贷款申请” 模型中的信息，运用复杂的信用评估算法来判断客户的信用等级，这就是领域服务在处理业务逻辑。\n\n##### 基础层\n基础层是贯穿所有层的，它的作用就是为其它各层提供通用的技术和基础服务，包括第三方工具、驱动、消息中间件、网关、文件、缓存以及数据库等。比较常见的功能还是提供数据库持久化。\n\n基础层包含基础服务，它采用依赖倒置设计，封装基础资源服务，实现应用层、领域层与基础层的解耦，降低外部资源变化对应用的影响。\n\n比如说，在传统架构设计中，由于上层应用对数据库的强耦合，很多公司在架构演进中最担忧的可能就是换数据库了，因为一旦更换数据库，就可能需要重写大部分的代码，这对应用来说是致命的。那采用依赖倒置的设计以后，应用层就可以通过解耦来保持独立的核心业务逻辑。当数据库变更时，我们只需要更换数据库基础服务就可以了，这样就将资源变更对应用的影响降到了最低。\n\n\n#### 2.2、分层代码结构示例\n系统架构：\n![分层架构_系统架构](2024-09-01-架构-DDD分层架构/分层架构_系统架构.png)\n包结构划分：\n![分层架构_包结构划分](2024-09-01-架构-DDD分层架构/分层架构_包结构划分.png)\n代码指导：\n![分层架构_代码指示](2024-09-01-架构-DDD分层架构/分层架构_代码指示.png)\n\n\n### 三、六边形架构\n2005年，Alistair Cockburn提出了端口和适配器架构Ports & Adapters Architecture(又称六边形架构Hexagonal Architecture)。\n![六边形架构](2024-09-01-架构-DDD分层架构/六边形架构.png)\n端口和适配器架构中的相关概念：\n- 工具Tools： 应用application使用的工具Tools(WebSerevr, Cli, DB, SearchEngine, MQ)\n- 端口Port： 在application core层定义的工具交互规范（即定义 工具Tools如何使用application core的规范 或 工具Tools如何被application core使用的规范），对应编程语言的interface定义，且端口定义应该符合应用层逻辑（不可简单模仿或者直接使用底层工具的API）\n- 适配器Adapter： 连接工具Tools(WebSerevr, Cli, DB, SearchEngine, MQ)和应用核心application core的代码单元\n  - 适配器依赖port（调用port 或 实现port）和工具，但是application core仅依赖port。\n- 主动适配器（Primary/Driving Adapters ） - 主动调用应用核心Application Core，触发应用执行某项活动\n  - 主动适配器 -> 依赖端口 -> 注入端口实现，\n  - 例如主动适配器Controller -> 依赖端口ServiceInterface -> 注入端口实现ServiceImpl\n- 被动适配器（Secondary/Driven Adapters） - 被应用核心Application Core调用来执行动作，实现应用定义的端口\n  - 端口 -->被动适配器实现端口逻辑-> 包装系统外部工具，\n  - 例如端口RespositoryInterface -> 被动适配器Mysql实现MysqlRepositoryImpl -> 调用Mysql数据库\n\n几边形不重要，可以N多边，重点是Port & Adapter思想，关于端口和适配器架构的优势：\n- 核心业务在最中心（最重要），\n- 核心业务依赖Port，Adapter依赖Port（主动） 或 Adapter为Port的具体实现（被动），\n- 核心业务逻辑与实现细节（技术框架、底层存储、工具、传输通信机制等）相隔离，\n- 保持核心业务逻辑的可重用性，\n- 可通过（注入）不同Adapter实现来切换技术实现，避免技术框架、工具、供应商锁定，\n- 且基于mock Port的形式更易于测试。\n\n\n### 四、洋葱架构\n洋葱架构（Onion Architecture） 在2008年由Jeffrey Palermo提出。\n![洋葱架构](2024-09-01-架构-DDD分层架构/洋葱架构.png)\n洋葱架构在DDD的基础上，将内层（业务逻辑层，Business Logic）进一步划分，最终为：\n- **Adapters**，即六边形架构中的适配器Adapter层\n  - User Interface、Infrastructure、Tests\n- **Application Core，应用核心层**，也即原来的六边形架构中心的Business Logic层\n  - **Application Services** - 应用服务册层\n  - **Domain Services** - 领域服务层\n  - **Domain Model** - 领域模型层\n\n且明确了依赖方向：\n- 外层依赖内层\n- 内层不知道外层\n- 且在不破坏依赖方向的前提下，外层亦可以直接调用任一内层（不一定是相邻接的2层），参考CQRS中Query实现（Application Services直接调用DAO）\n\n\n在洋葱架构中，各层的职能是这样划分的：\n- 领域模型实现领域内核心业务逻辑，它封装了企业级的业务规则。领域模型的主体是实体，一个实体可以是一个带方法的对象，也可以是一个数据结构和方法集合。\n- 领域服务实现涉及多个实体的复杂业务逻辑。\n- 应用服务实现与用户操作相关的服务组合与编排，它包含了应用特有的业务流程规则，封装和实现了系统所有用例。\n- 最外层主要提供适配的能力，适配能力分为主动适配和被动适配。主动适配主要实现外部用户、网页、批处理和自动化测试等对内层业务逻辑访问适配。被动适配主要是实现核心业务逻辑对基础资源访问的适配，比如数据库、缓存、文件系统和消息中间件等。\n- 红圈内的领域模型、领域服务和应用服务一起组成软件核心业务能力。\n\n\n\n### 五、整洁架构【Clean Architecture】\n2012年Robert C. Martin (又名Uncle Bob) 提出了整洁架构Clean Architecture，整洁架构将EBI、六边形架构Hexagonal、洋葱架构Onoin等整合成一个可以实际落地的架构。\n![整洁架构](2024-09-01-架构-DDD分层架构/整洁架构.png)\n与洋葱架构相比，整洁架构调整如下：\n- Application Services调整为Use Cases\n- Domain Services, Domain Model调整为Entities\n\n整洁架构并没有带来突破性的概念或模式，但是：\n- 它发掘了某种程度上被遗忘了的概念、规则和模式；\n- 它澄清了一些实用且重要的概念、规则和模式；\n- 它告诉我们如何把所有的概念、规则和模式整合起来，形成一种构建复杂应用并保持可维护性的标准套路\n\n### 六、清晰架构\n2017年Herberto Graca在其软件架构编年史系列文章中提出清晰架构Explicit Architecture，即将DDD, Hexagonal, Onion, Clean, CQRS等进行融合后的架构。\n![清晰架构](2024-09-01-架构-DDD分层架构/清晰架构.png)\n最中心的<font color=#e98787>**红色多边形**</font>Application Core即表示业务逻辑实现，即应用核心\n- 红色多边形的边界即表示端口Port，即应用核心的入口/出口定义\n- **Application Layer** - 应用层，包括：\n  - **Application Services**，业务用例的编排服务即及其interface定义，应用服务的作用通常如下：\n    - 使用 Repostitory 查找一个或多个实体；\n    - 让这些实体执行一些领域逻辑；\n    - 再次使用 Repostitory 让这些实体持久化，有效地保存数据变化；\n    - 触发应用事件（如发送邮件、调用第三方API、发送MQ消息等）。\n  - **CQRS命令/查询处理器**\n  - **Event Listener事件监听器**\n  - **Port端口定义**，如ORM 接口Repostitory、搜索引擎接口、消息接口等等\n- **Domain Layer - 领域层**，这一层含了数据和操作数据的逻辑，它们只和领域本身有关，独立于调用这些逻辑的业务过程。它们完全独立，对应用层完全无感知。\n  - **Domain Services - 领域服务**，封装涉及多实体（相同或不同实体类型）的领域逻辑，且领域服务间可以相互调用。\n  - **Domain Models - 领域模型**，在架构的正中心，完全不依赖外部任何层次的领域模型。它包含了那些表示领域中某个概念的业务对象，如实体、值对象、枚举以及其它领域模型种用到的任何对象（如领域事件Domain Events，简单理解为MQ消息）。\n- 红色多边形的外侧左半圆部分即为**主/主动适配器**（用户界面User Interface实现）\n  - 如Spring MVC中的Controller实现\n  - Command Query Bus 命令查询总线\n- 红色多边形的外侧右半圆部分即**次/被动适配器**（基础设置Infrastructure实现）\n  - 如数据持久化实现Mysql、短信通知实现、MQ通知、搜索引擎ES实现等\n  - Event Bus 事件总线\n- 依赖方向由外到内，且内层不知道外层（参见之前洋葱架构） \n\n\n>TIPS: 清晰架构只是一份指南！\n应用才是疆域，现实情况和具体用例才是运用这些知识的地方，它们才能勾勒出实际架构的轮廓！\n我们需要理解所有这些模式，\n但我们还时常需要思考和理解我们的应用需要什么，我们应该在追求解耦和内聚的道路上走多远。\n这个决定可能受到许多因素的影响，\n包括项目的功能需求，也包括构建应用的时间期限，应用寿命，开发团队的经验等等因素。\n\n### 七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：\n![总的架构演进图](2024-09-01-架构-DDD分层架构/总的架构演进图.png)\n\n\n---\n\n参考文章：\n[DDD中常提到的应用架构总结（六边形、洋葱、整洁、清晰）](https://code84.com/730128.html)      \n[微服务架构模型：几种常见模型的对比和分析](https://zq99299.github.io/note-book2/ddd/02/03.html#%E4%BB%8E%E4%B8%89%E7%A7%8D%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B%E7%9C%8B%E4%B8%AD%E5%8F%B0%E5%92%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1)\n[DDD 领域驱动设计-应用架构](https://juejin.cn/post/7170631967178752030)\n\nEBI：\nhttps://herbertograca.com/2017/08/24/ebi-architecture/\n\n端口和适配器架构：\n11.端口和适配器架构(译) - https://www.jianshu.com/p/f39f4537857e\nhttps://herbertograca.com/2017/09/14/ports-adapters-architecture/\n\n洋葱架构：\nhttps://herbertograca.com/2017/09/21/onion-architecture/\nhttps://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/\n\n整洁架构：\nhttps://herbertograca.com/2017/09/28/clean-architecture-standing-on-the-shoulders-of-giants/\nhttps://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\n\n清晰架构：\nhttps://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/\n17.清晰架构(01): 融合 DDD、洋葱架构、整洁架构、CQRS…(译) - https://www.jianshu.com/p/d3e8b9ac097b\n\nDDD：\nhttps://herbertograca.com/2017/09/07/domain-driven-design/","source":"_posts/2024-09-03-架构-DDD应用架构.md","raw":"---\ntitle: 《架构》DDD应用架构\ndate: 2024-09-03 10:00:00\ncategories:\n  - [架构, DDD]\n---\n\n### 一、DDD的应用架构\n领域驱动设计（DDD）主要包含以下几种应用架构：\n- 分层架构\n- 六边形架构\n- 洋葱架构\n- 整洁架构\n- 清晰架构\n\n<!--more-->\n\n### 二、分层架构\nDDD 的分层架构在不断发展。最早是传统的四层架构；后来四层架构有了进一步的优化，实现了各层对基础层的解耦；再后来领域层和应用层之间增加了上下文环境（Context）层，五层架构（DCI）就此形成了。\n![传统4层架构](2024-09-01-架构-DDD分层架构/传统4层架构.png)\n我们看一下上面这张图，在最早的传统四层架构中，**基础层是被其它层依赖的，它位于最核心的位置** ，那按照分层架构的思想，它应该就是核心，但实际上领域层才是软件的核心，所以这种依赖是有问题的。后来我们采用了依赖倒置（Dependency inversion principle,DIP）的设计，优化了传统的四层架构，实现了各层对基础层的解耦。\n\n#### 2.1、分层说明\n我们今天讲的 DDD 分层架构就是优化后的四层架构。在下面这张图中，从上到下依次是：用户接口层、应用层、领域层和基础层。那 DDD 各层的主要职责是什么呢？下面我来逐一介绍一下。\n![分层架构](2024-09-01-架构-DDD分层架构/分层架构.png)\n##### 用户接口层\n用户接口层负责向用户显示信息和解释用户指令。这里的用户可能是：用户、程序、自动化测试和批处理脚本等等。\n\n##### 应用层\n只负责业务流程的串联，对不同领域的服务调用进行编排。          \n事务控制一般在Application层， 在该层我们可以进行安全认证，权限校验，持久化事务控制，或者向其他系统发生基于事件的消息通知，也是作为领域层和用户接口层的桥梁。\n命名规范：command入参为XxxCmdRequest，query入参为XxxQueryRequest\n\nApplicationService的接口入参只能是一个Command、Query或Event对象，CQE对象需要能代表当前方法的业务语意。 ApplicationService集中罗列系统核心的业务用例(Command)。读写（Command和Query）建议分开，放到不同的Service。\n> 是协调领域层和其他外部系统的中间层。它不包含业务逻辑的核心部分，而是负责组织和调用领域层的服务来完成业务操作。例如，在电商系统的订单处理中，应用层会协调领域层的 “订单服务”、“库存服务” 和 “支付服务” 等来完成一个完整的下单流程。它起到了一个流程编排的作用，确保业务操作按照正确的顺序和规则进行。\n\n##### 领域层\n领域层的作用是实现企业核心业务逻辑，通过各种校验手段保证业务的正确性。领域层主要体现领域模型的业务能力，它用来表达业务概念、业务状态和业务规则。\n\n领域层包含聚合根、实体、值对象、领域服务等领域模型中的领域对象。\n\n这里我要特别解释一下其中几个领域对象的关系，以便你在设计领域层的时候能更加清楚。首先，领域模型的业务逻辑主要是由实体和领域服务来实现的，其中实体会采用充血模型来实现所有与之相关的业务功能。其次，你要知道，实体和领域对象在实现业务逻辑上不是同级的，当领域中的某些功能，单一实体（或者值对象）不能实现时，领域服务就会出马，它可以组合聚合内的多个实体（或者值对象），实现复杂的业务逻辑。\n> 例如，在信贷系统中，领域层的 “信用评估服务” 会根据 “客户” 模型和 “贷款申请” 模型中的信息，运用复杂的信用评估算法来判断客户的信用等级，这就是领域服务在处理业务逻辑。\n\n##### 基础层\n基础层是贯穿所有层的，它的作用就是为其它各层提供通用的技术和基础服务，包括第三方工具、驱动、消息中间件、网关、文件、缓存以及数据库等。比较常见的功能还是提供数据库持久化。\n\n基础层包含基础服务，它采用依赖倒置设计，封装基础资源服务，实现应用层、领域层与基础层的解耦，降低外部资源变化对应用的影响。\n\n比如说，在传统架构设计中，由于上层应用对数据库的强耦合，很多公司在架构演进中最担忧的可能就是换数据库了，因为一旦更换数据库，就可能需要重写大部分的代码，这对应用来说是致命的。那采用依赖倒置的设计以后，应用层就可以通过解耦来保持独立的核心业务逻辑。当数据库变更时，我们只需要更换数据库基础服务就可以了，这样就将资源变更对应用的影响降到了最低。\n\n\n#### 2.2、分层代码结构示例\n系统架构：\n![分层架构_系统架构](2024-09-01-架构-DDD分层架构/分层架构_系统架构.png)\n包结构划分：\n![分层架构_包结构划分](2024-09-01-架构-DDD分层架构/分层架构_包结构划分.png)\n代码指导：\n![分层架构_代码指示](2024-09-01-架构-DDD分层架构/分层架构_代码指示.png)\n\n\n### 三、六边形架构\n2005年，Alistair Cockburn提出了端口和适配器架构Ports & Adapters Architecture(又称六边形架构Hexagonal Architecture)。\n![六边形架构](2024-09-01-架构-DDD分层架构/六边形架构.png)\n端口和适配器架构中的相关概念：\n- 工具Tools： 应用application使用的工具Tools(WebSerevr, Cli, DB, SearchEngine, MQ)\n- 端口Port： 在application core层定义的工具交互规范（即定义 工具Tools如何使用application core的规范 或 工具Tools如何被application core使用的规范），对应编程语言的interface定义，且端口定义应该符合应用层逻辑（不可简单模仿或者直接使用底层工具的API）\n- 适配器Adapter： 连接工具Tools(WebSerevr, Cli, DB, SearchEngine, MQ)和应用核心application core的代码单元\n  - 适配器依赖port（调用port 或 实现port）和工具，但是application core仅依赖port。\n- 主动适配器（Primary/Driving Adapters ） - 主动调用应用核心Application Core，触发应用执行某项活动\n  - 主动适配器 -> 依赖端口 -> 注入端口实现，\n  - 例如主动适配器Controller -> 依赖端口ServiceInterface -> 注入端口实现ServiceImpl\n- 被动适配器（Secondary/Driven Adapters） - 被应用核心Application Core调用来执行动作，实现应用定义的端口\n  - 端口 -->被动适配器实现端口逻辑-> 包装系统外部工具，\n  - 例如端口RespositoryInterface -> 被动适配器Mysql实现MysqlRepositoryImpl -> 调用Mysql数据库\n\n几边形不重要，可以N多边，重点是Port & Adapter思想，关于端口和适配器架构的优势：\n- 核心业务在最中心（最重要），\n- 核心业务依赖Port，Adapter依赖Port（主动） 或 Adapter为Port的具体实现（被动），\n- 核心业务逻辑与实现细节（技术框架、底层存储、工具、传输通信机制等）相隔离，\n- 保持核心业务逻辑的可重用性，\n- 可通过（注入）不同Adapter实现来切换技术实现，避免技术框架、工具、供应商锁定，\n- 且基于mock Port的形式更易于测试。\n\n\n### 四、洋葱架构\n洋葱架构（Onion Architecture） 在2008年由Jeffrey Palermo提出。\n![洋葱架构](2024-09-01-架构-DDD分层架构/洋葱架构.png)\n洋葱架构在DDD的基础上，将内层（业务逻辑层，Business Logic）进一步划分，最终为：\n- **Adapters**，即六边形架构中的适配器Adapter层\n  - User Interface、Infrastructure、Tests\n- **Application Core，应用核心层**，也即原来的六边形架构中心的Business Logic层\n  - **Application Services** - 应用服务册层\n  - **Domain Services** - 领域服务层\n  - **Domain Model** - 领域模型层\n\n且明确了依赖方向：\n- 外层依赖内层\n- 内层不知道外层\n- 且在不破坏依赖方向的前提下，外层亦可以直接调用任一内层（不一定是相邻接的2层），参考CQRS中Query实现（Application Services直接调用DAO）\n\n\n在洋葱架构中，各层的职能是这样划分的：\n- 领域模型实现领域内核心业务逻辑，它封装了企业级的业务规则。领域模型的主体是实体，一个实体可以是一个带方法的对象，也可以是一个数据结构和方法集合。\n- 领域服务实现涉及多个实体的复杂业务逻辑。\n- 应用服务实现与用户操作相关的服务组合与编排，它包含了应用特有的业务流程规则，封装和实现了系统所有用例。\n- 最外层主要提供适配的能力，适配能力分为主动适配和被动适配。主动适配主要实现外部用户、网页、批处理和自动化测试等对内层业务逻辑访问适配。被动适配主要是实现核心业务逻辑对基础资源访问的适配，比如数据库、缓存、文件系统和消息中间件等。\n- 红圈内的领域模型、领域服务和应用服务一起组成软件核心业务能力。\n\n\n\n### 五、整洁架构【Clean Architecture】\n2012年Robert C. Martin (又名Uncle Bob) 提出了整洁架构Clean Architecture，整洁架构将EBI、六边形架构Hexagonal、洋葱架构Onoin等整合成一个可以实际落地的架构。\n![整洁架构](2024-09-01-架构-DDD分层架构/整洁架构.png)\n与洋葱架构相比，整洁架构调整如下：\n- Application Services调整为Use Cases\n- Domain Services, Domain Model调整为Entities\n\n整洁架构并没有带来突破性的概念或模式，但是：\n- 它发掘了某种程度上被遗忘了的概念、规则和模式；\n- 它澄清了一些实用且重要的概念、规则和模式；\n- 它告诉我们如何把所有的概念、规则和模式整合起来，形成一种构建复杂应用并保持可维护性的标准套路\n\n### 六、清晰架构\n2017年Herberto Graca在其软件架构编年史系列文章中提出清晰架构Explicit Architecture，即将DDD, Hexagonal, Onion, Clean, CQRS等进行融合后的架构。\n![清晰架构](2024-09-01-架构-DDD分层架构/清晰架构.png)\n最中心的<font color=#e98787>**红色多边形**</font>Application Core即表示业务逻辑实现，即应用核心\n- 红色多边形的边界即表示端口Port，即应用核心的入口/出口定义\n- **Application Layer** - 应用层，包括：\n  - **Application Services**，业务用例的编排服务即及其interface定义，应用服务的作用通常如下：\n    - 使用 Repostitory 查找一个或多个实体；\n    - 让这些实体执行一些领域逻辑；\n    - 再次使用 Repostitory 让这些实体持久化，有效地保存数据变化；\n    - 触发应用事件（如发送邮件、调用第三方API、发送MQ消息等）。\n  - **CQRS命令/查询处理器**\n  - **Event Listener事件监听器**\n  - **Port端口定义**，如ORM 接口Repostitory、搜索引擎接口、消息接口等等\n- **Domain Layer - 领域层**，这一层含了数据和操作数据的逻辑，它们只和领域本身有关，独立于调用这些逻辑的业务过程。它们完全独立，对应用层完全无感知。\n  - **Domain Services - 领域服务**，封装涉及多实体（相同或不同实体类型）的领域逻辑，且领域服务间可以相互调用。\n  - **Domain Models - 领域模型**，在架构的正中心，完全不依赖外部任何层次的领域模型。它包含了那些表示领域中某个概念的业务对象，如实体、值对象、枚举以及其它领域模型种用到的任何对象（如领域事件Domain Events，简单理解为MQ消息）。\n- 红色多边形的外侧左半圆部分即为**主/主动适配器**（用户界面User Interface实现）\n  - 如Spring MVC中的Controller实现\n  - Command Query Bus 命令查询总线\n- 红色多边形的外侧右半圆部分即**次/被动适配器**（基础设置Infrastructure实现）\n  - 如数据持久化实现Mysql、短信通知实现、MQ通知、搜索引擎ES实现等\n  - Event Bus 事件总线\n- 依赖方向由外到内，且内层不知道外层（参见之前洋葱架构） \n\n\n>TIPS: 清晰架构只是一份指南！\n应用才是疆域，现实情况和具体用例才是运用这些知识的地方，它们才能勾勒出实际架构的轮廓！\n我们需要理解所有这些模式，\n但我们还时常需要思考和理解我们的应用需要什么，我们应该在追求解耦和内聚的道路上走多远。\n这个决定可能受到许多因素的影响，\n包括项目的功能需求，也包括构建应用的时间期限，应用寿命，开发团队的经验等等因素。\n\n### 七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：\n![总的架构演进图](2024-09-01-架构-DDD分层架构/总的架构演进图.png)\n\n\n---\n\n参考文章：\n[DDD中常提到的应用架构总结（六边形、洋葱、整洁、清晰）](https://code84.com/730128.html)      \n[微服务架构模型：几种常见模型的对比和分析](https://zq99299.github.io/note-book2/ddd/02/03.html#%E4%BB%8E%E4%B8%89%E7%A7%8D%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B%E7%9C%8B%E4%B8%AD%E5%8F%B0%E5%92%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1)\n[DDD 领域驱动设计-应用架构](https://juejin.cn/post/7170631967178752030)\n\nEBI：\nhttps://herbertograca.com/2017/08/24/ebi-architecture/\n\n端口和适配器架构：\n11.端口和适配器架构(译) - https://www.jianshu.com/p/f39f4537857e\nhttps://herbertograca.com/2017/09/14/ports-adapters-architecture/\n\n洋葱架构：\nhttps://herbertograca.com/2017/09/21/onion-architecture/\nhttps://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/\n\n整洁架构：\nhttps://herbertograca.com/2017/09/28/clean-architecture-standing-on-the-shoulders-of-giants/\nhttps://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\n\n清晰架构：\nhttps://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/\n17.清晰架构(01): 融合 DDD、洋葱架构、整洁架构、CQRS…(译) - https://www.jianshu.com/p/d3e8b9ac097b\n\nDDD：\nhttps://herbertograca.com/2017/09/07/domain-driven-design/","slug":"2024-09-03-架构-DDD应用架构","published":1,"updated":"2024-12-03T15:20:14.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyf005ta13knrqs5xrz","content":"<h3 id=\"一、DDD的应用架构\"><a href=\"#一、DDD的应用架构\" class=\"headerlink\" title=\"一、DDD的应用架构\"></a>一、DDD的应用架构</h3><p>领域驱动设计（DDD）主要包含以下几种应用架构：</p>\n<ul>\n<li>分层架构</li>\n<li>六边形架构</li>\n<li>洋葱架构</li>\n<li>整洁架构</li>\n<li>清晰架构</li>\n</ul>\n<a id=\"more\"></a>\n\n<h3 id=\"二、分层架构\"><a href=\"#二、分层架构\" class=\"headerlink\" title=\"二、分层架构\"></a>二、分层架构</h3><p>DDD 的分层架构在不断发展。最早是传统的四层架构；后来四层架构有了进一步的优化，实现了各层对基础层的解耦；再后来领域层和应用层之间增加了上下文环境（Context）层，五层架构（DCI）就此形成了。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E4%BC%A0%E7%BB%9F4%E5%B1%82%E6%9E%B6%E6%9E%84.png\" alt=\"传统4层架构\"><br>我们看一下上面这张图，在最早的传统四层架构中，<strong>基础层是被其它层依赖的，它位于最核心的位置</strong> ，那按照分层架构的思想，它应该就是核心，但实际上领域层才是软件的核心，所以这种依赖是有问题的。后来我们采用了依赖倒置（Dependency inversion principle,DIP）的设计，优化了传统的四层架构，实现了各层对基础层的解耦。</p>\n<h4 id=\"2-1、分层说明\"><a href=\"#2-1、分层说明\" class=\"headerlink\" title=\"2.1、分层说明\"></a>2.1、分层说明</h4><p>我们今天讲的 DDD 分层架构就是优化后的四层架构。在下面这张图中，从上到下依次是：用户接口层、应用层、领域层和基础层。那 DDD 各层的主要职责是什么呢？下面我来逐一介绍一下。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84.png\" alt=\"分层架构\"></p>\n<h5 id=\"用户接口层\"><a href=\"#用户接口层\" class=\"headerlink\" title=\"用户接口层\"></a>用户接口层</h5><p>用户接口层负责向用户显示信息和解释用户指令。这里的用户可能是：用户、程序、自动化测试和批处理脚本等等。</p>\n<h5 id=\"应用层\"><a href=\"#应用层\" class=\"headerlink\" title=\"应用层\"></a>应用层</h5><p>只负责业务流程的串联，对不同领域的服务调用进行编排。<br>事务控制一般在Application层， 在该层我们可以进行安全认证，权限校验，持久化事务控制，或者向其他系统发生基于事件的消息通知，也是作为领域层和用户接口层的桥梁。<br>命名规范：command入参为XxxCmdRequest，query入参为XxxQueryRequest</p>\n<p>ApplicationService的接口入参只能是一个Command、Query或Event对象，CQE对象需要能代表当前方法的业务语意。 ApplicationService集中罗列系统核心的业务用例(Command)。读写（Command和Query）建议分开，放到不同的Service。</p>\n<blockquote>\n<p>是协调领域层和其他外部系统的中间层。它不包含业务逻辑的核心部分，而是负责组织和调用领域层的服务来完成业务操作。例如，在电商系统的订单处理中，应用层会协调领域层的 “订单服务”、“库存服务” 和 “支付服务” 等来完成一个完整的下单流程。它起到了一个流程编排的作用，确保业务操作按照正确的顺序和规则进行。</p>\n</blockquote>\n<h5 id=\"领域层\"><a href=\"#领域层\" class=\"headerlink\" title=\"领域层\"></a>领域层</h5><p>领域层的作用是实现企业核心业务逻辑，通过各种校验手段保证业务的正确性。领域层主要体现领域模型的业务能力，它用来表达业务概念、业务状态和业务规则。</p>\n<p>领域层包含聚合根、实体、值对象、领域服务等领域模型中的领域对象。</p>\n<p>这里我要特别解释一下其中几个领域对象的关系，以便你在设计领域层的时候能更加清楚。首先，领域模型的业务逻辑主要是由实体和领域服务来实现的，其中实体会采用充血模型来实现所有与之相关的业务功能。其次，你要知道，实体和领域对象在实现业务逻辑上不是同级的，当领域中的某些功能，单一实体（或者值对象）不能实现时，领域服务就会出马，它可以组合聚合内的多个实体（或者值对象），实现复杂的业务逻辑。</p>\n<blockquote>\n<p>例如，在信贷系统中，领域层的 “信用评估服务” 会根据 “客户” 模型和 “贷款申请” 模型中的信息，运用复杂的信用评估算法来判断客户的信用等级，这就是领域服务在处理业务逻辑。</p>\n</blockquote>\n<h5 id=\"基础层\"><a href=\"#基础层\" class=\"headerlink\" title=\"基础层\"></a>基础层</h5><p>基础层是贯穿所有层的，它的作用就是为其它各层提供通用的技术和基础服务，包括第三方工具、驱动、消息中间件、网关、文件、缓存以及数据库等。比较常见的功能还是提供数据库持久化。</p>\n<p>基础层包含基础服务，它采用依赖倒置设计，封装基础资源服务，实现应用层、领域层与基础层的解耦，降低外部资源变化对应用的影响。</p>\n<p>比如说，在传统架构设计中，由于上层应用对数据库的强耦合，很多公司在架构演进中最担忧的可能就是换数据库了，因为一旦更换数据库，就可能需要重写大部分的代码，这对应用来说是致命的。那采用依赖倒置的设计以后，应用层就可以通过解耦来保持独立的核心业务逻辑。当数据库变更时，我们只需要更换数据库基础服务就可以了，这样就将资源变更对应用的影响降到了最低。</p>\n<h4 id=\"2-2、分层代码结构示例\"><a href=\"#2-2、分层代码结构示例\" class=\"headerlink\" title=\"2.2、分层代码结构示例\"></a>2.2、分层代码结构示例</h4><p>系统架构：<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84_%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png\" alt=\"分层架构_系统架构\"><br>包结构划分：<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84_%E5%8C%85%E7%BB%93%E6%9E%84%E5%88%92%E5%88%86.png\" alt=\"分层架构_包结构划分\"><br>代码指导：<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84_%E4%BB%A3%E7%A0%81%E6%8C%87%E7%A4%BA.png\" alt=\"分层架构_代码指示\"></p>\n<h3 id=\"三、六边形架构\"><a href=\"#三、六边形架构\" class=\"headerlink\" title=\"三、六边形架构\"></a>三、六边形架构</h3><p>2005年，Alistair Cockburn提出了端口和适配器架构Ports &amp; Adapters Architecture(又称六边形架构Hexagonal Architecture)。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%85%AD%E8%BE%B9%E5%BD%A2%E6%9E%B6%E6%9E%84.png\" alt=\"六边形架构\"><br>端口和适配器架构中的相关概念：</p>\n<ul>\n<li>工具Tools： 应用application使用的工具Tools(WebSerevr, Cli, DB, SearchEngine, MQ)</li>\n<li>端口Port： 在application core层定义的工具交互规范（即定义 工具Tools如何使用application core的规范 或 工具Tools如何被application core使用的规范），对应编程语言的interface定义，且端口定义应该符合应用层逻辑（不可简单模仿或者直接使用底层工具的API）</li>\n<li>适配器Adapter： 连接工具Tools(WebSerevr, Cli, DB, SearchEngine, MQ)和应用核心application core的代码单元<ul>\n<li>适配器依赖port（调用port 或 实现port）和工具，但是application core仅依赖port。</li>\n</ul>\n</li>\n<li>主动适配器（Primary/Driving Adapters ） - 主动调用应用核心Application Core，触发应用执行某项活动<ul>\n<li>主动适配器 -&gt; 依赖端口 -&gt; 注入端口实现，</li>\n<li>例如主动适配器Controller -&gt; 依赖端口ServiceInterface -&gt; 注入端口实现ServiceImpl</li>\n</ul>\n</li>\n<li>被动适配器（Secondary/Driven Adapters） - 被应用核心Application Core调用来执行动作，实现应用定义的端口<ul>\n<li>端口 –&gt;被动适配器实现端口逻辑-&gt; 包装系统外部工具，</li>\n<li>例如端口RespositoryInterface -&gt; 被动适配器Mysql实现MysqlRepositoryImpl -&gt; 调用Mysql数据库</li>\n</ul>\n</li>\n</ul>\n<p>几边形不重要，可以N多边，重点是Port &amp; Adapter思想，关于端口和适配器架构的优势：</p>\n<ul>\n<li>核心业务在最中心（最重要），</li>\n<li>核心业务依赖Port，Adapter依赖Port（主动） 或 Adapter为Port的具体实现（被动），</li>\n<li>核心业务逻辑与实现细节（技术框架、底层存储、工具、传输通信机制等）相隔离，</li>\n<li>保持核心业务逻辑的可重用性，</li>\n<li>可通过（注入）不同Adapter实现来切换技术实现，避免技术框架、工具、供应商锁定，</li>\n<li>且基于mock Port的形式更易于测试。</li>\n</ul>\n<h3 id=\"四、洋葱架构\"><a href=\"#四、洋葱架构\" class=\"headerlink\" title=\"四、洋葱架构\"></a>四、洋葱架构</h3><p>洋葱架构（Onion Architecture） 在2008年由Jeffrey Palermo提出。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E6%B4%8B%E8%91%B1%E6%9E%B6%E6%9E%84.png\" alt=\"洋葱架构\"><br>洋葱架构在DDD的基础上，将内层（业务逻辑层，Business Logic）进一步划分，最终为：</p>\n<ul>\n<li><strong>Adapters</strong>，即六边形架构中的适配器Adapter层<ul>\n<li>User Interface、Infrastructure、Tests</li>\n</ul>\n</li>\n<li><strong>Application Core，应用核心层</strong>，也即原来的六边形架构中心的Business Logic层<ul>\n<li><strong>Application Services</strong> - 应用服务册层</li>\n<li><strong>Domain Services</strong> - 领域服务层</li>\n<li><strong>Domain Model</strong> - 领域模型层</li>\n</ul>\n</li>\n</ul>\n<p>且明确了依赖方向：</p>\n<ul>\n<li>外层依赖内层</li>\n<li>内层不知道外层</li>\n<li>且在不破坏依赖方向的前提下，外层亦可以直接调用任一内层（不一定是相邻接的2层），参考CQRS中Query实现（Application Services直接调用DAO）</li>\n</ul>\n<p>在洋葱架构中，各层的职能是这样划分的：</p>\n<ul>\n<li>领域模型实现领域内核心业务逻辑，它封装了企业级的业务规则。领域模型的主体是实体，一个实体可以是一个带方法的对象，也可以是一个数据结构和方法集合。</li>\n<li>领域服务实现涉及多个实体的复杂业务逻辑。</li>\n<li>应用服务实现与用户操作相关的服务组合与编排，它包含了应用特有的业务流程规则，封装和实现了系统所有用例。</li>\n<li>最外层主要提供适配的能力，适配能力分为主动适配和被动适配。主动适配主要实现外部用户、网页、批处理和自动化测试等对内层业务逻辑访问适配。被动适配主要是实现核心业务逻辑对基础资源访问的适配，比如数据库、缓存、文件系统和消息中间件等。</li>\n<li>红圈内的领域模型、领域服务和应用服务一起组成软件核心业务能力。</li>\n</ul>\n<h3 id=\"五、整洁架构【Clean-Architecture】\"><a href=\"#五、整洁架构【Clean-Architecture】\" class=\"headerlink\" title=\"五、整洁架构【Clean Architecture】\"></a>五、整洁架构【Clean Architecture】</h3><p>2012年Robert C. Martin (又名Uncle Bob) 提出了整洁架构Clean Architecture，整洁架构将EBI、六边形架构Hexagonal、洋葱架构Onoin等整合成一个可以实际落地的架构。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84.png\" alt=\"整洁架构\"><br>与洋葱架构相比，整洁架构调整如下：</p>\n<ul>\n<li>Application Services调整为Use Cases</li>\n<li>Domain Services, Domain Model调整为Entities</li>\n</ul>\n<p>整洁架构并没有带来突破性的概念或模式，但是：</p>\n<ul>\n<li>它发掘了某种程度上被遗忘了的概念、规则和模式；</li>\n<li>它澄清了一些实用且重要的概念、规则和模式；</li>\n<li>它告诉我们如何把所有的概念、规则和模式整合起来，形成一种构建复杂应用并保持可维护性的标准套路</li>\n</ul>\n<h3 id=\"六、清晰架构\"><a href=\"#六、清晰架构\" class=\"headerlink\" title=\"六、清晰架构\"></a>六、清晰架构</h3><p>2017年Herberto Graca在其软件架构编年史系列文章中提出清晰架构Explicit Architecture，即将DDD, Hexagonal, Onion, Clean, CQRS等进行融合后的架构。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E6%B8%85%E6%99%B0%E6%9E%B6%E6%9E%84.png\" alt=\"清晰架构\"><br>最中心的<font color=\"#e98787\"><strong>红色多边形</strong></font>Application Core即表示业务逻辑实现，即应用核心</p>\n<ul>\n<li>红色多边形的边界即表示端口Port，即应用核心的入口/出口定义</li>\n<li><strong>Application Layer</strong> - 应用层，包括：<ul>\n<li><strong>Application Services</strong>，业务用例的编排服务即及其interface定义，应用服务的作用通常如下：<ul>\n<li>使用 Repostitory 查找一个或多个实体；</li>\n<li>让这些实体执行一些领域逻辑；</li>\n<li>再次使用 Repostitory 让这些实体持久化，有效地保存数据变化；</li>\n<li>触发应用事件（如发送邮件、调用第三方API、发送MQ消息等）。</li>\n</ul>\n</li>\n<li><strong>CQRS命令/查询处理器</strong></li>\n<li><strong>Event Listener事件监听器</strong></li>\n<li><strong>Port端口定义</strong>，如ORM 接口Repostitory、搜索引擎接口、消息接口等等</li>\n</ul>\n</li>\n<li><strong>Domain Layer - 领域层</strong>，这一层含了数据和操作数据的逻辑，它们只和领域本身有关，独立于调用这些逻辑的业务过程。它们完全独立，对应用层完全无感知。<ul>\n<li><strong>Domain Services - 领域服务</strong>，封装涉及多实体（相同或不同实体类型）的领域逻辑，且领域服务间可以相互调用。</li>\n<li><strong>Domain Models - 领域模型</strong>，在架构的正中心，完全不依赖外部任何层次的领域模型。它包含了那些表示领域中某个概念的业务对象，如实体、值对象、枚举以及其它领域模型种用到的任何对象（如领域事件Domain Events，简单理解为MQ消息）。</li>\n</ul>\n</li>\n<li>红色多边形的外侧左半圆部分即为<strong>主/主动适配器</strong>（用户界面User Interface实现）<ul>\n<li>如Spring MVC中的Controller实现</li>\n<li>Command Query Bus 命令查询总线</li>\n</ul>\n</li>\n<li>红色多边形的外侧右半圆部分即<strong>次/被动适配器</strong>（基础设置Infrastructure实现）<ul>\n<li>如数据持久化实现Mysql、短信通知实现、MQ通知、搜索引擎ES实现等</li>\n<li>Event Bus 事件总线</li>\n</ul>\n</li>\n<li>依赖方向由外到内，且内层不知道外层（参见之前洋葱架构） </li>\n</ul>\n<blockquote>\n<p>TIPS: 清晰架构只是一份指南！<br>应用才是疆域，现实情况和具体用例才是运用这些知识的地方，它们才能勾勒出实际架构的轮廓！<br>我们需要理解所有这些模式，<br>但我们还时常需要思考和理解我们的应用需要什么，我们应该在追求解耦和内聚的道路上走多远。<br>这个决定可能受到许多因素的影响，<br>包括项目的功能需求，也包括构建应用的时间期限，应用寿命，开发团队的经验等等因素。</p>\n</blockquote>\n<h3 id=\"七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：\"><a href=\"#七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：\" class=\"headerlink\" title=\"七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：\"></a>七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：</h3><p><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E6%80%BB%E7%9A%84%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B%E5%9B%BE.png\" alt=\"总的架构演进图\"></p>\n<hr>\n<p>参考文章：<br><a href=\"https://code84.com/730128.html\" target=\"_blank\" rel=\"noopener\">DDD中常提到的应用架构总结（六边形、洋葱、整洁、清晰）</a><br><a href=\"https://zq99299.github.io/note-book2/ddd/02/03.html#%E4%BB%8E%E4%B8%89%E7%A7%8D%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B%E7%9C%8B%E4%B8%AD%E5%8F%B0%E5%92%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1\" target=\"_blank\" rel=\"noopener\">微服务架构模型：几种常见模型的对比和分析</a><br><a href=\"https://juejin.cn/post/7170631967178752030\" target=\"_blank\" rel=\"noopener\">DDD 领域驱动设计-应用架构</a></p>\n<p>EBI：<br><a href=\"https://herbertograca.com/2017/08/24/ebi-architecture/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/08/24/ebi-architecture/</a></p>\n<p>端口和适配器架构：<br>11.端口和适配器架构(译) - <a href=\"https://www.jianshu.com/p/f39f4537857e\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/f39f4537857e</a><br><a href=\"https://herbertograca.com/2017/09/14/ports-adapters-architecture/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/09/14/ports-adapters-architecture/</a></p>\n<p>洋葱架构：<br><a href=\"https://herbertograca.com/2017/09/21/onion-architecture/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/09/21/onion-architecture/</a><br><a href=\"https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/\" target=\"_blank\" rel=\"noopener\">https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/</a></p>\n<p>整洁架构：<br><a href=\"https://herbertograca.com/2017/09/28/clean-architecture-standing-on-the-shoulders-of-giants/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/09/28/clean-architecture-standing-on-the-shoulders-of-giants/</a><br><a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\" target=\"_blank\" rel=\"noopener\">https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html</a></p>\n<p>清晰架构：<br><a href=\"https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/</a><br>17.清晰架构(01): 融合 DDD、洋葱架构、整洁架构、CQRS…(译) - <a href=\"https://www.jianshu.com/p/d3e8b9ac097b\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/d3e8b9ac097b</a></p>\n<p>DDD：<br><a href=\"https://herbertograca.com/2017/09/07/domain-driven-design/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/09/07/domain-driven-design/</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、DDD的应用架构\"><a href=\"#一、DDD的应用架构\" class=\"headerlink\" title=\"一、DDD的应用架构\"></a>一、DDD的应用架构</h3><p>领域驱动设计（DDD）主要包含以下几种应用架构：</p>\n<ul>\n<li>分层架构</li>\n<li>六边形架构</li>\n<li>洋葱架构</li>\n<li>整洁架构</li>\n<li>清晰架构</li>\n</ul>","more":"<h3 id=\"二、分层架构\"><a href=\"#二、分层架构\" class=\"headerlink\" title=\"二、分层架构\"></a>二、分层架构</h3><p>DDD 的分层架构在不断发展。最早是传统的四层架构；后来四层架构有了进一步的优化，实现了各层对基础层的解耦；再后来领域层和应用层之间增加了上下文环境（Context）层，五层架构（DCI）就此形成了。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E4%BC%A0%E7%BB%9F4%E5%B1%82%E6%9E%B6%E6%9E%84.png\" alt=\"传统4层架构\"><br>我们看一下上面这张图，在最早的传统四层架构中，<strong>基础层是被其它层依赖的，它位于最核心的位置</strong> ，那按照分层架构的思想，它应该就是核心，但实际上领域层才是软件的核心，所以这种依赖是有问题的。后来我们采用了依赖倒置（Dependency inversion principle,DIP）的设计，优化了传统的四层架构，实现了各层对基础层的解耦。</p>\n<h4 id=\"2-1、分层说明\"><a href=\"#2-1、分层说明\" class=\"headerlink\" title=\"2.1、分层说明\"></a>2.1、分层说明</h4><p>我们今天讲的 DDD 分层架构就是优化后的四层架构。在下面这张图中，从上到下依次是：用户接口层、应用层、领域层和基础层。那 DDD 各层的主要职责是什么呢？下面我来逐一介绍一下。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84.png\" alt=\"分层架构\"></p>\n<h5 id=\"用户接口层\"><a href=\"#用户接口层\" class=\"headerlink\" title=\"用户接口层\"></a>用户接口层</h5><p>用户接口层负责向用户显示信息和解释用户指令。这里的用户可能是：用户、程序、自动化测试和批处理脚本等等。</p>\n<h5 id=\"应用层\"><a href=\"#应用层\" class=\"headerlink\" title=\"应用层\"></a>应用层</h5><p>只负责业务流程的串联，对不同领域的服务调用进行编排。<br>事务控制一般在Application层， 在该层我们可以进行安全认证，权限校验，持久化事务控制，或者向其他系统发生基于事件的消息通知，也是作为领域层和用户接口层的桥梁。<br>命名规范：command入参为XxxCmdRequest，query入参为XxxQueryRequest</p>\n<p>ApplicationService的接口入参只能是一个Command、Query或Event对象，CQE对象需要能代表当前方法的业务语意。 ApplicationService集中罗列系统核心的业务用例(Command)。读写（Command和Query）建议分开，放到不同的Service。</p>\n<blockquote>\n<p>是协调领域层和其他外部系统的中间层。它不包含业务逻辑的核心部分，而是负责组织和调用领域层的服务来完成业务操作。例如，在电商系统的订单处理中，应用层会协调领域层的 “订单服务”、“库存服务” 和 “支付服务” 等来完成一个完整的下单流程。它起到了一个流程编排的作用，确保业务操作按照正确的顺序和规则进行。</p>\n</blockquote>\n<h5 id=\"领域层\"><a href=\"#领域层\" class=\"headerlink\" title=\"领域层\"></a>领域层</h5><p>领域层的作用是实现企业核心业务逻辑，通过各种校验手段保证业务的正确性。领域层主要体现领域模型的业务能力，它用来表达业务概念、业务状态和业务规则。</p>\n<p>领域层包含聚合根、实体、值对象、领域服务等领域模型中的领域对象。</p>\n<p>这里我要特别解释一下其中几个领域对象的关系，以便你在设计领域层的时候能更加清楚。首先，领域模型的业务逻辑主要是由实体和领域服务来实现的，其中实体会采用充血模型来实现所有与之相关的业务功能。其次，你要知道，实体和领域对象在实现业务逻辑上不是同级的，当领域中的某些功能，单一实体（或者值对象）不能实现时，领域服务就会出马，它可以组合聚合内的多个实体（或者值对象），实现复杂的业务逻辑。</p>\n<blockquote>\n<p>例如，在信贷系统中，领域层的 “信用评估服务” 会根据 “客户” 模型和 “贷款申请” 模型中的信息，运用复杂的信用评估算法来判断客户的信用等级，这就是领域服务在处理业务逻辑。</p>\n</blockquote>\n<h5 id=\"基础层\"><a href=\"#基础层\" class=\"headerlink\" title=\"基础层\"></a>基础层</h5><p>基础层是贯穿所有层的，它的作用就是为其它各层提供通用的技术和基础服务，包括第三方工具、驱动、消息中间件、网关、文件、缓存以及数据库等。比较常见的功能还是提供数据库持久化。</p>\n<p>基础层包含基础服务，它采用依赖倒置设计，封装基础资源服务，实现应用层、领域层与基础层的解耦，降低外部资源变化对应用的影响。</p>\n<p>比如说，在传统架构设计中，由于上层应用对数据库的强耦合，很多公司在架构演进中最担忧的可能就是换数据库了，因为一旦更换数据库，就可能需要重写大部分的代码，这对应用来说是致命的。那采用依赖倒置的设计以后，应用层就可以通过解耦来保持独立的核心业务逻辑。当数据库变更时，我们只需要更换数据库基础服务就可以了，这样就将资源变更对应用的影响降到了最低。</p>\n<h4 id=\"2-2、分层代码结构示例\"><a href=\"#2-2、分层代码结构示例\" class=\"headerlink\" title=\"2.2、分层代码结构示例\"></a>2.2、分层代码结构示例</h4><p>系统架构：<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84_%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png\" alt=\"分层架构_系统架构\"><br>包结构划分：<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84_%E5%8C%85%E7%BB%93%E6%9E%84%E5%88%92%E5%88%86.png\" alt=\"分层架构_包结构划分\"><br>代码指导：<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84_%E4%BB%A3%E7%A0%81%E6%8C%87%E7%A4%BA.png\" alt=\"分层架构_代码指示\"></p>\n<h3 id=\"三、六边形架构\"><a href=\"#三、六边形架构\" class=\"headerlink\" title=\"三、六边形架构\"></a>三、六边形架构</h3><p>2005年，Alistair Cockburn提出了端口和适配器架构Ports &amp; Adapters Architecture(又称六边形架构Hexagonal Architecture)。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E5%85%AD%E8%BE%B9%E5%BD%A2%E6%9E%B6%E6%9E%84.png\" alt=\"六边形架构\"><br>端口和适配器架构中的相关概念：</p>\n<ul>\n<li>工具Tools： 应用application使用的工具Tools(WebSerevr, Cli, DB, SearchEngine, MQ)</li>\n<li>端口Port： 在application core层定义的工具交互规范（即定义 工具Tools如何使用application core的规范 或 工具Tools如何被application core使用的规范），对应编程语言的interface定义，且端口定义应该符合应用层逻辑（不可简单模仿或者直接使用底层工具的API）</li>\n<li>适配器Adapter： 连接工具Tools(WebSerevr, Cli, DB, SearchEngine, MQ)和应用核心application core的代码单元<ul>\n<li>适配器依赖port（调用port 或 实现port）和工具，但是application core仅依赖port。</li>\n</ul>\n</li>\n<li>主动适配器（Primary/Driving Adapters ） - 主动调用应用核心Application Core，触发应用执行某项活动<ul>\n<li>主动适配器 -&gt; 依赖端口 -&gt; 注入端口实现，</li>\n<li>例如主动适配器Controller -&gt; 依赖端口ServiceInterface -&gt; 注入端口实现ServiceImpl</li>\n</ul>\n</li>\n<li>被动适配器（Secondary/Driven Adapters） - 被应用核心Application Core调用来执行动作，实现应用定义的端口<ul>\n<li>端口 –&gt;被动适配器实现端口逻辑-&gt; 包装系统外部工具，</li>\n<li>例如端口RespositoryInterface -&gt; 被动适配器Mysql实现MysqlRepositoryImpl -&gt; 调用Mysql数据库</li>\n</ul>\n</li>\n</ul>\n<p>几边形不重要，可以N多边，重点是Port &amp; Adapter思想，关于端口和适配器架构的优势：</p>\n<ul>\n<li>核心业务在最中心（最重要），</li>\n<li>核心业务依赖Port，Adapter依赖Port（主动） 或 Adapter为Port的具体实现（被动），</li>\n<li>核心业务逻辑与实现细节（技术框架、底层存储、工具、传输通信机制等）相隔离，</li>\n<li>保持核心业务逻辑的可重用性，</li>\n<li>可通过（注入）不同Adapter实现来切换技术实现，避免技术框架、工具、供应商锁定，</li>\n<li>且基于mock Port的形式更易于测试。</li>\n</ul>\n<h3 id=\"四、洋葱架构\"><a href=\"#四、洋葱架构\" class=\"headerlink\" title=\"四、洋葱架构\"></a>四、洋葱架构</h3><p>洋葱架构（Onion Architecture） 在2008年由Jeffrey Palermo提出。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E6%B4%8B%E8%91%B1%E6%9E%B6%E6%9E%84.png\" alt=\"洋葱架构\"><br>洋葱架构在DDD的基础上，将内层（业务逻辑层，Business Logic）进一步划分，最终为：</p>\n<ul>\n<li><strong>Adapters</strong>，即六边形架构中的适配器Adapter层<ul>\n<li>User Interface、Infrastructure、Tests</li>\n</ul>\n</li>\n<li><strong>Application Core，应用核心层</strong>，也即原来的六边形架构中心的Business Logic层<ul>\n<li><strong>Application Services</strong> - 应用服务册层</li>\n<li><strong>Domain Services</strong> - 领域服务层</li>\n<li><strong>Domain Model</strong> - 领域模型层</li>\n</ul>\n</li>\n</ul>\n<p>且明确了依赖方向：</p>\n<ul>\n<li>外层依赖内层</li>\n<li>内层不知道外层</li>\n<li>且在不破坏依赖方向的前提下，外层亦可以直接调用任一内层（不一定是相邻接的2层），参考CQRS中Query实现（Application Services直接调用DAO）</li>\n</ul>\n<p>在洋葱架构中，各层的职能是这样划分的：</p>\n<ul>\n<li>领域模型实现领域内核心业务逻辑，它封装了企业级的业务规则。领域模型的主体是实体，一个实体可以是一个带方法的对象，也可以是一个数据结构和方法集合。</li>\n<li>领域服务实现涉及多个实体的复杂业务逻辑。</li>\n<li>应用服务实现与用户操作相关的服务组合与编排，它包含了应用特有的业务流程规则，封装和实现了系统所有用例。</li>\n<li>最外层主要提供适配的能力，适配能力分为主动适配和被动适配。主动适配主要实现外部用户、网页、批处理和自动化测试等对内层业务逻辑访问适配。被动适配主要是实现核心业务逻辑对基础资源访问的适配，比如数据库、缓存、文件系统和消息中间件等。</li>\n<li>红圈内的领域模型、领域服务和应用服务一起组成软件核心业务能力。</li>\n</ul>\n<h3 id=\"五、整洁架构【Clean-Architecture】\"><a href=\"#五、整洁架构【Clean-Architecture】\" class=\"headerlink\" title=\"五、整洁架构【Clean Architecture】\"></a>五、整洁架构【Clean Architecture】</h3><p>2012年Robert C. Martin (又名Uncle Bob) 提出了整洁架构Clean Architecture，整洁架构将EBI、六边形架构Hexagonal、洋葱架构Onoin等整合成一个可以实际落地的架构。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84.png\" alt=\"整洁架构\"><br>与洋葱架构相比，整洁架构调整如下：</p>\n<ul>\n<li>Application Services调整为Use Cases</li>\n<li>Domain Services, Domain Model调整为Entities</li>\n</ul>\n<p>整洁架构并没有带来突破性的概念或模式，但是：</p>\n<ul>\n<li>它发掘了某种程度上被遗忘了的概念、规则和模式；</li>\n<li>它澄清了一些实用且重要的概念、规则和模式；</li>\n<li>它告诉我们如何把所有的概念、规则和模式整合起来，形成一种构建复杂应用并保持可维护性的标准套路</li>\n</ul>\n<h3 id=\"六、清晰架构\"><a href=\"#六、清晰架构\" class=\"headerlink\" title=\"六、清晰架构\"></a>六、清晰架构</h3><p>2017年Herberto Graca在其软件架构编年史系列文章中提出清晰架构Explicit Architecture，即将DDD, Hexagonal, Onion, Clean, CQRS等进行融合后的架构。<br><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E6%B8%85%E6%99%B0%E6%9E%B6%E6%9E%84.png\" alt=\"清晰架构\"><br>最中心的<font color=\"#e98787\"><strong>红色多边形</strong></font>Application Core即表示业务逻辑实现，即应用核心</p>\n<ul>\n<li>红色多边形的边界即表示端口Port，即应用核心的入口/出口定义</li>\n<li><strong>Application Layer</strong> - 应用层，包括：<ul>\n<li><strong>Application Services</strong>，业务用例的编排服务即及其interface定义，应用服务的作用通常如下：<ul>\n<li>使用 Repostitory 查找一个或多个实体；</li>\n<li>让这些实体执行一些领域逻辑；</li>\n<li>再次使用 Repostitory 让这些实体持久化，有效地保存数据变化；</li>\n<li>触发应用事件（如发送邮件、调用第三方API、发送MQ消息等）。</li>\n</ul>\n</li>\n<li><strong>CQRS命令/查询处理器</strong></li>\n<li><strong>Event Listener事件监听器</strong></li>\n<li><strong>Port端口定义</strong>，如ORM 接口Repostitory、搜索引擎接口、消息接口等等</li>\n</ul>\n</li>\n<li><strong>Domain Layer - 领域层</strong>，这一层含了数据和操作数据的逻辑，它们只和领域本身有关，独立于调用这些逻辑的业务过程。它们完全独立，对应用层完全无感知。<ul>\n<li><strong>Domain Services - 领域服务</strong>，封装涉及多实体（相同或不同实体类型）的领域逻辑，且领域服务间可以相互调用。</li>\n<li><strong>Domain Models - 领域模型</strong>，在架构的正中心，完全不依赖外部任何层次的领域模型。它包含了那些表示领域中某个概念的业务对象，如实体、值对象、枚举以及其它领域模型种用到的任何对象（如领域事件Domain Events，简单理解为MQ消息）。</li>\n</ul>\n</li>\n<li>红色多边形的外侧左半圆部分即为<strong>主/主动适配器</strong>（用户界面User Interface实现）<ul>\n<li>如Spring MVC中的Controller实现</li>\n<li>Command Query Bus 命令查询总线</li>\n</ul>\n</li>\n<li>红色多边形的外侧右半圆部分即<strong>次/被动适配器</strong>（基础设置Infrastructure实现）<ul>\n<li>如数据持久化实现Mysql、短信通知实现、MQ通知、搜索引擎ES实现等</li>\n<li>Event Bus 事件总线</li>\n</ul>\n</li>\n<li>依赖方向由外到内，且内层不知道外层（参见之前洋葱架构） </li>\n</ul>\n<blockquote>\n<p>TIPS: 清晰架构只是一份指南！<br>应用才是疆域，现实情况和具体用例才是运用这些知识的地方，它们才能勾勒出实际架构的轮廓！<br>我们需要理解所有这些模式，<br>但我们还时常需要思考和理解我们的应用需要什么，我们应该在追求解耦和内聚的道路上走多远。<br>这个决定可能受到许多因素的影响，<br>包括项目的功能需求，也包括构建应用的时间期限，应用寿命，开发团队的经验等等因素。</p>\n</blockquote>\n<h3 id=\"七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：\"><a href=\"#七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：\" class=\"headerlink\" title=\"七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：\"></a>七、关于传统分层、六边形、洋葱、整洁、清晰架构的演进可参见下图：</h3><p><img src=\"/2024/09/03/2024-09-03-架构-DDD应用架构/%E6%80%BB%E7%9A%84%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B%E5%9B%BE.png\" alt=\"总的架构演进图\"></p>\n<hr>\n<p>参考文章：<br><a href=\"https://code84.com/730128.html\" target=\"_blank\" rel=\"noopener\">DDD中常提到的应用架构总结（六边形、洋葱、整洁、清晰）</a><br><a href=\"https://zq99299.github.io/note-book2/ddd/02/03.html#%E4%BB%8E%E4%B8%89%E7%A7%8D%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B%E7%9C%8B%E4%B8%AD%E5%8F%B0%E5%92%8C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1\" target=\"_blank\" rel=\"noopener\">微服务架构模型：几种常见模型的对比和分析</a><br><a href=\"https://juejin.cn/post/7170631967178752030\" target=\"_blank\" rel=\"noopener\">DDD 领域驱动设计-应用架构</a></p>\n<p>EBI：<br><a href=\"https://herbertograca.com/2017/08/24/ebi-architecture/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/08/24/ebi-architecture/</a></p>\n<p>端口和适配器架构：<br>11.端口和适配器架构(译) - <a href=\"https://www.jianshu.com/p/f39f4537857e\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/f39f4537857e</a><br><a href=\"https://herbertograca.com/2017/09/14/ports-adapters-architecture/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/09/14/ports-adapters-architecture/</a></p>\n<p>洋葱架构：<br><a href=\"https://herbertograca.com/2017/09/21/onion-architecture/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/09/21/onion-architecture/</a><br><a href=\"https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/\" target=\"_blank\" rel=\"noopener\">https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/</a></p>\n<p>整洁架构：<br><a href=\"https://herbertograca.com/2017/09/28/clean-architecture-standing-on-the-shoulders-of-giants/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/09/28/clean-architecture-standing-on-the-shoulders-of-giants/</a><br><a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\" target=\"_blank\" rel=\"noopener\">https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html</a></p>\n<p>清晰架构：<br><a href=\"https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/</a><br>17.清晰架构(01): 融合 DDD、洋葱架构、整洁架构、CQRS…(译) - <a href=\"https://www.jianshu.com/p/d3e8b9ac097b\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/d3e8b9ac097b</a></p>\n<p>DDD：<br><a href=\"https://herbertograca.com/2017/09/07/domain-driven-design/\" target=\"_blank\" rel=\"noopener\">https://herbertograca.com/2017/09/07/domain-driven-design/</a></p>"},{"title":"spring启动过程","date":"2020-12-28T02:17:49.000Z","_content":"# 一、核心\nspring两大核心，IOC依赖注入和AOP面向切面编程。\n\n# 二、容器\n想要启动spring，需要创建一个ApplicationContext容器，该容器是spring的核心。\n\nApplicationContext类组织结构：\n![ApplicationContext](2020-12-28-spring启动过程/ApplicationContext.png)\n\n<!--more-->    \n\nApplicationContext实质上也是BeanFactory工厂。\n* 几种实现方式\n    * ConfigurableApplicationContext：是比较上层的一个接口，该接口也是比较重要的一个接口，几乎所有的应用上下文都实现了该接口。该接口在ApplicationContext的基础上提供了配置应用上下文的能力，此外提供了生命周期的控制能力\n    * ClassPathXmlApplicationContext：它是从类的根路径下加载配置文件\n    * FileSystemXmlApplicationContext： 它是从磁盘路径上加载配置文件，配置文件可以在磁盘的任意位置。\n    * AnnotationConfigApplicationContext: 当我们使用注解配置容器对象时，需要使用此类来创建 spring 容器。它用来读取注解\n\n# 三、容器启动过程\n> 方式1：通过反射方式\n```\nClass<?> applicationContextClass = classLoader.loadClass(\"org.springframework.context.support.ClassPathXmlApplicationContext\");\nConstructor<?> constructor = applicationContextClass.getConstructor(String[].class);\nObject springContext = constructor.newInstance(new Object[] { springConfigPathArray });\n```\n\n> 方式2：new\n```\nApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:applicationfile.xml\");\n```\n\n## 3.1、容器创建过程\n用ClassPathXmlApplicationContext解析，在实例化过程中，会调用refresh()方法，进行容器的创建及一系列操作。\n```\npublic ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException {\n    super(parent);\n    // 解析xml配置文件列表\n    setConfigLocations(configLocations);\n    if (refresh) {\n        //核心方法\n        refresh();\n    }\n}\n```\n### 1. refresh()方法\n```\npublic void refresh() throws BeansException, IllegalStateException {\n    synchronized (this.startupShutdownMonitor) {\n        // 准备工作，记录下容器的启动时间、标记已启动状态、处理配置文件中的占位符\n        prepareRefresh();\n        \n        /** 这步完成后，配置文件就会解析成一个个BeanDefinition，注册到BeanFactory 中，\n          * 当然，这里说的 Bean 还没有初始化，只是配置信息都提取出来了，\n          * 注册也只是将这些信息都保存到了注册中心(说到底核心是一个beanName->beanDefinition的map)\n        */\n        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\n        \n        // 设置BeanFactory的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean\n        prepareBeanFactory(beanFactory);\n        try {\n            /**【这里需要知道BeanFactoryPostProcessor这个知识点，Bean如果实现了此接口，\n              * 那么在容器初始化以后，Spring会负责调用里面的postProcessBeanFactory 方法。】\n              * 这里是提供给子类的扩展点，到这里的时候，所有的Bean都加载、注册完成了，但是都还没有初始化\n              * 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事\n            */\n            postProcessBeanFactory(beanFactory);\n\n            // 调用BeanFactoryPostProcessor各个实现类的 postProcessBeanFactory(factory) 方法\n            invokeBeanFactoryPostProcessors(beanFactory);\n\n            /** 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别\n              * 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization\n              * 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化\n            */\n            registerBeanPostProcessors(beanFactory);\n\n            // Initialize message source for this context.\n            initMessageSource();\n\n            // 初始化当前 ApplicationContext 的事件广播器\n            initApplicationEventMulticaster();\n\n            /** 从方法名就可以知道，典型的模板方法(钩子方法)，\n              * 具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前）\n            */\n            onRefresh();\n\n            // 注册事件监听器，监听器需要实现 ApplicationListener 接口\n            registerListeners();\n\n            // 重点，重点，重点\n            // 初始化所有的  singleton beans\n            //（lazy-init 的除外）\n            /** <bean id=\"testBean\" class=\"cn.itcast.test.TestBean\" />\n              * 该bean默认的设置为:\n              * <bean id=\"testBean\" calss=\"cn.itcast.test.TestBean\" lazy-init=\"false\" />\n              * lazy-init=\"false\"\n              * 立即加载，表示在spring启动时，立刻进行实例化。\n            */\n            finishBeanFactoryInitialization(beanFactory);\n\n            // 最后，广播事件，ApplicationContext 初始化完成\n            finishRefresh();\n        }\n\n        catch (BeansException ex) {\n            logger.warn(\"Exception encountered during context initialization - cancelling refresh attempt\", ex);\n\n            // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源\n            destroyBeans();\n\n            // Reset 'active' flag.\n            cancelRefresh(ex);\n\n            // 把异常往外抛\n            throw ex;\n        }\n    }\n}\n```\n\n### 2. 注册BeanDefinition\n![ApplicationContext](2020-12-28-spring启动过程/beanDefination.png)\n1. 注册BeanDefinition方法：ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\n2. 需要被描述为 bean definitions 的配置对象主要分为如下几大类，\n    * xml-based，解析 xml beans 的情况；\n    * 使用 @Autowired、@Required 注解注入 beans 的解析情况；\n        * 需要特殊处理并解析的元素 <context:annotation-config/>\n    * 使用 @Component、@Service、@Repository，@Beans 注解注入 beans 的解析情况；\n        * 需要特殊处理并解析的元素 <context:annotation-scan/>\n        * 解析当前的 .class 字节码，解析出对应的 annotation，比如 @Service，然后生成beanDefinition\n        * 还需为注解类生成beanName\n    * @Controller注解，内部有@Component\n    \n#### 2.1、xml-based类型配置的注册\n处理<bean>标签\n```\n<bean id=\"threadPool\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\">\n```\n1. 解析bean标签入口DefaultBeanDefinitionDocumentReader#processBeanDefinition\n2. 实际实现由XmlBeanDefinitionReader去解析XML文件\n3. BeanDefinitionParserDelegate解析Bean标签，创建beanDefinition,解析bean标签属性及子标签设置到beanDefinition中\n4. 最后生成beanDefinitionMap<beanName,beanDefinition>和beanDefinitionNames，然后放入到容器内\n\n    \n#### 2.2、@Component等注解的注册\n1. 需要配置：<context:component-scan\n2. component-scan标签的前缀是context,这种带有前缀的标签叫做自定义标签，自定义标签的解析流程如下：\n    * 首先找到自定义标签的前缀对应的namespaceUri --> xmlns:context=\"http://www.springframework.org/schema/context\"\n    * 在META-INF文件夹内的spring.handlers文件中配置有该namespaceUri对应的处理类 --> http\\://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler\n    * DefaultBeanDefinitionDocumentReader#parseBeanDefinitions  --> delegate.parseCustomElement(ele)\n    * component-scan元素的处理类为ComponentScanBeanDefinitionParser\n    *  \n    \n通过 @Component、@Service 注解的方式注入的 bean 往往没有配置 bean name，所以往往需要通过程序的方式自行生成相应的 bean name，看看内部的源码，如何生成 bean name 的，\n```\n/**\n * 因为通过 @Component、@Serivce 等注解的方式不会像 xml-based 配置那样提供了一个 name 的标签，可以指定 bean name；所以，这里需要去单独为其生成一个；\n */\n@Override\npublic String generateBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) {\n   if (definition instanceof AnnotatedBeanDefinition) {\n      String beanName = determineBeanNameFromAnnotation((AnnotatedBeanDefinition) definition); // 处理诸如 @Service(\"dogService\") 的情况\n      if (StringUtils.hasText(beanName)) {\n         // Explicit bean name found.\n         return beanName;\n      }\n   }\n   // Fallback: generate a unique default bean name. 里面的实现逻辑就是通过将 Class Name 的首字母大写编程小写，然后返回；\n   return buildDefaultBeanName(definition, registry);\n}\n```\n* ComponentScanBeanDefinitionParser.parse()\n* \n\n#### 2.3、BeanDefinition包含属性\n```\n<bean id=\"abstractDataSource\" name=\"aliasName\"class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\" abstract=\"true\"  lazy-init=\"true\">\n    <!-- 配置初始化大小、最小、最大 -->\n    <property name=\"initialSize\" value=\"2\" />\n    <property name=\"minIdle\" value=\"2\" />\n    <property name=\"maxActive\" value=\"5\" />\t\n</bean>\n```\n以上面代码为例：id, class名称，property属性, init-method, 别名, 是否懒加载\n* init-method：初始化方法名，\n* name：别名，spring通过一个map保存BeanDefinition信息，key=beanName，value=BeanDefinition； -> beanDefinitionMap\nspring有一个别名映射map，例如beanName=张三，aliasName=小三，那么在aliasMap中添加一个键值对，key=张三，value=小三\n通过别名获取时，需要重定向一次。\n\n[参考](https://www.shangyang.me/2017/04/07/spring-core-container-sourcecode-analysis-register-bean-definitions/)\n\n#### 2.4、 解析自定义标签\n1. 生成标签解析器handler(在init方法中添加parser类)\n2. 在spring.handlers文件配置\n3. 创建对应标签的parser解析器\n\n\n### 3. prepareBeanFactory\n* 为工厂设置类的加载器、表达式解析器、属性编辑器注册器等\n* 为工厂添加后处理器、要忽略的依赖接口\n* 在工厂中注册可解析的依赖\n* 在工厂中提前注册一些单例Bean\n\n### 4. beanFactory后置处理器\nspring的一个重要扩展点：例如可以手动注册一下BeanDefinition，修改或者是移除一些BeanDefinition\n```\n//实例化并调用所有已注册的 BeanFactoryPostProcessor\n//调用BeanFactoryPostProcessor各个实现类的 postProcessBeanFactory(factory) 方法\ninvokeBeanFactoryPostProcessors(beanFactory);\n```\n* 实例化 + 调用执行\n* BeanFactoryPostProcessor：主要的操作对象是beanFactory\n* BeanFactoryRegistryPostProcessor：主要的操作对象是BeanDefinition\n\n\n\n\n### 5. bean后置处理器\n```\n//注册\n1. registerBeanPostProcessors(beanFactory);\n//从bean工厂中找到所有实现BeanPostProcessor接口的类\n2. String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);\n//实例化\n3. BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);\n```\n1. 实例化并注册BeanPostProcessors\n    * 注册AutowiredAnnotationBeanPostProcessor\n    * 注册CommonAnnotationBeanPostProcessor\n2. 注意：BeanPostProcessor此时未执行，执行时间是在bean初始化时，初始化之前调用postProcessBeforeInitialization，\n    初始化之后postProcessAfterInitialization\n         \n    \n\n### 6. bean实例化和初始化\n0. 有一写bean已经实例化了，例如BFPP, BPP\n1. 实例初始化方法：finishBeanFactoryInitialization(beanFactory);\n2. 遍历beanDefinitionNames，对beanDefinition进行实例化和初始化；AbstractBeanFactory.doGetBean()\n```\nbeanNames = new ArrayList<String>(this.beanDefinitionNames);\n// Trigger initialization of all non-lazy singleton beans...\nfor (String beanName : beanNames) {\n    getBean(beanName);\n}\n```\n> BeanFactory与FactoryBean的区别？\n```\n1. 两个都可以用来创建对象\n2. BeanFactory需要严格遵守SpringBean的生命周期，从实例化、初始化等等，流程复杂\n3. 所以引入了FactoryBean，快捷的创建，会创建两个对象，\n    1. 一个继承FactoryBean的类，由Spring创建，交给Spring管理，会在一级缓存中管理（singletonObjects)\n    2. 另外一个是实际对象，由FactoryBean创建，也交给Spring管理，会在factoryBeanObjectCache缓存中\n```\n\n\n> 实例化阶段\n\ngetBean() -> doGetBean()\n* Object sharedInstance = getSingleton(beanName);\n    * 首先从缓存中获取（三级缓存）\n* 缓存不存在，如果原型模式下存在循环依赖，抛出异常\n* 进入创建环节\n```\nsharedInstance = getSingleton(beanName, new ObjectFactory<Object>() {\n    @Override\n    public Object getObject() throws BeansException {\n        try {\n            //函数式\n            return createBean(beanName, mbd, args);\n        } catch (BeansException ex) {\n        }\n    }\n});\n标记\ngetSingleton() -> beforeSingletonCreation() -> this.singletonsCurrentlyInCreation.add(beanName)，将当前bean加入到正在创建的map内\n\n```\n* createBean()创建环节\n```\ncreateBean(){\n    1. mbd.prepareMethodOverrides()；//lookup-method重写，cglib生成代理对象\n    //Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.\n    //给BeanPostProcessors一个机会来返回代理来替代真正的实例，AOP\n    2. resolveBeforeInstantiation() {\n        //调用BeanPostProcessor的postProcessBeforeInstantiation方法，进行\n        for (BeanPostProcessor bp : getBeanPostProcessors()) {\n            ibp.postProcessBeforeInstantiation()\n        }\n    }\n    3. doCreateBean() {\n        //instanceWrapper，bean实例的一个封装对象\n        if (instanceWrapper == null) {\n            //根据执行bean使用对应的策略创建新的实例，如：工厂方法，构造函数主动注入，简单实例化\n            instanceWrapper = createBeanInstance(beanName, mbd, args);\n            createBeanInstance() {\n                Class<?> beanClass = resolveBeanClass(mbd, beanName);\n                if (mbd.getFactoryMethodName() != null)  {\n                    //自定义bean工厂方式生成bean实例\n                    return instantiateUsingFactoryMethod(beanName, mbd, args);\n                }\n                //选择构造器，@Autowired注解，可以在构造器、方法、字段上注入\n            }\n        }\n        //bean创建后，BeanPostProcessor后置处理\n        applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);\n        //早期暴露，解决循环依赖\n        boolean earlySingletonExposure = (mbd.isSingleton() && this.allowCircularReferences && isSingletonCurrentlyInCreation(beanName));\n        if (earlySingletonExposure) {\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"Eagerly caching bean '\" + beanName +\n                        \"' to allow for resolving potential circular references\");\n            }\n            //初始化之前将创建实例的objectFactory添加到工厂中，解决后期代理问题\n            addSingletonFactory(beanName, new ObjectFactory<Object>() {\n                @Override\n                public Object getObject() throws BeansException {\n                    return getEarlyBeanReference(beanName, mbd, bean);\n                }\n            });\n        }\n    }\n}\n```\n\n\n* 单例bean引用原型bean，通过 lookup-method 解决\n    * 原型：scope=\"prototype\"，每次请求都会创建新的bean\n\n* 创建bean方式\n    * factory-method=\"create\"，配置工厂（静态或者是实例，静态static）\n    * factoryBean\n    * BeanFactory\n    * 反射\n\n> 填充阶段\n\n* @Autowired和@Inject都是按照类型注入，使用后置处理器进行实例化注入（AutowiredAnnotationBeanPostProcessor）、\n* @Resource按名称注入\n\n\n> 初始化阶段\n\n1. 执行Aware接口对应的方法\n2. 执行BPP的before的初始化方法\n3. 调用执行init-method方法\n    1. 实现了InitializingBean接口之后调用afterPropertiesSet方法\n    2. 调用执行用户自定义初始化方法：init-method方法\n4. 执行BPP的after的初始化方法，实际进行**AOP代理**\n\n> InitializingBean接口\n\nspring的加载bean的源码类(AbstractAutowireCapableBeanFactory)可以看到\n```\nprotected void invokeInitMethods(String beanName, final Object bean, RootBeanDefinition mbd)\n            throws Throwable {\n//判断该bean是否实现了实现了InitializingBean接口，如果实现了InitializingBean接口，则调用bean的afterPropertiesSet方法\n        boolean isInitializingBean = (bean instanceof InitializingBean);\n        if (isInitializingBean && (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) {\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\");\n            }\n            if (System.getSecurityManager() != null) {\n                try {\n                    AccessController.doPrivileged(new PrivilegedExceptionAction<Object>() {\n                        public Object run() throws Exception {\n                            //调用afterPropertiesSet\n                            ((InitializingBean) bean).afterPropertiesSet();\n                            return null;\n                        }\n                    }, getAccessControlContext());\n                }\n                catch (PrivilegedActionException pae) {\n                    throw pae.getException();\n                }\n            }\n            else {\n                //调用afterPropertiesSet\n                ((InitializingBean) bean).afterPropertiesSet();\n            }\n        }\n        if (mbd != null) {            //判断是否指定了init-method方法，如果指定了init-method方法，则再调用制定的init-method\n            String initMethodName = mbd.getInitMethodName();\n            if (initMethodName != null && !(isInitializingBean && \"afterPropertiesSet\".equals(initMethodName)) &&\n                    !mbd.isExternallyManagedInitMethod(initMethodName)) {\n                //反射调用init-method方法\n                invokeCustomInitMethod(beanName, bean, mbd);\n            }\n        }\n    }\n```\n* 1：spring为bean提供了两种初始化bean的方式，实现InitializingBean接口，实现afterPropertiesSet方法，或者在配置文件中同过init-method指定，两种方式可以同时使用\n* 2：实现InitializingBean接口是直接调用afterPropertiesSet方法，比通过反射调用init-method指定的方法效率相对来说要高点。但是init-method方式消除了对spring的依赖\n* 3：如果调用afterPropertiesSet方法时出错，则不调用init-method指定的方法。\n\n> 循环依赖\n\nA-B;B->A\n1. 一级缓存：singletonObjects\n    * 步骤3：将B放入一级缓存，将A放入一级缓存，清除三级\n2. 二级缓存：earlySingletonObjects\n    * 步骤2：发现循环依赖时，将A放入二级缓存，清除三级\n3. 三级缓存：singletonFactories\n    * 步骤1：存入时机：实例化后，将ObjectFactory放入三级缓存\n    * 在获取具体对象的时候，直接生成代理对象，在获取的时候通过lambda表达式中动态生成\n如果没有代理，只需要二级缓存就可以，所以需要三级缓存。在整个三级缓存中，对象仅能存在一份。\n\n\n\n# 四、bean的生命周期\n1. 读取配置，生成beanDefinition，放入beanDefinitionMap\n    * AOP对象的beanDefinition也会此时生成，AspectjAwareAdvisorAutoProxyCreator\n2. 实例化和执行BeanFactoryPostProcessor(BFPP)，可以修改或者引入其他的beanDefinition，BFPP操作的对象是BeanFactory.\n    * ConfigurationClassPostProcessor：用来对相关注解的解析工作\n3. registerBeanPostProcessor，注册BeanPostProcess并且实例化，用于实例化时调用before和after接口\n4. 实例化对象，createBeanInstance\n    * 在一个对象创建之前，必须先把AOP需要的对象提前准备好，因为无法预估哪些对象需要动态代理\n    * 实例化之前：\n        * 哪个步骤可以提前实例化并且生成对应的对象，resolveBeforeInstantiation() -> BPP.before()\n        * AOP的相关对象创建好\n    * 创建方式\n        * factoryMethod，通过工厂方法\n        * 通过反射创建\n        * 代理方式\n    * 实例化之后\n5. 填充属性，populateBean\n    * 会创建依赖的对象\n6. 初始化\n    *. 执行Aware接口对应的方法\n    *. 执行BPP的before的初始化方法\n    *. 调用执行init-method方法\n        1. 实现了InitializingBean接口之后调用afterPropertiesSet方法\n        2. 调用执行用户自定义初始化方法：init-method方法\n    *. 执行after的初始化方法，AOP\n            \n            \n# 五、import标签\n* Spring IOC容器初使化的时候会调用AbstractApplicationContext 的refresh方法\n* 在refresh里会调用各种BeanFactoryPostProcessor， 其中就包括我们需要关注的ConfigurationClassPostProcessor。\n* ConfigurationClassPostProcessor 不但用于处理@Configuration注解，里面也有处理@Import注解。\n* 最终的处理是通过 ConfigurationClassParser 这个类完成对Import各种情况的处理\n            \n","source":"_posts/2020-12-28-spring启动过程.md","raw":"---\ntitle: spring启动过程\ndate: 2020-12-28 10:17:49\ncategories:\n  - [spring, 原理]\n---\n# 一、核心\nspring两大核心，IOC依赖注入和AOP面向切面编程。\n\n# 二、容器\n想要启动spring，需要创建一个ApplicationContext容器，该容器是spring的核心。\n\nApplicationContext类组织结构：\n![ApplicationContext](2020-12-28-spring启动过程/ApplicationContext.png)\n\n<!--more-->    \n\nApplicationContext实质上也是BeanFactory工厂。\n* 几种实现方式\n    * ConfigurableApplicationContext：是比较上层的一个接口，该接口也是比较重要的一个接口，几乎所有的应用上下文都实现了该接口。该接口在ApplicationContext的基础上提供了配置应用上下文的能力，此外提供了生命周期的控制能力\n    * ClassPathXmlApplicationContext：它是从类的根路径下加载配置文件\n    * FileSystemXmlApplicationContext： 它是从磁盘路径上加载配置文件，配置文件可以在磁盘的任意位置。\n    * AnnotationConfigApplicationContext: 当我们使用注解配置容器对象时，需要使用此类来创建 spring 容器。它用来读取注解\n\n# 三、容器启动过程\n> 方式1：通过反射方式\n```\nClass<?> applicationContextClass = classLoader.loadClass(\"org.springframework.context.support.ClassPathXmlApplicationContext\");\nConstructor<?> constructor = applicationContextClass.getConstructor(String[].class);\nObject springContext = constructor.newInstance(new Object[] { springConfigPathArray });\n```\n\n> 方式2：new\n```\nApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:applicationfile.xml\");\n```\n\n## 3.1、容器创建过程\n用ClassPathXmlApplicationContext解析，在实例化过程中，会调用refresh()方法，进行容器的创建及一系列操作。\n```\npublic ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException {\n    super(parent);\n    // 解析xml配置文件列表\n    setConfigLocations(configLocations);\n    if (refresh) {\n        //核心方法\n        refresh();\n    }\n}\n```\n### 1. refresh()方法\n```\npublic void refresh() throws BeansException, IllegalStateException {\n    synchronized (this.startupShutdownMonitor) {\n        // 准备工作，记录下容器的启动时间、标记已启动状态、处理配置文件中的占位符\n        prepareRefresh();\n        \n        /** 这步完成后，配置文件就会解析成一个个BeanDefinition，注册到BeanFactory 中，\n          * 当然，这里说的 Bean 还没有初始化，只是配置信息都提取出来了，\n          * 注册也只是将这些信息都保存到了注册中心(说到底核心是一个beanName->beanDefinition的map)\n        */\n        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\n        \n        // 设置BeanFactory的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean\n        prepareBeanFactory(beanFactory);\n        try {\n            /**【这里需要知道BeanFactoryPostProcessor这个知识点，Bean如果实现了此接口，\n              * 那么在容器初始化以后，Spring会负责调用里面的postProcessBeanFactory 方法。】\n              * 这里是提供给子类的扩展点，到这里的时候，所有的Bean都加载、注册完成了，但是都还没有初始化\n              * 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事\n            */\n            postProcessBeanFactory(beanFactory);\n\n            // 调用BeanFactoryPostProcessor各个实现类的 postProcessBeanFactory(factory) 方法\n            invokeBeanFactoryPostProcessors(beanFactory);\n\n            /** 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别\n              * 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization\n              * 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化\n            */\n            registerBeanPostProcessors(beanFactory);\n\n            // Initialize message source for this context.\n            initMessageSource();\n\n            // 初始化当前 ApplicationContext 的事件广播器\n            initApplicationEventMulticaster();\n\n            /** 从方法名就可以知道，典型的模板方法(钩子方法)，\n              * 具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前）\n            */\n            onRefresh();\n\n            // 注册事件监听器，监听器需要实现 ApplicationListener 接口\n            registerListeners();\n\n            // 重点，重点，重点\n            // 初始化所有的  singleton beans\n            //（lazy-init 的除外）\n            /** <bean id=\"testBean\" class=\"cn.itcast.test.TestBean\" />\n              * 该bean默认的设置为:\n              * <bean id=\"testBean\" calss=\"cn.itcast.test.TestBean\" lazy-init=\"false\" />\n              * lazy-init=\"false\"\n              * 立即加载，表示在spring启动时，立刻进行实例化。\n            */\n            finishBeanFactoryInitialization(beanFactory);\n\n            // 最后，广播事件，ApplicationContext 初始化完成\n            finishRefresh();\n        }\n\n        catch (BeansException ex) {\n            logger.warn(\"Exception encountered during context initialization - cancelling refresh attempt\", ex);\n\n            // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源\n            destroyBeans();\n\n            // Reset 'active' flag.\n            cancelRefresh(ex);\n\n            // 把异常往外抛\n            throw ex;\n        }\n    }\n}\n```\n\n### 2. 注册BeanDefinition\n![ApplicationContext](2020-12-28-spring启动过程/beanDefination.png)\n1. 注册BeanDefinition方法：ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\n2. 需要被描述为 bean definitions 的配置对象主要分为如下几大类，\n    * xml-based，解析 xml beans 的情况；\n    * 使用 @Autowired、@Required 注解注入 beans 的解析情况；\n        * 需要特殊处理并解析的元素 <context:annotation-config/>\n    * 使用 @Component、@Service、@Repository，@Beans 注解注入 beans 的解析情况；\n        * 需要特殊处理并解析的元素 <context:annotation-scan/>\n        * 解析当前的 .class 字节码，解析出对应的 annotation，比如 @Service，然后生成beanDefinition\n        * 还需为注解类生成beanName\n    * @Controller注解，内部有@Component\n    \n#### 2.1、xml-based类型配置的注册\n处理<bean>标签\n```\n<bean id=\"threadPool\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\">\n```\n1. 解析bean标签入口DefaultBeanDefinitionDocumentReader#processBeanDefinition\n2. 实际实现由XmlBeanDefinitionReader去解析XML文件\n3. BeanDefinitionParserDelegate解析Bean标签，创建beanDefinition,解析bean标签属性及子标签设置到beanDefinition中\n4. 最后生成beanDefinitionMap<beanName,beanDefinition>和beanDefinitionNames，然后放入到容器内\n\n    \n#### 2.2、@Component等注解的注册\n1. 需要配置：<context:component-scan\n2. component-scan标签的前缀是context,这种带有前缀的标签叫做自定义标签，自定义标签的解析流程如下：\n    * 首先找到自定义标签的前缀对应的namespaceUri --> xmlns:context=\"http://www.springframework.org/schema/context\"\n    * 在META-INF文件夹内的spring.handlers文件中配置有该namespaceUri对应的处理类 --> http\\://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler\n    * DefaultBeanDefinitionDocumentReader#parseBeanDefinitions  --> delegate.parseCustomElement(ele)\n    * component-scan元素的处理类为ComponentScanBeanDefinitionParser\n    *  \n    \n通过 @Component、@Service 注解的方式注入的 bean 往往没有配置 bean name，所以往往需要通过程序的方式自行生成相应的 bean name，看看内部的源码，如何生成 bean name 的，\n```\n/**\n * 因为通过 @Component、@Serivce 等注解的方式不会像 xml-based 配置那样提供了一个 name 的标签，可以指定 bean name；所以，这里需要去单独为其生成一个；\n */\n@Override\npublic String generateBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) {\n   if (definition instanceof AnnotatedBeanDefinition) {\n      String beanName = determineBeanNameFromAnnotation((AnnotatedBeanDefinition) definition); // 处理诸如 @Service(\"dogService\") 的情况\n      if (StringUtils.hasText(beanName)) {\n         // Explicit bean name found.\n         return beanName;\n      }\n   }\n   // Fallback: generate a unique default bean name. 里面的实现逻辑就是通过将 Class Name 的首字母大写编程小写，然后返回；\n   return buildDefaultBeanName(definition, registry);\n}\n```\n* ComponentScanBeanDefinitionParser.parse()\n* \n\n#### 2.3、BeanDefinition包含属性\n```\n<bean id=\"abstractDataSource\" name=\"aliasName\"class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\" abstract=\"true\"  lazy-init=\"true\">\n    <!-- 配置初始化大小、最小、最大 -->\n    <property name=\"initialSize\" value=\"2\" />\n    <property name=\"minIdle\" value=\"2\" />\n    <property name=\"maxActive\" value=\"5\" />\t\n</bean>\n```\n以上面代码为例：id, class名称，property属性, init-method, 别名, 是否懒加载\n* init-method：初始化方法名，\n* name：别名，spring通过一个map保存BeanDefinition信息，key=beanName，value=BeanDefinition； -> beanDefinitionMap\nspring有一个别名映射map，例如beanName=张三，aliasName=小三，那么在aliasMap中添加一个键值对，key=张三，value=小三\n通过别名获取时，需要重定向一次。\n\n[参考](https://www.shangyang.me/2017/04/07/spring-core-container-sourcecode-analysis-register-bean-definitions/)\n\n#### 2.4、 解析自定义标签\n1. 生成标签解析器handler(在init方法中添加parser类)\n2. 在spring.handlers文件配置\n3. 创建对应标签的parser解析器\n\n\n### 3. prepareBeanFactory\n* 为工厂设置类的加载器、表达式解析器、属性编辑器注册器等\n* 为工厂添加后处理器、要忽略的依赖接口\n* 在工厂中注册可解析的依赖\n* 在工厂中提前注册一些单例Bean\n\n### 4. beanFactory后置处理器\nspring的一个重要扩展点：例如可以手动注册一下BeanDefinition，修改或者是移除一些BeanDefinition\n```\n//实例化并调用所有已注册的 BeanFactoryPostProcessor\n//调用BeanFactoryPostProcessor各个实现类的 postProcessBeanFactory(factory) 方法\ninvokeBeanFactoryPostProcessors(beanFactory);\n```\n* 实例化 + 调用执行\n* BeanFactoryPostProcessor：主要的操作对象是beanFactory\n* BeanFactoryRegistryPostProcessor：主要的操作对象是BeanDefinition\n\n\n\n\n### 5. bean后置处理器\n```\n//注册\n1. registerBeanPostProcessors(beanFactory);\n//从bean工厂中找到所有实现BeanPostProcessor接口的类\n2. String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);\n//实例化\n3. BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);\n```\n1. 实例化并注册BeanPostProcessors\n    * 注册AutowiredAnnotationBeanPostProcessor\n    * 注册CommonAnnotationBeanPostProcessor\n2. 注意：BeanPostProcessor此时未执行，执行时间是在bean初始化时，初始化之前调用postProcessBeforeInitialization，\n    初始化之后postProcessAfterInitialization\n         \n    \n\n### 6. bean实例化和初始化\n0. 有一写bean已经实例化了，例如BFPP, BPP\n1. 实例初始化方法：finishBeanFactoryInitialization(beanFactory);\n2. 遍历beanDefinitionNames，对beanDefinition进行实例化和初始化；AbstractBeanFactory.doGetBean()\n```\nbeanNames = new ArrayList<String>(this.beanDefinitionNames);\n// Trigger initialization of all non-lazy singleton beans...\nfor (String beanName : beanNames) {\n    getBean(beanName);\n}\n```\n> BeanFactory与FactoryBean的区别？\n```\n1. 两个都可以用来创建对象\n2. BeanFactory需要严格遵守SpringBean的生命周期，从实例化、初始化等等，流程复杂\n3. 所以引入了FactoryBean，快捷的创建，会创建两个对象，\n    1. 一个继承FactoryBean的类，由Spring创建，交给Spring管理，会在一级缓存中管理（singletonObjects)\n    2. 另外一个是实际对象，由FactoryBean创建，也交给Spring管理，会在factoryBeanObjectCache缓存中\n```\n\n\n> 实例化阶段\n\ngetBean() -> doGetBean()\n* Object sharedInstance = getSingleton(beanName);\n    * 首先从缓存中获取（三级缓存）\n* 缓存不存在，如果原型模式下存在循环依赖，抛出异常\n* 进入创建环节\n```\nsharedInstance = getSingleton(beanName, new ObjectFactory<Object>() {\n    @Override\n    public Object getObject() throws BeansException {\n        try {\n            //函数式\n            return createBean(beanName, mbd, args);\n        } catch (BeansException ex) {\n        }\n    }\n});\n标记\ngetSingleton() -> beforeSingletonCreation() -> this.singletonsCurrentlyInCreation.add(beanName)，将当前bean加入到正在创建的map内\n\n```\n* createBean()创建环节\n```\ncreateBean(){\n    1. mbd.prepareMethodOverrides()；//lookup-method重写，cglib生成代理对象\n    //Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.\n    //给BeanPostProcessors一个机会来返回代理来替代真正的实例，AOP\n    2. resolveBeforeInstantiation() {\n        //调用BeanPostProcessor的postProcessBeforeInstantiation方法，进行\n        for (BeanPostProcessor bp : getBeanPostProcessors()) {\n            ibp.postProcessBeforeInstantiation()\n        }\n    }\n    3. doCreateBean() {\n        //instanceWrapper，bean实例的一个封装对象\n        if (instanceWrapper == null) {\n            //根据执行bean使用对应的策略创建新的实例，如：工厂方法，构造函数主动注入，简单实例化\n            instanceWrapper = createBeanInstance(beanName, mbd, args);\n            createBeanInstance() {\n                Class<?> beanClass = resolveBeanClass(mbd, beanName);\n                if (mbd.getFactoryMethodName() != null)  {\n                    //自定义bean工厂方式生成bean实例\n                    return instantiateUsingFactoryMethod(beanName, mbd, args);\n                }\n                //选择构造器，@Autowired注解，可以在构造器、方法、字段上注入\n            }\n        }\n        //bean创建后，BeanPostProcessor后置处理\n        applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);\n        //早期暴露，解决循环依赖\n        boolean earlySingletonExposure = (mbd.isSingleton() && this.allowCircularReferences && isSingletonCurrentlyInCreation(beanName));\n        if (earlySingletonExposure) {\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"Eagerly caching bean '\" + beanName +\n                        \"' to allow for resolving potential circular references\");\n            }\n            //初始化之前将创建实例的objectFactory添加到工厂中，解决后期代理问题\n            addSingletonFactory(beanName, new ObjectFactory<Object>() {\n                @Override\n                public Object getObject() throws BeansException {\n                    return getEarlyBeanReference(beanName, mbd, bean);\n                }\n            });\n        }\n    }\n}\n```\n\n\n* 单例bean引用原型bean，通过 lookup-method 解决\n    * 原型：scope=\"prototype\"，每次请求都会创建新的bean\n\n* 创建bean方式\n    * factory-method=\"create\"，配置工厂（静态或者是实例，静态static）\n    * factoryBean\n    * BeanFactory\n    * 反射\n\n> 填充阶段\n\n* @Autowired和@Inject都是按照类型注入，使用后置处理器进行实例化注入（AutowiredAnnotationBeanPostProcessor）、\n* @Resource按名称注入\n\n\n> 初始化阶段\n\n1. 执行Aware接口对应的方法\n2. 执行BPP的before的初始化方法\n3. 调用执行init-method方法\n    1. 实现了InitializingBean接口之后调用afterPropertiesSet方法\n    2. 调用执行用户自定义初始化方法：init-method方法\n4. 执行BPP的after的初始化方法，实际进行**AOP代理**\n\n> InitializingBean接口\n\nspring的加载bean的源码类(AbstractAutowireCapableBeanFactory)可以看到\n```\nprotected void invokeInitMethods(String beanName, final Object bean, RootBeanDefinition mbd)\n            throws Throwable {\n//判断该bean是否实现了实现了InitializingBean接口，如果实现了InitializingBean接口，则调用bean的afterPropertiesSet方法\n        boolean isInitializingBean = (bean instanceof InitializingBean);\n        if (isInitializingBean && (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) {\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\");\n            }\n            if (System.getSecurityManager() != null) {\n                try {\n                    AccessController.doPrivileged(new PrivilegedExceptionAction<Object>() {\n                        public Object run() throws Exception {\n                            //调用afterPropertiesSet\n                            ((InitializingBean) bean).afterPropertiesSet();\n                            return null;\n                        }\n                    }, getAccessControlContext());\n                }\n                catch (PrivilegedActionException pae) {\n                    throw pae.getException();\n                }\n            }\n            else {\n                //调用afterPropertiesSet\n                ((InitializingBean) bean).afterPropertiesSet();\n            }\n        }\n        if (mbd != null) {            //判断是否指定了init-method方法，如果指定了init-method方法，则再调用制定的init-method\n            String initMethodName = mbd.getInitMethodName();\n            if (initMethodName != null && !(isInitializingBean && \"afterPropertiesSet\".equals(initMethodName)) &&\n                    !mbd.isExternallyManagedInitMethod(initMethodName)) {\n                //反射调用init-method方法\n                invokeCustomInitMethod(beanName, bean, mbd);\n            }\n        }\n    }\n```\n* 1：spring为bean提供了两种初始化bean的方式，实现InitializingBean接口，实现afterPropertiesSet方法，或者在配置文件中同过init-method指定，两种方式可以同时使用\n* 2：实现InitializingBean接口是直接调用afterPropertiesSet方法，比通过反射调用init-method指定的方法效率相对来说要高点。但是init-method方式消除了对spring的依赖\n* 3：如果调用afterPropertiesSet方法时出错，则不调用init-method指定的方法。\n\n> 循环依赖\n\nA-B;B->A\n1. 一级缓存：singletonObjects\n    * 步骤3：将B放入一级缓存，将A放入一级缓存，清除三级\n2. 二级缓存：earlySingletonObjects\n    * 步骤2：发现循环依赖时，将A放入二级缓存，清除三级\n3. 三级缓存：singletonFactories\n    * 步骤1：存入时机：实例化后，将ObjectFactory放入三级缓存\n    * 在获取具体对象的时候，直接生成代理对象，在获取的时候通过lambda表达式中动态生成\n如果没有代理，只需要二级缓存就可以，所以需要三级缓存。在整个三级缓存中，对象仅能存在一份。\n\n\n\n# 四、bean的生命周期\n1. 读取配置，生成beanDefinition，放入beanDefinitionMap\n    * AOP对象的beanDefinition也会此时生成，AspectjAwareAdvisorAutoProxyCreator\n2. 实例化和执行BeanFactoryPostProcessor(BFPP)，可以修改或者引入其他的beanDefinition，BFPP操作的对象是BeanFactory.\n    * ConfigurationClassPostProcessor：用来对相关注解的解析工作\n3. registerBeanPostProcessor，注册BeanPostProcess并且实例化，用于实例化时调用before和after接口\n4. 实例化对象，createBeanInstance\n    * 在一个对象创建之前，必须先把AOP需要的对象提前准备好，因为无法预估哪些对象需要动态代理\n    * 实例化之前：\n        * 哪个步骤可以提前实例化并且生成对应的对象，resolveBeforeInstantiation() -> BPP.before()\n        * AOP的相关对象创建好\n    * 创建方式\n        * factoryMethod，通过工厂方法\n        * 通过反射创建\n        * 代理方式\n    * 实例化之后\n5. 填充属性，populateBean\n    * 会创建依赖的对象\n6. 初始化\n    *. 执行Aware接口对应的方法\n    *. 执行BPP的before的初始化方法\n    *. 调用执行init-method方法\n        1. 实现了InitializingBean接口之后调用afterPropertiesSet方法\n        2. 调用执行用户自定义初始化方法：init-method方法\n    *. 执行after的初始化方法，AOP\n            \n            \n# 五、import标签\n* Spring IOC容器初使化的时候会调用AbstractApplicationContext 的refresh方法\n* 在refresh里会调用各种BeanFactoryPostProcessor， 其中就包括我们需要关注的ConfigurationClassPostProcessor。\n* ConfigurationClassPostProcessor 不但用于处理@Configuration注解，里面也有处理@Import注解。\n* 最终的处理是通过 ConfigurationClassParser 这个类完成对Import各种情况的处理\n            \n","slug":"2020-12-28-spring启动过程","published":1,"updated":"2024-10-18T01:56:54.324Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyg005va13khs4g13d2","content":"<h1 id=\"一、核心\"><a href=\"#一、核心\" class=\"headerlink\" title=\"一、核心\"></a>一、核心</h1><p>spring两大核心，IOC依赖注入和AOP面向切面编程。</p>\n<h1 id=\"二、容器\"><a href=\"#二、容器\" class=\"headerlink\" title=\"二、容器\"></a>二、容器</h1><p>想要启动spring，需要创建一个ApplicationContext容器，该容器是spring的核心。</p>\n<p>ApplicationContext类组织结构：<br><img src=\"/2020/12/28/2020-12-28-spring启动过程/ApplicationContext.png\" alt=\"ApplicationContext\"></p>\n<a id=\"more\"></a>    \n\n<p>ApplicationContext实质上也是BeanFactory工厂。</p>\n<ul>\n<li>几种实现方式<ul>\n<li>ConfigurableApplicationContext：是比较上层的一个接口，该接口也是比较重要的一个接口，几乎所有的应用上下文都实现了该接口。该接口在ApplicationContext的基础上提供了配置应用上下文的能力，此外提供了生命周期的控制能力</li>\n<li>ClassPathXmlApplicationContext：它是从类的根路径下加载配置文件</li>\n<li>FileSystemXmlApplicationContext： 它是从磁盘路径上加载配置文件，配置文件可以在磁盘的任意位置。</li>\n<li>AnnotationConfigApplicationContext: 当我们使用注解配置容器对象时，需要使用此类来创建 spring 容器。它用来读取注解</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"三、容器启动过程\"><a href=\"#三、容器启动过程\" class=\"headerlink\" title=\"三、容器启动过程\"></a>三、容器启动过程</h1><blockquote>\n<p>方式1：通过反射方式</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Class&lt;?&gt; applicationContextClass = classLoader.loadClass(&quot;org.springframework.context.support.ClassPathXmlApplicationContext&quot;);</span><br><span class=\"line\">Constructor&lt;?&gt; constructor = applicationContextClass.getConstructor(String[].class);</span><br><span class=\"line\">Object springContext = constructor.newInstance(new Object[] &#123; springConfigPathArray &#125;);</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>方式2：new</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ApplicationContext context = new ClassPathXmlApplicationContext(&quot;classpath:applicationfile.xml&quot;);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-1、容器创建过程\"><a href=\"#3-1、容器创建过程\" class=\"headerlink\" title=\"3.1、容器创建过程\"></a>3.1、容器创建过程</h2><p>用ClassPathXmlApplicationContext解析，在实例化过程中，会调用refresh()方法，进行容器的创建及一系列操作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123;</span><br><span class=\"line\">    super(parent);</span><br><span class=\"line\">    // 解析xml配置文件列表</span><br><span class=\"line\">    setConfigLocations(configLocations);</span><br><span class=\"line\">    if (refresh) &#123;</span><br><span class=\"line\">        //核心方法</span><br><span class=\"line\">        refresh();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-refresh-方法\"><a href=\"#1-refresh-方法\" class=\"headerlink\" title=\"1. refresh()方法\"></a>1. refresh()方法</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void refresh() throws BeansException, IllegalStateException &#123;</span><br><span class=\"line\">    synchronized (this.startupShutdownMonitor) &#123;</span><br><span class=\"line\">        // 准备工作，记录下容器的启动时间、标记已启动状态、处理配置文件中的占位符</span><br><span class=\"line\">        prepareRefresh();</span><br><span class=\"line\">        </span><br><span class=\"line\">        /** 这步完成后，配置文件就会解析成一个个BeanDefinition，注册到BeanFactory 中，</span><br><span class=\"line\">          * 当然，这里说的 Bean 还没有初始化，只是配置信息都提取出来了，</span><br><span class=\"line\">          * 注册也只是将这些信息都保存到了注册中心(说到底核心是一个beanName-&gt;beanDefinition的map)</span><br><span class=\"line\">        */</span><br><span class=\"line\">        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();</span><br><span class=\"line\">        </span><br><span class=\"line\">        // 设置BeanFactory的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean</span><br><span class=\"line\">        prepareBeanFactory(beanFactory);</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            /**【这里需要知道BeanFactoryPostProcessor这个知识点，Bean如果实现了此接口，</span><br><span class=\"line\">              * 那么在容器初始化以后，Spring会负责调用里面的postProcessBeanFactory 方法。】</span><br><span class=\"line\">              * 这里是提供给子类的扩展点，到这里的时候，所有的Bean都加载、注册完成了，但是都还没有初始化</span><br><span class=\"line\">              * 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事</span><br><span class=\"line\">            */</span><br><span class=\"line\">            postProcessBeanFactory(beanFactory);</span><br><span class=\"line\"></span><br><span class=\"line\">            // 调用BeanFactoryPostProcessor各个实现类的 postProcessBeanFactory(factory) 方法</span><br><span class=\"line\">            invokeBeanFactoryPostProcessors(beanFactory);</span><br><span class=\"line\"></span><br><span class=\"line\">            /** 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别</span><br><span class=\"line\">              * 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization</span><br><span class=\"line\">              * 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化</span><br><span class=\"line\">            */</span><br><span class=\"line\">            registerBeanPostProcessors(beanFactory);</span><br><span class=\"line\"></span><br><span class=\"line\">            // Initialize message source for this context.</span><br><span class=\"line\">            initMessageSource();</span><br><span class=\"line\"></span><br><span class=\"line\">            // 初始化当前 ApplicationContext 的事件广播器</span><br><span class=\"line\">            initApplicationEventMulticaster();</span><br><span class=\"line\"></span><br><span class=\"line\">            /** 从方法名就可以知道，典型的模板方法(钩子方法)，</span><br><span class=\"line\">              * 具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前）</span><br><span class=\"line\">            */</span><br><span class=\"line\">            onRefresh();</span><br><span class=\"line\"></span><br><span class=\"line\">            // 注册事件监听器，监听器需要实现 ApplicationListener 接口</span><br><span class=\"line\">            registerListeners();</span><br><span class=\"line\"></span><br><span class=\"line\">            // 重点，重点，重点</span><br><span class=\"line\">            // 初始化所有的  singleton beans</span><br><span class=\"line\">            //（lazy-init 的除外）</span><br><span class=\"line\">            /** &lt;bean id=&quot;testBean&quot; class=&quot;cn.itcast.test.TestBean&quot; /&gt;</span><br><span class=\"line\">              * 该bean默认的设置为:</span><br><span class=\"line\">              * &lt;bean id=&quot;testBean&quot; calss=&quot;cn.itcast.test.TestBean&quot; lazy-init=&quot;false&quot; /&gt;</span><br><span class=\"line\">              * lazy-init=&quot;false&quot;</span><br><span class=\"line\">              * 立即加载，表示在spring启动时，立刻进行实例化。</span><br><span class=\"line\">            */</span><br><span class=\"line\">            finishBeanFactoryInitialization(beanFactory);</span><br><span class=\"line\"></span><br><span class=\"line\">            // 最后，广播事件，ApplicationContext 初始化完成</span><br><span class=\"line\">            finishRefresh();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        catch (BeansException ex) &#123;</span><br><span class=\"line\">            logger.warn(&quot;Exception encountered during context initialization - cancelling refresh attempt&quot;, ex);</span><br><span class=\"line\"></span><br><span class=\"line\">            // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源</span><br><span class=\"line\">            destroyBeans();</span><br><span class=\"line\"></span><br><span class=\"line\">            // Reset &apos;active&apos; flag.</span><br><span class=\"line\">            cancelRefresh(ex);</span><br><span class=\"line\"></span><br><span class=\"line\">            // 把异常往外抛</span><br><span class=\"line\">            throw ex;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-注册BeanDefinition\"><a href=\"#2-注册BeanDefinition\" class=\"headerlink\" title=\"2. 注册BeanDefinition\"></a>2. 注册BeanDefinition</h3><p><img src=\"/2020/12/28/2020-12-28-spring启动过程/beanDefination.png\" alt=\"ApplicationContext\"></p>\n<ol>\n<li>注册BeanDefinition方法：ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();</li>\n<li>需要被描述为 bean definitions 的配置对象主要分为如下几大类，<ul>\n<li>xml-based，解析 xml beans 的情况；</li>\n<li>使用 @Autowired、@Required 注解注入 beans 的解析情况；<ul>\n<li>需要特殊处理并解析的元素 <a href=\"context:annotation-config/\" target=\"_blank\" rel=\"noopener\">context:annotation-config/</a></li>\n</ul>\n</li>\n<li>使用 @Component、@Service、@Repository，@Beans 注解注入 beans 的解析情况；<ul>\n<li>需要特殊处理并解析的元素 <a href=\"context:annotation-scan/\" target=\"_blank\" rel=\"noopener\">context:annotation-scan/</a></li>\n<li>解析当前的 .class 字节码，解析出对应的 annotation，比如 @Service，然后生成beanDefinition</li>\n<li>还需为注解类生成beanName</li>\n</ul>\n</li>\n<li>@Controller注解，内部有@Component</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"2-1、xml-based类型配置的注册\"><a href=\"#2-1、xml-based类型配置的注册\" class=\"headerlink\" title=\"2.1、xml-based类型配置的注册\"></a>2.1、xml-based类型配置的注册</h4><p>处理<bean>标签</bean></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;bean id=&quot;threadPool&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>解析bean标签入口DefaultBeanDefinitionDocumentReader#processBeanDefinition</li>\n<li>实际实现由XmlBeanDefinitionReader去解析XML文件</li>\n<li>BeanDefinitionParserDelegate解析Bean标签，创建beanDefinition,解析bean标签属性及子标签设置到beanDefinition中</li>\n<li>最后生成beanDefinitionMap&lt;beanName,beanDefinition&gt;和beanDefinitionNames，然后放入到容器内</li>\n</ol>\n<h4 id=\"2-2、-Component等注解的注册\"><a href=\"#2-2、-Component等注解的注册\" class=\"headerlink\" title=\"2.2、@Component等注解的注册\"></a>2.2、@Component等注解的注册</h4><ol>\n<li>需要配置：&lt;context:component-scan</li>\n<li>component-scan标签的前缀是context,这种带有前缀的标签叫做自定义标签，自定义标签的解析流程如下：<ul>\n<li>首先找到自定义标签的前缀对应的namespaceUri –&gt; xmlns:context=”<a href=\"http://www.springframework.org/schema/context&quot;\" target=\"_blank\" rel=\"noopener\">http://www.springframework.org/schema/context&quot;</a></li>\n<li>在META-INF文件夹内的spring.handlers文件中配置有该namespaceUri对应的处理类 –&gt; http://<a href=\"http://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler\" target=\"_blank\" rel=\"noopener\">www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler</a></li>\n<li>DefaultBeanDefinitionDocumentReader#parseBeanDefinitions  –&gt; delegate.parseCustomElement(ele)</li>\n<li>component-scan元素的处理类为ComponentScanBeanDefinitionParser</li>\n<li></li>\n</ul>\n</li>\n</ol>\n<p>通过 @Component、@Service 注解的方式注入的 bean 往往没有配置 bean name，所以往往需要通过程序的方式自行生成相应的 bean name，看看内部的源码，如何生成 bean name 的，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * 因为通过 @Component、@Serivce 等注解的方式不会像 xml-based 配置那样提供了一个 name 的标签，可以指定 bean name；所以，这里需要去单独为其生成一个；</span><br><span class=\"line\"> */</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public String generateBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) &#123;</span><br><span class=\"line\">   if (definition instanceof AnnotatedBeanDefinition) &#123;</span><br><span class=\"line\">      String beanName = determineBeanNameFromAnnotation((AnnotatedBeanDefinition) definition); // 处理诸如 @Service(&quot;dogService&quot;) 的情况</span><br><span class=\"line\">      if (StringUtils.hasText(beanName)) &#123;</span><br><span class=\"line\">         // Explicit bean name found.</span><br><span class=\"line\">         return beanName;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   // Fallback: generate a unique default bean name. 里面的实现逻辑就是通过将 Class Name 的首字母大写编程小写，然后返回；</span><br><span class=\"line\">   return buildDefaultBeanName(definition, registry);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>ComponentScanBeanDefinitionParser.parse()</li>\n<li></li>\n</ul>\n<h4 id=\"2-3、BeanDefinition包含属性\"><a href=\"#2-3、BeanDefinition包含属性\" class=\"headerlink\" title=\"2.3、BeanDefinition包含属性\"></a>2.3、BeanDefinition包含属性</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;bean id=&quot;abstractDataSource&quot; name=&quot;aliasName&quot;class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot; abstract=&quot;true&quot;  lazy-init=&quot;true&quot;&gt;</span><br><span class=\"line\">    &lt;!-- 配置初始化大小、最小、最大 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;initialSize&quot; value=&quot;2&quot; /&gt;</span><br><span class=\"line\">    &lt;property name=&quot;minIdle&quot; value=&quot;2&quot; /&gt;</span><br><span class=\"line\">    &lt;property name=&quot;maxActive&quot; value=&quot;5&quot; /&gt;\t</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure>\n\n<p>以上面代码为例：id, class名称，property属性, init-method, 别名, 是否懒加载</p>\n<ul>\n<li>init-method：初始化方法名，</li>\n<li>name：别名，spring通过一个map保存BeanDefinition信息，key=beanName，value=BeanDefinition； -&gt; beanDefinitionMap<br>spring有一个别名映射map，例如beanName=张三，aliasName=小三，那么在aliasMap中添加一个键值对，key=张三，value=小三<br>通过别名获取时，需要重定向一次。</li>\n</ul>\n<p><a href=\"https://www.shangyang.me/2017/04/07/spring-core-container-sourcecode-analysis-register-bean-definitions/\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n<h4 id=\"2-4、-解析自定义标签\"><a href=\"#2-4、-解析自定义标签\" class=\"headerlink\" title=\"2.4、 解析自定义标签\"></a>2.4、 解析自定义标签</h4><ol>\n<li>生成标签解析器handler(在init方法中添加parser类)</li>\n<li>在spring.handlers文件配置</li>\n<li>创建对应标签的parser解析器</li>\n</ol>\n<h3 id=\"3-prepareBeanFactory\"><a href=\"#3-prepareBeanFactory\" class=\"headerlink\" title=\"3. prepareBeanFactory\"></a>3. prepareBeanFactory</h3><ul>\n<li>为工厂设置类的加载器、表达式解析器、属性编辑器注册器等</li>\n<li>为工厂添加后处理器、要忽略的依赖接口</li>\n<li>在工厂中注册可解析的依赖</li>\n<li>在工厂中提前注册一些单例Bean</li>\n</ul>\n<h3 id=\"4-beanFactory后置处理器\"><a href=\"#4-beanFactory后置处理器\" class=\"headerlink\" title=\"4. beanFactory后置处理器\"></a>4. beanFactory后置处理器</h3><p>spring的一个重要扩展点：例如可以手动注册一下BeanDefinition，修改或者是移除一些BeanDefinition</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//实例化并调用所有已注册的 BeanFactoryPostProcessor</span><br><span class=\"line\">//调用BeanFactoryPostProcessor各个实现类的 postProcessBeanFactory(factory) 方法</span><br><span class=\"line\">invokeBeanFactoryPostProcessors(beanFactory);</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>实例化 + 调用执行</li>\n<li>BeanFactoryPostProcessor：主要的操作对象是beanFactory</li>\n<li>BeanFactoryRegistryPostProcessor：主要的操作对象是BeanDefinition</li>\n</ul>\n<h3 id=\"5-bean后置处理器\"><a href=\"#5-bean后置处理器\" class=\"headerlink\" title=\"5. bean后置处理器\"></a>5. bean后置处理器</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//注册</span><br><span class=\"line\">1. registerBeanPostProcessors(beanFactory);</span><br><span class=\"line\">//从bean工厂中找到所有实现BeanPostProcessor接口的类</span><br><span class=\"line\">2. String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);</span><br><span class=\"line\">//实例化</span><br><span class=\"line\">3. BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>实例化并注册BeanPostProcessors<ul>\n<li>注册AutowiredAnnotationBeanPostProcessor</li>\n<li>注册CommonAnnotationBeanPostProcessor</li>\n</ul>\n</li>\n<li>注意：BeanPostProcessor此时未执行，执行时间是在bean初始化时，初始化之前调用postProcessBeforeInitialization，<br> 初始化之后postProcessAfterInitialization</li>\n</ol>\n<h3 id=\"6-bean实例化和初始化\"><a href=\"#6-bean实例化和初始化\" class=\"headerlink\" title=\"6. bean实例化和初始化\"></a>6. bean实例化和初始化</h3><ol start=\"0\">\n<li>有一写bean已经实例化了，例如BFPP, BPP</li>\n<li>实例初始化方法：finishBeanFactoryInitialization(beanFactory);</li>\n<li>遍历beanDefinitionNames，对beanDefinition进行实例化和初始化；AbstractBeanFactory.doGetBean()<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames);</span><br><span class=\"line\">// Trigger initialization of all non-lazy singleton beans...</span><br><span class=\"line\">for (String beanName : beanNames) &#123;</span><br><span class=\"line\">    getBean(beanName);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<blockquote>\n<p>BeanFactory与FactoryBean的区别？</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 两个都可以用来创建对象</span><br><span class=\"line\">2. BeanFactory需要严格遵守SpringBean的生命周期，从实例化、初始化等等，流程复杂</span><br><span class=\"line\">3. 所以引入了FactoryBean，快捷的创建，会创建两个对象，</span><br><span class=\"line\">    1. 一个继承FactoryBean的类，由Spring创建，交给Spring管理，会在一级缓存中管理（singletonObjects)</span><br><span class=\"line\">    2. 另外一个是实际对象，由FactoryBean创建，也交给Spring管理，会在factoryBeanObjectCache缓存中</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>实例化阶段</p>\n</blockquote>\n<p>getBean() -&gt; doGetBean()</p>\n<ul>\n<li><p>Object sharedInstance = getSingleton(beanName);</p>\n<ul>\n<li>首先从缓存中获取（三级缓存）</li>\n</ul>\n</li>\n<li><p>缓存不存在，如果原型模式下存在循环依赖，抛出异常</p>\n</li>\n<li><p>进入创建环节</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public Object getObject() throws BeansException &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            //函数式</span><br><span class=\"line\">            return createBean(beanName, mbd, args);</span><br><span class=\"line\">        &#125; catch (BeansException ex) &#123;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">标记</span><br><span class=\"line\">getSingleton() -&gt; beforeSingletonCreation() -&gt; this.singletonsCurrentlyInCreation.add(beanName)，将当前bean加入到正在创建的map内</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>createBean()创建环节</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">createBean()&#123;</span><br><span class=\"line\">    1. mbd.prepareMethodOverrides()；//lookup-method重写，cglib生成代理对象</span><br><span class=\"line\">    //Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.</span><br><span class=\"line\">    //给BeanPostProcessors一个机会来返回代理来替代真正的实例，AOP</span><br><span class=\"line\">    2. resolveBeforeInstantiation() &#123;</span><br><span class=\"line\">        //调用BeanPostProcessor的postProcessBeforeInstantiation方法，进行</span><br><span class=\"line\">        for (BeanPostProcessor bp : getBeanPostProcessors()) &#123;</span><br><span class=\"line\">            ibp.postProcessBeforeInstantiation()</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    3. doCreateBean() &#123;</span><br><span class=\"line\">        //instanceWrapper，bean实例的一个封装对象</span><br><span class=\"line\">        if (instanceWrapper == null) &#123;</span><br><span class=\"line\">            //根据执行bean使用对应的策略创建新的实例，如：工厂方法，构造函数主动注入，简单实例化</span><br><span class=\"line\">            instanceWrapper = createBeanInstance(beanName, mbd, args);</span><br><span class=\"line\">            createBeanInstance() &#123;</span><br><span class=\"line\">                Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName);</span><br><span class=\"line\">                if (mbd.getFactoryMethodName() != null)  &#123;</span><br><span class=\"line\">                    //自定义bean工厂方式生成bean实例</span><br><span class=\"line\">                    return instantiateUsingFactoryMethod(beanName, mbd, args);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                //选择构造器，@Autowired注解，可以在构造器、方法、字段上注入</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //bean创建后，BeanPostProcessor后置处理</span><br><span class=\"line\">        applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);</span><br><span class=\"line\">        //早期暴露，解决循环依赖</span><br><span class=\"line\">        boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName));</span><br><span class=\"line\">        if (earlySingletonExposure) &#123;</span><br><span class=\"line\">            if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">                logger.debug(&quot;Eagerly caching bean &apos;&quot; + beanName +</span><br><span class=\"line\">                        &quot;&apos; to allow for resolving potential circular references&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            //初始化之前将创建实例的objectFactory添加到工厂中，解决后期代理问题</span><br><span class=\"line\">            addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123;</span><br><span class=\"line\">                @Override</span><br><span class=\"line\">                public Object getObject() throws BeansException &#123;</span><br><span class=\"line\">                    return getEarlyBeanReference(beanName, mbd, bean);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>单例bean引用原型bean，通过 lookup-method 解决</p>\n<ul>\n<li>原型：scope=”prototype”，每次请求都会创建新的bean</li>\n</ul>\n</li>\n<li><p>创建bean方式</p>\n<ul>\n<li>factory-method=”create”，配置工厂（静态或者是实例，静态static）</li>\n<li>factoryBean</li>\n<li>BeanFactory</li>\n<li>反射</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>填充阶段</p>\n</blockquote>\n<ul>\n<li>@Autowired和@Inject都是按照类型注入，使用后置处理器进行实例化注入（AutowiredAnnotationBeanPostProcessor）、</li>\n<li>@Resource按名称注入</li>\n</ul>\n<blockquote>\n<p>初始化阶段</p>\n</blockquote>\n<ol>\n<li>执行Aware接口对应的方法</li>\n<li>执行BPP的before的初始化方法</li>\n<li>调用执行init-method方法<ol>\n<li>实现了InitializingBean接口之后调用afterPropertiesSet方法</li>\n<li>调用执行用户自定义初始化方法：init-method方法</li>\n</ol>\n</li>\n<li>执行BPP的after的初始化方法，实际进行<strong>AOP代理</strong></li>\n</ol>\n<blockquote>\n<p>InitializingBean接口</p>\n</blockquote>\n<p>spring的加载bean的源码类(AbstractAutowireCapableBeanFactory)可以看到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void invokeInitMethods(String beanName, final Object bean, RootBeanDefinition mbd)</span><br><span class=\"line\">            throws Throwable &#123;</span><br><span class=\"line\">//判断该bean是否实现了实现了InitializingBean接口，如果实现了InitializingBean接口，则调用bean的afterPropertiesSet方法</span><br><span class=\"line\">        boolean isInitializingBean = (bean instanceof InitializingBean);</span><br><span class=\"line\">        if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(&quot;afterPropertiesSet&quot;))) &#123;</span><br><span class=\"line\">            if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">                logger.debug(&quot;Invoking afterPropertiesSet() on bean with name &apos;&quot; + beanName + &quot;&apos;&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (System.getSecurityManager() != null) &#123;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Object&gt;() &#123;</span><br><span class=\"line\">                        public Object run() throws Exception &#123;</span><br><span class=\"line\">                            //调用afterPropertiesSet</span><br><span class=\"line\">                            ((InitializingBean) bean).afterPropertiesSet();</span><br><span class=\"line\">                            return null;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;, getAccessControlContext());</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                catch (PrivilegedActionException pae) &#123;</span><br><span class=\"line\">                    throw pae.getException();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            else &#123;</span><br><span class=\"line\">                //调用afterPropertiesSet</span><br><span class=\"line\">                ((InitializingBean) bean).afterPropertiesSet();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (mbd != null) &#123;            //判断是否指定了init-method方法，如果指定了init-method方法，则再调用制定的init-method</span><br><span class=\"line\">            String initMethodName = mbd.getInitMethodName();</span><br><span class=\"line\">            if (initMethodName != null &amp;&amp; !(isInitializingBean &amp;&amp; &quot;afterPropertiesSet&quot;.equals(initMethodName)) &amp;&amp;</span><br><span class=\"line\">                    !mbd.isExternallyManagedInitMethod(initMethodName)) &#123;</span><br><span class=\"line\">                //反射调用init-method方法</span><br><span class=\"line\">                invokeCustomInitMethod(beanName, bean, mbd);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>1：spring为bean提供了两种初始化bean的方式，实现InitializingBean接口，实现afterPropertiesSet方法，或者在配置文件中同过init-method指定，两种方式可以同时使用</li>\n<li>2：实现InitializingBean接口是直接调用afterPropertiesSet方法，比通过反射调用init-method指定的方法效率相对来说要高点。但是init-method方式消除了对spring的依赖</li>\n<li>3：如果调用afterPropertiesSet方法时出错，则不调用init-method指定的方法。</li>\n</ul>\n<blockquote>\n<p>循环依赖</p>\n</blockquote>\n<p>A-B;B-&gt;A</p>\n<ol>\n<li>一级缓存：singletonObjects<ul>\n<li>步骤3：将B放入一级缓存，将A放入一级缓存，清除三级</li>\n</ul>\n</li>\n<li>二级缓存：earlySingletonObjects<ul>\n<li>步骤2：发现循环依赖时，将A放入二级缓存，清除三级</li>\n</ul>\n</li>\n<li>三级缓存：singletonFactories<ul>\n<li>步骤1：存入时机：实例化后，将ObjectFactory放入三级缓存</li>\n<li>在获取具体对象的时候，直接生成代理对象，在获取的时候通过lambda表达式中动态生成<br>如果没有代理，只需要二级缓存就可以，所以需要三级缓存。在整个三级缓存中，对象仅能存在一份。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"四、bean的生命周期\"><a href=\"#四、bean的生命周期\" class=\"headerlink\" title=\"四、bean的生命周期\"></a>四、bean的生命周期</h1><ol>\n<li>读取配置，生成beanDefinition，放入beanDefinitionMap<ul>\n<li>AOP对象的beanDefinition也会此时生成，AspectjAwareAdvisorAutoProxyCreator</li>\n</ul>\n</li>\n<li>实例化和执行BeanFactoryPostProcessor(BFPP)，可以修改或者引入其他的beanDefinition，BFPP操作的对象是BeanFactory.<ul>\n<li>ConfigurationClassPostProcessor：用来对相关注解的解析工作</li>\n</ul>\n</li>\n<li>registerBeanPostProcessor，注册BeanPostProcess并且实例化，用于实例化时调用before和after接口</li>\n<li>实例化对象，createBeanInstance<ul>\n<li>在一个对象创建之前，必须先把AOP需要的对象提前准备好，因为无法预估哪些对象需要动态代理</li>\n<li>实例化之前：<ul>\n<li>哪个步骤可以提前实例化并且生成对应的对象，resolveBeforeInstantiation() -&gt; BPP.before()</li>\n<li>AOP的相关对象创建好</li>\n</ul>\n</li>\n<li>创建方式<ul>\n<li>factoryMethod，通过工厂方法</li>\n<li>通过反射创建</li>\n<li>代理方式</li>\n</ul>\n</li>\n<li>实例化之后</li>\n</ul>\n</li>\n<li>填充属性，populateBean<ul>\n<li>会创建依赖的对象</li>\n</ul>\n</li>\n<li>初始化<br> *. 执行Aware接口对应的方法<br> *. 执行BPP的before的初始化方法<br> *. 调用执行init-method方法<pre><code>1. 实现了InitializingBean接口之后调用afterPropertiesSet方法\n2. 调用执行用户自定义初始化方法：init-method方法</code></pre> *. 执行after的初始化方法，AOP</li>\n</ol>\n<h1 id=\"五、import标签\"><a href=\"#五、import标签\" class=\"headerlink\" title=\"五、import标签\"></a>五、import标签</h1><ul>\n<li>Spring IOC容器初使化的时候会调用AbstractApplicationContext 的refresh方法</li>\n<li>在refresh里会调用各种BeanFactoryPostProcessor， 其中就包括我们需要关注的ConfigurationClassPostProcessor。</li>\n<li>ConfigurationClassPostProcessor 不但用于处理@Configuration注解，里面也有处理@Import注解。</li>\n<li>最终的处理是通过 ConfigurationClassParser 这个类完成对Import各种情况的处理</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"一、核心\"><a href=\"#一、核心\" class=\"headerlink\" title=\"一、核心\"></a>一、核心</h1><p>spring两大核心，IOC依赖注入和AOP面向切面编程。</p>\n<h1 id=\"二、容器\"><a href=\"#二、容器\" class=\"headerlink\" title=\"二、容器\"></a>二、容器</h1><p>想要启动spring，需要创建一个ApplicationContext容器，该容器是spring的核心。</p>\n<p>ApplicationContext类组织结构：<br><img src=\"/2020/12/28/2020-12-28-spring启动过程/ApplicationContext.png\" alt=\"ApplicationContext\"></p>","more":"<p>ApplicationContext实质上也是BeanFactory工厂。</p>\n<ul>\n<li>几种实现方式<ul>\n<li>ConfigurableApplicationContext：是比较上层的一个接口，该接口也是比较重要的一个接口，几乎所有的应用上下文都实现了该接口。该接口在ApplicationContext的基础上提供了配置应用上下文的能力，此外提供了生命周期的控制能力</li>\n<li>ClassPathXmlApplicationContext：它是从类的根路径下加载配置文件</li>\n<li>FileSystemXmlApplicationContext： 它是从磁盘路径上加载配置文件，配置文件可以在磁盘的任意位置。</li>\n<li>AnnotationConfigApplicationContext: 当我们使用注解配置容器对象时，需要使用此类来创建 spring 容器。它用来读取注解</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"三、容器启动过程\"><a href=\"#三、容器启动过程\" class=\"headerlink\" title=\"三、容器启动过程\"></a>三、容器启动过程</h1><blockquote>\n<p>方式1：通过反射方式</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Class&lt;?&gt; applicationContextClass = classLoader.loadClass(&quot;org.springframework.context.support.ClassPathXmlApplicationContext&quot;);</span><br><span class=\"line\">Constructor&lt;?&gt; constructor = applicationContextClass.getConstructor(String[].class);</span><br><span class=\"line\">Object springContext = constructor.newInstance(new Object[] &#123; springConfigPathArray &#125;);</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>方式2：new</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ApplicationContext context = new ClassPathXmlApplicationContext(&quot;classpath:applicationfile.xml&quot;);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-1、容器创建过程\"><a href=\"#3-1、容器创建过程\" class=\"headerlink\" title=\"3.1、容器创建过程\"></a>3.1、容器创建过程</h2><p>用ClassPathXmlApplicationContext解析，在实例化过程中，会调用refresh()方法，进行容器的创建及一系列操作。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123;</span><br><span class=\"line\">    super(parent);</span><br><span class=\"line\">    // 解析xml配置文件列表</span><br><span class=\"line\">    setConfigLocations(configLocations);</span><br><span class=\"line\">    if (refresh) &#123;</span><br><span class=\"line\">        //核心方法</span><br><span class=\"line\">        refresh();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1-refresh-方法\"><a href=\"#1-refresh-方法\" class=\"headerlink\" title=\"1. refresh()方法\"></a>1. refresh()方法</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void refresh() throws BeansException, IllegalStateException &#123;</span><br><span class=\"line\">    synchronized (this.startupShutdownMonitor) &#123;</span><br><span class=\"line\">        // 准备工作，记录下容器的启动时间、标记已启动状态、处理配置文件中的占位符</span><br><span class=\"line\">        prepareRefresh();</span><br><span class=\"line\">        </span><br><span class=\"line\">        /** 这步完成后，配置文件就会解析成一个个BeanDefinition，注册到BeanFactory 中，</span><br><span class=\"line\">          * 当然，这里说的 Bean 还没有初始化，只是配置信息都提取出来了，</span><br><span class=\"line\">          * 注册也只是将这些信息都保存到了注册中心(说到底核心是一个beanName-&gt;beanDefinition的map)</span><br><span class=\"line\">        */</span><br><span class=\"line\">        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();</span><br><span class=\"line\">        </span><br><span class=\"line\">        // 设置BeanFactory的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean</span><br><span class=\"line\">        prepareBeanFactory(beanFactory);</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            /**【这里需要知道BeanFactoryPostProcessor这个知识点，Bean如果实现了此接口，</span><br><span class=\"line\">              * 那么在容器初始化以后，Spring会负责调用里面的postProcessBeanFactory 方法。】</span><br><span class=\"line\">              * 这里是提供给子类的扩展点，到这里的时候，所有的Bean都加载、注册完成了，但是都还没有初始化</span><br><span class=\"line\">              * 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事</span><br><span class=\"line\">            */</span><br><span class=\"line\">            postProcessBeanFactory(beanFactory);</span><br><span class=\"line\"></span><br><span class=\"line\">            // 调用BeanFactoryPostProcessor各个实现类的 postProcessBeanFactory(factory) 方法</span><br><span class=\"line\">            invokeBeanFactoryPostProcessors(beanFactory);</span><br><span class=\"line\"></span><br><span class=\"line\">            /** 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别</span><br><span class=\"line\">              * 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization</span><br><span class=\"line\">              * 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化</span><br><span class=\"line\">            */</span><br><span class=\"line\">            registerBeanPostProcessors(beanFactory);</span><br><span class=\"line\"></span><br><span class=\"line\">            // Initialize message source for this context.</span><br><span class=\"line\">            initMessageSource();</span><br><span class=\"line\"></span><br><span class=\"line\">            // 初始化当前 ApplicationContext 的事件广播器</span><br><span class=\"line\">            initApplicationEventMulticaster();</span><br><span class=\"line\"></span><br><span class=\"line\">            /** 从方法名就可以知道，典型的模板方法(钩子方法)，</span><br><span class=\"line\">              * 具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前）</span><br><span class=\"line\">            */</span><br><span class=\"line\">            onRefresh();</span><br><span class=\"line\"></span><br><span class=\"line\">            // 注册事件监听器，监听器需要实现 ApplicationListener 接口</span><br><span class=\"line\">            registerListeners();</span><br><span class=\"line\"></span><br><span class=\"line\">            // 重点，重点，重点</span><br><span class=\"line\">            // 初始化所有的  singleton beans</span><br><span class=\"line\">            //（lazy-init 的除外）</span><br><span class=\"line\">            /** &lt;bean id=&quot;testBean&quot; class=&quot;cn.itcast.test.TestBean&quot; /&gt;</span><br><span class=\"line\">              * 该bean默认的设置为:</span><br><span class=\"line\">              * &lt;bean id=&quot;testBean&quot; calss=&quot;cn.itcast.test.TestBean&quot; lazy-init=&quot;false&quot; /&gt;</span><br><span class=\"line\">              * lazy-init=&quot;false&quot;</span><br><span class=\"line\">              * 立即加载，表示在spring启动时，立刻进行实例化。</span><br><span class=\"line\">            */</span><br><span class=\"line\">            finishBeanFactoryInitialization(beanFactory);</span><br><span class=\"line\"></span><br><span class=\"line\">            // 最后，广播事件，ApplicationContext 初始化完成</span><br><span class=\"line\">            finishRefresh();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        catch (BeansException ex) &#123;</span><br><span class=\"line\">            logger.warn(&quot;Exception encountered during context initialization - cancelling refresh attempt&quot;, ex);</span><br><span class=\"line\"></span><br><span class=\"line\">            // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源</span><br><span class=\"line\">            destroyBeans();</span><br><span class=\"line\"></span><br><span class=\"line\">            // Reset &apos;active&apos; flag.</span><br><span class=\"line\">            cancelRefresh(ex);</span><br><span class=\"line\"></span><br><span class=\"line\">            // 把异常往外抛</span><br><span class=\"line\">            throw ex;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-注册BeanDefinition\"><a href=\"#2-注册BeanDefinition\" class=\"headerlink\" title=\"2. 注册BeanDefinition\"></a>2. 注册BeanDefinition</h3><p><img src=\"/2020/12/28/2020-12-28-spring启动过程/beanDefination.png\" alt=\"ApplicationContext\"></p>\n<ol>\n<li>注册BeanDefinition方法：ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();</li>\n<li>需要被描述为 bean definitions 的配置对象主要分为如下几大类，<ul>\n<li>xml-based，解析 xml beans 的情况；</li>\n<li>使用 @Autowired、@Required 注解注入 beans 的解析情况；<ul>\n<li>需要特殊处理并解析的元素 <a href=\"context:annotation-config/\" target=\"_blank\" rel=\"noopener\">context:annotation-config/</a></li>\n</ul>\n</li>\n<li>使用 @Component、@Service、@Repository，@Beans 注解注入 beans 的解析情况；<ul>\n<li>需要特殊处理并解析的元素 <a href=\"context:annotation-scan/\" target=\"_blank\" rel=\"noopener\">context:annotation-scan/</a></li>\n<li>解析当前的 .class 字节码，解析出对应的 annotation，比如 @Service，然后生成beanDefinition</li>\n<li>还需为注解类生成beanName</li>\n</ul>\n</li>\n<li>@Controller注解，内部有@Component</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"2-1、xml-based类型配置的注册\"><a href=\"#2-1、xml-based类型配置的注册\" class=\"headerlink\" title=\"2.1、xml-based类型配置的注册\"></a>2.1、xml-based类型配置的注册</h4><p>处理<bean>标签</bean></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;bean id=&quot;threadPool&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt;</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>解析bean标签入口DefaultBeanDefinitionDocumentReader#processBeanDefinition</li>\n<li>实际实现由XmlBeanDefinitionReader去解析XML文件</li>\n<li>BeanDefinitionParserDelegate解析Bean标签，创建beanDefinition,解析bean标签属性及子标签设置到beanDefinition中</li>\n<li>最后生成beanDefinitionMap&lt;beanName,beanDefinition&gt;和beanDefinitionNames，然后放入到容器内</li>\n</ol>\n<h4 id=\"2-2、-Component等注解的注册\"><a href=\"#2-2、-Component等注解的注册\" class=\"headerlink\" title=\"2.2、@Component等注解的注册\"></a>2.2、@Component等注解的注册</h4><ol>\n<li>需要配置：&lt;context:component-scan</li>\n<li>component-scan标签的前缀是context,这种带有前缀的标签叫做自定义标签，自定义标签的解析流程如下：<ul>\n<li>首先找到自定义标签的前缀对应的namespaceUri –&gt; xmlns:context=”<a href=\"http://www.springframework.org/schema/context&quot;\" target=\"_blank\" rel=\"noopener\">http://www.springframework.org/schema/context&quot;</a></li>\n<li>在META-INF文件夹内的spring.handlers文件中配置有该namespaceUri对应的处理类 –&gt; http://<a href=\"http://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler\" target=\"_blank\" rel=\"noopener\">www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler</a></li>\n<li>DefaultBeanDefinitionDocumentReader#parseBeanDefinitions  –&gt; delegate.parseCustomElement(ele)</li>\n<li>component-scan元素的处理类为ComponentScanBeanDefinitionParser</li>\n<li></li>\n</ul>\n</li>\n</ol>\n<p>通过 @Component、@Service 注解的方式注入的 bean 往往没有配置 bean name，所以往往需要通过程序的方式自行生成相应的 bean name，看看内部的源码，如何生成 bean name 的，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * 因为通过 @Component、@Serivce 等注解的方式不会像 xml-based 配置那样提供了一个 name 的标签，可以指定 bean name；所以，这里需要去单独为其生成一个；</span><br><span class=\"line\"> */</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public String generateBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) &#123;</span><br><span class=\"line\">   if (definition instanceof AnnotatedBeanDefinition) &#123;</span><br><span class=\"line\">      String beanName = determineBeanNameFromAnnotation((AnnotatedBeanDefinition) definition); // 处理诸如 @Service(&quot;dogService&quot;) 的情况</span><br><span class=\"line\">      if (StringUtils.hasText(beanName)) &#123;</span><br><span class=\"line\">         // Explicit bean name found.</span><br><span class=\"line\">         return beanName;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   // Fallback: generate a unique default bean name. 里面的实现逻辑就是通过将 Class Name 的首字母大写编程小写，然后返回；</span><br><span class=\"line\">   return buildDefaultBeanName(definition, registry);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>ComponentScanBeanDefinitionParser.parse()</li>\n<li></li>\n</ul>\n<h4 id=\"2-3、BeanDefinition包含属性\"><a href=\"#2-3、BeanDefinition包含属性\" class=\"headerlink\" title=\"2.3、BeanDefinition包含属性\"></a>2.3、BeanDefinition包含属性</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;bean id=&quot;abstractDataSource&quot; name=&quot;aliasName&quot;class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot; abstract=&quot;true&quot;  lazy-init=&quot;true&quot;&gt;</span><br><span class=\"line\">    &lt;!-- 配置初始化大小、最小、最大 --&gt;</span><br><span class=\"line\">    &lt;property name=&quot;initialSize&quot; value=&quot;2&quot; /&gt;</span><br><span class=\"line\">    &lt;property name=&quot;minIdle&quot; value=&quot;2&quot; /&gt;</span><br><span class=\"line\">    &lt;property name=&quot;maxActive&quot; value=&quot;5&quot; /&gt;\t</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure>\n\n<p>以上面代码为例：id, class名称，property属性, init-method, 别名, 是否懒加载</p>\n<ul>\n<li>init-method：初始化方法名，</li>\n<li>name：别名，spring通过一个map保存BeanDefinition信息，key=beanName，value=BeanDefinition； -&gt; beanDefinitionMap<br>spring有一个别名映射map，例如beanName=张三，aliasName=小三，那么在aliasMap中添加一个键值对，key=张三，value=小三<br>通过别名获取时，需要重定向一次。</li>\n</ul>\n<p><a href=\"https://www.shangyang.me/2017/04/07/spring-core-container-sourcecode-analysis-register-bean-definitions/\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n<h4 id=\"2-4、-解析自定义标签\"><a href=\"#2-4、-解析自定义标签\" class=\"headerlink\" title=\"2.4、 解析自定义标签\"></a>2.4、 解析自定义标签</h4><ol>\n<li>生成标签解析器handler(在init方法中添加parser类)</li>\n<li>在spring.handlers文件配置</li>\n<li>创建对应标签的parser解析器</li>\n</ol>\n<h3 id=\"3-prepareBeanFactory\"><a href=\"#3-prepareBeanFactory\" class=\"headerlink\" title=\"3. prepareBeanFactory\"></a>3. prepareBeanFactory</h3><ul>\n<li>为工厂设置类的加载器、表达式解析器、属性编辑器注册器等</li>\n<li>为工厂添加后处理器、要忽略的依赖接口</li>\n<li>在工厂中注册可解析的依赖</li>\n<li>在工厂中提前注册一些单例Bean</li>\n</ul>\n<h3 id=\"4-beanFactory后置处理器\"><a href=\"#4-beanFactory后置处理器\" class=\"headerlink\" title=\"4. beanFactory后置处理器\"></a>4. beanFactory后置处理器</h3><p>spring的一个重要扩展点：例如可以手动注册一下BeanDefinition，修改或者是移除一些BeanDefinition</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//实例化并调用所有已注册的 BeanFactoryPostProcessor</span><br><span class=\"line\">//调用BeanFactoryPostProcessor各个实现类的 postProcessBeanFactory(factory) 方法</span><br><span class=\"line\">invokeBeanFactoryPostProcessors(beanFactory);</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>实例化 + 调用执行</li>\n<li>BeanFactoryPostProcessor：主要的操作对象是beanFactory</li>\n<li>BeanFactoryRegistryPostProcessor：主要的操作对象是BeanDefinition</li>\n</ul>\n<h3 id=\"5-bean后置处理器\"><a href=\"#5-bean后置处理器\" class=\"headerlink\" title=\"5. bean后置处理器\"></a>5. bean后置处理器</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//注册</span><br><span class=\"line\">1. registerBeanPostProcessors(beanFactory);</span><br><span class=\"line\">//从bean工厂中找到所有实现BeanPostProcessor接口的类</span><br><span class=\"line\">2. String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);</span><br><span class=\"line\">//实例化</span><br><span class=\"line\">3. BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>实例化并注册BeanPostProcessors<ul>\n<li>注册AutowiredAnnotationBeanPostProcessor</li>\n<li>注册CommonAnnotationBeanPostProcessor</li>\n</ul>\n</li>\n<li>注意：BeanPostProcessor此时未执行，执行时间是在bean初始化时，初始化之前调用postProcessBeforeInitialization，<br> 初始化之后postProcessAfterInitialization</li>\n</ol>\n<h3 id=\"6-bean实例化和初始化\"><a href=\"#6-bean实例化和初始化\" class=\"headerlink\" title=\"6. bean实例化和初始化\"></a>6. bean实例化和初始化</h3><ol start=\"0\">\n<li>有一写bean已经实例化了，例如BFPP, BPP</li>\n<li>实例初始化方法：finishBeanFactoryInitialization(beanFactory);</li>\n<li>遍历beanDefinitionNames，对beanDefinition进行实例化和初始化；AbstractBeanFactory.doGetBean()<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames);</span><br><span class=\"line\">// Trigger initialization of all non-lazy singleton beans...</span><br><span class=\"line\">for (String beanName : beanNames) &#123;</span><br><span class=\"line\">    getBean(beanName);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<blockquote>\n<p>BeanFactory与FactoryBean的区别？</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1. 两个都可以用来创建对象</span><br><span class=\"line\">2. BeanFactory需要严格遵守SpringBean的生命周期，从实例化、初始化等等，流程复杂</span><br><span class=\"line\">3. 所以引入了FactoryBean，快捷的创建，会创建两个对象，</span><br><span class=\"line\">    1. 一个继承FactoryBean的类，由Spring创建，交给Spring管理，会在一级缓存中管理（singletonObjects)</span><br><span class=\"line\">    2. 另外一个是实际对象，由FactoryBean创建，也交给Spring管理，会在factoryBeanObjectCache缓存中</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>实例化阶段</p>\n</blockquote>\n<p>getBean() -&gt; doGetBean()</p>\n<ul>\n<li><p>Object sharedInstance = getSingleton(beanName);</p>\n<ul>\n<li>首先从缓存中获取（三级缓存）</li>\n</ul>\n</li>\n<li><p>缓存不存在，如果原型模式下存在循环依赖，抛出异常</p>\n</li>\n<li><p>进入创建环节</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public Object getObject() throws BeansException &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            //函数式</span><br><span class=\"line\">            return createBean(beanName, mbd, args);</span><br><span class=\"line\">        &#125; catch (BeansException ex) &#123;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">标记</span><br><span class=\"line\">getSingleton() -&gt; beforeSingletonCreation() -&gt; this.singletonsCurrentlyInCreation.add(beanName)，将当前bean加入到正在创建的map内</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>createBean()创建环节</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">createBean()&#123;</span><br><span class=\"line\">    1. mbd.prepareMethodOverrides()；//lookup-method重写，cglib生成代理对象</span><br><span class=\"line\">    //Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.</span><br><span class=\"line\">    //给BeanPostProcessors一个机会来返回代理来替代真正的实例，AOP</span><br><span class=\"line\">    2. resolveBeforeInstantiation() &#123;</span><br><span class=\"line\">        //调用BeanPostProcessor的postProcessBeforeInstantiation方法，进行</span><br><span class=\"line\">        for (BeanPostProcessor bp : getBeanPostProcessors()) &#123;</span><br><span class=\"line\">            ibp.postProcessBeforeInstantiation()</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    3. doCreateBean() &#123;</span><br><span class=\"line\">        //instanceWrapper，bean实例的一个封装对象</span><br><span class=\"line\">        if (instanceWrapper == null) &#123;</span><br><span class=\"line\">            //根据执行bean使用对应的策略创建新的实例，如：工厂方法，构造函数主动注入，简单实例化</span><br><span class=\"line\">            instanceWrapper = createBeanInstance(beanName, mbd, args);</span><br><span class=\"line\">            createBeanInstance() &#123;</span><br><span class=\"line\">                Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName);</span><br><span class=\"line\">                if (mbd.getFactoryMethodName() != null)  &#123;</span><br><span class=\"line\">                    //自定义bean工厂方式生成bean实例</span><br><span class=\"line\">                    return instantiateUsingFactoryMethod(beanName, mbd, args);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                //选择构造器，@Autowired注解，可以在构造器、方法、字段上注入</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //bean创建后，BeanPostProcessor后置处理</span><br><span class=\"line\">        applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);</span><br><span class=\"line\">        //早期暴露，解决循环依赖</span><br><span class=\"line\">        boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName));</span><br><span class=\"line\">        if (earlySingletonExposure) &#123;</span><br><span class=\"line\">            if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">                logger.debug(&quot;Eagerly caching bean &apos;&quot; + beanName +</span><br><span class=\"line\">                        &quot;&apos; to allow for resolving potential circular references&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            //初始化之前将创建实例的objectFactory添加到工厂中，解决后期代理问题</span><br><span class=\"line\">            addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123;</span><br><span class=\"line\">                @Override</span><br><span class=\"line\">                public Object getObject() throws BeansException &#123;</span><br><span class=\"line\">                    return getEarlyBeanReference(beanName, mbd, bean);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>单例bean引用原型bean，通过 lookup-method 解决</p>\n<ul>\n<li>原型：scope=”prototype”，每次请求都会创建新的bean</li>\n</ul>\n</li>\n<li><p>创建bean方式</p>\n<ul>\n<li>factory-method=”create”，配置工厂（静态或者是实例，静态static）</li>\n<li>factoryBean</li>\n<li>BeanFactory</li>\n<li>反射</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>填充阶段</p>\n</blockquote>\n<ul>\n<li>@Autowired和@Inject都是按照类型注入，使用后置处理器进行实例化注入（AutowiredAnnotationBeanPostProcessor）、</li>\n<li>@Resource按名称注入</li>\n</ul>\n<blockquote>\n<p>初始化阶段</p>\n</blockquote>\n<ol>\n<li>执行Aware接口对应的方法</li>\n<li>执行BPP的before的初始化方法</li>\n<li>调用执行init-method方法<ol>\n<li>实现了InitializingBean接口之后调用afterPropertiesSet方法</li>\n<li>调用执行用户自定义初始化方法：init-method方法</li>\n</ol>\n</li>\n<li>执行BPP的after的初始化方法，实际进行<strong>AOP代理</strong></li>\n</ol>\n<blockquote>\n<p>InitializingBean接口</p>\n</blockquote>\n<p>spring的加载bean的源码类(AbstractAutowireCapableBeanFactory)可以看到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected void invokeInitMethods(String beanName, final Object bean, RootBeanDefinition mbd)</span><br><span class=\"line\">            throws Throwable &#123;</span><br><span class=\"line\">//判断该bean是否实现了实现了InitializingBean接口，如果实现了InitializingBean接口，则调用bean的afterPropertiesSet方法</span><br><span class=\"line\">        boolean isInitializingBean = (bean instanceof InitializingBean);</span><br><span class=\"line\">        if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(&quot;afterPropertiesSet&quot;))) &#123;</span><br><span class=\"line\">            if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">                logger.debug(&quot;Invoking afterPropertiesSet() on bean with name &apos;&quot; + beanName + &quot;&apos;&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (System.getSecurityManager() != null) &#123;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Object&gt;() &#123;</span><br><span class=\"line\">                        public Object run() throws Exception &#123;</span><br><span class=\"line\">                            //调用afterPropertiesSet</span><br><span class=\"line\">                            ((InitializingBean) bean).afterPropertiesSet();</span><br><span class=\"line\">                            return null;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;, getAccessControlContext());</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                catch (PrivilegedActionException pae) &#123;</span><br><span class=\"line\">                    throw pae.getException();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            else &#123;</span><br><span class=\"line\">                //调用afterPropertiesSet</span><br><span class=\"line\">                ((InitializingBean) bean).afterPropertiesSet();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (mbd != null) &#123;            //判断是否指定了init-method方法，如果指定了init-method方法，则再调用制定的init-method</span><br><span class=\"line\">            String initMethodName = mbd.getInitMethodName();</span><br><span class=\"line\">            if (initMethodName != null &amp;&amp; !(isInitializingBean &amp;&amp; &quot;afterPropertiesSet&quot;.equals(initMethodName)) &amp;&amp;</span><br><span class=\"line\">                    !mbd.isExternallyManagedInitMethod(initMethodName)) &#123;</span><br><span class=\"line\">                //反射调用init-method方法</span><br><span class=\"line\">                invokeCustomInitMethod(beanName, bean, mbd);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>1：spring为bean提供了两种初始化bean的方式，实现InitializingBean接口，实现afterPropertiesSet方法，或者在配置文件中同过init-method指定，两种方式可以同时使用</li>\n<li>2：实现InitializingBean接口是直接调用afterPropertiesSet方法，比通过反射调用init-method指定的方法效率相对来说要高点。但是init-method方式消除了对spring的依赖</li>\n<li>3：如果调用afterPropertiesSet方法时出错，则不调用init-method指定的方法。</li>\n</ul>\n<blockquote>\n<p>循环依赖</p>\n</blockquote>\n<p>A-B;B-&gt;A</p>\n<ol>\n<li>一级缓存：singletonObjects<ul>\n<li>步骤3：将B放入一级缓存，将A放入一级缓存，清除三级</li>\n</ul>\n</li>\n<li>二级缓存：earlySingletonObjects<ul>\n<li>步骤2：发现循环依赖时，将A放入二级缓存，清除三级</li>\n</ul>\n</li>\n<li>三级缓存：singletonFactories<ul>\n<li>步骤1：存入时机：实例化后，将ObjectFactory放入三级缓存</li>\n<li>在获取具体对象的时候，直接生成代理对象，在获取的时候通过lambda表达式中动态生成<br>如果没有代理，只需要二级缓存就可以，所以需要三级缓存。在整个三级缓存中，对象仅能存在一份。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"四、bean的生命周期\"><a href=\"#四、bean的生命周期\" class=\"headerlink\" title=\"四、bean的生命周期\"></a>四、bean的生命周期</h1><ol>\n<li>读取配置，生成beanDefinition，放入beanDefinitionMap<ul>\n<li>AOP对象的beanDefinition也会此时生成，AspectjAwareAdvisorAutoProxyCreator</li>\n</ul>\n</li>\n<li>实例化和执行BeanFactoryPostProcessor(BFPP)，可以修改或者引入其他的beanDefinition，BFPP操作的对象是BeanFactory.<ul>\n<li>ConfigurationClassPostProcessor：用来对相关注解的解析工作</li>\n</ul>\n</li>\n<li>registerBeanPostProcessor，注册BeanPostProcess并且实例化，用于实例化时调用before和after接口</li>\n<li>实例化对象，createBeanInstance<ul>\n<li>在一个对象创建之前，必须先把AOP需要的对象提前准备好，因为无法预估哪些对象需要动态代理</li>\n<li>实例化之前：<ul>\n<li>哪个步骤可以提前实例化并且生成对应的对象，resolveBeforeInstantiation() -&gt; BPP.before()</li>\n<li>AOP的相关对象创建好</li>\n</ul>\n</li>\n<li>创建方式<ul>\n<li>factoryMethod，通过工厂方法</li>\n<li>通过反射创建</li>\n<li>代理方式</li>\n</ul>\n</li>\n<li>实例化之后</li>\n</ul>\n</li>\n<li>填充属性，populateBean<ul>\n<li>会创建依赖的对象</li>\n</ul>\n</li>\n<li>初始化<br> *. 执行Aware接口对应的方法<br> *. 执行BPP的before的初始化方法<br> *. 调用执行init-method方法<pre><code>1. 实现了InitializingBean接口之后调用afterPropertiesSet方法\n2. 调用执行用户自定义初始化方法：init-method方法</code></pre> *. 执行after的初始化方法，AOP</li>\n</ol>\n<h1 id=\"五、import标签\"><a href=\"#五、import标签\" class=\"headerlink\" title=\"五、import标签\"></a>五、import标签</h1><ul>\n<li>Spring IOC容器初使化的时候会调用AbstractApplicationContext 的refresh方法</li>\n<li>在refresh里会调用各种BeanFactoryPostProcessor， 其中就包括我们需要关注的ConfigurationClassPostProcessor。</li>\n<li>ConfigurationClassPostProcessor 不但用于处理@Configuration注解，里面也有处理@Import注解。</li>\n<li>最终的处理是通过 ConfigurationClassParser 这个类完成对Import各种情况的处理</li>\n</ul>"},{"title":"《架构》三层架构演化到DDD","date":"2024-09-13T02:00:00.000Z","_content":"\n### 一、三层架构的问题\n尽管三层架构有其优点，在处理复杂业务时，三层架构也可能面临一些问题。具体有：\n- **业务逻辑分散：** 在三层架构中，业务逻辑往往分散在不同的层中，导致业务流程难以理清，影响了代码的可读性和可维护性。\n- **领域模型贫血：** 三层架构中，领域逻辑和数据存储混合在一起，导致领域模型的业务方法受限，难以表达复杂的业务规则。\n- **过度依赖数据存储：** 不同层之间对数据存储的依赖紧密，当切换数据存储介质时，需要大量修改代码。\n\n<!--more-->\n\n旧代码结构示例：        \n![传统分层代码结构](2024-09-13-架构-三层架构的演进到DDD/传统分层代码结构.png)\n随着业务的不断复杂化，service层变得越来越庞大，服务之间的引用也变得越来越混乱，这为项目带来了风险和不确定性。\n\n### 二、三层架构演化到DDD\n通过如下方法，将DDD思想融入现有的三层架构中，以实现更高内聚、更低耦合的代码架构。\n- **领域的划分：** DDD将service层按业务场景划分成不同的领域，每个领域内包含实体、值对象、聚合根等元素。\n- **内聚的领域：** 在领域内，业务尽量内聚，避免领域之间的耦合。每个领域内部可以根据需要建立更细粒度的子域，进一步提高内聚性。\n- **应用层的组合：** 引入一个Application层，将领域内的service组合调用，形成业务服务，避免服务之间直接引用，降低耦合度。\n\n经过我们的修改，三层架构可以（组合和聚合）演进到右侧架构模式，通过这种方式，我们能够更好地组织和管理代码，实现领域内高内聚低耦合的目标。\n![三层架构到DDD](2024-09-13-架构-三层架构的演进到DDD/三层架构到DDD.png)\n\n包结构如下：\n![DDD包结构](2024-09-13-架构-三层架构的演进到DDD/DDD包结构.png)\n\n展开包结构如下：\n![DDD包结构展开](2024-09-13-架构-三层架构的演进到DDD/DDD包结构展开.png)\n\n> Tips：阿里内部很多项目都是以DDD分层结构为模板进行构建的。\n\n参考文章：\n[领域驱动设计(DDD): 三层架构到DDD架构演化](https://juejin.cn/post/7270393208776785960)         \n[DDD领域驱动设计落地实践](https://www.cnblogs.com/dennyzhangdd/p/14376904.html#_label1_0)     \n[DDD落地：从阿里商品域，看DDD在大厂如何落地？](https://www.cnblogs.com/crazymakercircle/p/17897418.html#autoid-h3-6-1-0)       \n[DDD领域驱动设计](https://juejin.cn/post/7171064476366536741#heading-25)","source":"_posts/2024-09-13-架构-三层架构的演进到DDD.md","raw":"---\ntitle: 《架构》三层架构演化到DDD\ndate: 2024-09-13 10:00:00\ncategories:\n  - [架构, DDD]\n---\n\n### 一、三层架构的问题\n尽管三层架构有其优点，在处理复杂业务时，三层架构也可能面临一些问题。具体有：\n- **业务逻辑分散：** 在三层架构中，业务逻辑往往分散在不同的层中，导致业务流程难以理清，影响了代码的可读性和可维护性。\n- **领域模型贫血：** 三层架构中，领域逻辑和数据存储混合在一起，导致领域模型的业务方法受限，难以表达复杂的业务规则。\n- **过度依赖数据存储：** 不同层之间对数据存储的依赖紧密，当切换数据存储介质时，需要大量修改代码。\n\n<!--more-->\n\n旧代码结构示例：        \n![传统分层代码结构](2024-09-13-架构-三层架构的演进到DDD/传统分层代码结构.png)\n随着业务的不断复杂化，service层变得越来越庞大，服务之间的引用也变得越来越混乱，这为项目带来了风险和不确定性。\n\n### 二、三层架构演化到DDD\n通过如下方法，将DDD思想融入现有的三层架构中，以实现更高内聚、更低耦合的代码架构。\n- **领域的划分：** DDD将service层按业务场景划分成不同的领域，每个领域内包含实体、值对象、聚合根等元素。\n- **内聚的领域：** 在领域内，业务尽量内聚，避免领域之间的耦合。每个领域内部可以根据需要建立更细粒度的子域，进一步提高内聚性。\n- **应用层的组合：** 引入一个Application层，将领域内的service组合调用，形成业务服务，避免服务之间直接引用，降低耦合度。\n\n经过我们的修改，三层架构可以（组合和聚合）演进到右侧架构模式，通过这种方式，我们能够更好地组织和管理代码，实现领域内高内聚低耦合的目标。\n![三层架构到DDD](2024-09-13-架构-三层架构的演进到DDD/三层架构到DDD.png)\n\n包结构如下：\n![DDD包结构](2024-09-13-架构-三层架构的演进到DDD/DDD包结构.png)\n\n展开包结构如下：\n![DDD包结构展开](2024-09-13-架构-三层架构的演进到DDD/DDD包结构展开.png)\n\n> Tips：阿里内部很多项目都是以DDD分层结构为模板进行构建的。\n\n参考文章：\n[领域驱动设计(DDD): 三层架构到DDD架构演化](https://juejin.cn/post/7270393208776785960)         \n[DDD领域驱动设计落地实践](https://www.cnblogs.com/dennyzhangdd/p/14376904.html#_label1_0)     \n[DDD落地：从阿里商品域，看DDD在大厂如何落地？](https://www.cnblogs.com/crazymakercircle/p/17897418.html#autoid-h3-6-1-0)       \n[DDD领域驱动设计](https://juejin.cn/post/7171064476366536741#heading-25)","slug":"2024-09-13-架构-三层架构的演进到DDD","published":1,"updated":"2024-12-06T08:33:25.288Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyh005ya13kwvbyypp4","content":"<h3 id=\"一、三层架构的问题\"><a href=\"#一、三层架构的问题\" class=\"headerlink\" title=\"一、三层架构的问题\"></a>一、三层架构的问题</h3><p>尽管三层架构有其优点，在处理复杂业务时，三层架构也可能面临一些问题。具体有：</p>\n<ul>\n<li><strong>业务逻辑分散：</strong> 在三层架构中，业务逻辑往往分散在不同的层中，导致业务流程难以理清，影响了代码的可读性和可维护性。</li>\n<li><strong>领域模型贫血：</strong> 三层架构中，领域逻辑和数据存储混合在一起，导致领域模型的业务方法受限，难以表达复杂的业务规则。</li>\n<li><strong>过度依赖数据存储：</strong> 不同层之间对数据存储的依赖紧密，当切换数据存储介质时，需要大量修改代码。</li>\n</ul>\n<a id=\"more\"></a>\n\n<p>旧代码结构示例：<br><img src=\"/2024/09/13/2024-09-13-架构-三层架构的演进到DDD/%E4%BC%A0%E7%BB%9F%E5%88%86%E5%B1%82%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84.png\" alt=\"传统分层代码结构\"><br>随着业务的不断复杂化，service层变得越来越庞大，服务之间的引用也变得越来越混乱，这为项目带来了风险和不确定性。</p>\n<h3 id=\"二、三层架构演化到DDD\"><a href=\"#二、三层架构演化到DDD\" class=\"headerlink\" title=\"二、三层架构演化到DDD\"></a>二、三层架构演化到DDD</h3><p>通过如下方法，将DDD思想融入现有的三层架构中，以实现更高内聚、更低耦合的代码架构。</p>\n<ul>\n<li><strong>领域的划分：</strong> DDD将service层按业务场景划分成不同的领域，每个领域内包含实体、值对象、聚合根等元素。</li>\n<li><strong>内聚的领域：</strong> 在领域内，业务尽量内聚，避免领域之间的耦合。每个领域内部可以根据需要建立更细粒度的子域，进一步提高内聚性。</li>\n<li><strong>应用层的组合：</strong> 引入一个Application层，将领域内的service组合调用，形成业务服务，避免服务之间直接引用，降低耦合度。</li>\n</ul>\n<p>经过我们的修改，三层架构可以（组合和聚合）演进到右侧架构模式，通过这种方式，我们能够更好地组织和管理代码，实现领域内高内聚低耦合的目标。<br><img src=\"/2024/09/13/2024-09-13-架构-三层架构的演进到DDD/%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84%E5%88%B0DDD.png\" alt=\"三层架构到DDD\"></p>\n<p>包结构如下：<br><img src=\"/2024/09/13/2024-09-13-架构-三层架构的演进到DDD/DDD%E5%8C%85%E7%BB%93%E6%9E%84.png\" alt=\"DDD包结构\"></p>\n<p>展开包结构如下：<br><img src=\"/2024/09/13/2024-09-13-架构-三层架构的演进到DDD/DDD%E5%8C%85%E7%BB%93%E6%9E%84%E5%B1%95%E5%BC%80.png\" alt=\"DDD包结构展开\"></p>\n<blockquote>\n<p>Tips：阿里内部很多项目都是以DDD分层结构为模板进行构建的。</p>\n</blockquote>\n<p>参考文章：<br><a href=\"https://juejin.cn/post/7270393208776785960\" target=\"_blank\" rel=\"noopener\">领域驱动设计(DDD): 三层架构到DDD架构演化</a><br><a href=\"https://www.cnblogs.com/dennyzhangdd/p/14376904.html#_label1_0\" target=\"_blank\" rel=\"noopener\">DDD领域驱动设计落地实践</a><br><a href=\"https://www.cnblogs.com/crazymakercircle/p/17897418.html#autoid-h3-6-1-0\" target=\"_blank\" rel=\"noopener\">DDD落地：从阿里商品域，看DDD在大厂如何落地？</a><br><a href=\"https://juejin.cn/post/7171064476366536741#heading-25\" target=\"_blank\" rel=\"noopener\">DDD领域驱动设计</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、三层架构的问题\"><a href=\"#一、三层架构的问题\" class=\"headerlink\" title=\"一、三层架构的问题\"></a>一、三层架构的问题</h3><p>尽管三层架构有其优点，在处理复杂业务时，三层架构也可能面临一些问题。具体有：</p>\n<ul>\n<li><strong>业务逻辑分散：</strong> 在三层架构中，业务逻辑往往分散在不同的层中，导致业务流程难以理清，影响了代码的可读性和可维护性。</li>\n<li><strong>领域模型贫血：</strong> 三层架构中，领域逻辑和数据存储混合在一起，导致领域模型的业务方法受限，难以表达复杂的业务规则。</li>\n<li><strong>过度依赖数据存储：</strong> 不同层之间对数据存储的依赖紧密，当切换数据存储介质时，需要大量修改代码。</li>\n</ul>","more":"<p>旧代码结构示例：<br><img src=\"/2024/09/13/2024-09-13-架构-三层架构的演进到DDD/%E4%BC%A0%E7%BB%9F%E5%88%86%E5%B1%82%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84.png\" alt=\"传统分层代码结构\"><br>随着业务的不断复杂化，service层变得越来越庞大，服务之间的引用也变得越来越混乱，这为项目带来了风险和不确定性。</p>\n<h3 id=\"二、三层架构演化到DDD\"><a href=\"#二、三层架构演化到DDD\" class=\"headerlink\" title=\"二、三层架构演化到DDD\"></a>二、三层架构演化到DDD</h3><p>通过如下方法，将DDD思想融入现有的三层架构中，以实现更高内聚、更低耦合的代码架构。</p>\n<ul>\n<li><strong>领域的划分：</strong> DDD将service层按业务场景划分成不同的领域，每个领域内包含实体、值对象、聚合根等元素。</li>\n<li><strong>内聚的领域：</strong> 在领域内，业务尽量内聚，避免领域之间的耦合。每个领域内部可以根据需要建立更细粒度的子域，进一步提高内聚性。</li>\n<li><strong>应用层的组合：</strong> 引入一个Application层，将领域内的service组合调用，形成业务服务，避免服务之间直接引用，降低耦合度。</li>\n</ul>\n<p>经过我们的修改，三层架构可以（组合和聚合）演进到右侧架构模式，通过这种方式，我们能够更好地组织和管理代码，实现领域内高内聚低耦合的目标。<br><img src=\"/2024/09/13/2024-09-13-架构-三层架构的演进到DDD/%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84%E5%88%B0DDD.png\" alt=\"三层架构到DDD\"></p>\n<p>包结构如下：<br><img src=\"/2024/09/13/2024-09-13-架构-三层架构的演进到DDD/DDD%E5%8C%85%E7%BB%93%E6%9E%84.png\" alt=\"DDD包结构\"></p>\n<p>展开包结构如下：<br><img src=\"/2024/09/13/2024-09-13-架构-三层架构的演进到DDD/DDD%E5%8C%85%E7%BB%93%E6%9E%84%E5%B1%95%E5%BC%80.png\" alt=\"DDD包结构展开\"></p>\n<blockquote>\n<p>Tips：阿里内部很多项目都是以DDD分层结构为模板进行构建的。</p>\n</blockquote>\n<p>参考文章：<br><a href=\"https://juejin.cn/post/7270393208776785960\" target=\"_blank\" rel=\"noopener\">领域驱动设计(DDD): 三层架构到DDD架构演化</a><br><a href=\"https://www.cnblogs.com/dennyzhangdd/p/14376904.html#_label1_0\" target=\"_blank\" rel=\"noopener\">DDD领域驱动设计落地实践</a><br><a href=\"https://www.cnblogs.com/crazymakercircle/p/17897418.html#autoid-h3-6-1-0\" target=\"_blank\" rel=\"noopener\">DDD落地：从阿里商品域，看DDD在大厂如何落地？</a><br><a href=\"https://juejin.cn/post/7171064476366536741#heading-25\" target=\"_blank\" rel=\"noopener\">DDD领域驱动设计</a></p>"},{"title":"本博客搭建","date":"2018-10-02T03:41:10.000Z","_content":"记录一下搭建过程，备忘。\n\n### 1、安装相应软件\n\n下载和安装 Node.js 和 npm\n如下命令：查看版本号\n```dtd\nnode -v\nnpm -version\n```\n\n### 2、具体流程\n\n基于多人协作\n``` bash\n1、 创建githubname.github.io的仓库。\n2、 创建分支：hexo\n3、 本地创建空文件夹，执行hexo init[将生成_config.yml等文件]，然后将空文件夹内的所有内容复制到本地仓库\n4、 在hexo分支执行hexo g, hexo s。然后访问http://localhost:4000，就可以看见博客\n    4.1、会出现空白页的情况，此时可能是themes未安装next主题\n        解决方法：将主题克隆到 themes/next目录下 \n        git clone https://github.com/iissnan/hexo-theme-next themes/next\n    \n\n注意：githubname必须是github账户的名字\n```\n\n\n\nMore info: [博客搭建详细过程](https://github.com/qiubaiying/qiubaiying.github.io/wiki/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B)\n\n### 3、主题\n\n主题切换\n``` bash\n1、 使用next主题，需要在themes文件夹中将next主题clone下来\n2、 需要配置_config.yml文件: \n    theme: next\n3、 next配置 themes/next/_config.yml\n    本博客主题样式: scheme: Gemini\n    头像: avatar: /images/touxiang.jpg\n    菜单：menu\n \n问题：若hexo g过程中出现 No layout，则执行hexo clean\n```\n\nMore info: [Next主题](http://theme-next.iissnan.com/getting-started.html)\nMore info: [Next具体样式](https://theme-next.iissnan.com/theme-settings.html)\n\n\n### 4、文章创建\n\n方式一\n``` bash\nhexo博客目录下，hexo new \"文章名称\"\n```\n\n方式二\n``` bash\n博客目录下的/source/_posts/，创建新文章md文件\n将相应的图片放到 source\\images目录\n```\n\nMore info: [新文章](https://winney07.github.io/2018/08/02/%E5%9C%A8Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0/)\n\n### 5、文章发布\n\n需要将文章发布至nam.github.io\n``` bash\n1、 配置_config.yml\n    deploy:\n      type: git\n      repo: https://github.com/**/name.github.io.git\n      branch: master\n2、 执行 hexo d\n\n注意：发布路径必须是master\n```\n\nMore info: [发布](https://hexo.io/docs/deployment.html)\n\n\n### 6、本地启动\n\n\n``` bash\nhexo g\nhexo s\n```\n\n### 7、使用时序图\n\n安装插件\n``` bash\n    npm install hexo-tag-plantuml --save\n```\n语法\n``` bash\n    {% plantuml %}\n        Bob->Alice : hello\n    {% endplantuml %} \n```\nMore info: [参考](http://www.zhaiqianfeng.com/2017/05/hexo-plantuml.html)\n### 8、其他设置\n配置首页文章折叠(300个字折叠)\n```dtd\nauto_excerpt:\n  enable: true\n  length: 300\n```\n\n语言设置：\n项目的_config.yml修改配置\n```dtd\nlanguage: zh-Hans\n```\n\n阅读数量统计\n```dtd\nbusuanzi_count:\n    enable:true\n```\n\n### 9、相关问题\n问题1：fatal: 无法访问 'https://github.com...'：Empty reply from server\n    \n    问题原因：\n    解决方案：\n    \n问题2：TypeError [ERR_INVALID_ARG_TYPE]: The \"mode\" argument must be of type number. Received an instance of Object\n    \n    问题原因：node和hexo版本问题\n    解决方案：降低node的版本\n","source":"_posts/本博客搭建.md","raw":"---\ntitle: 本博客搭建\ndate: 2018-10-02 11:41:10\ncategories: hexo\n---\n记录一下搭建过程，备忘。\n\n### 1、安装相应软件\n\n下载和安装 Node.js 和 npm\n如下命令：查看版本号\n```dtd\nnode -v\nnpm -version\n```\n\n### 2、具体流程\n\n基于多人协作\n``` bash\n1、 创建githubname.github.io的仓库。\n2、 创建分支：hexo\n3、 本地创建空文件夹，执行hexo init[将生成_config.yml等文件]，然后将空文件夹内的所有内容复制到本地仓库\n4、 在hexo分支执行hexo g, hexo s。然后访问http://localhost:4000，就可以看见博客\n    4.1、会出现空白页的情况，此时可能是themes未安装next主题\n        解决方法：将主题克隆到 themes/next目录下 \n        git clone https://github.com/iissnan/hexo-theme-next themes/next\n    \n\n注意：githubname必须是github账户的名字\n```\n\n\n\nMore info: [博客搭建详细过程](https://github.com/qiubaiying/qiubaiying.github.io/wiki/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B)\n\n### 3、主题\n\n主题切换\n``` bash\n1、 使用next主题，需要在themes文件夹中将next主题clone下来\n2、 需要配置_config.yml文件: \n    theme: next\n3、 next配置 themes/next/_config.yml\n    本博客主题样式: scheme: Gemini\n    头像: avatar: /images/touxiang.jpg\n    菜单：menu\n \n问题：若hexo g过程中出现 No layout，则执行hexo clean\n```\n\nMore info: [Next主题](http://theme-next.iissnan.com/getting-started.html)\nMore info: [Next具体样式](https://theme-next.iissnan.com/theme-settings.html)\n\n\n### 4、文章创建\n\n方式一\n``` bash\nhexo博客目录下，hexo new \"文章名称\"\n```\n\n方式二\n``` bash\n博客目录下的/source/_posts/，创建新文章md文件\n将相应的图片放到 source\\images目录\n```\n\nMore info: [新文章](https://winney07.github.io/2018/08/02/%E5%9C%A8Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0/)\n\n### 5、文章发布\n\n需要将文章发布至nam.github.io\n``` bash\n1、 配置_config.yml\n    deploy:\n      type: git\n      repo: https://github.com/**/name.github.io.git\n      branch: master\n2、 执行 hexo d\n\n注意：发布路径必须是master\n```\n\nMore info: [发布](https://hexo.io/docs/deployment.html)\n\n\n### 6、本地启动\n\n\n``` bash\nhexo g\nhexo s\n```\n\n### 7、使用时序图\n\n安装插件\n``` bash\n    npm install hexo-tag-plantuml --save\n```\n语法\n``` bash\n    {% plantuml %}\n        Bob->Alice : hello\n    {% endplantuml %} \n```\nMore info: [参考](http://www.zhaiqianfeng.com/2017/05/hexo-plantuml.html)\n### 8、其他设置\n配置首页文章折叠(300个字折叠)\n```dtd\nauto_excerpt:\n  enable: true\n  length: 300\n```\n\n语言设置：\n项目的_config.yml修改配置\n```dtd\nlanguage: zh-Hans\n```\n\n阅读数量统计\n```dtd\nbusuanzi_count:\n    enable:true\n```\n\n### 9、相关问题\n问题1：fatal: 无法访问 'https://github.com...'：Empty reply from server\n    \n    问题原因：\n    解决方案：\n    \n问题2：TypeError [ERR_INVALID_ARG_TYPE]: The \"mode\" argument must be of type number. Received an instance of Object\n    \n    问题原因：node和hexo版本问题\n    解决方案：降低node的版本\n","slug":"本博客搭建","published":1,"updated":"2024-10-17T03:44:51.416Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyi0060a13kkuw45syr","content":"<p>记录一下搭建过程，备忘。</p>\n<h3 id=\"1、安装相应软件\"><a href=\"#1、安装相应软件\" class=\"headerlink\" title=\"1、安装相应软件\"></a>1、安装相应软件</h3><p>下载和安装 Node.js 和 npm<br>如下命令：查看版本号</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node -v</span><br><span class=\"line\">npm -version</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2、具体流程\"><a href=\"#2、具体流程\" class=\"headerlink\" title=\"2、具体流程\"></a>2、具体流程</h3><p>基于多人协作</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、 创建githubname.github.io的仓库。</span><br><span class=\"line\">2、 创建分支：hexo</span><br><span class=\"line\">3、 本地创建空文件夹，执行hexo init[将生成_config.yml等文件]，然后将空文件夹内的所有内容复制到本地仓库</span><br><span class=\"line\">4、 在hexo分支执行hexo g, hexo s。然后访问http://localhost:4000，就可以看见博客</span><br><span class=\"line\">    4.1、会出现空白页的情况，此时可能是themes未安装next主题</span><br><span class=\"line\">        解决方法：将主题克隆到 themes/next目录下 </span><br><span class=\"line\">        git <span class=\"built_in\">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">注意：githubname必须是github账户的名字</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://github.com/qiubaiying/qiubaiying.github.io/wiki/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B\" target=\"_blank\" rel=\"noopener\">博客搭建详细过程</a></p>\n<h3 id=\"3、主题\"><a href=\"#3、主题\" class=\"headerlink\" title=\"3、主题\"></a>3、主题</h3><p>主题切换</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、 使用next主题，需要在themes文件夹中将next主题<span class=\"built_in\">clone</span>下来</span><br><span class=\"line\">2、 需要配置_config.yml文件: </span><br><span class=\"line\">    theme: next</span><br><span class=\"line\">3、 next配置 themes/next/_config.yml</span><br><span class=\"line\">    本博客主题样式: scheme: Gemini</span><br><span class=\"line\">    头像: avatar: /images/touxiang.jpg</span><br><span class=\"line\">    菜单：menu</span><br><span class=\"line\"> </span><br><span class=\"line\">问题：若hexo g过程中出现 No layout，则执行hexo clean</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"noopener\">Next主题</a><br>More info: <a href=\"https://theme-next.iissnan.com/theme-settings.html\" target=\"_blank\" rel=\"noopener\">Next具体样式</a></p>\n<h3 id=\"4、文章创建\"><a href=\"#4、文章创建\" class=\"headerlink\" title=\"4、文章创建\"></a>4、文章创建</h3><p>方式一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo博客目录下，hexo new <span class=\"string\">\"文章名称\"</span></span><br></pre></td></tr></table></figure>\n\n<p>方式二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">博客目录下的/<span class=\"built_in\">source</span>/_posts/，创建新文章md文件</span><br><span class=\"line\">将相应的图片放到 <span class=\"built_in\">source</span>\\images目录</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://winney07.github.io/2018/08/02/%E5%9C%A8Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0/\" target=\"_blank\" rel=\"noopener\">新文章</a></p>\n<h3 id=\"5、文章发布\"><a href=\"#5、文章发布\" class=\"headerlink\" title=\"5、文章发布\"></a>5、文章发布</h3><p>需要将文章发布至nam.github.io</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、 配置_config.yml</span><br><span class=\"line\">    deploy:</span><br><span class=\"line\">      <span class=\"built_in\">type</span>: git</span><br><span class=\"line\">      repo: https://github.com/**/name.github.io.git</span><br><span class=\"line\">      branch: master</span><br><span class=\"line\">2、 执行 hexo d</span><br><span class=\"line\"></span><br><span class=\"line\">注意：发布路径必须是master</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">发布</a></p>\n<h3 id=\"6、本地启动\"><a href=\"#6、本地启动\" class=\"headerlink\" title=\"6、本地启动\"></a>6、本地启动</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g</span><br><span class=\"line\">hexo s</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7、使用时序图\"><a href=\"#7、使用时序图\" class=\"headerlink\" title=\"7、使用时序图\"></a>7、使用时序图</h3><p>安装插件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-tag-plantuml --save</span><br></pre></td></tr></table></figure>\n\n<p>语法</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;% plantuml %&#125;</span><br><span class=\"line\">    Bob-&gt;Alice : hello</span><br><span class=\"line\">&#123;% endplantuml %&#125;</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"http://www.zhaiqianfeng.com/2017/05/hexo-plantuml.html\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n<h3 id=\"8、其他设置\"><a href=\"#8、其他设置\" class=\"headerlink\" title=\"8、其他设置\"></a>8、其他设置</h3><p>配置首页文章折叠(300个字折叠)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto_excerpt:</span><br><span class=\"line\">  enable: true</span><br><span class=\"line\">  length: 300</span><br></pre></td></tr></table></figure>\n\n<p>语言设置：<br>项目的_config.yml修改配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">language: zh-Hans</span><br></pre></td></tr></table></figure>\n\n<p>阅读数量统计</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">busuanzi_count:</span><br><span class=\"line\">    enable:true</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"9、相关问题\"><a href=\"#9、相关问题\" class=\"headerlink\" title=\"9、相关问题\"></a>9、相关问题</h3><p>问题1：fatal: 无法访问 ‘<a href=\"https://github.com...&#39;：Empty\" target=\"_blank\" rel=\"noopener\">https://github.com...&#39;：Empty</a> reply from server</p>\n<pre><code>问题原因：\n解决方案：</code></pre><p>问题2：TypeError [ERR_INVALID_ARG_TYPE]: The “mode” argument must be of type number. Received an instance of Object</p>\n<pre><code>问题原因：node和hexo版本问题\n解决方案：降低node的版本</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>记录一下搭建过程，备忘。</p>\n<h3 id=\"1、安装相应软件\"><a href=\"#1、安装相应软件\" class=\"headerlink\" title=\"1、安装相应软件\"></a>1、安装相应软件</h3><p>下载和安装 Node.js 和 npm<br>如下命令：查看版本号</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node -v</span><br><span class=\"line\">npm -version</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2、具体流程\"><a href=\"#2、具体流程\" class=\"headerlink\" title=\"2、具体流程\"></a>2、具体流程</h3><p>基于多人协作</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、 创建githubname.github.io的仓库。</span><br><span class=\"line\">2、 创建分支：hexo</span><br><span class=\"line\">3、 本地创建空文件夹，执行hexo init[将生成_config.yml等文件]，然后将空文件夹内的所有内容复制到本地仓库</span><br><span class=\"line\">4、 在hexo分支执行hexo g, hexo s。然后访问http://localhost:4000，就可以看见博客</span><br><span class=\"line\">    4.1、会出现空白页的情况，此时可能是themes未安装next主题</span><br><span class=\"line\">        解决方法：将主题克隆到 themes/next目录下 </span><br><span class=\"line\">        git <span class=\"built_in\">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">注意：githubname必须是github账户的名字</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://github.com/qiubaiying/qiubaiying.github.io/wiki/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B\" target=\"_blank\" rel=\"noopener\">博客搭建详细过程</a></p>\n<h3 id=\"3、主题\"><a href=\"#3、主题\" class=\"headerlink\" title=\"3、主题\"></a>3、主题</h3><p>主题切换</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、 使用next主题，需要在themes文件夹中将next主题<span class=\"built_in\">clone</span>下来</span><br><span class=\"line\">2、 需要配置_config.yml文件: </span><br><span class=\"line\">    theme: next</span><br><span class=\"line\">3、 next配置 themes/next/_config.yml</span><br><span class=\"line\">    本博客主题样式: scheme: Gemini</span><br><span class=\"line\">    头像: avatar: /images/touxiang.jpg</span><br><span class=\"line\">    菜单：menu</span><br><span class=\"line\"> </span><br><span class=\"line\">问题：若hexo g过程中出现 No layout，则执行hexo clean</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"noopener\">Next主题</a><br>More info: <a href=\"https://theme-next.iissnan.com/theme-settings.html\" target=\"_blank\" rel=\"noopener\">Next具体样式</a></p>\n<h3 id=\"4、文章创建\"><a href=\"#4、文章创建\" class=\"headerlink\" title=\"4、文章创建\"></a>4、文章创建</h3><p>方式一</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo博客目录下，hexo new <span class=\"string\">\"文章名称\"</span></span><br></pre></td></tr></table></figure>\n\n<p>方式二</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">博客目录下的/<span class=\"built_in\">source</span>/_posts/，创建新文章md文件</span><br><span class=\"line\">将相应的图片放到 <span class=\"built_in\">source</span>\\images目录</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://winney07.github.io/2018/08/02/%E5%9C%A8Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0/\" target=\"_blank\" rel=\"noopener\">新文章</a></p>\n<h3 id=\"5、文章发布\"><a href=\"#5、文章发布\" class=\"headerlink\" title=\"5、文章发布\"></a>5、文章发布</h3><p>需要将文章发布至nam.github.io</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、 配置_config.yml</span><br><span class=\"line\">    deploy:</span><br><span class=\"line\">      <span class=\"built_in\">type</span>: git</span><br><span class=\"line\">      repo: https://github.com/**/name.github.io.git</span><br><span class=\"line\">      branch: master</span><br><span class=\"line\">2、 执行 hexo d</span><br><span class=\"line\"></span><br><span class=\"line\">注意：发布路径必须是master</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">发布</a></p>\n<h3 id=\"6、本地启动\"><a href=\"#6、本地启动\" class=\"headerlink\" title=\"6、本地启动\"></a>6、本地启动</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g</span><br><span class=\"line\">hexo s</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7、使用时序图\"><a href=\"#7、使用时序图\" class=\"headerlink\" title=\"7、使用时序图\"></a>7、使用时序图</h3><p>安装插件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-tag-plantuml --save</span><br></pre></td></tr></table></figure>\n\n<p>语法</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;% plantuml %&#125;</span><br><span class=\"line\">    Bob-&gt;Alice : hello</span><br><span class=\"line\">&#123;% endplantuml %&#125;</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"http://www.zhaiqianfeng.com/2017/05/hexo-plantuml.html\" target=\"_blank\" rel=\"noopener\">参考</a></p>\n<h3 id=\"8、其他设置\"><a href=\"#8、其他设置\" class=\"headerlink\" title=\"8、其他设置\"></a>8、其他设置</h3><p>配置首页文章折叠(300个字折叠)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">auto_excerpt:</span><br><span class=\"line\">  enable: true</span><br><span class=\"line\">  length: 300</span><br></pre></td></tr></table></figure>\n\n<p>语言设置：<br>项目的_config.yml修改配置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">language: zh-Hans</span><br></pre></td></tr></table></figure>\n\n<p>阅读数量统计</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">busuanzi_count:</span><br><span class=\"line\">    enable:true</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"9、相关问题\"><a href=\"#9、相关问题\" class=\"headerlink\" title=\"9、相关问题\"></a>9、相关问题</h3><p>问题1：fatal: 无法访问 ‘<a href=\"https://github.com...&#39;：Empty\" target=\"_blank\" rel=\"noopener\">https://github.com...&#39;：Empty</a> reply from server</p>\n<pre><code>问题原因：\n解决方案：</code></pre><p>问题2：TypeError [ERR_INVALID_ARG_TYPE]: The “mode” argument must be of type number. Received an instance of Object</p>\n<pre><code>问题原因：node和hexo版本问题\n解决方案：降低node的版本</code></pre>"},{"title":"《稳定性》单元化改造示例","date":"2024-07-18T02:00:00.000Z","_content":"\n    这是稳定性系列的第七篇文章，主要介绍的是限购的单元化。\n\n### 一、基础术语\n<style>\ntable th:first-of-type {\n    width: 12%;\n}\ntable th:nth-of-type(2) {\n    width: 70%;\n}\n</style>\n\n\n| 术语            | 含义                                                  |\n|---------------|-----------------------------------------------------|\n| buy           | 下单系统，负责订单生成、资源扣减、支付等。                               |\n| ump           | 统一营销平台，做的就是把这些蓝字在整个交易过程中串联起来，对接交易平台，制定规则，计算并整合优惠结果。 |\n| BBQ           | 限购系统，限购的角度可以分两种，一种是针对于商品限购，一种是针对于订单限购。              |\n| budget-center | 预算系统。                                               |\n\n<!-- more -->\n### 二、业务流程及目标\n- 现状：\n  - buy：已经交易单元化了。\n  - BBQ：限购系统，未做单元化，内部接口的逻辑是调用budget-center的提供的接口（是budget-center的封装层），底层数据存储在budget-center内。\n  - budget-center：预算系统，未做单元化，只有中心服务。\n![现状](2024-07-18-稳定性-单元化改造示例/现状.png)\n- 目标：\n  - BBQ：去掉封装层，buy直接调用budget-center。\n  - budget-center：交易单元化。\n![目标](2024-07-18-稳定性-单元化改造示例/目标.png)\n\n### 三、方案\n![4阶段](2024-07-18-稳定性-单元化改造示例/4阶段.png)\n> 分成4个阶段\n> - 服务准备阶段\n> - 联调测试阶段\n> - 灰度切流阶段\n> - 最终阶段\n\n#### 3.1、服务准备阶段\n服务准备阶段，主要是对业务上下文分析及改造、服务单元化改造、DB单元化改造和tair单元化改造。\n##### 3.1.1、服务单元化改造\n###### 接口改造：\n需要对自己的接口（Java interface）进行标记是什么类型，如果标记为单元路由，目前我们内部的规范是方法的第一个参数为小写的long buyerId，RPC在路由的时候会根据这个值判断用户所在的机房。\n```java\n@HSFProvider(serviceInterface = OrderService.class, writeMode=center, route=0)\npublic class OrderServiceImpl implements OrderService {\n    @Autowired\n    private OrderDAO orderDAO;\n\n    @Override\n    public OrderModel queryOrder(Long buyerId, Long orderId) {\n        return orderDAO.queryOrder(orderId);\n    }\n}\n\nwriteMode： 属性告知 HSF 某个 服务是中心服务（center）还是单元服务（unit）。\nroute：用于路由的用户 ID 参数位于方法签名中的位置，如 route=0 表示方法第一个参数。\n```\n![路由逻辑](2024-07-18-稳定性-单元化改造示例/路由逻辑.png)\n\n##### 3.1.2、业务上下文分析及改造\n推动调用旧接口的业务进行接口切换。\n\n##### 3.1.3、DB单元化改造\n单元化应用目前使用的数据层都是TDDL。 数据层的改造点主要有三方面单元化：\n1. sequence：TDDL需要提供一个sequence组件,根据当前单元的个数生成全局唯一的sequence,这样当单元流量切换时,sequence总是唯一的,不会产生冲突.\n2. 中心化数据源：为了防止数据错写,有些数据源(比如库存)需要保证只在中心单元才能启动.TDDL需要在数据源初始化的时候,判断当前机器的角色与数据源的配置,如果是中心数据源而应用服务器属于单元,则忽略该数据源的启动。\n3. 写保护：数据落库之前的最后一层中间件就是数据层,为了防止错写,TDDL雲要提供一种机制,当单元化数据落库时,检查要落库的数据是否符合当前的路由规则,不符合则拒绝写入。\n4. 存储层：单元化最核心的问题就是数据问题，有2种数据模式：\n   1. unit模式：用户在各自映射的单元写对应的数据，数据会和中心做双向同步;如买家数据\n   2. copy模式：数据在中心写，全量同步到各个单元;如卖家数据\n![数据库层](2024-07-18-稳定性-单元化改造示例/数据库层.png)\n\n\n> 使用unit模式，申请单元DB，然后通过DRC做数据的同步。\n\n##### 3.1.4、tair单元化改造\n![tair单元化](2024-07-18-稳定性-单元化改造示例/tair单元化.png)\n在数据发生变更时，也需要对单元的缓存进行失效;通过 invaild-server 来对单元的缓存进行失效。\n\n> 数据的变更信息，通过 DRC 广播到多个机房，实现缓存的刷新，保证各个机房的缓存一致性。\n\n##### 3.1.5、消息通信层改造\n![消息通信层](2024-07-18-稳定性-单元化改造示例/消息通信层.png)\n实现原则是，尽量保持单元内部消息在内部投递和消费，同时所有消息会路由到中心，保证没有做单元化部署的业务也能接收到消息。把消息投递到准确的单元订阅者。单元1发布的消息，会被单元1的订阅者收到，单元化的应用流量会被均衡分配到每个单元。\n\n#### 3.2、测试联调阶段\n##### 3.2.2、数据一致性保障\n###### 数据库和缓存的数据一致性核对\n通过BCP核对，监听DRC消息后，核对两边的数据一致性。\n###### 中心和单元的数据一致性核对\n![常见的数据一致性方案](2024-07-18-稳定性-单元化改造示例/常见的数据一致性方案.png)\n1. 全量数据比对：一般通过离线表核对。\n2. 增量数据核对：监听binlog mq异步方式去核对。（中间可能需要延迟核对，因为中心&单元之间会有数据延迟）\n\n> 全增结合\n\n##### 3.2.3、监控\n基础监控 & 业务监控的建设。\n\n#### 3.3、灰度切流阶段\n##### 3.3.1、切流方案\n方案类似如下：\n![切流流程](2024-07-18-稳定性-单元化改造示例/切流流程.png)\n\n后续用户的请求就会直接被路由到正确的机房。\n\n\n参考文章：   \n[阿里技术架构演进及过程中遇到的问题](https://juejin.cn/post/7338422591517310991)   \n[饿了么异地多活的数据实施-DRC](https://pic.huodongjia.com/ganhuodocs/2017-08-09/1502263496.67.pdf)    \n[看完这篇异地多活的改造，我决定和架构师battle一下](https://tech.dewu.com/article?id=9)   \n[单元化架构在字节跳动的落地实践](https://www.163.com/dy/article/JFDUC45H0511D3QS.html)    \n[单元化 理论基础 && 实践方案](https://blog.51cto.com/u_6478076/5109051)\n\n\n","source":"_posts/2024-07-18-稳定性-单元化改造示例.md","raw":"---\ntitle: 《稳定性》单元化改造示例\ndate: 2024-07-18 10:00:00\ncategories:\n  - [ 稳定性, 高可用、单元化]\n  - [ 阿里 ]\ntags:\n  - 阿里\n---\n\n    这是稳定性系列的第七篇文章，主要介绍的是限购的单元化。\n\n### 一、基础术语\n<style>\ntable th:first-of-type {\n    width: 12%;\n}\ntable th:nth-of-type(2) {\n    width: 70%;\n}\n</style>\n\n\n| 术语            | 含义                                                  |\n|---------------|-----------------------------------------------------|\n| buy           | 下单系统，负责订单生成、资源扣减、支付等。                               |\n| ump           | 统一营销平台，做的就是把这些蓝字在整个交易过程中串联起来，对接交易平台，制定规则，计算并整合优惠结果。 |\n| BBQ           | 限购系统，限购的角度可以分两种，一种是针对于商品限购，一种是针对于订单限购。              |\n| budget-center | 预算系统。                                               |\n\n<!-- more -->\n### 二、业务流程及目标\n- 现状：\n  - buy：已经交易单元化了。\n  - BBQ：限购系统，未做单元化，内部接口的逻辑是调用budget-center的提供的接口（是budget-center的封装层），底层数据存储在budget-center内。\n  - budget-center：预算系统，未做单元化，只有中心服务。\n![现状](2024-07-18-稳定性-单元化改造示例/现状.png)\n- 目标：\n  - BBQ：去掉封装层，buy直接调用budget-center。\n  - budget-center：交易单元化。\n![目标](2024-07-18-稳定性-单元化改造示例/目标.png)\n\n### 三、方案\n![4阶段](2024-07-18-稳定性-单元化改造示例/4阶段.png)\n> 分成4个阶段\n> - 服务准备阶段\n> - 联调测试阶段\n> - 灰度切流阶段\n> - 最终阶段\n\n#### 3.1、服务准备阶段\n服务准备阶段，主要是对业务上下文分析及改造、服务单元化改造、DB单元化改造和tair单元化改造。\n##### 3.1.1、服务单元化改造\n###### 接口改造：\n需要对自己的接口（Java interface）进行标记是什么类型，如果标记为单元路由，目前我们内部的规范是方法的第一个参数为小写的long buyerId，RPC在路由的时候会根据这个值判断用户所在的机房。\n```java\n@HSFProvider(serviceInterface = OrderService.class, writeMode=center, route=0)\npublic class OrderServiceImpl implements OrderService {\n    @Autowired\n    private OrderDAO orderDAO;\n\n    @Override\n    public OrderModel queryOrder(Long buyerId, Long orderId) {\n        return orderDAO.queryOrder(orderId);\n    }\n}\n\nwriteMode： 属性告知 HSF 某个 服务是中心服务（center）还是单元服务（unit）。\nroute：用于路由的用户 ID 参数位于方法签名中的位置，如 route=0 表示方法第一个参数。\n```\n![路由逻辑](2024-07-18-稳定性-单元化改造示例/路由逻辑.png)\n\n##### 3.1.2、业务上下文分析及改造\n推动调用旧接口的业务进行接口切换。\n\n##### 3.1.3、DB单元化改造\n单元化应用目前使用的数据层都是TDDL。 数据层的改造点主要有三方面单元化：\n1. sequence：TDDL需要提供一个sequence组件,根据当前单元的个数生成全局唯一的sequence,这样当单元流量切换时,sequence总是唯一的,不会产生冲突.\n2. 中心化数据源：为了防止数据错写,有些数据源(比如库存)需要保证只在中心单元才能启动.TDDL需要在数据源初始化的时候,判断当前机器的角色与数据源的配置,如果是中心数据源而应用服务器属于单元,则忽略该数据源的启动。\n3. 写保护：数据落库之前的最后一层中间件就是数据层,为了防止错写,TDDL雲要提供一种机制,当单元化数据落库时,检查要落库的数据是否符合当前的路由规则,不符合则拒绝写入。\n4. 存储层：单元化最核心的问题就是数据问题，有2种数据模式：\n   1. unit模式：用户在各自映射的单元写对应的数据，数据会和中心做双向同步;如买家数据\n   2. copy模式：数据在中心写，全量同步到各个单元;如卖家数据\n![数据库层](2024-07-18-稳定性-单元化改造示例/数据库层.png)\n\n\n> 使用unit模式，申请单元DB，然后通过DRC做数据的同步。\n\n##### 3.1.4、tair单元化改造\n![tair单元化](2024-07-18-稳定性-单元化改造示例/tair单元化.png)\n在数据发生变更时，也需要对单元的缓存进行失效;通过 invaild-server 来对单元的缓存进行失效。\n\n> 数据的变更信息，通过 DRC 广播到多个机房，实现缓存的刷新，保证各个机房的缓存一致性。\n\n##### 3.1.5、消息通信层改造\n![消息通信层](2024-07-18-稳定性-单元化改造示例/消息通信层.png)\n实现原则是，尽量保持单元内部消息在内部投递和消费，同时所有消息会路由到中心，保证没有做单元化部署的业务也能接收到消息。把消息投递到准确的单元订阅者。单元1发布的消息，会被单元1的订阅者收到，单元化的应用流量会被均衡分配到每个单元。\n\n#### 3.2、测试联调阶段\n##### 3.2.2、数据一致性保障\n###### 数据库和缓存的数据一致性核对\n通过BCP核对，监听DRC消息后，核对两边的数据一致性。\n###### 中心和单元的数据一致性核对\n![常见的数据一致性方案](2024-07-18-稳定性-单元化改造示例/常见的数据一致性方案.png)\n1. 全量数据比对：一般通过离线表核对。\n2. 增量数据核对：监听binlog mq异步方式去核对。（中间可能需要延迟核对，因为中心&单元之间会有数据延迟）\n\n> 全增结合\n\n##### 3.2.3、监控\n基础监控 & 业务监控的建设。\n\n#### 3.3、灰度切流阶段\n##### 3.3.1、切流方案\n方案类似如下：\n![切流流程](2024-07-18-稳定性-单元化改造示例/切流流程.png)\n\n后续用户的请求就会直接被路由到正确的机房。\n\n\n参考文章：   \n[阿里技术架构演进及过程中遇到的问题](https://juejin.cn/post/7338422591517310991)   \n[饿了么异地多活的数据实施-DRC](https://pic.huodongjia.com/ganhuodocs/2017-08-09/1502263496.67.pdf)    \n[看完这篇异地多活的改造，我决定和架构师battle一下](https://tech.dewu.com/article?id=9)   \n[单元化架构在字节跳动的落地实践](https://www.163.com/dy/article/JFDUC45H0511D3QS.html)    \n[单元化 理论基础 && 实践方案](https://blog.51cto.com/u_6478076/5109051)\n\n\n","slug":"2024-07-18-稳定性-单元化改造示例","published":1,"updated":"2024-10-31T09:25:44.771Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyj0062a13kxfa6nk1o","content":"<pre><code>这是稳定性系列的第七篇文章，主要介绍的是限购的单元化。</code></pre><h3 id=\"一、基础术语\"><a href=\"#一、基础术语\" class=\"headerlink\" title=\"一、基础术语\"></a>一、基础术语</h3><style>\ntable th:first-of-type {\n    width: 12%;\n}\ntable th:nth-of-type(2) {\n    width: 70%;\n}\n</style>\n\n\n<table>\n<thead>\n<tr>\n<th>术语</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>buy</td>\n<td>下单系统，负责订单生成、资源扣减、支付等。</td>\n</tr>\n<tr>\n<td>ump</td>\n<td>统一营销平台，做的就是把这些蓝字在整个交易过程中串联起来，对接交易平台，制定规则，计算并整合优惠结果。</td>\n</tr>\n<tr>\n<td>BBQ</td>\n<td>限购系统，限购的角度可以分两种，一种是针对于商品限购，一种是针对于订单限购。</td>\n</tr>\n<tr>\n<td>budget-center</td>\n<td>预算系统。</td>\n</tr>\n</tbody></table>\n<a id=\"more\"></a>\n<h3 id=\"二、业务流程及目标\"><a href=\"#二、业务流程及目标\" class=\"headerlink\" title=\"二、业务流程及目标\"></a>二、业务流程及目标</h3><ul>\n<li>现状：<ul>\n<li>buy：已经交易单元化了。</li>\n<li>BBQ：限购系统，未做单元化，内部接口的逻辑是调用budget-center的提供的接口（是budget-center的封装层），底层数据存储在budget-center内。</li>\n<li>budget-center：预算系统，未做单元化，只有中心服务。<br><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E7%8E%B0%E7%8A%B6.png\" alt=\"现状\"></li>\n</ul>\n</li>\n<li>目标：<ul>\n<li>BBQ：去掉封装层，buy直接调用budget-center。</li>\n<li>budget-center：交易单元化。<br><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E7%9B%AE%E6%A0%87.png\" alt=\"目标\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"三、方案\"><a href=\"#三、方案\" class=\"headerlink\" title=\"三、方案\"></a>三、方案</h3><p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/4%E9%98%B6%E6%AE%B5.png\" alt=\"4阶段\"></p>\n<blockquote>\n<p>分成4个阶段</p>\n<ul>\n<li>服务准备阶段</li>\n<li>联调测试阶段</li>\n<li>灰度切流阶段</li>\n<li>最终阶段</li>\n</ul>\n</blockquote>\n<h4 id=\"3-1、服务准备阶段\"><a href=\"#3-1、服务准备阶段\" class=\"headerlink\" title=\"3.1、服务准备阶段\"></a>3.1、服务准备阶段</h4><p>服务准备阶段，主要是对业务上下文分析及改造、服务单元化改造、DB单元化改造和tair单元化改造。</p>\n<h5 id=\"3-1-1、服务单元化改造\"><a href=\"#3-1-1、服务单元化改造\" class=\"headerlink\" title=\"3.1.1、服务单元化改造\"></a>3.1.1、服务单元化改造</h5><h6 id=\"接口改造：\"><a href=\"#接口改造：\" class=\"headerlink\" title=\"接口改造：\"></a>接口改造：</h6><p>需要对自己的接口（Java interface）进行标记是什么类型，如果标记为单元路由，目前我们内部的规范是方法的第一个参数为小写的long buyerId，RPC在路由的时候会根据这个值判断用户所在的机房。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@HSFProvider</span>(serviceInterface = OrderService<span class=\"class\">.<span class=\"keyword\">class</span>, <span class=\"title\">writeMode</span></span>=center, route=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">OrderServiceImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">OrderService</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Autowired</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> OrderDAO orderDAO;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> OrderModel <span class=\"title\">queryOrder</span><span class=\"params\">(Long buyerId, Long orderId)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> orderDAO.queryOrder(orderId);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">writeMode： 属性告知 HSF 某个 服务是中心服务（center）还是单元服务（unit）。</span><br><span class=\"line\">route：用于路由的用户 ID 参数位于方法签名中的位置，如 route=<span class=\"number\">0</span> 表示方法第一个参数。</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E8%B7%AF%E7%94%B1%E9%80%BB%E8%BE%91.png\" alt=\"路由逻辑\"></p>\n<h5 id=\"3-1-2、业务上下文分析及改造\"><a href=\"#3-1-2、业务上下文分析及改造\" class=\"headerlink\" title=\"3.1.2、业务上下文分析及改造\"></a>3.1.2、业务上下文分析及改造</h5><p>推动调用旧接口的业务进行接口切换。</p>\n<h5 id=\"3-1-3、DB单元化改造\"><a href=\"#3-1-3、DB单元化改造\" class=\"headerlink\" title=\"3.1.3、DB单元化改造\"></a>3.1.3、DB单元化改造</h5><p>单元化应用目前使用的数据层都是TDDL。 数据层的改造点主要有三方面单元化：</p>\n<ol>\n<li>sequence：TDDL需要提供一个sequence组件,根据当前单元的个数生成全局唯一的sequence,这样当单元流量切换时,sequence总是唯一的,不会产生冲突.</li>\n<li>中心化数据源：为了防止数据错写,有些数据源(比如库存)需要保证只在中心单元才能启动.TDDL需要在数据源初始化的时候,判断当前机器的角色与数据源的配置,如果是中心数据源而应用服务器属于单元,则忽略该数据源的启动。</li>\n<li>写保护：数据落库之前的最后一层中间件就是数据层,为了防止错写,TDDL雲要提供一种机制,当单元化数据落库时,检查要落库的数据是否符合当前的路由规则,不符合则拒绝写入。</li>\n<li>存储层：单元化最核心的问题就是数据问题，有2种数据模式：<ol>\n<li>unit模式：用户在各自映射的单元写对应的数据，数据会和中心做双向同步;如买家数据</li>\n<li>copy模式：数据在中心写，全量同步到各个单元;如卖家数据<br><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B1%82.png\" alt=\"数据库层\"></li>\n</ol>\n</li>\n</ol>\n<blockquote>\n<p>使用unit模式，申请单元DB，然后通过DRC做数据的同步。</p>\n</blockquote>\n<h5 id=\"3-1-4、tair单元化改造\"><a href=\"#3-1-4、tair单元化改造\" class=\"headerlink\" title=\"3.1.4、tair单元化改造\"></a>3.1.4、tair单元化改造</h5><p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/tair%E5%8D%95%E5%85%83%E5%8C%96.png\" alt=\"tair单元化\"><br>在数据发生变更时，也需要对单元的缓存进行失效;通过 invaild-server 来对单元的缓存进行失效。</p>\n<blockquote>\n<p>数据的变更信息，通过 DRC 广播到多个机房，实现缓存的刷新，保证各个机房的缓存一致性。</p>\n</blockquote>\n<h5 id=\"3-1-5、消息通信层改造\"><a href=\"#3-1-5、消息通信层改造\" class=\"headerlink\" title=\"3.1.5、消息通信层改造\"></a>3.1.5、消息通信层改造</h5><p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E6%B6%88%E6%81%AF%E9%80%9A%E4%BF%A1%E5%B1%82.png\" alt=\"消息通信层\"><br>实现原则是，尽量保持单元内部消息在内部投递和消费，同时所有消息会路由到中心，保证没有做单元化部署的业务也能接收到消息。把消息投递到准确的单元订阅者。单元1发布的消息，会被单元1的订阅者收到，单元化的应用流量会被均衡分配到每个单元。</p>\n<h4 id=\"3-2、测试联调阶段\"><a href=\"#3-2、测试联调阶段\" class=\"headerlink\" title=\"3.2、测试联调阶段\"></a>3.2、测试联调阶段</h4><h5 id=\"3-2-2、数据一致性保障\"><a href=\"#3-2-2、数据一致性保障\" class=\"headerlink\" title=\"3.2.2、数据一致性保障\"></a>3.2.2、数据一致性保障</h5><h6 id=\"数据库和缓存的数据一致性核对\"><a href=\"#数据库和缓存的数据一致性核对\" class=\"headerlink\" title=\"数据库和缓存的数据一致性核对\"></a>数据库和缓存的数据一致性核对</h6><p>通过BCP核对，监听DRC消息后，核对两边的数据一致性。</p>\n<h6 id=\"中心和单元的数据一致性核对\"><a href=\"#中心和单元的数据一致性核对\" class=\"headerlink\" title=\"中心和单元的数据一致性核对\"></a>中心和单元的数据一致性核对</h6><p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E6%96%B9%E6%A1%88.png\" alt=\"常见的数据一致性方案\"></p>\n<ol>\n<li>全量数据比对：一般通过离线表核对。</li>\n<li>增量数据核对：监听binlog mq异步方式去核对。（中间可能需要延迟核对，因为中心&amp;单元之间会有数据延迟）</li>\n</ol>\n<blockquote>\n<p>全增结合</p>\n</blockquote>\n<h5 id=\"3-2-3、监控\"><a href=\"#3-2-3、监控\" class=\"headerlink\" title=\"3.2.3、监控\"></a>3.2.3、监控</h5><p>基础监控 &amp; 业务监控的建设。</p>\n<h4 id=\"3-3、灰度切流阶段\"><a href=\"#3-3、灰度切流阶段\" class=\"headerlink\" title=\"3.3、灰度切流阶段\"></a>3.3、灰度切流阶段</h4><h5 id=\"3-3-1、切流方案\"><a href=\"#3-3-1、切流方案\" class=\"headerlink\" title=\"3.3.1、切流方案\"></a>3.3.1、切流方案</h5><p>方案类似如下：<br><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E5%88%87%E6%B5%81%E6%B5%81%E7%A8%8B.png\" alt=\"切流流程\"></p>\n<p>后续用户的请求就会直接被路由到正确的机房。</p>\n<p>参考文章：<br><a href=\"https://juejin.cn/post/7338422591517310991\" target=\"_blank\" rel=\"noopener\">阿里技术架构演进及过程中遇到的问题</a><br><a href=\"https://pic.huodongjia.com/ganhuodocs/2017-08-09/1502263496.67.pdf\" target=\"_blank\" rel=\"noopener\">饿了么异地多活的数据实施-DRC</a><br><a href=\"https://tech.dewu.com/article?id=9\" target=\"_blank\" rel=\"noopener\">看完这篇异地多活的改造，我决定和架构师battle一下</a><br><a href=\"https://www.163.com/dy/article/JFDUC45H0511D3QS.html\" target=\"_blank\" rel=\"noopener\">单元化架构在字节跳动的落地实践</a><br><a href=\"https://blog.51cto.com/u_6478076/5109051\" target=\"_blank\" rel=\"noopener\">单元化 理论基础 &amp;&amp; 实践方案</a></p>\n","site":{"data":{}},"excerpt":"<pre><code>这是稳定性系列的第七篇文章，主要介绍的是限购的单元化。</code></pre><h3 id=\"一、基础术语\"><a href=\"#一、基础术语\" class=\"headerlink\" title=\"一、基础术语\"></a>一、基础术语</h3><style>\ntable th:first-of-type {\n    width: 12%;\n}\ntable th:nth-of-type(2) {\n    width: 70%;\n}\n</style>\n\n\n<table>\n<thead>\n<tr>\n<th>术语</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>buy</td>\n<td>下单系统，负责订单生成、资源扣减、支付等。</td>\n</tr>\n<tr>\n<td>ump</td>\n<td>统一营销平台，做的就是把这些蓝字在整个交易过程中串联起来，对接交易平台，制定规则，计算并整合优惠结果。</td>\n</tr>\n<tr>\n<td>BBQ</td>\n<td>限购系统，限购的角度可以分两种，一种是针对于商品限购，一种是针对于订单限购。</td>\n</tr>\n<tr>\n<td>budget-center</td>\n<td>预算系统。</td>\n</tr>\n</tbody></table>","more":"<h3 id=\"二、业务流程及目标\"><a href=\"#二、业务流程及目标\" class=\"headerlink\" title=\"二、业务流程及目标\"></a>二、业务流程及目标</h3><ul>\n<li>现状：<ul>\n<li>buy：已经交易单元化了。</li>\n<li>BBQ：限购系统，未做单元化，内部接口的逻辑是调用budget-center的提供的接口（是budget-center的封装层），底层数据存储在budget-center内。</li>\n<li>budget-center：预算系统，未做单元化，只有中心服务。<br><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E7%8E%B0%E7%8A%B6.png\" alt=\"现状\"></li>\n</ul>\n</li>\n<li>目标：<ul>\n<li>BBQ：去掉封装层，buy直接调用budget-center。</li>\n<li>budget-center：交易单元化。<br><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E7%9B%AE%E6%A0%87.png\" alt=\"目标\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"三、方案\"><a href=\"#三、方案\" class=\"headerlink\" title=\"三、方案\"></a>三、方案</h3><p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/4%E9%98%B6%E6%AE%B5.png\" alt=\"4阶段\"></p>\n<blockquote>\n<p>分成4个阶段</p>\n<ul>\n<li>服务准备阶段</li>\n<li>联调测试阶段</li>\n<li>灰度切流阶段</li>\n<li>最终阶段</li>\n</ul>\n</blockquote>\n<h4 id=\"3-1、服务准备阶段\"><a href=\"#3-1、服务准备阶段\" class=\"headerlink\" title=\"3.1、服务准备阶段\"></a>3.1、服务准备阶段</h4><p>服务准备阶段，主要是对业务上下文分析及改造、服务单元化改造、DB单元化改造和tair单元化改造。</p>\n<h5 id=\"3-1-1、服务单元化改造\"><a href=\"#3-1-1、服务单元化改造\" class=\"headerlink\" title=\"3.1.1、服务单元化改造\"></a>3.1.1、服务单元化改造</h5><h6 id=\"接口改造：\"><a href=\"#接口改造：\" class=\"headerlink\" title=\"接口改造：\"></a>接口改造：</h6><p>需要对自己的接口（Java interface）进行标记是什么类型，如果标记为单元路由，目前我们内部的规范是方法的第一个参数为小写的long buyerId，RPC在路由的时候会根据这个值判断用户所在的机房。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@HSFProvider</span>(serviceInterface = OrderService<span class=\"class\">.<span class=\"keyword\">class</span>, <span class=\"title\">writeMode</span></span>=center, route=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">OrderServiceImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">OrderService</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Autowired</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> OrderDAO orderDAO;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> OrderModel <span class=\"title\">queryOrder</span><span class=\"params\">(Long buyerId, Long orderId)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> orderDAO.queryOrder(orderId);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">writeMode： 属性告知 HSF 某个 服务是中心服务（center）还是单元服务（unit）。</span><br><span class=\"line\">route：用于路由的用户 ID 参数位于方法签名中的位置，如 route=<span class=\"number\">0</span> 表示方法第一个参数。</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E8%B7%AF%E7%94%B1%E9%80%BB%E8%BE%91.png\" alt=\"路由逻辑\"></p>\n<h5 id=\"3-1-2、业务上下文分析及改造\"><a href=\"#3-1-2、业务上下文分析及改造\" class=\"headerlink\" title=\"3.1.2、业务上下文分析及改造\"></a>3.1.2、业务上下文分析及改造</h5><p>推动调用旧接口的业务进行接口切换。</p>\n<h5 id=\"3-1-3、DB单元化改造\"><a href=\"#3-1-3、DB单元化改造\" class=\"headerlink\" title=\"3.1.3、DB单元化改造\"></a>3.1.3、DB单元化改造</h5><p>单元化应用目前使用的数据层都是TDDL。 数据层的改造点主要有三方面单元化：</p>\n<ol>\n<li>sequence：TDDL需要提供一个sequence组件,根据当前单元的个数生成全局唯一的sequence,这样当单元流量切换时,sequence总是唯一的,不会产生冲突.</li>\n<li>中心化数据源：为了防止数据错写,有些数据源(比如库存)需要保证只在中心单元才能启动.TDDL需要在数据源初始化的时候,判断当前机器的角色与数据源的配置,如果是中心数据源而应用服务器属于单元,则忽略该数据源的启动。</li>\n<li>写保护：数据落库之前的最后一层中间件就是数据层,为了防止错写,TDDL雲要提供一种机制,当单元化数据落库时,检查要落库的数据是否符合当前的路由规则,不符合则拒绝写入。</li>\n<li>存储层：单元化最核心的问题就是数据问题，有2种数据模式：<ol>\n<li>unit模式：用户在各自映射的单元写对应的数据，数据会和中心做双向同步;如买家数据</li>\n<li>copy模式：数据在中心写，全量同步到各个单元;如卖家数据<br><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B1%82.png\" alt=\"数据库层\"></li>\n</ol>\n</li>\n</ol>\n<blockquote>\n<p>使用unit模式，申请单元DB，然后通过DRC做数据的同步。</p>\n</blockquote>\n<h5 id=\"3-1-4、tair单元化改造\"><a href=\"#3-1-4、tair单元化改造\" class=\"headerlink\" title=\"3.1.4、tair单元化改造\"></a>3.1.4、tair单元化改造</h5><p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/tair%E5%8D%95%E5%85%83%E5%8C%96.png\" alt=\"tair单元化\"><br>在数据发生变更时，也需要对单元的缓存进行失效;通过 invaild-server 来对单元的缓存进行失效。</p>\n<blockquote>\n<p>数据的变更信息，通过 DRC 广播到多个机房，实现缓存的刷新，保证各个机房的缓存一致性。</p>\n</blockquote>\n<h5 id=\"3-1-5、消息通信层改造\"><a href=\"#3-1-5、消息通信层改造\" class=\"headerlink\" title=\"3.1.5、消息通信层改造\"></a>3.1.5、消息通信层改造</h5><p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E6%B6%88%E6%81%AF%E9%80%9A%E4%BF%A1%E5%B1%82.png\" alt=\"消息通信层\"><br>实现原则是，尽量保持单元内部消息在内部投递和消费，同时所有消息会路由到中心，保证没有做单元化部署的业务也能接收到消息。把消息投递到准确的单元订阅者。单元1发布的消息，会被单元1的订阅者收到，单元化的应用流量会被均衡分配到每个单元。</p>\n<h4 id=\"3-2、测试联调阶段\"><a href=\"#3-2、测试联调阶段\" class=\"headerlink\" title=\"3.2、测试联调阶段\"></a>3.2、测试联调阶段</h4><h5 id=\"3-2-2、数据一致性保障\"><a href=\"#3-2-2、数据一致性保障\" class=\"headerlink\" title=\"3.2.2、数据一致性保障\"></a>3.2.2、数据一致性保障</h5><h6 id=\"数据库和缓存的数据一致性核对\"><a href=\"#数据库和缓存的数据一致性核对\" class=\"headerlink\" title=\"数据库和缓存的数据一致性核对\"></a>数据库和缓存的数据一致性核对</h6><p>通过BCP核对，监听DRC消息后，核对两边的数据一致性。</p>\n<h6 id=\"中心和单元的数据一致性核对\"><a href=\"#中心和单元的数据一致性核对\" class=\"headerlink\" title=\"中心和单元的数据一致性核对\"></a>中心和单元的数据一致性核对</h6><p><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E6%96%B9%E6%A1%88.png\" alt=\"常见的数据一致性方案\"></p>\n<ol>\n<li>全量数据比对：一般通过离线表核对。</li>\n<li>增量数据核对：监听binlog mq异步方式去核对。（中间可能需要延迟核对，因为中心&amp;单元之间会有数据延迟）</li>\n</ol>\n<blockquote>\n<p>全增结合</p>\n</blockquote>\n<h5 id=\"3-2-3、监控\"><a href=\"#3-2-3、监控\" class=\"headerlink\" title=\"3.2.3、监控\"></a>3.2.3、监控</h5><p>基础监控 &amp; 业务监控的建设。</p>\n<h4 id=\"3-3、灰度切流阶段\"><a href=\"#3-3、灰度切流阶段\" class=\"headerlink\" title=\"3.3、灰度切流阶段\"></a>3.3、灰度切流阶段</h4><h5 id=\"3-3-1、切流方案\"><a href=\"#3-3-1、切流方案\" class=\"headerlink\" title=\"3.3.1、切流方案\"></a>3.3.1、切流方案</h5><p>方案类似如下：<br><img src=\"/2024/07/18/2024-07-18-稳定性-单元化改造示例/%E5%88%87%E6%B5%81%E6%B5%81%E7%A8%8B.png\" alt=\"切流流程\"></p>\n<p>后续用户的请求就会直接被路由到正确的机房。</p>\n<p>参考文章：<br><a href=\"https://juejin.cn/post/7338422591517310991\" target=\"_blank\" rel=\"noopener\">阿里技术架构演进及过程中遇到的问题</a><br><a href=\"https://pic.huodongjia.com/ganhuodocs/2017-08-09/1502263496.67.pdf\" target=\"_blank\" rel=\"noopener\">饿了么异地多活的数据实施-DRC</a><br><a href=\"https://tech.dewu.com/article?id=9\" target=\"_blank\" rel=\"noopener\">看完这篇异地多活的改造，我决定和架构师battle一下</a><br><a href=\"https://www.163.com/dy/article/JFDUC45H0511D3QS.html\" target=\"_blank\" rel=\"noopener\">单元化架构在字节跳动的落地实践</a><br><a href=\"https://blog.51cto.com/u_6478076/5109051\" target=\"_blank\" rel=\"noopener\">单元化 理论基础 &amp;&amp; 实践方案</a></p>"},{"title":"Linux-io模型","date":"2019-04-11T07:43:10.000Z","_content":"### 前言\n先了解一下同步、异步、阻塞、非阻塞的相关概念。\n\n- 同步：一般指的是程序的顺序执行\n```\n    public class TestClass{\n        public static void main(String[] args) {\n            A();\n        }\n        public static void A() {\n            System.out.println(\"A执行\");\n            B();\n            System.out.println(\"A执行完成\");\n        }\n        \n        public static void B() {\n            System.out.println(\"B执行\");\n            while(true) {\n                ....\n            }\n            System.out.println(\"B执行完成\");\n        }\n    }\n```\n<!--more-->  \n\n从该例子中，只有当B()执行完成后，A()方法才会输出\"A执行完成\"，这就是同步。\n    整个处理过程顺序执行，当各个过程都执行完毕，并返回结果。是一种线性执行的方式，执行的流程不能跨越\n    \n- 异步：ajax就是最好的例子\n```\n    function ajaxTest() {\n        console.log(\"方法开始执行\");\n        $.ajax({\n            url: \"/A/remoteCall\",\n            type: \"post\",\n            success: function (data) {\n                while(true) {\n                    console.log(\"方法开始执行\");\n                }\n            }\n        });\n        console.log(\"方法执行结束\");\n    }\n```\n\n\n方法执行，不需要等待ajax的返回结果。\n\n    \n- 阻塞：一般指的是线程的状态\n```\n    public Result export) {\n            try {\n                InputStream inputStream = new ByteArrayInputStream(ExcelUtil.getInstance().export(excelDataList, map, groupIdNameMap).toByteArray());\n                FileCopyUtils.copy(inputStream, outputStream);\n            } catch (Exception e) {\n                log.error(\"导出Excel出错了\", e);\n                result.setMessage(\"操作失败!\");\n                result.setStatus(REST_STATUS.FAILD_EXCEPTION);\n            }\n            return result;\n        }\n```\n\n\n>例如导出中，操作系统读取文件返回花较长时间，程序不会往下执行，进入阻塞状态。    \n    \nMore info: [参考文章](https://www.jianshu.com/p/aed6067eeac9)    \n    \n### Linux IO模型\n\n1. 阻塞IO（bloking IO）\n2. 非阻塞IO（non-blocking IO）\n3. 多路复用IO（multiplexing IO）\n4. 信号驱动式IO（signal-driven IO）\n5. 异步IO（asynchronous IO）                \n\n\n#### 一. 同步阻塞IO\n![Linux-io模型](2019-04-11-Linux-io模型/sync-block.png)\n- 两个步骤：\n\n   1. 步骤一：用户空间的应用程序执行一个系统调用（recvform），linux kernel开始IO的第一阶段：准备数据。这会导致应用程序阻塞（进程自己选择的阻塞），什么也不干，直到数据准备好。\n   2. 步骤二：当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。\n\n#### 二. 同步非阻塞IO\n![Linux-io模型](2019-04-11-Linux-io模型/sync-nonblock.png)\n>同步非阻塞就是通过轮训的方式（轮训执行系统调用），去判断数据是否准备好（轮训者：程序进程）\n需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。\n\n\n#### 三. IO多路复用\n![Linux-io模型](2019-04-11-Linux-io模型/async-block.png)\n\n\n>强调一点就是，IO多路复用模型并没有涉及到非阻塞，进程在发出select后，要一直阻塞等待其监听的所有IO操作至少有一个数据准备好才返回，强调阻塞状态，不存在非阻塞。\n而在 Java NIO中也可以实现多路复用，主要是利用多路复用器 Selector，与这里的 select函数类型，Selector会不断轮询注册在其上的通道Channel，如果有某一个Channel上面发生读或写事件，这个Channel处于就绪状态，就会被Selector轮询出来。关于Java NIO实现多路复用更多的介绍请查询相关文章。\n\n\nMore info:[参考文章](https://www.jianshu.com/p/486b0965c296)","source":"_posts/2019-04-11-Linux-io模型.md","raw":"---\ntitle: Linux-io模型\ndate: 2019-04-11 15:43:10\ncategories: \n  - [linux]\ntags: Linux IO\n---\n### 前言\n先了解一下同步、异步、阻塞、非阻塞的相关概念。\n\n- 同步：一般指的是程序的顺序执行\n```\n    public class TestClass{\n        public static void main(String[] args) {\n            A();\n        }\n        public static void A() {\n            System.out.println(\"A执行\");\n            B();\n            System.out.println(\"A执行完成\");\n        }\n        \n        public static void B() {\n            System.out.println(\"B执行\");\n            while(true) {\n                ....\n            }\n            System.out.println(\"B执行完成\");\n        }\n    }\n```\n<!--more-->  \n\n从该例子中，只有当B()执行完成后，A()方法才会输出\"A执行完成\"，这就是同步。\n    整个处理过程顺序执行，当各个过程都执行完毕，并返回结果。是一种线性执行的方式，执行的流程不能跨越\n    \n- 异步：ajax就是最好的例子\n```\n    function ajaxTest() {\n        console.log(\"方法开始执行\");\n        $.ajax({\n            url: \"/A/remoteCall\",\n            type: \"post\",\n            success: function (data) {\n                while(true) {\n                    console.log(\"方法开始执行\");\n                }\n            }\n        });\n        console.log(\"方法执行结束\");\n    }\n```\n\n\n方法执行，不需要等待ajax的返回结果。\n\n    \n- 阻塞：一般指的是线程的状态\n```\n    public Result export) {\n            try {\n                InputStream inputStream = new ByteArrayInputStream(ExcelUtil.getInstance().export(excelDataList, map, groupIdNameMap).toByteArray());\n                FileCopyUtils.copy(inputStream, outputStream);\n            } catch (Exception e) {\n                log.error(\"导出Excel出错了\", e);\n                result.setMessage(\"操作失败!\");\n                result.setStatus(REST_STATUS.FAILD_EXCEPTION);\n            }\n            return result;\n        }\n```\n\n\n>例如导出中，操作系统读取文件返回花较长时间，程序不会往下执行，进入阻塞状态。    \n    \nMore info: [参考文章](https://www.jianshu.com/p/aed6067eeac9)    \n    \n### Linux IO模型\n\n1. 阻塞IO（bloking IO）\n2. 非阻塞IO（non-blocking IO）\n3. 多路复用IO（multiplexing IO）\n4. 信号驱动式IO（signal-driven IO）\n5. 异步IO（asynchronous IO）                \n\n\n#### 一. 同步阻塞IO\n![Linux-io模型](2019-04-11-Linux-io模型/sync-block.png)\n- 两个步骤：\n\n   1. 步骤一：用户空间的应用程序执行一个系统调用（recvform），linux kernel开始IO的第一阶段：准备数据。这会导致应用程序阻塞（进程自己选择的阻塞），什么也不干，直到数据准备好。\n   2. 步骤二：当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。\n\n#### 二. 同步非阻塞IO\n![Linux-io模型](2019-04-11-Linux-io模型/sync-nonblock.png)\n>同步非阻塞就是通过轮训的方式（轮训执行系统调用），去判断数据是否准备好（轮训者：程序进程）\n需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。\n\n\n#### 三. IO多路复用\n![Linux-io模型](2019-04-11-Linux-io模型/async-block.png)\n\n\n>强调一点就是，IO多路复用模型并没有涉及到非阻塞，进程在发出select后，要一直阻塞等待其监听的所有IO操作至少有一个数据准备好才返回，强调阻塞状态，不存在非阻塞。\n而在 Java NIO中也可以实现多路复用，主要是利用多路复用器 Selector，与这里的 select函数类型，Selector会不断轮询注册在其上的通道Channel，如果有某一个Channel上面发生读或写事件，这个Channel处于就绪状态，就会被Selector轮询出来。关于Java NIO实现多路复用更多的介绍请查询相关文章。\n\n\nMore info:[参考文章](https://www.jianshu.com/p/486b0965c296)","slug":"2019-04-11-Linux-io模型","published":1,"updated":"2024-12-09T03:22:02.685Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpnyk0065a13k5eqygezq","content":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>先了解一下同步、异步、阻塞、非阻塞的相关概念。</p>\n<ul>\n<li>同步：一般指的是程序的顺序执行<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class TestClass&#123;</span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        A();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    public static void A() &#123;</span><br><span class=\"line\">        System.out.println(&quot;A执行&quot;);</span><br><span class=\"line\">        B();</span><br><span class=\"line\">        System.out.println(&quot;A执行完成&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    public static void B() &#123;</span><br><span class=\"line\">        System.out.println(&quot;B执行&quot;);</span><br><span class=\"line\">        while(true) &#123;</span><br><span class=\"line\">            ....</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        System.out.println(&quot;B执行完成&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<a id=\"more\"></a>  \n\n<p>从该例子中，只有当B()执行完成后，A()方法才会输出”A执行完成”，这就是同步。<br>    整个处理过程顺序执行，当各个过程都执行完毕，并返回结果。是一种线性执行的方式，执行的流程不能跨越</p>\n<ul>\n<li>异步：ajax就是最好的例子<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function ajaxTest() &#123;</span><br><span class=\"line\">    console.log(&quot;方法开始执行&quot;);</span><br><span class=\"line\">    $.ajax(&#123;</span><br><span class=\"line\">        url: &quot;/A/remoteCall&quot;,</span><br><span class=\"line\">        type: &quot;post&quot;,</span><br><span class=\"line\">        success: function (data) &#123;</span><br><span class=\"line\">            while(true) &#123;</span><br><span class=\"line\">                console.log(&quot;方法开始执行&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">    console.log(&quot;方法执行结束&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>方法执行，不需要等待ajax的返回结果。</p>\n<ul>\n<li>阻塞：一般指的是线程的状态<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Result export) &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            InputStream inputStream = new ByteArrayInputStream(ExcelUtil.getInstance().export(excelDataList, map, groupIdNameMap).toByteArray());</span><br><span class=\"line\">            FileCopyUtils.copy(inputStream, outputStream);</span><br><span class=\"line\">        &#125; catch (Exception e) &#123;</span><br><span class=\"line\">            log.error(&quot;导出Excel出错了&quot;, e);</span><br><span class=\"line\">            result.setMessage(&quot;操作失败!&quot;);</span><br><span class=\"line\">            result.setStatus(REST_STATUS.FAILD_EXCEPTION);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return result;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<blockquote>\n<p>例如导出中，操作系统读取文件返回花较长时间，程序不会往下执行，进入阻塞状态。    </p>\n</blockquote>\n<p>More info: <a href=\"https://www.jianshu.com/p/aed6067eeac9\" target=\"_blank\" rel=\"noopener\">参考文章</a>    </p>\n<h3 id=\"Linux-IO模型\"><a href=\"#Linux-IO模型\" class=\"headerlink\" title=\"Linux IO模型\"></a>Linux IO模型</h3><ol>\n<li>阻塞IO（bloking IO）</li>\n<li>非阻塞IO（non-blocking IO）</li>\n<li>多路复用IO（multiplexing IO）</li>\n<li>信号驱动式IO（signal-driven IO）</li>\n<li>异步IO（asynchronous IO）                </li>\n</ol>\n<h4 id=\"一-同步阻塞IO\"><a href=\"#一-同步阻塞IO\" class=\"headerlink\" title=\"一. 同步阻塞IO\"></a>一. 同步阻塞IO</h4><p><img src=\"/2019/04/11/2019-04-11-Linux-io模型/sync-block.png\" alt=\"Linux-io模型\"></p>\n<ul>\n<li><p>两个步骤：</p>\n<ol>\n<li>步骤一：用户空间的应用程序执行一个系统调用（recvform），linux kernel开始IO的第一阶段：准备数据。这会导致应用程序阻塞（进程自己选择的阻塞），什么也不干，直到数据准备好。</li>\n<li>步骤二：当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。</li>\n</ol>\n</li>\n</ul>\n<h4 id=\"二-同步非阻塞IO\"><a href=\"#二-同步非阻塞IO\" class=\"headerlink\" title=\"二. 同步非阻塞IO\"></a>二. 同步非阻塞IO</h4><p><img src=\"/2019/04/11/2019-04-11-Linux-io模型/sync-nonblock.png\" alt=\"Linux-io模型\"></p>\n<blockquote>\n<p>同步非阻塞就是通过轮训的方式（轮训执行系统调用），去判断数据是否准备好（轮训者：程序进程）<br>需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。</p>\n</blockquote>\n<h4 id=\"三-IO多路复用\"><a href=\"#三-IO多路复用\" class=\"headerlink\" title=\"三. IO多路复用\"></a>三. IO多路复用</h4><p><img src=\"/2019/04/11/2019-04-11-Linux-io模型/async-block.png\" alt=\"Linux-io模型\"></p>\n<blockquote>\n<p>强调一点就是，IO多路复用模型并没有涉及到非阻塞，进程在发出select后，要一直阻塞等待其监听的所有IO操作至少有一个数据准备好才返回，强调阻塞状态，不存在非阻塞。<br>而在 Java NIO中也可以实现多路复用，主要是利用多路复用器 Selector，与这里的 select函数类型，Selector会不断轮询注册在其上的通道Channel，如果有某一个Channel上面发生读或写事件，这个Channel处于就绪状态，就会被Selector轮询出来。关于Java NIO实现多路复用更多的介绍请查询相关文章。</p>\n</blockquote>\n<p>More info:<a href=\"https://www.jianshu.com/p/486b0965c296\" target=\"_blank\" rel=\"noopener\">参考文章</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>先了解一下同步、异步、阻塞、非阻塞的相关概念。</p>\n<ul>\n<li>同步：一般指的是程序的顺序执行<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class TestClass&#123;</span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        A();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    public static void A() &#123;</span><br><span class=\"line\">        System.out.println(&quot;A执行&quot;);</span><br><span class=\"line\">        B();</span><br><span class=\"line\">        System.out.println(&quot;A执行完成&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    public static void B() &#123;</span><br><span class=\"line\">        System.out.println(&quot;B执行&quot;);</span><br><span class=\"line\">        while(true) &#123;</span><br><span class=\"line\">            ....</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        System.out.println(&quot;B执行完成&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>","more":"<p>从该例子中，只有当B()执行完成后，A()方法才会输出”A执行完成”，这就是同步。<br>    整个处理过程顺序执行，当各个过程都执行完毕，并返回结果。是一种线性执行的方式，执行的流程不能跨越</p>\n<ul>\n<li>异步：ajax就是最好的例子<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">function ajaxTest() &#123;</span><br><span class=\"line\">    console.log(&quot;方法开始执行&quot;);</span><br><span class=\"line\">    $.ajax(&#123;</span><br><span class=\"line\">        url: &quot;/A/remoteCall&quot;,</span><br><span class=\"line\">        type: &quot;post&quot;,</span><br><span class=\"line\">        success: function (data) &#123;</span><br><span class=\"line\">            while(true) &#123;</span><br><span class=\"line\">                console.log(&quot;方法开始执行&quot;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">    console.log(&quot;方法执行结束&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>方法执行，不需要等待ajax的返回结果。</p>\n<ul>\n<li>阻塞：一般指的是线程的状态<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public Result export) &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            InputStream inputStream = new ByteArrayInputStream(ExcelUtil.getInstance().export(excelDataList, map, groupIdNameMap).toByteArray());</span><br><span class=\"line\">            FileCopyUtils.copy(inputStream, outputStream);</span><br><span class=\"line\">        &#125; catch (Exception e) &#123;</span><br><span class=\"line\">            log.error(&quot;导出Excel出错了&quot;, e);</span><br><span class=\"line\">            result.setMessage(&quot;操作失败!&quot;);</span><br><span class=\"line\">            result.setStatus(REST_STATUS.FAILD_EXCEPTION);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return result;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<blockquote>\n<p>例如导出中，操作系统读取文件返回花较长时间，程序不会往下执行，进入阻塞状态。    </p>\n</blockquote>\n<p>More info: <a href=\"https://www.jianshu.com/p/aed6067eeac9\" target=\"_blank\" rel=\"noopener\">参考文章</a>    </p>\n<h3 id=\"Linux-IO模型\"><a href=\"#Linux-IO模型\" class=\"headerlink\" title=\"Linux IO模型\"></a>Linux IO模型</h3><ol>\n<li>阻塞IO（bloking IO）</li>\n<li>非阻塞IO（non-blocking IO）</li>\n<li>多路复用IO（multiplexing IO）</li>\n<li>信号驱动式IO（signal-driven IO）</li>\n<li>异步IO（asynchronous IO）                </li>\n</ol>\n<h4 id=\"一-同步阻塞IO\"><a href=\"#一-同步阻塞IO\" class=\"headerlink\" title=\"一. 同步阻塞IO\"></a>一. 同步阻塞IO</h4><p><img src=\"/2019/04/11/2019-04-11-Linux-io模型/sync-block.png\" alt=\"Linux-io模型\"></p>\n<ul>\n<li><p>两个步骤：</p>\n<ol>\n<li>步骤一：用户空间的应用程序执行一个系统调用（recvform），linux kernel开始IO的第一阶段：准备数据。这会导致应用程序阻塞（进程自己选择的阻塞），什么也不干，直到数据准备好。</li>\n<li>步骤二：当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。</li>\n</ol>\n</li>\n</ul>\n<h4 id=\"二-同步非阻塞IO\"><a href=\"#二-同步非阻塞IO\" class=\"headerlink\" title=\"二. 同步非阻塞IO\"></a>二. 同步非阻塞IO</h4><p><img src=\"/2019/04/11/2019-04-11-Linux-io模型/sync-nonblock.png\" alt=\"Linux-io模型\"></p>\n<blockquote>\n<p>同步非阻塞就是通过轮训的方式（轮训执行系统调用），去判断数据是否准备好（轮训者：程序进程）<br>需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。</p>\n</blockquote>\n<h4 id=\"三-IO多路复用\"><a href=\"#三-IO多路复用\" class=\"headerlink\" title=\"三. IO多路复用\"></a>三. IO多路复用</h4><p><img src=\"/2019/04/11/2019-04-11-Linux-io模型/async-block.png\" alt=\"Linux-io模型\"></p>\n<blockquote>\n<p>强调一点就是，IO多路复用模型并没有涉及到非阻塞，进程在发出select后，要一直阻塞等待其监听的所有IO操作至少有一个数据准备好才返回，强调阻塞状态，不存在非阻塞。<br>而在 Java NIO中也可以实现多路复用，主要是利用多路复用器 Selector，与这里的 select函数类型，Selector会不断轮询注册在其上的通道Channel，如果有某一个Channel上面发生读或写事件，这个Channel处于就绪状态，就会被Selector轮询出来。关于Java NIO实现多路复用更多的介绍请查询相关文章。</p>\n</blockquote>\n<p>More info:<a href=\"https://www.jianshu.com/p/486b0965c296\" target=\"_blank\" rel=\"noopener\">参考文章</a></p>"},{"title":"《架构》常见技术框架性能","date":"2024-08-23T02:00:00.000Z","_content":"\n### 一、常见技术框架性能\n\n#### 1.1、Nginx\nNginx 是一款轻量级的高性能 Web 服务器、反向代理服务器以及邮件服务器。它在处理高并发连接和静态资源服务方面表现卓越，被广泛应用于各种互联网架构中。\n\n性能：\n- 一般情况下，系统的性能瓶颈基本不会是 Nginx。单机 Nginx 可以达到 30w +。\n<!--more-->\n\n<details style=\"background-color: #dbdbdb;padding: 10px;\">\n<summary>▲ 点击查看“代理”相关定义</summary>\n\n![正反向代理](2024-08-23-架构-常见技术框架性能/正反向代理.png)\n\n##### 1.1.1、正向代理 和 反向代理 的区别\n\n相同点\n1. **位置和功能**： <font color=#e98787>正向代理和反向代理都位于客户端和真实服务器之间</font>，它们的主要功能都是将客户端的请求转发给服务器，然后再将服务器的响应转发给客户端。\n2. **提高访问速度**： <font color=#e98787>两者都能通过缓存机制提高访问速度</font>。当客户端请求某个资源时，如果代理服务器已经缓存了该资源，就可以直接从缓存中提供，而无需再次从原始服务器获取，从而节省了时间和带宽。\n\n\n不同点\n1. **代理对象**： 正向代理是为客户端提供代理服务，即服务器不知道真正的客户端是谁。而反向代理则是为服务器提供代理服务，即客户端不知道真正的服务器是谁。\n2. **架设位置**： 正向代理通常是由客户端架设的，而反向代理则是由服务器架设的。\n3. **用途和目的**： 正向代理的主要用途是为在防火墙内的局域网客户端提供访问Internet的途径，侧重于解决访问限制问题。而反向代理的主要用途是将防火墙后面的服务器提供给Internet用户访问，其目的在于实现负载均衡、安全防护等。\n4. **服务对象**： 在正向代理中，服务器不知道真正的用户是谁；而在反向代理中，用户不知道真正的服务器是谁。\n\n</details>\n\n#### 1.2、Redis\n性能：\n- Redis 官方的性能测试报告：https://redis.io/topics/benchmarks 。从报告中，我们可以得出 Redis 的单机 QPS 可以达到 8w+（CPU性能有关系，也和执行的命令也有关系比如执行 SET 命令甚至可以达到10w+QPS）。\n\n#### 1.3、MySQL\nMySQL单机的QPS为大概在 4K 左右。\n- 写TPS：1000。\n- 读QPS：4K，耗时一般在几毫秒。\n\n\n#### 1.4、Tomcat\n单机 Tomcat 的QPS 在 2w左右。这个和你的 Tomcat 配置有很大关系，举个例子Tomcat 支持的连接器有 NIO、NIO.2 和 APR。 AprEndpoint 是通过 JNI 调用 APR 本地库而实现非阻塞 I/O 的，性能更好，Tomcat 配置 APR 为 连接器的话，QPS 可以达到 3w左右。更多相关内容可以自行搜索 Tomcat 性能优化。\n\n#### 1.5、Rocketmq\n在1台生产者、1台broker、1台namesrv 、1台消费者的架构中：\n- 只生产不消费场景，最大的tps是22235。\n- 一边生产一边消费的场景，最大的tps生产是18738，消费最大的tps是18738。\n- 只消费不生产，最大的tps是48435。\n\n#### 1.6、kafka\n(Kafka资源估算)[https://www.cnblogs.com/jiaxzeng/p/17227706.html]\n\n\n\n参考文章：\n[终于有人把正向代理和反向代理解释的明明白白了！](https://cloud.tencent.com/developer/article/1418457)","source":"_posts/2024-08-23-架构-常见技术框架性能.md","raw":"---\ntitle: 《架构》常见技术框架性能\ndate: 2024-08-23 10:00:00\ncategories:\n  - [架构]\n---\n\n### 一、常见技术框架性能\n\n#### 1.1、Nginx\nNginx 是一款轻量级的高性能 Web 服务器、反向代理服务器以及邮件服务器。它在处理高并发连接和静态资源服务方面表现卓越，被广泛应用于各种互联网架构中。\n\n性能：\n- 一般情况下，系统的性能瓶颈基本不会是 Nginx。单机 Nginx 可以达到 30w +。\n<!--more-->\n\n<details style=\"background-color: #dbdbdb;padding: 10px;\">\n<summary>▲ 点击查看“代理”相关定义</summary>\n\n![正反向代理](2024-08-23-架构-常见技术框架性能/正反向代理.png)\n\n##### 1.1.1、正向代理 和 反向代理 的区别\n\n相同点\n1. **位置和功能**： <font color=#e98787>正向代理和反向代理都位于客户端和真实服务器之间</font>，它们的主要功能都是将客户端的请求转发给服务器，然后再将服务器的响应转发给客户端。\n2. **提高访问速度**： <font color=#e98787>两者都能通过缓存机制提高访问速度</font>。当客户端请求某个资源时，如果代理服务器已经缓存了该资源，就可以直接从缓存中提供，而无需再次从原始服务器获取，从而节省了时间和带宽。\n\n\n不同点\n1. **代理对象**： 正向代理是为客户端提供代理服务，即服务器不知道真正的客户端是谁。而反向代理则是为服务器提供代理服务，即客户端不知道真正的服务器是谁。\n2. **架设位置**： 正向代理通常是由客户端架设的，而反向代理则是由服务器架设的。\n3. **用途和目的**： 正向代理的主要用途是为在防火墙内的局域网客户端提供访问Internet的途径，侧重于解决访问限制问题。而反向代理的主要用途是将防火墙后面的服务器提供给Internet用户访问，其目的在于实现负载均衡、安全防护等。\n4. **服务对象**： 在正向代理中，服务器不知道真正的用户是谁；而在反向代理中，用户不知道真正的服务器是谁。\n\n</details>\n\n#### 1.2、Redis\n性能：\n- Redis 官方的性能测试报告：https://redis.io/topics/benchmarks 。从报告中，我们可以得出 Redis 的单机 QPS 可以达到 8w+（CPU性能有关系，也和执行的命令也有关系比如执行 SET 命令甚至可以达到10w+QPS）。\n\n#### 1.3、MySQL\nMySQL单机的QPS为大概在 4K 左右。\n- 写TPS：1000。\n- 读QPS：4K，耗时一般在几毫秒。\n\n\n#### 1.4、Tomcat\n单机 Tomcat 的QPS 在 2w左右。这个和你的 Tomcat 配置有很大关系，举个例子Tomcat 支持的连接器有 NIO、NIO.2 和 APR。 AprEndpoint 是通过 JNI 调用 APR 本地库而实现非阻塞 I/O 的，性能更好，Tomcat 配置 APR 为 连接器的话，QPS 可以达到 3w左右。更多相关内容可以自行搜索 Tomcat 性能优化。\n\n#### 1.5、Rocketmq\n在1台生产者、1台broker、1台namesrv 、1台消费者的架构中：\n- 只生产不消费场景，最大的tps是22235。\n- 一边生产一边消费的场景，最大的tps生产是18738，消费最大的tps是18738。\n- 只消费不生产，最大的tps是48435。\n\n#### 1.6、kafka\n(Kafka资源估算)[https://www.cnblogs.com/jiaxzeng/p/17227706.html]\n\n\n\n参考文章：\n[终于有人把正向代理和反向代理解释的明明白白了！](https://cloud.tencent.com/developer/article/1418457)","slug":"2024-08-23-架构-常见技术框架性能","published":1,"updated":"2024-11-26T14:45:11.647Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpo2w00aja13k2y56ld8e","content":"<h3 id=\"一、常见技术框架性能\"><a href=\"#一、常见技术框架性能\" class=\"headerlink\" title=\"一、常见技术框架性能\"></a>一、常见技术框架性能</h3><h4 id=\"1-1、Nginx\"><a href=\"#1-1、Nginx\" class=\"headerlink\" title=\"1.1、Nginx\"></a>1.1、Nginx</h4><p>Nginx 是一款轻量级的高性能 Web 服务器、反向代理服务器以及邮件服务器。它在处理高并发连接和静态资源服务方面表现卓越，被广泛应用于各种互联网架构中。</p>\n<p>性能：</p>\n<ul>\n<li>一般情况下，系统的性能瓶颈基本不会是 Nginx。单机 Nginx 可以达到 30w +。<a id=\"more\"></a>\n\n</li>\n</ul>\n<details style=\"background-color: #dbdbdb;padding: 10px;\">\n<summary>▲ 点击查看“代理”相关定义</summary>\n\n<p><img src=\"/2024/08/23/2024-08-23-架构-常见技术框架性能/%E6%AD%A3%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86.png\" alt=\"正反向代理\"></p>\n<h5 id=\"1-1-1、正向代理-和-反向代理-的区别\"><a href=\"#1-1-1、正向代理-和-反向代理-的区别\" class=\"headerlink\" title=\"1.1.1、正向代理 和 反向代理 的区别\"></a>1.1.1、正向代理 和 反向代理 的区别</h5><p>相同点</p>\n<ol>\n<li><strong>位置和功能</strong>： <font color=\"#e98787\">正向代理和反向代理都位于客户端和真实服务器之间</font>，它们的主要功能都是将客户端的请求转发给服务器，然后再将服务器的响应转发给客户端。</li>\n<li><strong>提高访问速度</strong>： <font color=\"#e98787\">两者都能通过缓存机制提高访问速度</font>。当客户端请求某个资源时，如果代理服务器已经缓存了该资源，就可以直接从缓存中提供，而无需再次从原始服务器获取，从而节省了时间和带宽。</li>\n</ol>\n<p>不同点</p>\n<ol>\n<li><strong>代理对象</strong>： 正向代理是为客户端提供代理服务，即服务器不知道真正的客户端是谁。而反向代理则是为服务器提供代理服务，即客户端不知道真正的服务器是谁。</li>\n<li><strong>架设位置</strong>： 正向代理通常是由客户端架设的，而反向代理则是由服务器架设的。</li>\n<li><strong>用途和目的</strong>： 正向代理的主要用途是为在防火墙内的局域网客户端提供访问Internet的途径，侧重于解决访问限制问题。而反向代理的主要用途是将防火墙后面的服务器提供给Internet用户访问，其目的在于实现负载均衡、安全防护等。</li>\n<li><strong>服务对象</strong>： 在正向代理中，服务器不知道真正的用户是谁；而在反向代理中，用户不知道真正的服务器是谁。</li>\n</ol>\n</details>\n\n<h4 id=\"1-2、Redis\"><a href=\"#1-2、Redis\" class=\"headerlink\" title=\"1.2、Redis\"></a>1.2、Redis</h4><p>性能：</p>\n<ul>\n<li>Redis 官方的性能测试报告：<a href=\"https://redis.io/topics/benchmarks\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/benchmarks</a> 。从报告中，我们可以得出 Redis 的单机 QPS 可以达到 8w+（CPU性能有关系，也和执行的命令也有关系比如执行 SET 命令甚至可以达到10w+QPS）。</li>\n</ul>\n<h4 id=\"1-3、MySQL\"><a href=\"#1-3、MySQL\" class=\"headerlink\" title=\"1.3、MySQL\"></a>1.3、MySQL</h4><p>MySQL单机的QPS为大概在 4K 左右。</p>\n<ul>\n<li>写TPS：1000。</li>\n<li>读QPS：4K，耗时一般在几毫秒。</li>\n</ul>\n<h4 id=\"1-4、Tomcat\"><a href=\"#1-4、Tomcat\" class=\"headerlink\" title=\"1.4、Tomcat\"></a>1.4、Tomcat</h4><p>单机 Tomcat 的QPS 在 2w左右。这个和你的 Tomcat 配置有很大关系，举个例子Tomcat 支持的连接器有 NIO、NIO.2 和 APR。 AprEndpoint 是通过 JNI 调用 APR 本地库而实现非阻塞 I/O 的，性能更好，Tomcat 配置 APR 为 连接器的话，QPS 可以达到 3w左右。更多相关内容可以自行搜索 Tomcat 性能优化。</p>\n<h4 id=\"1-5、Rocketmq\"><a href=\"#1-5、Rocketmq\" class=\"headerlink\" title=\"1.5、Rocketmq\"></a>1.5、Rocketmq</h4><p>在1台生产者、1台broker、1台namesrv 、1台消费者的架构中：</p>\n<ul>\n<li>只生产不消费场景，最大的tps是22235。</li>\n<li>一边生产一边消费的场景，最大的tps生产是18738，消费最大的tps是18738。</li>\n<li>只消费不生产，最大的tps是48435。</li>\n</ul>\n<h4 id=\"1-6、kafka\"><a href=\"#1-6、kafka\" class=\"headerlink\" title=\"1.6、kafka\"></a>1.6、kafka</h4><p>(Kafka资源估算)[<a href=\"https://www.cnblogs.com/jiaxzeng/p/17227706.html]\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/jiaxzeng/p/17227706.html]</a></p>\n<p>参考文章：<br><a href=\"https://cloud.tencent.com/developer/article/1418457\" target=\"_blank\" rel=\"noopener\">终于有人把正向代理和反向代理解释的明明白白了！</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、常见技术框架性能\"><a href=\"#一、常见技术框架性能\" class=\"headerlink\" title=\"一、常见技术框架性能\"></a>一、常见技术框架性能</h3><h4 id=\"1-1、Nginx\"><a href=\"#1-1、Nginx\" class=\"headerlink\" title=\"1.1、Nginx\"></a>1.1、Nginx</h4><p>Nginx 是一款轻量级的高性能 Web 服务器、反向代理服务器以及邮件服务器。它在处理高并发连接和静态资源服务方面表现卓越，被广泛应用于各种互联网架构中。</p>\n<p>性能：</p>\n<ul>\n<li>一般情况下，系统的性能瓶颈基本不会是 Nginx。单机 Nginx 可以达到 30w +。</li></ul>","more":"\n\n<details style=\"background-color: #dbdbdb;padding: 10px;\">\n<summary>▲ 点击查看“代理”相关定义</summary>\n\n<p><img src=\"/2024/08/23/2024-08-23-架构-常见技术框架性能/%E6%AD%A3%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86.png\" alt=\"正反向代理\"></p>\n<h5 id=\"1-1-1、正向代理-和-反向代理-的区别\"><a href=\"#1-1-1、正向代理-和-反向代理-的区别\" class=\"headerlink\" title=\"1.1.1、正向代理 和 反向代理 的区别\"></a>1.1.1、正向代理 和 反向代理 的区别</h5><p>相同点</p>\n<ol>\n<li><strong>位置和功能</strong>： <font color=\"#e98787\">正向代理和反向代理都位于客户端和真实服务器之间</font>，它们的主要功能都是将客户端的请求转发给服务器，然后再将服务器的响应转发给客户端。</li>\n<li><strong>提高访问速度</strong>： <font color=\"#e98787\">两者都能通过缓存机制提高访问速度</font>。当客户端请求某个资源时，如果代理服务器已经缓存了该资源，就可以直接从缓存中提供，而无需再次从原始服务器获取，从而节省了时间和带宽。</li>\n</ol>\n<p>不同点</p>\n<ol>\n<li><strong>代理对象</strong>： 正向代理是为客户端提供代理服务，即服务器不知道真正的客户端是谁。而反向代理则是为服务器提供代理服务，即客户端不知道真正的服务器是谁。</li>\n<li><strong>架设位置</strong>： 正向代理通常是由客户端架设的，而反向代理则是由服务器架设的。</li>\n<li><strong>用途和目的</strong>： 正向代理的主要用途是为在防火墙内的局域网客户端提供访问Internet的途径，侧重于解决访问限制问题。而反向代理的主要用途是将防火墙后面的服务器提供给Internet用户访问，其目的在于实现负载均衡、安全防护等。</li>\n<li><strong>服务对象</strong>： 在正向代理中，服务器不知道真正的用户是谁；而在反向代理中，用户不知道真正的服务器是谁。</li>\n</ol>\n</details>\n\n<h4 id=\"1-2、Redis\"><a href=\"#1-2、Redis\" class=\"headerlink\" title=\"1.2、Redis\"></a>1.2、Redis</h4><p>性能：</p>\n<ul>\n<li>Redis 官方的性能测试报告：<a href=\"https://redis.io/topics/benchmarks\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/benchmarks</a> 。从报告中，我们可以得出 Redis 的单机 QPS 可以达到 8w+（CPU性能有关系，也和执行的命令也有关系比如执行 SET 命令甚至可以达到10w+QPS）。</li>\n</ul>\n<h4 id=\"1-3、MySQL\"><a href=\"#1-3、MySQL\" class=\"headerlink\" title=\"1.3、MySQL\"></a>1.3、MySQL</h4><p>MySQL单机的QPS为大概在 4K 左右。</p>\n<ul>\n<li>写TPS：1000。</li>\n<li>读QPS：4K，耗时一般在几毫秒。</li>\n</ul>\n<h4 id=\"1-4、Tomcat\"><a href=\"#1-4、Tomcat\" class=\"headerlink\" title=\"1.4、Tomcat\"></a>1.4、Tomcat</h4><p>单机 Tomcat 的QPS 在 2w左右。这个和你的 Tomcat 配置有很大关系，举个例子Tomcat 支持的连接器有 NIO、NIO.2 和 APR。 AprEndpoint 是通过 JNI 调用 APR 本地库而实现非阻塞 I/O 的，性能更好，Tomcat 配置 APR 为 连接器的话，QPS 可以达到 3w左右。更多相关内容可以自行搜索 Tomcat 性能优化。</p>\n<h4 id=\"1-5、Rocketmq\"><a href=\"#1-5、Rocketmq\" class=\"headerlink\" title=\"1.5、Rocketmq\"></a>1.5、Rocketmq</h4><p>在1台生产者、1台broker、1台namesrv 、1台消费者的架构中：</p>\n<ul>\n<li>只生产不消费场景，最大的tps是22235。</li>\n<li>一边生产一边消费的场景，最大的tps生产是18738，消费最大的tps是18738。</li>\n<li>只消费不生产，最大的tps是48435。</li>\n</ul>\n<h4 id=\"1-6、kafka\"><a href=\"#1-6、kafka\" class=\"headerlink\" title=\"1.6、kafka\"></a>1.6、kafka</h4><p>(Kafka资源估算)[<a href=\"https://www.cnblogs.com/jiaxzeng/p/17227706.html]\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/jiaxzeng/p/17227706.html]</a></p>\n<p>参考文章：<br><a href=\"https://cloud.tencent.com/developer/article/1418457\" target=\"_blank\" rel=\"noopener\">终于有人把正向代理和反向代理解释的明明白白了！</a></p>"},{"title":"《架构》DDD概念","date":"2024-08-28T02:00:00.000Z","_content":"\n### 一、DDD\n![什么是DDD](2024-08-28-架构-DDD概念/什么是DDD.png)\n领域驱动设计（Domain-Driven Design，简称DDD），DDD 是一种软件开发方法。\n\n<!--more-->\n\n### 二、DDD 的主要概念\n\n![DDD基本概念图](2024-08-28-架构-DDD概念/DDD基本概念图.png)\n\n---\n\n#### 2.1、通过类相关概念\n一些通用的软件设计概念及DDD的概念。\n##### 领域驱动设计（DDD）\nDDD 是 Domain-Driven Design 的缩写，是 Eric Evans 于 2004 年提出的一种软件设计方法和理念。\n\n其主要的思想是，利用确定的业务模型来指导业务与应用的设计和实现。主张开发人员与业务人员持续地沟通和模型的持续迭代式演化，以保证业务模型与代码实现的一致性，从而实现有效管理业务复杂度，优化软件设计的目的。\n\n##### 模型（Model）\n通常，模型是对对象、人或系统的信息表示。它通过较为简单的信息结构来代表我们需要理解的复杂事物或系统。\n\n地图、乐高、算筹都是模型，模型可以简化复杂事务的认知。我们天生就有用简单的东西代表另外一个东西的能力，比如幼儿园数数用的竹签，学习物理时的刚体、真空中的球形鸡，都是模型。通俗来说模型就是经验的抽象集合，平时听到的谚语、公式、定理，本质上都是一种模型。\n\n##### 领域模型（Domain Model）\n是对领域内的概念类和它们之间关系的抽象表示。它是 DDD 的核心部分，通过领域模型可以清晰地描述业务领域的结构和行为。例如，在电商系统的订单处理领域中，领域模型可能包括 “订单” 类、“订单项” 类、“商品” 类以及它们之间的关联关系（如一个订单包含多个订单项，一个订单项对应一个商品）。这些类具有各自的属性（如订单的金额、订单项的数量、商品的价格等）和行为（如订单的创建、订单项的添加、商品价格的计算等）。\n\n##### 建模（Modeling）\n建模是构建模型的过程。\n\n在软件设计过程中，通过分析业务，将业务需求使用合适的模型表示出来，是建模的任务。模型可以作为业务分析的产出，并作为软件设计的重要理论基础。 比如在分析一个电商应用的业务时，抽象出订单、商品等概念，进一步定义出模型，并用合适的图例表达，往往是 UML 来表达。\n\n##### ⭐️领域建模\nDDD最关键的部分—— 领域建模 ，它的目的归纳起来就一句话： 提炼业务知识，形成统一语言，沉淀领域模型 。\n\n以下是领域建模的交付物：\n- **领域模型：** 包含领域对象、属性、关系、行为、边界范围等各个方面，用于描述业务的本质，这也是最重要的产出物。\n- **用例图：** 用于明确系统的功能。\n- **数据模型：** 描述系统的数据结构和关系，包括实体关系模型、关系数据库模型等。\n- **状态图：** 用于描述系统各个状态及其转移条件。\n- **活动图：** 用于描述系统流程中的各个活动及其关系。\n- **序列图：** 描述系统中各个对象之间的交互过程和消息传递序列。\n- **架构模型：** 包含系统的物理和逻辑结构，包括组件、模块、接口等。\n\n##### 模型驱动设计（Model-Driven Design）\n面向模型的分析设计方法，优先通过识别模型来简化业务设计。\n\n在设计过程中，以模型为中心，始终维护模型，并基于此指导软件设计。\n\n##### 软件设计（The Software Design）\n软件设计软件需求出发，对软件系统的整体结构、模块做出划分和规划，以便于具体代码的顺利编写。\n\n由于软件需求具有非结构化、准确的语义，软件设计往往通过经验完成，无法通过某种特定的推理路线严格推导实现。\n\n##### 战略设计（Strategic Design）\n战略设计也称为战略建模，是指对业务进行高层次的抽象和归类。主要手段包括理清上下文和进行子域的划分。\n\n战略设计关注模型的分离，其解决的问题是大的模型如何划分为小模型以及相互之间如何关联。战略设计的产出可以用于指导团队协作，使得规模巨大的软件可以被合理拆分。\n\n战略设计的产出通常为上下文图，以及模块或微服务划分。\n\n##### 战术设计（Tactical design）\n战术设计也称为战术建模，是指对特定上下文下的模型进行详细设计。\n\n战术设计的对象包括聚合、实体和值对象，其目标是用明确它们是什么以及相互之间有何关系。战术设计的产出可以是用 UML 表达的类图，需要细化到具体的属性，同时确保在代码级别可实现。\n\n##### 软件（Software）\nDDD 讨论下的软件是指，用于解决具体业务问题的计算机程序，既可以是单体也可以是分布式系统。\n\n软件设计是 DDD 的最终目的，使用 DDD 的各种工具可以指导软件设计，最终构建出健壮、容易维护的软件。\n\n##### 原则（Principle）\n为了更好的践行 DDD，需要遵守几个原则: 通用语言、聚焦核心域、协作共创和持续建模。\n\n这些原则是为了更好地服务业务，从业务驱动模型设计。\n\n##### 通用语言（Ubiquitous）\n通用语言（Ubiquitous language）是指在软件设计中，业务人员和开发人员需要使用无歧义的统一语言来对话。\n\n这些语言包括对概念的统一理解和定义，以及业务人员参与到软件建模中，否则业务的变化会造成软件巨大的变化。\n\n##### 聚焦核心域（Focus）\n核心域就是最关键的业务逻辑，聚焦核心域决定了软件的定位和投资重心。\n\n##### 协作共创（Collaboration）\n协作共创是指领域专家和业务专家共同建模。\n\n##### 持续建模（Continuous）\n持续建模是指模型需要随业务变化而被及时更新。\n\n##### 上下文（Context）\n上下文是语言学科的概念，指不同语境下的概念虽然相同的用词，可能具有不同的含义。\n\n在软件设计中，因为自然语言的原因，相同的用词导致实际是不同概念，会对建模和软件设计带来误导。同时，不同的上下文也是识别模型边界的手段。\n\n---\n\n#### 2.2、领域分析类概念\nDDD领域的相关概念。\n##### 问题空间（Problem Space）\n待解决的业务问题的集合。\n\n在 DDD 实践中，我们应该明确区分问题空间和解空间，避免混为一谈。\n\n##### 领域（Domain）\n领域（Domain）是业务相关知识的集合。\n\n通俗来说，领域就是业务知识。业务有一些内在规则，存在专业性，比如财务、CRM、OA、电商等不同领域的业务规则不同。计算机只是业务规则的自动化。\n\n##### 子域（Sub Domain）\n子域（Subdomain）是指在一个大的领域中划分出的相对独立的子领域，它通常代表一个独立的业务领域，具有特定的业务逻辑和功能需求。子域可以是整个系统的一个功能模块，也可以是一个独立的业务流程。\n\n##### 核心域（Core Domain）\n核心域是指领域中最核心的部分，通常对应企业的核心业务\n\n核心域需要我们投入最大精力，进行充分的分析。因为它是一个企业能运转的基础。\n\n##### 支撑域（Support Domain）\n“支撑域”（Supporting Domain）指的是与核心业务的实现和发展密切相关的非业务功能。这些支撑域可以包括安全认证、用户管理、日志记录等在整个系统中被多个子域所共享和使用的基础设施功能。支撑域和通用域概念上有些类似，区分他们的标准简单归纳下的话，支撑域是由外域提供的能力，通用域是本域提供。\n\n##### 通用域（General Domain）\n通用域（Generic Domain）是指与特定业务领域无关的通用功能，它是在整个领域中被多个子域所共享和复用的功能。通用域包括一些通用的服务、工具、组件等，用于支持多个子域的实现。\n\n---\n\n#### 2.3、建模类概念\nDDD领域设计相关模型的定义。\n##### 解空间（Solution Space）\n解空间是一个数学概念。是指满足问题的所有约束前提下，所有可行解的集合。在 DDD 的上下文中，指的是所有可能的解决方案的集合。\n\n解空间是相对问题空间存在的，认识到解空间存在的好处是解空间可以通过一些方法从问题空间导出，而不是通过猜测得出的。\n\n##### 领域模型（Model）\n领域模型（Model）是业务概念在程序中的一种表达方式。\n\n领域模型可以用来设计和理解整个软件结构。面向对象设计中的类概念是领域模型的一种表达方式。与此类似，UML的建模方法也可以应用在对领域模型的表达上。在 DDD 实践中，领域模型应当尽量简洁，能反应业务概念即可。\n\n##### 限界上下文（ Bounded context）\n限界上下文是有明确边界的上下文。在 DDD 实践中领域模型会被限定在限界上下文当中。\n\n限界上下文强调概念的一致性。虽然传统的方法学已经在追求概念的一致性，但是忽略了系统的庞大性，不论系统多庞大，在系统任何位置同一概念通用。DDD 不追求全局的一致性，而是将系统拆成多块，在相同的上下文中实现概念一致性。\n\n识别上下文可以从概念的二义性着手，比如商品的概念在物流、交易、支付含义完全不一样，但具有不同内涵和外延，实际上他们处在不同上下文。\n\n界限上下文可以用于微服务划分、避免模型的不正确复用带来的问题。\n\n##### 实体（Entity）\n实体（Entity）是在相同限界上下文中具有唯一标识的领域模型，可变，通过标识判断同一性。\n> 例：最简单的，公安系统的身份信息录入，对于人的模拟，即认为是实体，因为每个人是独一无二的，且其具有唯一标识（如公安系统分发的身份证号码）。\n\n1. **贫血模型** ：贫血模型是指领域对象只具有数据属性，缺乏相关的行为逻辑。在贫血模型中，业务逻辑主要存在于服务层或者其它外部对象中，领域对象仅被视为被动的数据容器。这种模型在领域驱动设计（DDD）中被认为是反模式，因为它无法更好地体现领域的核心概念和规则。\n2. **失血模型** ：和贫血模型相似，指的是领域对象缺少业务逻辑和领域行为，以至于数据和行为的重要部分都被丢失。这种模型经常出现在面向对象的开发中，尤其是基于关系数据库的实现中。\n3. **充血模型** ：充血模型是在领域对象中充分体现了业务逻辑和行为的模型。充血模型积极地包含了数据和相关的行为逻辑，它使得领域对象能够更好地封装与之相关的业务规则和行为，提供了更加一致和抽象的编程接口。充血模型是DDD中推崇的设计模式，使得领域对象能够成为业务规则的中心。\n4. **涨血模型** ：涨血模型是指在充血模型的基础上，进一步将领域对象的状态和行为扩展到前沿技术和新的设计模式中（有些理念力，涨血模型和充血模型的区别在于，涨血模型添加了持久层的行为）。\n\n> 充血模型虽然是DDD中推崇的设计模式，通过领域实体，一些关键行为和逻辑其实也能一起拿到了，但是在我的经验中，我更喜欢使用 贫血+充血的混合模型 （或者叫充血模型的简化版），因为这里涉及到一个标准的建立问题，如果只用充血模型的话，哪些行为和逻辑该下方到接口服务层，哪些又该收拢到实体中，这里面每个人的理念不一样。而我的标准是， 涉及到持久层和复杂行为都下放到服务层，简单行为放到实体模型中 。这样有个好处，随着业务的发展，如果只用充血模型，你的实体会越来越臃肿；如果只有贫血模型，自身又太单薄。所以一部分行为下放到服务层，我可以更细粒度的拆分服务接口，保证更优良的边界和代码可读性，同时也保证了模型自身的健壮性。\n最后，不论哪种模型，都没有绝对的好坏，能够很好的定义出设计标准，同时基于自己的理解设计出符合业务扩展的实体和服务就是好的模型。\n\n##### 值对象（Value Object）\n值对象 （Value Ojbect）是一种特殊的领域模型，不可变，通过值判断同一性。\n\n实体可以使用 ID 标识，但是值对象是用属性标识，任何属性的变化都视为新的值对象。比如一个银行账户，可以由 ID 唯一标识，币种和余额可以被修改但是还是同一个账户；交易单中的金额由币种和数值组成，无论修改哪一个属性，金额都不再是原来的金额。\n> 例：比如颜色信息，我们只需要知道{“name”:“黑色”，”css”:“#000000”}这样的值信息就能够满足要求了，这避免了我们对标识追踪带来的系统复杂性。\n\n值对象很重要，在习惯了使用数据库的数据建模后，很容易将所有对象看作实体。使用值对象，可以更好地做系统优化、精简设计。\n\n##### 聚合（Aggregate）\n聚合（Aggregate）是一组生命周期强一致，修改规则强关联的实体和值对象的集合，表达统一的业务意义。\n\n聚合的意义在于让业务统一、一致，在面向对象中有非常重要价值。比如，订单中有多个订单项，订单的总价是根据订单项目计算而来的。如果没有经验的开发者直接对订单项的做出修改，而不是由订单统一处理业务逻辑，会造成业务的一致性问题。\n\n聚合需要在相同的上下文中，不能跨上下文。\n\n##### 聚合根（ Aggregate Root）\n聚合根是聚合的根实体，它是一组相关对象的入口点，作为一个整体被外界访问，管理着聚合内其他对象的生命周期和完整性。聚合根通过封装聚合内部的对象，并定义了聚合的一致性边界，确保聚合内的对象之间的关系和约束得到维护。外部对象只能通过聚合根来访问和操作聚合内的对象，从而保证了聚合的完整性和一致性。\n> 聚合 = 聚合根实体 + 值对象 + 实体  组成。\n\n如何创建好的聚合？\n> 边界内的内容具有一致性：在一个事务中只修改一个聚合实例。如果你发现边界内很难接受强一致，不管是出于性能或产品需求的考虑，应该考虑剥离出独立的聚合，采用最终一致的方式。\n设计小聚合：大部分的聚合都可以只包含根实体，而无需包含其他实体。即使一定要包含，可以考虑将其创建为值对象。\n通过唯一标识来引用其他聚合或实体：当存在对象之间的关联时，建议引用其唯一标识而非引用其整体对象。如果是外部上下文中的实体，引用其唯一标识或将需要的属性构造值对象。 如果聚合创建复杂，推荐使用工厂方法来屏蔽内部复杂的创建逻辑。\n聚合内部多个组成对象的关系可以用来指导数据库创建，但不可避免存在一定的抗阻。如聚合中存在List<值对象>，那么在数据库中建立1:N的关联需要将值对象单独建表，此时是有id的，建议不要将该id暴露到资源库外部，对外隐蔽。\n\n\n---\n#### 2.4、软件设计类概念\n软件设计中的一些常见术语、常见技术等概念。\n##### 模块（Module）\n模块（Module）一组类或者对象组成的集合。\n\n在 DDD 实践中推荐使用限界上下文和聚合来指导模块划分。同时，如果不是特别复杂的业务逻辑也可以不遵循该模式。\n\n##### 仓储（Repository）\n仓储（Repository）是以持久化领域模型为职责的类。\n\n仓储的目的是屏蔽业务逻辑和持久化基础设施的差异。例如，对于同样的持久化业务需求，在采用关系型数据库和非关系型数据库作为存储基础设施时的实现细节是有所不同的。\n\n软件的设计往往是围绕着对数据的修改完成的。经验不多的开发者往往会认为，软件的开发过程就是对数据库的增删改查。但实际上基于该认知的软件设计让软件难以维护。\n\n对于采用关系数据库作为存储基础设施的项目，仓库层可以被 ORM 实现。若不使用 ORM，则需自己实现仓库。\n\n##### 服务（Service）\n服务（Service）是领域模型的操作者，负责领域内的业务规则的实现。\n\n领域模型用于承载数据和系统状态，服务承载业务逻辑的实践。\n\n在实践中如果使用主、客体的思维来进行设计，则服务为主体，领域模型为客体。使用拟人化的方式来对服务进行命名，可以让开发者更容易理解。比如，一个维护客户数据的 CRM 应用中，客户数据被抽象为模型： Client，对应的服务可以设计为：ClientManager。\n\n##### 工厂（Factory）\n工厂（Factory）是以构建领域模型（实体或值对象）为职责的类或方法。\n\n工厂可以利用不同的业务参数构建不同的领域模型。对于简单的业务逻辑实现可以不使用工厂。工厂的实现不一定是类的形式，也可以是具备工厂功能的方法。\n\n在面向对象程序设计中，工厂是一种设计模式。在广义的工厂模式中，工厂可以根据不同的规则的业务需求构造不同的对象。例如在 Redis 连接客户端的实现中，可以使用 Redis 单机、哨兵、集群等不同的方式来构建 Redis 连接客户端。\n\n##### 策略（Strategy）\n策略（Strategy）是业务规则的实现方式。\n\n例如通知业务，可以使用不同的渠道来实现，不同渠道的实现逻辑可以认为是不同的策略。 在面向对象程序设计中，策略模式也是一种设计模式，是多态的一种实现模式。\n\n策略通常会搭配着接口来设计。如果说接口是一种契约，那策略就是契约的履约方式。\n\n##### 规格（Specification）\n规格（Specification） 是一些特殊的业务规则。通常表现为用于校验（e.g. 数据格式，业务逻辑）、查询和搜索条件。\n\n在实践中，规格既可以被设计为灵活的查询或校验条件，也可以被抽象出来以便复用。\n\n例如，在 JPA、MongoDB、ElastiSearch和一些具有查询能力的 ORM 都大量使用这种设计方式，同样的在应用程序中我们也可以参考这种设计模式，把业务的规则提取出来。\n\n##### 分层架构（逻辑）\n分层架构是指在软件设计过程中按照既定的原则将不同的功能实现拆分到不同的层级进行实现的一种设计方式。每个层级有独立的职责，多个层次协同以提供完整功能。按照 DDD 的分层模型，通常可以划分为:接入层、应用层、领域层、基础设施层\n\n分层架构在具体的软件中可以表现为不同的形式。例如，在分布式系统中，不同层级的软件实现，可以表现为独立部署的服务。而在单体系统中，分层可以用不同的模块或包来实现。\n\n分层架构的设计理念与计算机网络的层级结构类似，上层依赖下层的实现，而下层实现无需关心上层实现。例如，HTTP 协议构建在 TCP 协议之上，TCP 协议只负责提供传输层的能力，而不需要知道具体的应用层协议。\n\n分层架构中层级的数量需要依照系统复杂度来定，并不需要死板地按照 DDD 推荐的四层来进行设计。在简单的系统中，可以通过减少分层来避免样板代码，减少冗余。例如，在 web 系统中有时候只有一种接入方式，接入层和应用层能力高度重叠，可以考虑直接使用应用层代替接入层。\n\n软件框架的使用，通常会引入新的层级，从而影响系统整体的分层架构。例如，ORM 框架本身就提供了对 Repository 的一层抽象。\n\n##### 接入层（Interface）\n接入层负责的是系统的输入和输出。\n\n接入层只关心沟通协议，不关心业务相关的数据校验。 接入层的实现是与业务应用强相关的，不同的业务应用有不同的实现方式。例如，对于普通的 Web 应用，基于 HTTP 协议的 API 是一种接入层实现方式；对于IoT传感器的数据上传业务，接入层的实现可能需要基于 websocket 或 MQTT 协议。\n\n接入层的特点：\n- 接入层对应用数据透明，只关心数据格式而不关心数据的内容\n- 在大部分单体系统中接入层通常被框架实现。例如，在 Spring Boot 框架中，HTTP 协议的 API 设计不需要关注 HTTP 协议本身。\n- 在分布式系统中接入层通常被网关实现。\n\n##### 应用层（Application）\n应用层，组织业务场景，编排业务，隔离场景对领域层的差异。\n\n应用层遵循面向对象核心思想中的 “关注点分离” 理念。应用层的关注点在于业务场景的处理。例如，对于一个服务多种类型用户的应用，to C 的网页界面和后台管理界面对应的是不同的业务场景。对于新用户注册这个业务来说，通过 to C 的网页注册和通过后台管理界面进行后台注册是不同的业务场景。然而，“用户注册”在系统层面的基本逻辑是一样的。所以，“用户注册”的基本业务逻辑可以交由领域层来实现。而两种不同渠道进行用户注册所需要进行的身份验证等逻辑，可以设计在应用层进行实现。这样便能达到关注点分离，复用核心业务逻辑的目的。\n\n应用层的特点：\n- 关心处理完一个完整的业务\n- 该层只负责业务编排，对象转换，而具体的业务逻辑由领域层实现\n- 虽不关心请求从何处来，但关心谁来、做什么、有没有权限做\n- 利用不同的领域服务来解决问题\n- 对最终一致性有要求的业务和事务处理需要放到应用层来处理\n- 功能权限放到这层\n\n##### 领域层（Domain）\n领域层，实现具体的业务逻辑、规则，为应用层提供无差别的服务能力。\n\n实际处理业务的地方，领域层需要对应用层提供无差别的服务和能力。例如，对于用户注册的场景，用户既可以通过邮箱自己注册，也可以由管理员在后台进行添加。用户注册的核心逻辑可以由领域层完成，但是对于不同渠道进行用户注册的参数校验和权限验证等逻辑则由应用层实现。\n\n领域层的特点：\n- 不关心场景，关心模型完整性和业务规则\n- 不关心谁来，不关心场景完整的业务，关心当前上下文的业务完整\n- 强一致性事务放到这层，聚合的事务是 “理所当然的”\n- 对应到分布式系统中的 domain service、后台等概念\n- 领域层做业务规则验证\n- 数据权限放到这层（比如只允许删除自己创建的商品），因为数据权限涉及业务规则\n- 根据业务情况，参考反范式理论，跨上下文使用值对象做必要的数据冗余\n\n##### 基础设施层（Infrastructure）\n基础设施层，提供具体的技术实现，比如存储，基础设施对业务保持透明。\n\n对于基础设施层来说，基础设施层并不是指 MySQL、Redis 等外部组件，而是外部组件的适配器，Hibernate、Mybatis、Redis Template 等，因此在 DDD 中适配器模式被多次提到，基础设施层往往不能单独存在，还是要依附于领域层。技术设施层的适配器还包括了外部系统的适配，互联网产品系统的外部系统非常多，常见的有活体监测、风控系统、税务发票等。\n\n技术设施层的特点：\n- 关心存储、通知、第三方系统等外部设施（防腐层隔离）\n- 基础设施的权限由配置到应用的凭证控制，例如数据库、对象存储的凭证，技术设施层不涉及用户的权限\n\n##### 部署架构（物理）\n部署架构是指具体的架构实现\n\n主要是在分布式系统、单体系统，甚至在客户端软件中体现。\n\n把逻辑架构和部署架构区分开可以很好的理解软件设计上和部署上的不同，对于应用构架来说，逻辑上的设计不一定对应部署结构。\n\n这样就很好理解 DDD 在不同场合中的使用方式，避免生搬硬套。当 DDD 的分层结构在单体应用中使用时，每层可能使用包、模块来表达，在微服务中使用时候，每层可能由不同角色的微服务来完成。\n\n##### 微服务（Micro Service）\n微服务是一种低耦合的分布式应用系统。\n\n维基百科的定义是：一种软件开发技术 - 面向服务的体系结构（SOA）架构样式的一种变体，将应用程序构造为一组松散耦合的服务。这个定义没有问题，但是忽略了一个重要的信息，微服务是一种分布式架构，微服务必须面对分布式系统的各种问题。\n\n分布式系统是通过计算机网络连接、协同工作的 IT 系统，因此在使用 DDD 时候，需要为这种系统做适配，而不是简单的做出切分。\n\n##### 单体（Monomer）\n单体是主要业务实现和部署在单一服务器上的应用。\n\n单体系统是相对于微服务来说的，其特点是主要的实现在单一的服务器中。\n\n##### 分布式应用系统（Distributed）\n分布式应用系统是建立在计算机网络之上的应用软件系统，不同单元通过计算机网络集成。\n\n---\n\n#### 2.5、事件风暴类概念\n\n##### 事件风暴（Event Storming）\n事件风暴是一种以工作坊的形式，使用 DDD 建模的方式。\n\n事件风暴的发明人是 Alberto Brandolini ，它来源于 Gamestorming，通过工作坊的方式将领域专家和技术专家拉到一起，进行建模。\n\n事件风暴是一种捕获行为需求的方法，类似传统软件的开发用例分析。所有人员（领域专家和技术专家） 对业务行为进行一次发散，并最终收敛达到业务的统一。\n\n##### 领域事件（Domain Event）\n事件是系统状态发生的某种客观现象，领域事件是和领域有关的事件。\n\n领域事件（Domain Event），是在业务上真实发生的客观事实，这些事实对系统会产生关键影响，是观察业务系统变化的关键点。领域事件一般是领域专家关心的。\n\n事件的评价方式是系统状态是否发生变化。系统状态变化意味着领域模型被业务规则操作，这是观察系统业务的好方法。\n\n识别领域事件的线索有：\n- 是否产生了某种数据\n- 系统状态是否发生变化，无论这种状态存放到数据库还是内存\n- 是否对外发送了某些消息\n\n\n##### 业务规则（Policy）\n业务规则是指对业务逻辑的定义和约束。\n\n不同的业务规则往往意味着不同的领域事件被触发，未来在技术实现时可能是一些分支条件，对应 DDD 实现中可能通过领域服务、规格、策略等方式实现。\n\n业务规则的识别是为了将数据和算法分开。\n\n##### 命令（Command）\n命令是执行者发起的操作，构成要件是执行者和行为。\n\n命令可以类比于 UML 分析中的业务用例，是某个场景中领域事件的触发动作。\n\n##### 执行者（Actor）\n执行者是指使用系统的主体，是导致系统状态变化的触发源。\n\n执行者有点像 UML 的涉众，不过区别是执行者不仅是用户，还包括外部系统和本系统。 在事件风暴中，执行者可以是：用户、外部系统、本系统、定时器。\n\n##### 用户（User）\n用户是执行者的一种，是指使用软件或服务的人。\n\n用户可以有不同的角色，通常我们会把不同角色的相似行为作为不同的命令来处理，有可能得到同样的事件。比如系统出现了商品已添加的事件，有可能有多个触发的场景： 1. 系统管理员在后台中添加 2. 商户在自己的管理平台中添加 3. 导入任务在特定时间添加\n\n1 2 是用户的行为，不过是不同的角色。\n\n##### 外部系统（Out System）\n外部系统是执行者的一种，系统开放 API 的调用发起者。\n\n有一些系统会提供对外的 API 给外部系统，这时候外部系统也会发出命令让系统产生事件，这里的外部系统特指作为执行者的外部系统。\n\n##### 本系统（System）\n本系统是执行者的一种，指系统本身。\n\n事件的触发可以由用户、外部系统、定时器触发，也可以由上一个事件触发，因此这里的触发者（主体）就是系统本身。\n\n##### 定时器（Timer）\n定时器是执行者的一种，通常是定时任务。\n\n定时器可以作为执行者，不过需要区别于本系统这个触发源。定时器可以看待为外部一个时间信号源，类似于计算机中主机中的振荡器。\n\n##### 参与人（Participants）\n作为工作坊的参与人员（应区别于执行者）。\n\n参与人只是一种角色，而非具体的一个人，可以是多个自然人做群体参与，也可以一人分饰不同的角色。\n\n在开始工作坊之前，参与人需要满足一些条件：\n- 参与人需要对解决的问题和产出目标达成共识\n- 参与人需要 DDD 的基本知识或接受过基本培训\n- 领域专家、技术专家需要能全程参加\n\n##### 领域专家（Domain Expert）\n领域专家是指熟悉业务规则的人，在工作坊中一般是能敲定业务规则的人。\n\n在实际的事件风暴工作坊中，领域专家是一个比技术专家更难获得人，一个合格的、能让工作坊进展下去的领域专家需要有几个要求：\n- 了解现有业务个情况\n- 能对具体的业务方向做出结论性的输出\n- 在做工作坊时，需要分清现状（As-IS）和目标（To-Be）业务，现状业务很多人都能说出来，不过真正的领域专家是能对目标业务做出描述的人。\n\n##### 技术专家（Tech Expert）\n技术专家是指熟悉技术方案和实现方式的人，能给出可行的技术方案和了解基础设计的限制条件。\n\n技术专家需要能对现有的技术做出描述，而未来的技术选型可能是动态的，能有一定预见性最好。技术专家往往是当前团队中最熟悉架构和代码的人。\n\n##### 主持人（Facilitator）\n主持人工作坊流程的推动者，以及 DDD 方法论的守护者。\n\n在一些工作坊中，主持人往往是外部的咨询师，他们有大量的实践经验，需要能对 DDD 的概念、方法有成体系的研究，并能推动工作坊进行。\n\n\n### 三、DDD 的优势和应用场景\n优势\n- 紧密贴合业务需求：通过与领域专家合作构建领域模型，能够确保软件系统准确地反映业务规则，减少因对业务理解偏差导致的软件功能不符合实际需求的情况。\n- 提高软件的可维护性和可扩展性：分层架构和限界上下文的划分使得系统的各个部分职责明确，当业务需求发生变化时，可以在相应的层次或限界上下文中进行修改，而不会对整个系统造成太大的影响。\n- 促进团队协作：DDD 强调领域专家和软件开发者的协作，有助于团队成员更好地理解业务，特别是对于新加入团队的成员，可以通过领域模型和限界上下文快速了解业务领域和系统架构。\n\n应用场景\n- 复杂业务领域的系统开发：如金融、电信、物流等行业的核心业务系统，这些领域业务规则复杂、业务流程长，DDD 可以有效地帮助梳理业务逻辑，构建高质量的软件系统。\n- 企业级应用集成（EAI）：在整合多个不同的企业内部系统或外部系统时，DDD 可以通过明确各系统的领域模型和限界上下文，更好地实现系统之间的交互和集成。\n\n\n\n参考文章：\n[DDD 概念参考](https://domain-driven-design.org/zh/ddd-concept-reference.html)        \n","source":"_posts/2024-08-28-架构-DDD概念.md","raw":"---\ntitle: 《架构》DDD概念\ndate: 2024-08-28 10:00:00\ncategories:\n  - [架构, DDD]\n---\n\n### 一、DDD\n![什么是DDD](2024-08-28-架构-DDD概念/什么是DDD.png)\n领域驱动设计（Domain-Driven Design，简称DDD），DDD 是一种软件开发方法。\n\n<!--more-->\n\n### 二、DDD 的主要概念\n\n![DDD基本概念图](2024-08-28-架构-DDD概念/DDD基本概念图.png)\n\n---\n\n#### 2.1、通过类相关概念\n一些通用的软件设计概念及DDD的概念。\n##### 领域驱动设计（DDD）\nDDD 是 Domain-Driven Design 的缩写，是 Eric Evans 于 2004 年提出的一种软件设计方法和理念。\n\n其主要的思想是，利用确定的业务模型来指导业务与应用的设计和实现。主张开发人员与业务人员持续地沟通和模型的持续迭代式演化，以保证业务模型与代码实现的一致性，从而实现有效管理业务复杂度，优化软件设计的目的。\n\n##### 模型（Model）\n通常，模型是对对象、人或系统的信息表示。它通过较为简单的信息结构来代表我们需要理解的复杂事物或系统。\n\n地图、乐高、算筹都是模型，模型可以简化复杂事务的认知。我们天生就有用简单的东西代表另外一个东西的能力，比如幼儿园数数用的竹签，学习物理时的刚体、真空中的球形鸡，都是模型。通俗来说模型就是经验的抽象集合，平时听到的谚语、公式、定理，本质上都是一种模型。\n\n##### 领域模型（Domain Model）\n是对领域内的概念类和它们之间关系的抽象表示。它是 DDD 的核心部分，通过领域模型可以清晰地描述业务领域的结构和行为。例如，在电商系统的订单处理领域中，领域模型可能包括 “订单” 类、“订单项” 类、“商品” 类以及它们之间的关联关系（如一个订单包含多个订单项，一个订单项对应一个商品）。这些类具有各自的属性（如订单的金额、订单项的数量、商品的价格等）和行为（如订单的创建、订单项的添加、商品价格的计算等）。\n\n##### 建模（Modeling）\n建模是构建模型的过程。\n\n在软件设计过程中，通过分析业务，将业务需求使用合适的模型表示出来，是建模的任务。模型可以作为业务分析的产出，并作为软件设计的重要理论基础。 比如在分析一个电商应用的业务时，抽象出订单、商品等概念，进一步定义出模型，并用合适的图例表达，往往是 UML 来表达。\n\n##### ⭐️领域建模\nDDD最关键的部分—— 领域建模 ，它的目的归纳起来就一句话： 提炼业务知识，形成统一语言，沉淀领域模型 。\n\n以下是领域建模的交付物：\n- **领域模型：** 包含领域对象、属性、关系、行为、边界范围等各个方面，用于描述业务的本质，这也是最重要的产出物。\n- **用例图：** 用于明确系统的功能。\n- **数据模型：** 描述系统的数据结构和关系，包括实体关系模型、关系数据库模型等。\n- **状态图：** 用于描述系统各个状态及其转移条件。\n- **活动图：** 用于描述系统流程中的各个活动及其关系。\n- **序列图：** 描述系统中各个对象之间的交互过程和消息传递序列。\n- **架构模型：** 包含系统的物理和逻辑结构，包括组件、模块、接口等。\n\n##### 模型驱动设计（Model-Driven Design）\n面向模型的分析设计方法，优先通过识别模型来简化业务设计。\n\n在设计过程中，以模型为中心，始终维护模型，并基于此指导软件设计。\n\n##### 软件设计（The Software Design）\n软件设计软件需求出发，对软件系统的整体结构、模块做出划分和规划，以便于具体代码的顺利编写。\n\n由于软件需求具有非结构化、准确的语义，软件设计往往通过经验完成，无法通过某种特定的推理路线严格推导实现。\n\n##### 战略设计（Strategic Design）\n战略设计也称为战略建模，是指对业务进行高层次的抽象和归类。主要手段包括理清上下文和进行子域的划分。\n\n战略设计关注模型的分离，其解决的问题是大的模型如何划分为小模型以及相互之间如何关联。战略设计的产出可以用于指导团队协作，使得规模巨大的软件可以被合理拆分。\n\n战略设计的产出通常为上下文图，以及模块或微服务划分。\n\n##### 战术设计（Tactical design）\n战术设计也称为战术建模，是指对特定上下文下的模型进行详细设计。\n\n战术设计的对象包括聚合、实体和值对象，其目标是用明确它们是什么以及相互之间有何关系。战术设计的产出可以是用 UML 表达的类图，需要细化到具体的属性，同时确保在代码级别可实现。\n\n##### 软件（Software）\nDDD 讨论下的软件是指，用于解决具体业务问题的计算机程序，既可以是单体也可以是分布式系统。\n\n软件设计是 DDD 的最终目的，使用 DDD 的各种工具可以指导软件设计，最终构建出健壮、容易维护的软件。\n\n##### 原则（Principle）\n为了更好的践行 DDD，需要遵守几个原则: 通用语言、聚焦核心域、协作共创和持续建模。\n\n这些原则是为了更好地服务业务，从业务驱动模型设计。\n\n##### 通用语言（Ubiquitous）\n通用语言（Ubiquitous language）是指在软件设计中，业务人员和开发人员需要使用无歧义的统一语言来对话。\n\n这些语言包括对概念的统一理解和定义，以及业务人员参与到软件建模中，否则业务的变化会造成软件巨大的变化。\n\n##### 聚焦核心域（Focus）\n核心域就是最关键的业务逻辑，聚焦核心域决定了软件的定位和投资重心。\n\n##### 协作共创（Collaboration）\n协作共创是指领域专家和业务专家共同建模。\n\n##### 持续建模（Continuous）\n持续建模是指模型需要随业务变化而被及时更新。\n\n##### 上下文（Context）\n上下文是语言学科的概念，指不同语境下的概念虽然相同的用词，可能具有不同的含义。\n\n在软件设计中，因为自然语言的原因，相同的用词导致实际是不同概念，会对建模和软件设计带来误导。同时，不同的上下文也是识别模型边界的手段。\n\n---\n\n#### 2.2、领域分析类概念\nDDD领域的相关概念。\n##### 问题空间（Problem Space）\n待解决的业务问题的集合。\n\n在 DDD 实践中，我们应该明确区分问题空间和解空间，避免混为一谈。\n\n##### 领域（Domain）\n领域（Domain）是业务相关知识的集合。\n\n通俗来说，领域就是业务知识。业务有一些内在规则，存在专业性，比如财务、CRM、OA、电商等不同领域的业务规则不同。计算机只是业务规则的自动化。\n\n##### 子域（Sub Domain）\n子域（Subdomain）是指在一个大的领域中划分出的相对独立的子领域，它通常代表一个独立的业务领域，具有特定的业务逻辑和功能需求。子域可以是整个系统的一个功能模块，也可以是一个独立的业务流程。\n\n##### 核心域（Core Domain）\n核心域是指领域中最核心的部分，通常对应企业的核心业务\n\n核心域需要我们投入最大精力，进行充分的分析。因为它是一个企业能运转的基础。\n\n##### 支撑域（Support Domain）\n“支撑域”（Supporting Domain）指的是与核心业务的实现和发展密切相关的非业务功能。这些支撑域可以包括安全认证、用户管理、日志记录等在整个系统中被多个子域所共享和使用的基础设施功能。支撑域和通用域概念上有些类似，区分他们的标准简单归纳下的话，支撑域是由外域提供的能力，通用域是本域提供。\n\n##### 通用域（General Domain）\n通用域（Generic Domain）是指与特定业务领域无关的通用功能，它是在整个领域中被多个子域所共享和复用的功能。通用域包括一些通用的服务、工具、组件等，用于支持多个子域的实现。\n\n---\n\n#### 2.3、建模类概念\nDDD领域设计相关模型的定义。\n##### 解空间（Solution Space）\n解空间是一个数学概念。是指满足问题的所有约束前提下，所有可行解的集合。在 DDD 的上下文中，指的是所有可能的解决方案的集合。\n\n解空间是相对问题空间存在的，认识到解空间存在的好处是解空间可以通过一些方法从问题空间导出，而不是通过猜测得出的。\n\n##### 领域模型（Model）\n领域模型（Model）是业务概念在程序中的一种表达方式。\n\n领域模型可以用来设计和理解整个软件结构。面向对象设计中的类概念是领域模型的一种表达方式。与此类似，UML的建模方法也可以应用在对领域模型的表达上。在 DDD 实践中，领域模型应当尽量简洁，能反应业务概念即可。\n\n##### 限界上下文（ Bounded context）\n限界上下文是有明确边界的上下文。在 DDD 实践中领域模型会被限定在限界上下文当中。\n\n限界上下文强调概念的一致性。虽然传统的方法学已经在追求概念的一致性，但是忽略了系统的庞大性，不论系统多庞大，在系统任何位置同一概念通用。DDD 不追求全局的一致性，而是将系统拆成多块，在相同的上下文中实现概念一致性。\n\n识别上下文可以从概念的二义性着手，比如商品的概念在物流、交易、支付含义完全不一样，但具有不同内涵和外延，实际上他们处在不同上下文。\n\n界限上下文可以用于微服务划分、避免模型的不正确复用带来的问题。\n\n##### 实体（Entity）\n实体（Entity）是在相同限界上下文中具有唯一标识的领域模型，可变，通过标识判断同一性。\n> 例：最简单的，公安系统的身份信息录入，对于人的模拟，即认为是实体，因为每个人是独一无二的，且其具有唯一标识（如公安系统分发的身份证号码）。\n\n1. **贫血模型** ：贫血模型是指领域对象只具有数据属性，缺乏相关的行为逻辑。在贫血模型中，业务逻辑主要存在于服务层或者其它外部对象中，领域对象仅被视为被动的数据容器。这种模型在领域驱动设计（DDD）中被认为是反模式，因为它无法更好地体现领域的核心概念和规则。\n2. **失血模型** ：和贫血模型相似，指的是领域对象缺少业务逻辑和领域行为，以至于数据和行为的重要部分都被丢失。这种模型经常出现在面向对象的开发中，尤其是基于关系数据库的实现中。\n3. **充血模型** ：充血模型是在领域对象中充分体现了业务逻辑和行为的模型。充血模型积极地包含了数据和相关的行为逻辑，它使得领域对象能够更好地封装与之相关的业务规则和行为，提供了更加一致和抽象的编程接口。充血模型是DDD中推崇的设计模式，使得领域对象能够成为业务规则的中心。\n4. **涨血模型** ：涨血模型是指在充血模型的基础上，进一步将领域对象的状态和行为扩展到前沿技术和新的设计模式中（有些理念力，涨血模型和充血模型的区别在于，涨血模型添加了持久层的行为）。\n\n> 充血模型虽然是DDD中推崇的设计模式，通过领域实体，一些关键行为和逻辑其实也能一起拿到了，但是在我的经验中，我更喜欢使用 贫血+充血的混合模型 （或者叫充血模型的简化版），因为这里涉及到一个标准的建立问题，如果只用充血模型的话，哪些行为和逻辑该下方到接口服务层，哪些又该收拢到实体中，这里面每个人的理念不一样。而我的标准是， 涉及到持久层和复杂行为都下放到服务层，简单行为放到实体模型中 。这样有个好处，随着业务的发展，如果只用充血模型，你的实体会越来越臃肿；如果只有贫血模型，自身又太单薄。所以一部分行为下放到服务层，我可以更细粒度的拆分服务接口，保证更优良的边界和代码可读性，同时也保证了模型自身的健壮性。\n最后，不论哪种模型，都没有绝对的好坏，能够很好的定义出设计标准，同时基于自己的理解设计出符合业务扩展的实体和服务就是好的模型。\n\n##### 值对象（Value Object）\n值对象 （Value Ojbect）是一种特殊的领域模型，不可变，通过值判断同一性。\n\n实体可以使用 ID 标识，但是值对象是用属性标识，任何属性的变化都视为新的值对象。比如一个银行账户，可以由 ID 唯一标识，币种和余额可以被修改但是还是同一个账户；交易单中的金额由币种和数值组成，无论修改哪一个属性，金额都不再是原来的金额。\n> 例：比如颜色信息，我们只需要知道{“name”:“黑色”，”css”:“#000000”}这样的值信息就能够满足要求了，这避免了我们对标识追踪带来的系统复杂性。\n\n值对象很重要，在习惯了使用数据库的数据建模后，很容易将所有对象看作实体。使用值对象，可以更好地做系统优化、精简设计。\n\n##### 聚合（Aggregate）\n聚合（Aggregate）是一组生命周期强一致，修改规则强关联的实体和值对象的集合，表达统一的业务意义。\n\n聚合的意义在于让业务统一、一致，在面向对象中有非常重要价值。比如，订单中有多个订单项，订单的总价是根据订单项目计算而来的。如果没有经验的开发者直接对订单项的做出修改，而不是由订单统一处理业务逻辑，会造成业务的一致性问题。\n\n聚合需要在相同的上下文中，不能跨上下文。\n\n##### 聚合根（ Aggregate Root）\n聚合根是聚合的根实体，它是一组相关对象的入口点，作为一个整体被外界访问，管理着聚合内其他对象的生命周期和完整性。聚合根通过封装聚合内部的对象，并定义了聚合的一致性边界，确保聚合内的对象之间的关系和约束得到维护。外部对象只能通过聚合根来访问和操作聚合内的对象，从而保证了聚合的完整性和一致性。\n> 聚合 = 聚合根实体 + 值对象 + 实体  组成。\n\n如何创建好的聚合？\n> 边界内的内容具有一致性：在一个事务中只修改一个聚合实例。如果你发现边界内很难接受强一致，不管是出于性能或产品需求的考虑，应该考虑剥离出独立的聚合，采用最终一致的方式。\n设计小聚合：大部分的聚合都可以只包含根实体，而无需包含其他实体。即使一定要包含，可以考虑将其创建为值对象。\n通过唯一标识来引用其他聚合或实体：当存在对象之间的关联时，建议引用其唯一标识而非引用其整体对象。如果是外部上下文中的实体，引用其唯一标识或将需要的属性构造值对象。 如果聚合创建复杂，推荐使用工厂方法来屏蔽内部复杂的创建逻辑。\n聚合内部多个组成对象的关系可以用来指导数据库创建，但不可避免存在一定的抗阻。如聚合中存在List<值对象>，那么在数据库中建立1:N的关联需要将值对象单独建表，此时是有id的，建议不要将该id暴露到资源库外部，对外隐蔽。\n\n\n---\n#### 2.4、软件设计类概念\n软件设计中的一些常见术语、常见技术等概念。\n##### 模块（Module）\n模块（Module）一组类或者对象组成的集合。\n\n在 DDD 实践中推荐使用限界上下文和聚合来指导模块划分。同时，如果不是特别复杂的业务逻辑也可以不遵循该模式。\n\n##### 仓储（Repository）\n仓储（Repository）是以持久化领域模型为职责的类。\n\n仓储的目的是屏蔽业务逻辑和持久化基础设施的差异。例如，对于同样的持久化业务需求，在采用关系型数据库和非关系型数据库作为存储基础设施时的实现细节是有所不同的。\n\n软件的设计往往是围绕着对数据的修改完成的。经验不多的开发者往往会认为，软件的开发过程就是对数据库的增删改查。但实际上基于该认知的软件设计让软件难以维护。\n\n对于采用关系数据库作为存储基础设施的项目，仓库层可以被 ORM 实现。若不使用 ORM，则需自己实现仓库。\n\n##### 服务（Service）\n服务（Service）是领域模型的操作者，负责领域内的业务规则的实现。\n\n领域模型用于承载数据和系统状态，服务承载业务逻辑的实践。\n\n在实践中如果使用主、客体的思维来进行设计，则服务为主体，领域模型为客体。使用拟人化的方式来对服务进行命名，可以让开发者更容易理解。比如，一个维护客户数据的 CRM 应用中，客户数据被抽象为模型： Client，对应的服务可以设计为：ClientManager。\n\n##### 工厂（Factory）\n工厂（Factory）是以构建领域模型（实体或值对象）为职责的类或方法。\n\n工厂可以利用不同的业务参数构建不同的领域模型。对于简单的业务逻辑实现可以不使用工厂。工厂的实现不一定是类的形式，也可以是具备工厂功能的方法。\n\n在面向对象程序设计中，工厂是一种设计模式。在广义的工厂模式中，工厂可以根据不同的规则的业务需求构造不同的对象。例如在 Redis 连接客户端的实现中，可以使用 Redis 单机、哨兵、集群等不同的方式来构建 Redis 连接客户端。\n\n##### 策略（Strategy）\n策略（Strategy）是业务规则的实现方式。\n\n例如通知业务，可以使用不同的渠道来实现，不同渠道的实现逻辑可以认为是不同的策略。 在面向对象程序设计中，策略模式也是一种设计模式，是多态的一种实现模式。\n\n策略通常会搭配着接口来设计。如果说接口是一种契约，那策略就是契约的履约方式。\n\n##### 规格（Specification）\n规格（Specification） 是一些特殊的业务规则。通常表现为用于校验（e.g. 数据格式，业务逻辑）、查询和搜索条件。\n\n在实践中，规格既可以被设计为灵活的查询或校验条件，也可以被抽象出来以便复用。\n\n例如，在 JPA、MongoDB、ElastiSearch和一些具有查询能力的 ORM 都大量使用这种设计方式，同样的在应用程序中我们也可以参考这种设计模式，把业务的规则提取出来。\n\n##### 分层架构（逻辑）\n分层架构是指在软件设计过程中按照既定的原则将不同的功能实现拆分到不同的层级进行实现的一种设计方式。每个层级有独立的职责，多个层次协同以提供完整功能。按照 DDD 的分层模型，通常可以划分为:接入层、应用层、领域层、基础设施层\n\n分层架构在具体的软件中可以表现为不同的形式。例如，在分布式系统中，不同层级的软件实现，可以表现为独立部署的服务。而在单体系统中，分层可以用不同的模块或包来实现。\n\n分层架构的设计理念与计算机网络的层级结构类似，上层依赖下层的实现，而下层实现无需关心上层实现。例如，HTTP 协议构建在 TCP 协议之上，TCP 协议只负责提供传输层的能力，而不需要知道具体的应用层协议。\n\n分层架构中层级的数量需要依照系统复杂度来定，并不需要死板地按照 DDD 推荐的四层来进行设计。在简单的系统中，可以通过减少分层来避免样板代码，减少冗余。例如，在 web 系统中有时候只有一种接入方式，接入层和应用层能力高度重叠，可以考虑直接使用应用层代替接入层。\n\n软件框架的使用，通常会引入新的层级，从而影响系统整体的分层架构。例如，ORM 框架本身就提供了对 Repository 的一层抽象。\n\n##### 接入层（Interface）\n接入层负责的是系统的输入和输出。\n\n接入层只关心沟通协议，不关心业务相关的数据校验。 接入层的实现是与业务应用强相关的，不同的业务应用有不同的实现方式。例如，对于普通的 Web 应用，基于 HTTP 协议的 API 是一种接入层实现方式；对于IoT传感器的数据上传业务，接入层的实现可能需要基于 websocket 或 MQTT 协议。\n\n接入层的特点：\n- 接入层对应用数据透明，只关心数据格式而不关心数据的内容\n- 在大部分单体系统中接入层通常被框架实现。例如，在 Spring Boot 框架中，HTTP 协议的 API 设计不需要关注 HTTP 协议本身。\n- 在分布式系统中接入层通常被网关实现。\n\n##### 应用层（Application）\n应用层，组织业务场景，编排业务，隔离场景对领域层的差异。\n\n应用层遵循面向对象核心思想中的 “关注点分离” 理念。应用层的关注点在于业务场景的处理。例如，对于一个服务多种类型用户的应用，to C 的网页界面和后台管理界面对应的是不同的业务场景。对于新用户注册这个业务来说，通过 to C 的网页注册和通过后台管理界面进行后台注册是不同的业务场景。然而，“用户注册”在系统层面的基本逻辑是一样的。所以，“用户注册”的基本业务逻辑可以交由领域层来实现。而两种不同渠道进行用户注册所需要进行的身份验证等逻辑，可以设计在应用层进行实现。这样便能达到关注点分离，复用核心业务逻辑的目的。\n\n应用层的特点：\n- 关心处理完一个完整的业务\n- 该层只负责业务编排，对象转换，而具体的业务逻辑由领域层实现\n- 虽不关心请求从何处来，但关心谁来、做什么、有没有权限做\n- 利用不同的领域服务来解决问题\n- 对最终一致性有要求的业务和事务处理需要放到应用层来处理\n- 功能权限放到这层\n\n##### 领域层（Domain）\n领域层，实现具体的业务逻辑、规则，为应用层提供无差别的服务能力。\n\n实际处理业务的地方，领域层需要对应用层提供无差别的服务和能力。例如，对于用户注册的场景，用户既可以通过邮箱自己注册，也可以由管理员在后台进行添加。用户注册的核心逻辑可以由领域层完成，但是对于不同渠道进行用户注册的参数校验和权限验证等逻辑则由应用层实现。\n\n领域层的特点：\n- 不关心场景，关心模型完整性和业务规则\n- 不关心谁来，不关心场景完整的业务，关心当前上下文的业务完整\n- 强一致性事务放到这层，聚合的事务是 “理所当然的”\n- 对应到分布式系统中的 domain service、后台等概念\n- 领域层做业务规则验证\n- 数据权限放到这层（比如只允许删除自己创建的商品），因为数据权限涉及业务规则\n- 根据业务情况，参考反范式理论，跨上下文使用值对象做必要的数据冗余\n\n##### 基础设施层（Infrastructure）\n基础设施层，提供具体的技术实现，比如存储，基础设施对业务保持透明。\n\n对于基础设施层来说，基础设施层并不是指 MySQL、Redis 等外部组件，而是外部组件的适配器，Hibernate、Mybatis、Redis Template 等，因此在 DDD 中适配器模式被多次提到，基础设施层往往不能单独存在，还是要依附于领域层。技术设施层的适配器还包括了外部系统的适配，互联网产品系统的外部系统非常多，常见的有活体监测、风控系统、税务发票等。\n\n技术设施层的特点：\n- 关心存储、通知、第三方系统等外部设施（防腐层隔离）\n- 基础设施的权限由配置到应用的凭证控制，例如数据库、对象存储的凭证，技术设施层不涉及用户的权限\n\n##### 部署架构（物理）\n部署架构是指具体的架构实现\n\n主要是在分布式系统、单体系统，甚至在客户端软件中体现。\n\n把逻辑架构和部署架构区分开可以很好的理解软件设计上和部署上的不同，对于应用构架来说，逻辑上的设计不一定对应部署结构。\n\n这样就很好理解 DDD 在不同场合中的使用方式，避免生搬硬套。当 DDD 的分层结构在单体应用中使用时，每层可能使用包、模块来表达，在微服务中使用时候，每层可能由不同角色的微服务来完成。\n\n##### 微服务（Micro Service）\n微服务是一种低耦合的分布式应用系统。\n\n维基百科的定义是：一种软件开发技术 - 面向服务的体系结构（SOA）架构样式的一种变体，将应用程序构造为一组松散耦合的服务。这个定义没有问题，但是忽略了一个重要的信息，微服务是一种分布式架构，微服务必须面对分布式系统的各种问题。\n\n分布式系统是通过计算机网络连接、协同工作的 IT 系统，因此在使用 DDD 时候，需要为这种系统做适配，而不是简单的做出切分。\n\n##### 单体（Monomer）\n单体是主要业务实现和部署在单一服务器上的应用。\n\n单体系统是相对于微服务来说的，其特点是主要的实现在单一的服务器中。\n\n##### 分布式应用系统（Distributed）\n分布式应用系统是建立在计算机网络之上的应用软件系统，不同单元通过计算机网络集成。\n\n---\n\n#### 2.5、事件风暴类概念\n\n##### 事件风暴（Event Storming）\n事件风暴是一种以工作坊的形式，使用 DDD 建模的方式。\n\n事件风暴的发明人是 Alberto Brandolini ，它来源于 Gamestorming，通过工作坊的方式将领域专家和技术专家拉到一起，进行建模。\n\n事件风暴是一种捕获行为需求的方法，类似传统软件的开发用例分析。所有人员（领域专家和技术专家） 对业务行为进行一次发散，并最终收敛达到业务的统一。\n\n##### 领域事件（Domain Event）\n事件是系统状态发生的某种客观现象，领域事件是和领域有关的事件。\n\n领域事件（Domain Event），是在业务上真实发生的客观事实，这些事实对系统会产生关键影响，是观察业务系统变化的关键点。领域事件一般是领域专家关心的。\n\n事件的评价方式是系统状态是否发生变化。系统状态变化意味着领域模型被业务规则操作，这是观察系统业务的好方法。\n\n识别领域事件的线索有：\n- 是否产生了某种数据\n- 系统状态是否发生变化，无论这种状态存放到数据库还是内存\n- 是否对外发送了某些消息\n\n\n##### 业务规则（Policy）\n业务规则是指对业务逻辑的定义和约束。\n\n不同的业务规则往往意味着不同的领域事件被触发，未来在技术实现时可能是一些分支条件，对应 DDD 实现中可能通过领域服务、规格、策略等方式实现。\n\n业务规则的识别是为了将数据和算法分开。\n\n##### 命令（Command）\n命令是执行者发起的操作，构成要件是执行者和行为。\n\n命令可以类比于 UML 分析中的业务用例，是某个场景中领域事件的触发动作。\n\n##### 执行者（Actor）\n执行者是指使用系统的主体，是导致系统状态变化的触发源。\n\n执行者有点像 UML 的涉众，不过区别是执行者不仅是用户，还包括外部系统和本系统。 在事件风暴中，执行者可以是：用户、外部系统、本系统、定时器。\n\n##### 用户（User）\n用户是执行者的一种，是指使用软件或服务的人。\n\n用户可以有不同的角色，通常我们会把不同角色的相似行为作为不同的命令来处理，有可能得到同样的事件。比如系统出现了商品已添加的事件，有可能有多个触发的场景： 1. 系统管理员在后台中添加 2. 商户在自己的管理平台中添加 3. 导入任务在特定时间添加\n\n1 2 是用户的行为，不过是不同的角色。\n\n##### 外部系统（Out System）\n外部系统是执行者的一种，系统开放 API 的调用发起者。\n\n有一些系统会提供对外的 API 给外部系统，这时候外部系统也会发出命令让系统产生事件，这里的外部系统特指作为执行者的外部系统。\n\n##### 本系统（System）\n本系统是执行者的一种，指系统本身。\n\n事件的触发可以由用户、外部系统、定时器触发，也可以由上一个事件触发，因此这里的触发者（主体）就是系统本身。\n\n##### 定时器（Timer）\n定时器是执行者的一种，通常是定时任务。\n\n定时器可以作为执行者，不过需要区别于本系统这个触发源。定时器可以看待为外部一个时间信号源，类似于计算机中主机中的振荡器。\n\n##### 参与人（Participants）\n作为工作坊的参与人员（应区别于执行者）。\n\n参与人只是一种角色，而非具体的一个人，可以是多个自然人做群体参与，也可以一人分饰不同的角色。\n\n在开始工作坊之前，参与人需要满足一些条件：\n- 参与人需要对解决的问题和产出目标达成共识\n- 参与人需要 DDD 的基本知识或接受过基本培训\n- 领域专家、技术专家需要能全程参加\n\n##### 领域专家（Domain Expert）\n领域专家是指熟悉业务规则的人，在工作坊中一般是能敲定业务规则的人。\n\n在实际的事件风暴工作坊中，领域专家是一个比技术专家更难获得人，一个合格的、能让工作坊进展下去的领域专家需要有几个要求：\n- 了解现有业务个情况\n- 能对具体的业务方向做出结论性的输出\n- 在做工作坊时，需要分清现状（As-IS）和目标（To-Be）业务，现状业务很多人都能说出来，不过真正的领域专家是能对目标业务做出描述的人。\n\n##### 技术专家（Tech Expert）\n技术专家是指熟悉技术方案和实现方式的人，能给出可行的技术方案和了解基础设计的限制条件。\n\n技术专家需要能对现有的技术做出描述，而未来的技术选型可能是动态的，能有一定预见性最好。技术专家往往是当前团队中最熟悉架构和代码的人。\n\n##### 主持人（Facilitator）\n主持人工作坊流程的推动者，以及 DDD 方法论的守护者。\n\n在一些工作坊中，主持人往往是外部的咨询师，他们有大量的实践经验，需要能对 DDD 的概念、方法有成体系的研究，并能推动工作坊进行。\n\n\n### 三、DDD 的优势和应用场景\n优势\n- 紧密贴合业务需求：通过与领域专家合作构建领域模型，能够确保软件系统准确地反映业务规则，减少因对业务理解偏差导致的软件功能不符合实际需求的情况。\n- 提高软件的可维护性和可扩展性：分层架构和限界上下文的划分使得系统的各个部分职责明确，当业务需求发生变化时，可以在相应的层次或限界上下文中进行修改，而不会对整个系统造成太大的影响。\n- 促进团队协作：DDD 强调领域专家和软件开发者的协作，有助于团队成员更好地理解业务，特别是对于新加入团队的成员，可以通过领域模型和限界上下文快速了解业务领域和系统架构。\n\n应用场景\n- 复杂业务领域的系统开发：如金融、电信、物流等行业的核心业务系统，这些领域业务规则复杂、业务流程长，DDD 可以有效地帮助梳理业务逻辑，构建高质量的软件系统。\n- 企业级应用集成（EAI）：在整合多个不同的企业内部系统或外部系统时，DDD 可以通过明确各系统的领域模型和限界上下文，更好地实现系统之间的交互和集成。\n\n\n\n参考文章：\n[DDD 概念参考](https://domain-driven-design.org/zh/ddd-concept-reference.html)        \n","slug":"2024-08-28-架构-DDD概念","published":1,"updated":"2024-12-03T14:51:47.059Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm4gqpo2x00aka13ks9mlekgr","content":"<h3 id=\"一、DDD\"><a href=\"#一、DDD\" class=\"headerlink\" title=\"一、DDD\"></a>一、DDD</h3><p><img src=\"/2024/08/28/2024-08-28-架构-DDD概念/%E4%BB%80%E4%B9%88%E6%98%AFDDD.png\" alt=\"什么是DDD\"><br>领域驱动设计（Domain-Driven Design，简称DDD），DDD 是一种软件开发方法。</p>\n<a id=\"more\"></a>\n\n<h3 id=\"二、DDD-的主要概念\"><a href=\"#二、DDD-的主要概念\" class=\"headerlink\" title=\"二、DDD 的主要概念\"></a>二、DDD 的主要概念</h3><p><img src=\"/2024/08/28/2024-08-28-架构-DDD概念/DDD%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%9B%BE.png\" alt=\"DDD基本概念图\"></p>\n<hr>\n<h4 id=\"2-1、通过类相关概念\"><a href=\"#2-1、通过类相关概念\" class=\"headerlink\" title=\"2.1、通过类相关概念\"></a>2.1、通过类相关概念</h4><p>一些通用的软件设计概念及DDD的概念。</p>\n<h5 id=\"领域驱动设计（DDD）\"><a href=\"#领域驱动设计（DDD）\" class=\"headerlink\" title=\"领域驱动设计（DDD）\"></a>领域驱动设计（DDD）</h5><p>DDD 是 Domain-Driven Design 的缩写，是 Eric Evans 于 2004 年提出的一种软件设计方法和理念。</p>\n<p>其主要的思想是，利用确定的业务模型来指导业务与应用的设计和实现。主张开发人员与业务人员持续地沟通和模型的持续迭代式演化，以保证业务模型与代码实现的一致性，从而实现有效管理业务复杂度，优化软件设计的目的。</p>\n<h5 id=\"模型（Model）\"><a href=\"#模型（Model）\" class=\"headerlink\" title=\"模型（Model）\"></a>模型（Model）</h5><p>通常，模型是对对象、人或系统的信息表示。它通过较为简单的信息结构来代表我们需要理解的复杂事物或系统。</p>\n<p>地图、乐高、算筹都是模型，模型可以简化复杂事务的认知。我们天生就有用简单的东西代表另外一个东西的能力，比如幼儿园数数用的竹签，学习物理时的刚体、真空中的球形鸡，都是模型。通俗来说模型就是经验的抽象集合，平时听到的谚语、公式、定理，本质上都是一种模型。</p>\n<h5 id=\"领域模型（Domain-Model）\"><a href=\"#领域模型（Domain-Model）\" class=\"headerlink\" title=\"领域模型（Domain Model）\"></a>领域模型（Domain Model）</h5><p>是对领域内的概念类和它们之间关系的抽象表示。它是 DDD 的核心部分，通过领域模型可以清晰地描述业务领域的结构和行为。例如，在电商系统的订单处理领域中，领域模型可能包括 “订单” 类、“订单项” 类、“商品” 类以及它们之间的关联关系（如一个订单包含多个订单项，一个订单项对应一个商品）。这些类具有各自的属性（如订单的金额、订单项的数量、商品的价格等）和行为（如订单的创建、订单项的添加、商品价格的计算等）。</p>\n<h5 id=\"建模（Modeling）\"><a href=\"#建模（Modeling）\" class=\"headerlink\" title=\"建模（Modeling）\"></a>建模（Modeling）</h5><p>建模是构建模型的过程。</p>\n<p>在软件设计过程中，通过分析业务，将业务需求使用合适的模型表示出来，是建模的任务。模型可以作为业务分析的产出，并作为软件设计的重要理论基础。 比如在分析一个电商应用的业务时，抽象出订单、商品等概念，进一步定义出模型，并用合适的图例表达，往往是 UML 来表达。</p>\n<h5 id=\"⭐️领域建模\"><a href=\"#⭐️领域建模\" class=\"headerlink\" title=\"⭐️领域建模\"></a>⭐️领域建模</h5><p>DDD最关键的部分—— 领域建模 ，它的目的归纳起来就一句话： 提炼业务知识，形成统一语言，沉淀领域模型 。</p>\n<p>以下是领域建模的交付物：</p>\n<ul>\n<li><strong>领域模型：</strong> 包含领域对象、属性、关系、行为、边界范围等各个方面，用于描述业务的本质，这也是最重要的产出物。</li>\n<li><strong>用例图：</strong> 用于明确系统的功能。</li>\n<li><strong>数据模型：</strong> 描述系统的数据结构和关系，包括实体关系模型、关系数据库模型等。</li>\n<li><strong>状态图：</strong> 用于描述系统各个状态及其转移条件。</li>\n<li><strong>活动图：</strong> 用于描述系统流程中的各个活动及其关系。</li>\n<li><strong>序列图：</strong> 描述系统中各个对象之间的交互过程和消息传递序列。</li>\n<li><strong>架构模型：</strong> 包含系统的物理和逻辑结构，包括组件、模块、接口等。</li>\n</ul>\n<h5 id=\"模型驱动设计（Model-Driven-Design）\"><a href=\"#模型驱动设计（Model-Driven-Design）\" class=\"headerlink\" title=\"模型驱动设计（Model-Driven Design）\"></a>模型驱动设计（Model-Driven Design）</h5><p>面向模型的分析设计方法，优先通过识别模型来简化业务设计。</p>\n<p>在设计过程中，以模型为中心，始终维护模型，并基于此指导软件设计。</p>\n<h5 id=\"软件设计（The-Software-Design）\"><a href=\"#软件设计（The-Software-Design）\" class=\"headerlink\" title=\"软件设计（The Software Design）\"></a>软件设计（The Software Design）</h5><p>软件设计软件需求出发，对软件系统的整体结构、模块做出划分和规划，以便于具体代码的顺利编写。</p>\n<p>由于软件需求具有非结构化、准确的语义，软件设计往往通过经验完成，无法通过某种特定的推理路线严格推导实现。</p>\n<h5 id=\"战略设计（Strategic-Design）\"><a href=\"#战略设计（Strategic-Design）\" class=\"headerlink\" title=\"战略设计（Strategic Design）\"></a>战略设计（Strategic Design）</h5><p>战略设计也称为战略建模，是指对业务进行高层次的抽象和归类。主要手段包括理清上下文和进行子域的划分。</p>\n<p>战略设计关注模型的分离，其解决的问题是大的模型如何划分为小模型以及相互之间如何关联。战略设计的产出可以用于指导团队协作，使得规模巨大的软件可以被合理拆分。</p>\n<p>战略设计的产出通常为上下文图，以及模块或微服务划分。</p>\n<h5 id=\"战术设计（Tactical-design）\"><a href=\"#战术设计（Tactical-design）\" class=\"headerlink\" title=\"战术设计（Tactical design）\"></a>战术设计（Tactical design）</h5><p>战术设计也称为战术建模，是指对特定上下文下的模型进行详细设计。</p>\n<p>战术设计的对象包括聚合、实体和值对象，其目标是用明确它们是什么以及相互之间有何关系。战术设计的产出可以是用 UML 表达的类图，需要细化到具体的属性，同时确保在代码级别可实现。</p>\n<h5 id=\"软件（Software）\"><a href=\"#软件（Software）\" class=\"headerlink\" title=\"软件（Software）\"></a>软件（Software）</h5><p>DDD 讨论下的软件是指，用于解决具体业务问题的计算机程序，既可以是单体也可以是分布式系统。</p>\n<p>软件设计是 DDD 的最终目的，使用 DDD 的各种工具可以指导软件设计，最终构建出健壮、容易维护的软件。</p>\n<h5 id=\"原则（Principle）\"><a href=\"#原则（Principle）\" class=\"headerlink\" title=\"原则（Principle）\"></a>原则（Principle）</h5><p>为了更好的践行 DDD，需要遵守几个原则: 通用语言、聚焦核心域、协作共创和持续建模。</p>\n<p>这些原则是为了更好地服务业务，从业务驱动模型设计。</p>\n<h5 id=\"通用语言（Ubiquitous）\"><a href=\"#通用语言（Ubiquitous）\" class=\"headerlink\" title=\"通用语言（Ubiquitous）\"></a>通用语言（Ubiquitous）</h5><p>通用语言（Ubiquitous language）是指在软件设计中，业务人员和开发人员需要使用无歧义的统一语言来对话。</p>\n<p>这些语言包括对概念的统一理解和定义，以及业务人员参与到软件建模中，否则业务的变化会造成软件巨大的变化。</p>\n<h5 id=\"聚焦核心域（Focus）\"><a href=\"#聚焦核心域（Focus）\" class=\"headerlink\" title=\"聚焦核心域（Focus）\"></a>聚焦核心域（Focus）</h5><p>核心域就是最关键的业务逻辑，聚焦核心域决定了软件的定位和投资重心。</p>\n<h5 id=\"协作共创（Collaboration）\"><a href=\"#协作共创（Collaboration）\" class=\"headerlink\" title=\"协作共创（Collaboration）\"></a>协作共创（Collaboration）</h5><p>协作共创是指领域专家和业务专家共同建模。</p>\n<h5 id=\"持续建模（Continuous）\"><a href=\"#持续建模（Continuous）\" class=\"headerlink\" title=\"持续建模（Continuous）\"></a>持续建模（Continuous）</h5><p>持续建模是指模型需要随业务变化而被及时更新。</p>\n<h5 id=\"上下文（Context）\"><a href=\"#上下文（Context）\" class=\"headerlink\" title=\"上下文（Context）\"></a>上下文（Context）</h5><p>上下文是语言学科的概念，指不同语境下的概念虽然相同的用词，可能具有不同的含义。</p>\n<p>在软件设计中，因为自然语言的原因，相同的用词导致实际是不同概念，会对建模和软件设计带来误导。同时，不同的上下文也是识别模型边界的手段。</p>\n<hr>\n<h4 id=\"2-2、领域分析类概念\"><a href=\"#2-2、领域分析类概念\" class=\"headerlink\" title=\"2.2、领域分析类概念\"></a>2.2、领域分析类概念</h4><p>DDD领域的相关概念。</p>\n<h5 id=\"问题空间（Problem-Space）\"><a href=\"#问题空间（Problem-Space）\" class=\"headerlink\" title=\"问题空间（Problem Space）\"></a>问题空间（Problem Space）</h5><p>待解决的业务问题的集合。</p>\n<p>在 DDD 实践中，我们应该明确区分问题空间和解空间，避免混为一谈。</p>\n<h5 id=\"领域（Domain）\"><a href=\"#领域（Domain）\" class=\"headerlink\" title=\"领域（Domain）\"></a>领域（Domain）</h5><p>领域（Domain）是业务相关知识的集合。</p>\n<p>通俗来说，领域就是业务知识。业务有一些内在规则，存在专业性，比如财务、CRM、OA、电商等不同领域的业务规则不同。计算机只是业务规则的自动化。</p>\n<h5 id=\"子域（Sub-Domain）\"><a href=\"#子域（Sub-Domain）\" class=\"headerlink\" title=\"子域（Sub Domain）\"></a>子域（Sub Domain）</h5><p>子域（Subdomain）是指在一个大的领域中划分出的相对独立的子领域，它通常代表一个独立的业务领域，具有特定的业务逻辑和功能需求。子域可以是整个系统的一个功能模块，也可以是一个独立的业务流程。</p>\n<h5 id=\"核心域（Core-Domain）\"><a href=\"#核心域（Core-Domain）\" class=\"headerlink\" title=\"核心域（Core Domain）\"></a>核心域（Core Domain）</h5><p>核心域是指领域中最核心的部分，通常对应企业的核心业务</p>\n<p>核心域需要我们投入最大精力，进行充分的分析。因为它是一个企业能运转的基础。</p>\n<h5 id=\"支撑域（Support-Domain）\"><a href=\"#支撑域（Support-Domain）\" class=\"headerlink\" title=\"支撑域（Support Domain）\"></a>支撑域（Support Domain）</h5><p>“支撑域”（Supporting Domain）指的是与核心业务的实现和发展密切相关的非业务功能。这些支撑域可以包括安全认证、用户管理、日志记录等在整个系统中被多个子域所共享和使用的基础设施功能。支撑域和通用域概念上有些类似，区分他们的标准简单归纳下的话，支撑域是由外域提供的能力，通用域是本域提供。</p>\n<h5 id=\"通用域（General-Domain）\"><a href=\"#通用域（General-Domain）\" class=\"headerlink\" title=\"通用域（General Domain）\"></a>通用域（General Domain）</h5><p>通用域（Generic Domain）是指与特定业务领域无关的通用功能，它是在整个领域中被多个子域所共享和复用的功能。通用域包括一些通用的服务、工具、组件等，用于支持多个子域的实现。</p>\n<hr>\n<h4 id=\"2-3、建模类概念\"><a href=\"#2-3、建模类概念\" class=\"headerlink\" title=\"2.3、建模类概念\"></a>2.3、建模类概念</h4><p>DDD领域设计相关模型的定义。</p>\n<h5 id=\"解空间（Solution-Space）\"><a href=\"#解空间（Solution-Space）\" class=\"headerlink\" title=\"解空间（Solution Space）\"></a>解空间（Solution Space）</h5><p>解空间是一个数学概念。是指满足问题的所有约束前提下，所有可行解的集合。在 DDD 的上下文中，指的是所有可能的解决方案的集合。</p>\n<p>解空间是相对问题空间存在的，认识到解空间存在的好处是解空间可以通过一些方法从问题空间导出，而不是通过猜测得出的。</p>\n<h5 id=\"领域模型（Model）\"><a href=\"#领域模型（Model）\" class=\"headerlink\" title=\"领域模型（Model）\"></a>领域模型（Model）</h5><p>领域模型（Model）是业务概念在程序中的一种表达方式。</p>\n<p>领域模型可以用来设计和理解整个软件结构。面向对象设计中的类概念是领域模型的一种表达方式。与此类似，UML的建模方法也可以应用在对领域模型的表达上。在 DDD 实践中，领域模型应当尽量简洁，能反应业务概念即可。</p>\n<h5 id=\"限界上下文（-Bounded-context）\"><a href=\"#限界上下文（-Bounded-context）\" class=\"headerlink\" title=\"限界上下文（ Bounded context）\"></a>限界上下文（ Bounded context）</h5><p>限界上下文是有明确边界的上下文。在 DDD 实践中领域模型会被限定在限界上下文当中。</p>\n<p>限界上下文强调概念的一致性。虽然传统的方法学已经在追求概念的一致性，但是忽略了系统的庞大性，不论系统多庞大，在系统任何位置同一概念通用。DDD 不追求全局的一致性，而是将系统拆成多块，在相同的上下文中实现概念一致性。</p>\n<p>识别上下文可以从概念的二义性着手，比如商品的概念在物流、交易、支付含义完全不一样，但具有不同内涵和外延，实际上他们处在不同上下文。</p>\n<p>界限上下文可以用于微服务划分、避免模型的不正确复用带来的问题。</p>\n<h5 id=\"实体（Entity）\"><a href=\"#实体（Entity）\" class=\"headerlink\" title=\"实体（Entity）\"></a>实体（Entity）</h5><p>实体（Entity）是在相同限界上下文中具有唯一标识的领域模型，可变，通过标识判断同一性。</p>\n<blockquote>\n<p>例：最简单的，公安系统的身份信息录入，对于人的模拟，即认为是实体，因为每个人是独一无二的，且其具有唯一标识（如公安系统分发的身份证号码）。</p>\n</blockquote>\n<ol>\n<li><strong>贫血模型</strong> ：贫血模型是指领域对象只具有数据属性，缺乏相关的行为逻辑。在贫血模型中，业务逻辑主要存在于服务层或者其它外部对象中，领域对象仅被视为被动的数据容器。这种模型在领域驱动设计（DDD）中被认为是反模式，因为它无法更好地体现领域的核心概念和规则。</li>\n<li><strong>失血模型</strong> ：和贫血模型相似，指的是领域对象缺少业务逻辑和领域行为，以至于数据和行为的重要部分都被丢失。这种模型经常出现在面向对象的开发中，尤其是基于关系数据库的实现中。</li>\n<li><strong>充血模型</strong> ：充血模型是在领域对象中充分体现了业务逻辑和行为的模型。充血模型积极地包含了数据和相关的行为逻辑，它使得领域对象能够更好地封装与之相关的业务规则和行为，提供了更加一致和抽象的编程接口。充血模型是DDD中推崇的设计模式，使得领域对象能够成为业务规则的中心。</li>\n<li><strong>涨血模型</strong> ：涨血模型是指在充血模型的基础上，进一步将领域对象的状态和行为扩展到前沿技术和新的设计模式中（有些理念力，涨血模型和充血模型的区别在于，涨血模型添加了持久层的行为）。</li>\n</ol>\n<blockquote>\n<p>充血模型虽然是DDD中推崇的设计模式，通过领域实体，一些关键行为和逻辑其实也能一起拿到了，但是在我的经验中，我更喜欢使用 贫血+充血的混合模型 （或者叫充血模型的简化版），因为这里涉及到一个标准的建立问题，如果只用充血模型的话，哪些行为和逻辑该下方到接口服务层，哪些又该收拢到实体中，这里面每个人的理念不一样。而我的标准是， 涉及到持久层和复杂行为都下放到服务层，简单行为放到实体模型中 。这样有个好处，随着业务的发展，如果只用充血模型，你的实体会越来越臃肿；如果只有贫血模型，自身又太单薄。所以一部分行为下放到服务层，我可以更细粒度的拆分服务接口，保证更优良的边界和代码可读性，同时也保证了模型自身的健壮性。<br>最后，不论哪种模型，都没有绝对的好坏，能够很好的定义出设计标准，同时基于自己的理解设计出符合业务扩展的实体和服务就是好的模型。</p>\n</blockquote>\n<h5 id=\"值对象（Value-Object）\"><a href=\"#值对象（Value-Object）\" class=\"headerlink\" title=\"值对象（Value Object）\"></a>值对象（Value Object）</h5><p>值对象 （Value Ojbect）是一种特殊的领域模型，不可变，通过值判断同一性。</p>\n<p>实体可以使用 ID 标识，但是值对象是用属性标识，任何属性的变化都视为新的值对象。比如一个银行账户，可以由 ID 唯一标识，币种和余额可以被修改但是还是同一个账户；交易单中的金额由币种和数值组成，无论修改哪一个属性，金额都不再是原来的金额。</p>\n<blockquote>\n<p>例：比如颜色信息，我们只需要知道{“name”:“黑色”，”css”:“#000000”}这样的值信息就能够满足要求了，这避免了我们对标识追踪带来的系统复杂性。</p>\n</blockquote>\n<p>值对象很重要，在习惯了使用数据库的数据建模后，很容易将所有对象看作实体。使用值对象，可以更好地做系统优化、精简设计。</p>\n<h5 id=\"聚合（Aggregate）\"><a href=\"#聚合（Aggregate）\" class=\"headerlink\" title=\"聚合（Aggregate）\"></a>聚合（Aggregate）</h5><p>聚合（Aggregate）是一组生命周期强一致，修改规则强关联的实体和值对象的集合，表达统一的业务意义。</p>\n<p>聚合的意义在于让业务统一、一致，在面向对象中有非常重要价值。比如，订单中有多个订单项，订单的总价是根据订单项目计算而来的。如果没有经验的开发者直接对订单项的做出修改，而不是由订单统一处理业务逻辑，会造成业务的一致性问题。</p>\n<p>聚合需要在相同的上下文中，不能跨上下文。</p>\n<h5 id=\"聚合根（-Aggregate-Root）\"><a href=\"#聚合根（-Aggregate-Root）\" class=\"headerlink\" title=\"聚合根（ Aggregate Root）\"></a>聚合根（ Aggregate Root）</h5><p>聚合根是聚合的根实体，它是一组相关对象的入口点，作为一个整体被外界访问，管理着聚合内其他对象的生命周期和完整性。聚合根通过封装聚合内部的对象，并定义了聚合的一致性边界，确保聚合内的对象之间的关系和约束得到维护。外部对象只能通过聚合根来访问和操作聚合内的对象，从而保证了聚合的完整性和一致性。</p>\n<blockquote>\n<p>聚合 = 聚合根实体 + 值对象 + 实体  组成。</p>\n</blockquote>\n<p>如何创建好的聚合？</p>\n<blockquote>\n<p>边界内的内容具有一致性：在一个事务中只修改一个聚合实例。如果你发现边界内很难接受强一致，不管是出于性能或产品需求的考虑，应该考虑剥离出独立的聚合，采用最终一致的方式。<br>设计小聚合：大部分的聚合都可以只包含根实体，而无需包含其他实体。即使一定要包含，可以考虑将其创建为值对象。<br>通过唯一标识来引用其他聚合或实体：当存在对象之间的关联时，建议引用其唯一标识而非引用其整体对象。如果是外部上下文中的实体，引用其唯一标识或将需要的属性构造值对象。 如果聚合创建复杂，推荐使用工厂方法来屏蔽内部复杂的创建逻辑。<br>聚合内部多个组成对象的关系可以用来指导数据库创建，但不可避免存在一定的抗阻。如聚合中存在List&lt;值对象&gt;，那么在数据库中建立1:N的关联需要将值对象单独建表，此时是有id的，建议不要将该id暴露到资源库外部，对外隐蔽。</p>\n</blockquote>\n<hr>\n<h4 id=\"2-4、软件设计类概念\"><a href=\"#2-4、软件设计类概念\" class=\"headerlink\" title=\"2.4、软件设计类概念\"></a>2.4、软件设计类概念</h4><p>软件设计中的一些常见术语、常见技术等概念。</p>\n<h5 id=\"模块（Module）\"><a href=\"#模块（Module）\" class=\"headerlink\" title=\"模块（Module）\"></a>模块（Module）</h5><p>模块（Module）一组类或者对象组成的集合。</p>\n<p>在 DDD 实践中推荐使用限界上下文和聚合来指导模块划分。同时，如果不是特别复杂的业务逻辑也可以不遵循该模式。</p>\n<h5 id=\"仓储（Repository）\"><a href=\"#仓储（Repository）\" class=\"headerlink\" title=\"仓储（Repository）\"></a>仓储（Repository）</h5><p>仓储（Repository）是以持久化领域模型为职责的类。</p>\n<p>仓储的目的是屏蔽业务逻辑和持久化基础设施的差异。例如，对于同样的持久化业务需求，在采用关系型数据库和非关系型数据库作为存储基础设施时的实现细节是有所不同的。</p>\n<p>软件的设计往往是围绕着对数据的修改完成的。经验不多的开发者往往会认为，软件的开发过程就是对数据库的增删改查。但实际上基于该认知的软件设计让软件难以维护。</p>\n<p>对于采用关系数据库作为存储基础设施的项目，仓库层可以被 ORM 实现。若不使用 ORM，则需自己实现仓库。</p>\n<h5 id=\"服务（Service）\"><a href=\"#服务（Service）\" class=\"headerlink\" title=\"服务（Service）\"></a>服务（Service）</h5><p>服务（Service）是领域模型的操作者，负责领域内的业务规则的实现。</p>\n<p>领域模型用于承载数据和系统状态，服务承载业务逻辑的实践。</p>\n<p>在实践中如果使用主、客体的思维来进行设计，则服务为主体，领域模型为客体。使用拟人化的方式来对服务进行命名，可以让开发者更容易理解。比如，一个维护客户数据的 CRM 应用中，客户数据被抽象为模型： Client，对应的服务可以设计为：ClientManager。</p>\n<h5 id=\"工厂（Factory）\"><a href=\"#工厂（Factory）\" class=\"headerlink\" title=\"工厂（Factory）\"></a>工厂（Factory）</h5><p>工厂（Factory）是以构建领域模型（实体或值对象）为职责的类或方法。</p>\n<p>工厂可以利用不同的业务参数构建不同的领域模型。对于简单的业务逻辑实现可以不使用工厂。工厂的实现不一定是类的形式，也可以是具备工厂功能的方法。</p>\n<p>在面向对象程序设计中，工厂是一种设计模式。在广义的工厂模式中，工厂可以根据不同的规则的业务需求构造不同的对象。例如在 Redis 连接客户端的实现中，可以使用 Redis 单机、哨兵、集群等不同的方式来构建 Redis 连接客户端。</p>\n<h5 id=\"策略（Strategy）\"><a href=\"#策略（Strategy）\" class=\"headerlink\" title=\"策略（Strategy）\"></a>策略（Strategy）</h5><p>策略（Strategy）是业务规则的实现方式。</p>\n<p>例如通知业务，可以使用不同的渠道来实现，不同渠道的实现逻辑可以认为是不同的策略。 在面向对象程序设计中，策略模式也是一种设计模式，是多态的一种实现模式。</p>\n<p>策略通常会搭配着接口来设计。如果说接口是一种契约，那策略就是契约的履约方式。</p>\n<h5 id=\"规格（Specification）\"><a href=\"#规格（Specification）\" class=\"headerlink\" title=\"规格（Specification）\"></a>规格（Specification）</h5><p>规格（Specification） 是一些特殊的业务规则。通常表现为用于校验（e.g. 数据格式，业务逻辑）、查询和搜索条件。</p>\n<p>在实践中，规格既可以被设计为灵活的查询或校验条件，也可以被抽象出来以便复用。</p>\n<p>例如，在 JPA、MongoDB、ElastiSearch和一些具有查询能力的 ORM 都大量使用这种设计方式，同样的在应用程序中我们也可以参考这种设计模式，把业务的规则提取出来。</p>\n<h5 id=\"分层架构（逻辑）\"><a href=\"#分层架构（逻辑）\" class=\"headerlink\" title=\"分层架构（逻辑）\"></a>分层架构（逻辑）</h5><p>分层架构是指在软件设计过程中按照既定的原则将不同的功能实现拆分到不同的层级进行实现的一种设计方式。每个层级有独立的职责，多个层次协同以提供完整功能。按照 DDD 的分层模型，通常可以划分为:接入层、应用层、领域层、基础设施层</p>\n<p>分层架构在具体的软件中可以表现为不同的形式。例如，在分布式系统中，不同层级的软件实现，可以表现为独立部署的服务。而在单体系统中，分层可以用不同的模块或包来实现。</p>\n<p>分层架构的设计理念与计算机网络的层级结构类似，上层依赖下层的实现，而下层实现无需关心上层实现。例如，HTTP 协议构建在 TCP 协议之上，TCP 协议只负责提供传输层的能力，而不需要知道具体的应用层协议。</p>\n<p>分层架构中层级的数量需要依照系统复杂度来定，并不需要死板地按照 DDD 推荐的四层来进行设计。在简单的系统中，可以通过减少分层来避免样板代码，减少冗余。例如，在 web 系统中有时候只有一种接入方式，接入层和应用层能力高度重叠，可以考虑直接使用应用层代替接入层。</p>\n<p>软件框架的使用，通常会引入新的层级，从而影响系统整体的分层架构。例如，ORM 框架本身就提供了对 Repository 的一层抽象。</p>\n<h5 id=\"接入层（Interface）\"><a href=\"#接入层（Interface）\" class=\"headerlink\" title=\"接入层（Interface）\"></a>接入层（Interface）</h5><p>接入层负责的是系统的输入和输出。</p>\n<p>接入层只关心沟通协议，不关心业务相关的数据校验。 接入层的实现是与业务应用强相关的，不同的业务应用有不同的实现方式。例如，对于普通的 Web 应用，基于 HTTP 协议的 API 是一种接入层实现方式；对于IoT传感器的数据上传业务，接入层的实现可能需要基于 websocket 或 MQTT 协议。</p>\n<p>接入层的特点：</p>\n<ul>\n<li>接入层对应用数据透明，只关心数据格式而不关心数据的内容</li>\n<li>在大部分单体系统中接入层通常被框架实现。例如，在 Spring Boot 框架中，HTTP 协议的 API 设计不需要关注 HTTP 协议本身。</li>\n<li>在分布式系统中接入层通常被网关实现。</li>\n</ul>\n<h5 id=\"应用层（Application）\"><a href=\"#应用层（Application）\" class=\"headerlink\" title=\"应用层（Application）\"></a>应用层（Application）</h5><p>应用层，组织业务场景，编排业务，隔离场景对领域层的差异。</p>\n<p>应用层遵循面向对象核心思想中的 “关注点分离” 理念。应用层的关注点在于业务场景的处理。例如，对于一个服务多种类型用户的应用，to C 的网页界面和后台管理界面对应的是不同的业务场景。对于新用户注册这个业务来说，通过 to C 的网页注册和通过后台管理界面进行后台注册是不同的业务场景。然而，“用户注册”在系统层面的基本逻辑是一样的。所以，“用户注册”的基本业务逻辑可以交由领域层来实现。而两种不同渠道进行用户注册所需要进行的身份验证等逻辑，可以设计在应用层进行实现。这样便能达到关注点分离，复用核心业务逻辑的目的。</p>\n<p>应用层的特点：</p>\n<ul>\n<li>关心处理完一个完整的业务</li>\n<li>该层只负责业务编排，对象转换，而具体的业务逻辑由领域层实现</li>\n<li>虽不关心请求从何处来，但关心谁来、做什么、有没有权限做</li>\n<li>利用不同的领域服务来解决问题</li>\n<li>对最终一致性有要求的业务和事务处理需要放到应用层来处理</li>\n<li>功能权限放到这层</li>\n</ul>\n<h5 id=\"领域层（Domain）\"><a href=\"#领域层（Domain）\" class=\"headerlink\" title=\"领域层（Domain）\"></a>领域层（Domain）</h5><p>领域层，实现具体的业务逻辑、规则，为应用层提供无差别的服务能力。</p>\n<p>实际处理业务的地方，领域层需要对应用层提供无差别的服务和能力。例如，对于用户注册的场景，用户既可以通过邮箱自己注册，也可以由管理员在后台进行添加。用户注册的核心逻辑可以由领域层完成，但是对于不同渠道进行用户注册的参数校验和权限验证等逻辑则由应用层实现。</p>\n<p>领域层的特点：</p>\n<ul>\n<li>不关心场景，关心模型完整性和业务规则</li>\n<li>不关心谁来，不关心场景完整的业务，关心当前上下文的业务完整</li>\n<li>强一致性事务放到这层，聚合的事务是 “理所当然的”</li>\n<li>对应到分布式系统中的 domain service、后台等概念</li>\n<li>领域层做业务规则验证</li>\n<li>数据权限放到这层（比如只允许删除自己创建的商品），因为数据权限涉及业务规则</li>\n<li>根据业务情况，参考反范式理论，跨上下文使用值对象做必要的数据冗余</li>\n</ul>\n<h5 id=\"基础设施层（Infrastructure）\"><a href=\"#基础设施层（Infrastructure）\" class=\"headerlink\" title=\"基础设施层（Infrastructure）\"></a>基础设施层（Infrastructure）</h5><p>基础设施层，提供具体的技术实现，比如存储，基础设施对业务保持透明。</p>\n<p>对于基础设施层来说，基础设施层并不是指 MySQL、Redis 等外部组件，而是外部组件的适配器，Hibernate、Mybatis、Redis Template 等，因此在 DDD 中适配器模式被多次提到，基础设施层往往不能单独存在，还是要依附于领域层。技术设施层的适配器还包括了外部系统的适配，互联网产品系统的外部系统非常多，常见的有活体监测、风控系统、税务发票等。</p>\n<p>技术设施层的特点：</p>\n<ul>\n<li>关心存储、通知、第三方系统等外部设施（防腐层隔离）</li>\n<li>基础设施的权限由配置到应用的凭证控制，例如数据库、对象存储的凭证，技术设施层不涉及用户的权限</li>\n</ul>\n<h5 id=\"部署架构（物理）\"><a href=\"#部署架构（物理）\" class=\"headerlink\" title=\"部署架构（物理）\"></a>部署架构（物理）</h5><p>部署架构是指具体的架构实现</p>\n<p>主要是在分布式系统、单体系统，甚至在客户端软件中体现。</p>\n<p>把逻辑架构和部署架构区分开可以很好的理解软件设计上和部署上的不同，对于应用构架来说，逻辑上的设计不一定对应部署结构。</p>\n<p>这样就很好理解 DDD 在不同场合中的使用方式，避免生搬硬套。当 DDD 的分层结构在单体应用中使用时，每层可能使用包、模块来表达，在微服务中使用时候，每层可能由不同角色的微服务来完成。</p>\n<h5 id=\"微服务（Micro-Service）\"><a href=\"#微服务（Micro-Service）\" class=\"headerlink\" title=\"微服务（Micro Service）\"></a>微服务（Micro Service）</h5><p>微服务是一种低耦合的分布式应用系统。</p>\n<p>维基百科的定义是：一种软件开发技术 - 面向服务的体系结构（SOA）架构样式的一种变体，将应用程序构造为一组松散耦合的服务。这个定义没有问题，但是忽略了一个重要的信息，微服务是一种分布式架构，微服务必须面对分布式系统的各种问题。</p>\n<p>分布式系统是通过计算机网络连接、协同工作的 IT 系统，因此在使用 DDD 时候，需要为这种系统做适配，而不是简单的做出切分。</p>\n<h5 id=\"单体（Monomer）\"><a href=\"#单体（Monomer）\" class=\"headerlink\" title=\"单体（Monomer）\"></a>单体（Monomer）</h5><p>单体是主要业务实现和部署在单一服务器上的应用。</p>\n<p>单体系统是相对于微服务来说的，其特点是主要的实现在单一的服务器中。</p>\n<h5 id=\"分布式应用系统（Distributed）\"><a href=\"#分布式应用系统（Distributed）\" class=\"headerlink\" title=\"分布式应用系统（Distributed）\"></a>分布式应用系统（Distributed）</h5><p>分布式应用系统是建立在计算机网络之上的应用软件系统，不同单元通过计算机网络集成。</p>\n<hr>\n<h4 id=\"2-5、事件风暴类概念\"><a href=\"#2-5、事件风暴类概念\" class=\"headerlink\" title=\"2.5、事件风暴类概念\"></a>2.5、事件风暴类概念</h4><h5 id=\"事件风暴（Event-Storming）\"><a href=\"#事件风暴（Event-Storming）\" class=\"headerlink\" title=\"事件风暴（Event Storming）\"></a>事件风暴（Event Storming）</h5><p>事件风暴是一种以工作坊的形式，使用 DDD 建模的方式。</p>\n<p>事件风暴的发明人是 Alberto Brandolini ，它来源于 Gamestorming，通过工作坊的方式将领域专家和技术专家拉到一起，进行建模。</p>\n<p>事件风暴是一种捕获行为需求的方法，类似传统软件的开发用例分析。所有人员（领域专家和技术专家） 对业务行为进行一次发散，并最终收敛达到业务的统一。</p>\n<h5 id=\"领域事件（Domain-Event）\"><a href=\"#领域事件（Domain-Event）\" class=\"headerlink\" title=\"领域事件（Domain Event）\"></a>领域事件（Domain Event）</h5><p>事件是系统状态发生的某种客观现象，领域事件是和领域有关的事件。</p>\n<p>领域事件（Domain Event），是在业务上真实发生的客观事实，这些事实对系统会产生关键影响，是观察业务系统变化的关键点。领域事件一般是领域专家关心的。</p>\n<p>事件的评价方式是系统状态是否发生变化。系统状态变化意味着领域模型被业务规则操作，这是观察系统业务的好方法。</p>\n<p>识别领域事件的线索有：</p>\n<ul>\n<li>是否产生了某种数据</li>\n<li>系统状态是否发生变化，无论这种状态存放到数据库还是内存</li>\n<li>是否对外发送了某些消息</li>\n</ul>\n<h5 id=\"业务规则（Policy）\"><a href=\"#业务规则（Policy）\" class=\"headerlink\" title=\"业务规则（Policy）\"></a>业务规则（Policy）</h5><p>业务规则是指对业务逻辑的定义和约束。</p>\n<p>不同的业务规则往往意味着不同的领域事件被触发，未来在技术实现时可能是一些分支条件，对应 DDD 实现中可能通过领域服务、规格、策略等方式实现。</p>\n<p>业务规则的识别是为了将数据和算法分开。</p>\n<h5 id=\"命令（Command）\"><a href=\"#命令（Command）\" class=\"headerlink\" title=\"命令（Command）\"></a>命令（Command）</h5><p>命令是执行者发起的操作，构成要件是执行者和行为。</p>\n<p>命令可以类比于 UML 分析中的业务用例，是某个场景中领域事件的触发动作。</p>\n<h5 id=\"执行者（Actor）\"><a href=\"#执行者（Actor）\" class=\"headerlink\" title=\"执行者（Actor）\"></a>执行者（Actor）</h5><p>执行者是指使用系统的主体，是导致系统状态变化的触发源。</p>\n<p>执行者有点像 UML 的涉众，不过区别是执行者不仅是用户，还包括外部系统和本系统。 在事件风暴中，执行者可以是：用户、外部系统、本系统、定时器。</p>\n<h5 id=\"用户（User）\"><a href=\"#用户（User）\" class=\"headerlink\" title=\"用户（User）\"></a>用户（User）</h5><p>用户是执行者的一种，是指使用软件或服务的人。</p>\n<p>用户可以有不同的角色，通常我们会把不同角色的相似行为作为不同的命令来处理，有可能得到同样的事件。比如系统出现了商品已添加的事件，有可能有多个触发的场景： 1. 系统管理员在后台中添加 2. 商户在自己的管理平台中添加 3. 导入任务在特定时间添加</p>\n<p>1 2 是用户的行为，不过是不同的角色。</p>\n<h5 id=\"外部系统（Out-System）\"><a href=\"#外部系统（Out-System）\" class=\"headerlink\" title=\"外部系统（Out System）\"></a>外部系统（Out System）</h5><p>外部系统是执行者的一种，系统开放 API 的调用发起者。</p>\n<p>有一些系统会提供对外的 API 给外部系统，这时候外部系统也会发出命令让系统产生事件，这里的外部系统特指作为执行者的外部系统。</p>\n<h5 id=\"本系统（System）\"><a href=\"#本系统（System）\" class=\"headerlink\" title=\"本系统（System）\"></a>本系统（System）</h5><p>本系统是执行者的一种，指系统本身。</p>\n<p>事件的触发可以由用户、外部系统、定时器触发，也可以由上一个事件触发，因此这里的触发者（主体）就是系统本身。</p>\n<h5 id=\"定时器（Timer）\"><a href=\"#定时器（Timer）\" class=\"headerlink\" title=\"定时器（Timer）\"></a>定时器（Timer）</h5><p>定时器是执行者的一种，通常是定时任务。</p>\n<p>定时器可以作为执行者，不过需要区别于本系统这个触发源。定时器可以看待为外部一个时间信号源，类似于计算机中主机中的振荡器。</p>\n<h5 id=\"参与人（Participants）\"><a href=\"#参与人（Participants）\" class=\"headerlink\" title=\"参与人（Participants）\"></a>参与人（Participants）</h5><p>作为工作坊的参与人员（应区别于执行者）。</p>\n<p>参与人只是一种角色，而非具体的一个人，可以是多个自然人做群体参与，也可以一人分饰不同的角色。</p>\n<p>在开始工作坊之前，参与人需要满足一些条件：</p>\n<ul>\n<li>参与人需要对解决的问题和产出目标达成共识</li>\n<li>参与人需要 DDD 的基本知识或接受过基本培训</li>\n<li>领域专家、技术专家需要能全程参加</li>\n</ul>\n<h5 id=\"领域专家（Domain-Expert）\"><a href=\"#领域专家（Domain-Expert）\" class=\"headerlink\" title=\"领域专家（Domain Expert）\"></a>领域专家（Domain Expert）</h5><p>领域专家是指熟悉业务规则的人，在工作坊中一般是能敲定业务规则的人。</p>\n<p>在实际的事件风暴工作坊中，领域专家是一个比技术专家更难获得人，一个合格的、能让工作坊进展下去的领域专家需要有几个要求：</p>\n<ul>\n<li>了解现有业务个情况</li>\n<li>能对具体的业务方向做出结论性的输出</li>\n<li>在做工作坊时，需要分清现状（As-IS）和目标（To-Be）业务，现状业务很多人都能说出来，不过真正的领域专家是能对目标业务做出描述的人。</li>\n</ul>\n<h5 id=\"技术专家（Tech-Expert）\"><a href=\"#技术专家（Tech-Expert）\" class=\"headerlink\" title=\"技术专家（Tech Expert）\"></a>技术专家（Tech Expert）</h5><p>技术专家是指熟悉技术方案和实现方式的人，能给出可行的技术方案和了解基础设计的限制条件。</p>\n<p>技术专家需要能对现有的技术做出描述，而未来的技术选型可能是动态的，能有一定预见性最好。技术专家往往是当前团队中最熟悉架构和代码的人。</p>\n<h5 id=\"主持人（Facilitator）\"><a href=\"#主持人（Facilitator）\" class=\"headerlink\" title=\"主持人（Facilitator）\"></a>主持人（Facilitator）</h5><p>主持人工作坊流程的推动者，以及 DDD 方法论的守护者。</p>\n<p>在一些工作坊中，主持人往往是外部的咨询师，他们有大量的实践经验，需要能对 DDD 的概念、方法有成体系的研究，并能推动工作坊进行。</p>\n<h3 id=\"三、DDD-的优势和应用场景\"><a href=\"#三、DDD-的优势和应用场景\" class=\"headerlink\" title=\"三、DDD 的优势和应用场景\"></a>三、DDD 的优势和应用场景</h3><p>优势</p>\n<ul>\n<li>紧密贴合业务需求：通过与领域专家合作构建领域模型，能够确保软件系统准确地反映业务规则，减少因对业务理解偏差导致的软件功能不符合实际需求的情况。</li>\n<li>提高软件的可维护性和可扩展性：分层架构和限界上下文的划分使得系统的各个部分职责明确，当业务需求发生变化时，可以在相应的层次或限界上下文中进行修改，而不会对整个系统造成太大的影响。</li>\n<li>促进团队协作：DDD 强调领域专家和软件开发者的协作，有助于团队成员更好地理解业务，特别是对于新加入团队的成员，可以通过领域模型和限界上下文快速了解业务领域和系统架构。</li>\n</ul>\n<p>应用场景</p>\n<ul>\n<li>复杂业务领域的系统开发：如金融、电信、物流等行业的核心业务系统，这些领域业务规则复杂、业务流程长，DDD 可以有效地帮助梳理业务逻辑，构建高质量的软件系统。</li>\n<li>企业级应用集成（EAI）：在整合多个不同的企业内部系统或外部系统时，DDD 可以通过明确各系统的领域模型和限界上下文，更好地实现系统之间的交互和集成。</li>\n</ul>\n<p>参考文章：<br><a href=\"https://domain-driven-design.org/zh/ddd-concept-reference.html\" target=\"_blank\" rel=\"noopener\">DDD 概念参考</a>        </p>\n","site":{"data":{}},"excerpt":"<h3 id=\"一、DDD\"><a href=\"#一、DDD\" class=\"headerlink\" title=\"一、DDD\"></a>一、DDD</h3><p><img src=\"/2024/08/28/2024-08-28-架构-DDD概念/%E4%BB%80%E4%B9%88%E6%98%AFDDD.png\" alt=\"什么是DDD\"><br>领域驱动设计（Domain-Driven Design，简称DDD），DDD 是一种软件开发方法。</p>","more":"<h3 id=\"二、DDD-的主要概念\"><a href=\"#二、DDD-的主要概念\" class=\"headerlink\" title=\"二、DDD 的主要概念\"></a>二、DDD 的主要概念</h3><p><img src=\"/2024/08/28/2024-08-28-架构-DDD概念/DDD%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%9B%BE.png\" alt=\"DDD基本概念图\"></p>\n<hr>\n<h4 id=\"2-1、通过类相关概念\"><a href=\"#2-1、通过类相关概念\" class=\"headerlink\" title=\"2.1、通过类相关概念\"></a>2.1、通过类相关概念</h4><p>一些通用的软件设计概念及DDD的概念。</p>\n<h5 id=\"领域驱动设计（DDD）\"><a href=\"#领域驱动设计（DDD）\" class=\"headerlink\" title=\"领域驱动设计（DDD）\"></a>领域驱动设计（DDD）</h5><p>DDD 是 Domain-Driven Design 的缩写，是 Eric Evans 于 2004 年提出的一种软件设计方法和理念。</p>\n<p>其主要的思想是，利用确定的业务模型来指导业务与应用的设计和实现。主张开发人员与业务人员持续地沟通和模型的持续迭代式演化，以保证业务模型与代码实现的一致性，从而实现有效管理业务复杂度，优化软件设计的目的。</p>\n<h5 id=\"模型（Model）\"><a href=\"#模型（Model）\" class=\"headerlink\" title=\"模型（Model）\"></a>模型（Model）</h5><p>通常，模型是对对象、人或系统的信息表示。它通过较为简单的信息结构来代表我们需要理解的复杂事物或系统。</p>\n<p>地图、乐高、算筹都是模型，模型可以简化复杂事务的认知。我们天生就有用简单的东西代表另外一个东西的能力，比如幼儿园数数用的竹签，学习物理时的刚体、真空中的球形鸡，都是模型。通俗来说模型就是经验的抽象集合，平时听到的谚语、公式、定理，本质上都是一种模型。</p>\n<h5 id=\"领域模型（Domain-Model）\"><a href=\"#领域模型（Domain-Model）\" class=\"headerlink\" title=\"领域模型（Domain Model）\"></a>领域模型（Domain Model）</h5><p>是对领域内的概念类和它们之间关系的抽象表示。它是 DDD 的核心部分，通过领域模型可以清晰地描述业务领域的结构和行为。例如，在电商系统的订单处理领域中，领域模型可能包括 “订单” 类、“订单项” 类、“商品” 类以及它们之间的关联关系（如一个订单包含多个订单项，一个订单项对应一个商品）。这些类具有各自的属性（如订单的金额、订单项的数量、商品的价格等）和行为（如订单的创建、订单项的添加、商品价格的计算等）。</p>\n<h5 id=\"建模（Modeling）\"><a href=\"#建模（Modeling）\" class=\"headerlink\" title=\"建模（Modeling）\"></a>建模（Modeling）</h5><p>建模是构建模型的过程。</p>\n<p>在软件设计过程中，通过分析业务，将业务需求使用合适的模型表示出来，是建模的任务。模型可以作为业务分析的产出，并作为软件设计的重要理论基础。 比如在分析一个电商应用的业务时，抽象出订单、商品等概念，进一步定义出模型，并用合适的图例表达，往往是 UML 来表达。</p>\n<h5 id=\"⭐️领域建模\"><a href=\"#⭐️领域建模\" class=\"headerlink\" title=\"⭐️领域建模\"></a>⭐️领域建模</h5><p>DDD最关键的部分—— 领域建模 ，它的目的归纳起来就一句话： 提炼业务知识，形成统一语言，沉淀领域模型 。</p>\n<p>以下是领域建模的交付物：</p>\n<ul>\n<li><strong>领域模型：</strong> 包含领域对象、属性、关系、行为、边界范围等各个方面，用于描述业务的本质，这也是最重要的产出物。</li>\n<li><strong>用例图：</strong> 用于明确系统的功能。</li>\n<li><strong>数据模型：</strong> 描述系统的数据结构和关系，包括实体关系模型、关系数据库模型等。</li>\n<li><strong>状态图：</strong> 用于描述系统各个状态及其转移条件。</li>\n<li><strong>活动图：</strong> 用于描述系统流程中的各个活动及其关系。</li>\n<li><strong>序列图：</strong> 描述系统中各个对象之间的交互过程和消息传递序列。</li>\n<li><strong>架构模型：</strong> 包含系统的物理和逻辑结构，包括组件、模块、接口等。</li>\n</ul>\n<h5 id=\"模型驱动设计（Model-Driven-Design）\"><a href=\"#模型驱动设计（Model-Driven-Design）\" class=\"headerlink\" title=\"模型驱动设计（Model-Driven Design）\"></a>模型驱动设计（Model-Driven Design）</h5><p>面向模型的分析设计方法，优先通过识别模型来简化业务设计。</p>\n<p>在设计过程中，以模型为中心，始终维护模型，并基于此指导软件设计。</p>\n<h5 id=\"软件设计（The-Software-Design）\"><a href=\"#软件设计（The-Software-Design）\" class=\"headerlink\" title=\"软件设计（The Software Design）\"></a>软件设计（The Software Design）</h5><p>软件设计软件需求出发，对软件系统的整体结构、模块做出划分和规划，以便于具体代码的顺利编写。</p>\n<p>由于软件需求具有非结构化、准确的语义，软件设计往往通过经验完成，无法通过某种特定的推理路线严格推导实现。</p>\n<h5 id=\"战略设计（Strategic-Design）\"><a href=\"#战略设计（Strategic-Design）\" class=\"headerlink\" title=\"战略设计（Strategic Design）\"></a>战略设计（Strategic Design）</h5><p>战略设计也称为战略建模，是指对业务进行高层次的抽象和归类。主要手段包括理清上下文和进行子域的划分。</p>\n<p>战略设计关注模型的分离，其解决的问题是大的模型如何划分为小模型以及相互之间如何关联。战略设计的产出可以用于指导团队协作，使得规模巨大的软件可以被合理拆分。</p>\n<p>战略设计的产出通常为上下文图，以及模块或微服务划分。</p>\n<h5 id=\"战术设计（Tactical-design）\"><a href=\"#战术设计（Tactical-design）\" class=\"headerlink\" title=\"战术设计（Tactical design）\"></a>战术设计（Tactical design）</h5><p>战术设计也称为战术建模，是指对特定上下文下的模型进行详细设计。</p>\n<p>战术设计的对象包括聚合、实体和值对象，其目标是用明确它们是什么以及相互之间有何关系。战术设计的产出可以是用 UML 表达的类图，需要细化到具体的属性，同时确保在代码级别可实现。</p>\n<h5 id=\"软件（Software）\"><a href=\"#软件（Software）\" class=\"headerlink\" title=\"软件（Software）\"></a>软件（Software）</h5><p>DDD 讨论下的软件是指，用于解决具体业务问题的计算机程序，既可以是单体也可以是分布式系统。</p>\n<p>软件设计是 DDD 的最终目的，使用 DDD 的各种工具可以指导软件设计，最终构建出健壮、容易维护的软件。</p>\n<h5 id=\"原则（Principle）\"><a href=\"#原则（Principle）\" class=\"headerlink\" title=\"原则（Principle）\"></a>原则（Principle）</h5><p>为了更好的践行 DDD，需要遵守几个原则: 通用语言、聚焦核心域、协作共创和持续建模。</p>\n<p>这些原则是为了更好地服务业务，从业务驱动模型设计。</p>\n<h5 id=\"通用语言（Ubiquitous）\"><a href=\"#通用语言（Ubiquitous）\" class=\"headerlink\" title=\"通用语言（Ubiquitous）\"></a>通用语言（Ubiquitous）</h5><p>通用语言（Ubiquitous language）是指在软件设计中，业务人员和开发人员需要使用无歧义的统一语言来对话。</p>\n<p>这些语言包括对概念的统一理解和定义，以及业务人员参与到软件建模中，否则业务的变化会造成软件巨大的变化。</p>\n<h5 id=\"聚焦核心域（Focus）\"><a href=\"#聚焦核心域（Focus）\" class=\"headerlink\" title=\"聚焦核心域（Focus）\"></a>聚焦核心域（Focus）</h5><p>核心域就是最关键的业务逻辑，聚焦核心域决定了软件的定位和投资重心。</p>\n<h5 id=\"协作共创（Collaboration）\"><a href=\"#协作共创（Collaboration）\" class=\"headerlink\" title=\"协作共创（Collaboration）\"></a>协作共创（Collaboration）</h5><p>协作共创是指领域专家和业务专家共同建模。</p>\n<h5 id=\"持续建模（Continuous）\"><a href=\"#持续建模（Continuous）\" class=\"headerlink\" title=\"持续建模（Continuous）\"></a>持续建模（Continuous）</h5><p>持续建模是指模型需要随业务变化而被及时更新。</p>\n<h5 id=\"上下文（Context）\"><a href=\"#上下文（Context）\" class=\"headerlink\" title=\"上下文（Context）\"></a>上下文（Context）</h5><p>上下文是语言学科的概念，指不同语境下的概念虽然相同的用词，可能具有不同的含义。</p>\n<p>在软件设计中，因为自然语言的原因，相同的用词导致实际是不同概念，会对建模和软件设计带来误导。同时，不同的上下文也是识别模型边界的手段。</p>\n<hr>\n<h4 id=\"2-2、领域分析类概念\"><a href=\"#2-2、领域分析类概念\" class=\"headerlink\" title=\"2.2、领域分析类概念\"></a>2.2、领域分析类概念</h4><p>DDD领域的相关概念。</p>\n<h5 id=\"问题空间（Problem-Space）\"><a href=\"#问题空间（Problem-Space）\" class=\"headerlink\" title=\"问题空间（Problem Space）\"></a>问题空间（Problem Space）</h5><p>待解决的业务问题的集合。</p>\n<p>在 DDD 实践中，我们应该明确区分问题空间和解空间，避免混为一谈。</p>\n<h5 id=\"领域（Domain）\"><a href=\"#领域（Domain）\" class=\"headerlink\" title=\"领域（Domain）\"></a>领域（Domain）</h5><p>领域（Domain）是业务相关知识的集合。</p>\n<p>通俗来说，领域就是业务知识。业务有一些内在规则，存在专业性，比如财务、CRM、OA、电商等不同领域的业务规则不同。计算机只是业务规则的自动化。</p>\n<h5 id=\"子域（Sub-Domain）\"><a href=\"#子域（Sub-Domain）\" class=\"headerlink\" title=\"子域（Sub Domain）\"></a>子域（Sub Domain）</h5><p>子域（Subdomain）是指在一个大的领域中划分出的相对独立的子领域，它通常代表一个独立的业务领域，具有特定的业务逻辑和功能需求。子域可以是整个系统的一个功能模块，也可以是一个独立的业务流程。</p>\n<h5 id=\"核心域（Core-Domain）\"><a href=\"#核心域（Core-Domain）\" class=\"headerlink\" title=\"核心域（Core Domain）\"></a>核心域（Core Domain）</h5><p>核心域是指领域中最核心的部分，通常对应企业的核心业务</p>\n<p>核心域需要我们投入最大精力，进行充分的分析。因为它是一个企业能运转的基础。</p>\n<h5 id=\"支撑域（Support-Domain）\"><a href=\"#支撑域（Support-Domain）\" class=\"headerlink\" title=\"支撑域（Support Domain）\"></a>支撑域（Support Domain）</h5><p>“支撑域”（Supporting Domain）指的是与核心业务的实现和发展密切相关的非业务功能。这些支撑域可以包括安全认证、用户管理、日志记录等在整个系统中被多个子域所共享和使用的基础设施功能。支撑域和通用域概念上有些类似，区分他们的标准简单归纳下的话，支撑域是由外域提供的能力，通用域是本域提供。</p>\n<h5 id=\"通用域（General-Domain）\"><a href=\"#通用域（General-Domain）\" class=\"headerlink\" title=\"通用域（General Domain）\"></a>通用域（General Domain）</h5><p>通用域（Generic Domain）是指与特定业务领域无关的通用功能，它是在整个领域中被多个子域所共享和复用的功能。通用域包括一些通用的服务、工具、组件等，用于支持多个子域的实现。</p>\n<hr>\n<h4 id=\"2-3、建模类概念\"><a href=\"#2-3、建模类概念\" class=\"headerlink\" title=\"2.3、建模类概念\"></a>2.3、建模类概念</h4><p>DDD领域设计相关模型的定义。</p>\n<h5 id=\"解空间（Solution-Space）\"><a href=\"#解空间（Solution-Space）\" class=\"headerlink\" title=\"解空间（Solution Space）\"></a>解空间（Solution Space）</h5><p>解空间是一个数学概念。是指满足问题的所有约束前提下，所有可行解的集合。在 DDD 的上下文中，指的是所有可能的解决方案的集合。</p>\n<p>解空间是相对问题空间存在的，认识到解空间存在的好处是解空间可以通过一些方法从问题空间导出，而不是通过猜测得出的。</p>\n<h5 id=\"领域模型（Model）\"><a href=\"#领域模型（Model）\" class=\"headerlink\" title=\"领域模型（Model）\"></a>领域模型（Model）</h5><p>领域模型（Model）是业务概念在程序中的一种表达方式。</p>\n<p>领域模型可以用来设计和理解整个软件结构。面向对象设计中的类概念是领域模型的一种表达方式。与此类似，UML的建模方法也可以应用在对领域模型的表达上。在 DDD 实践中，领域模型应当尽量简洁，能反应业务概念即可。</p>\n<h5 id=\"限界上下文（-Bounded-context）\"><a href=\"#限界上下文（-Bounded-context）\" class=\"headerlink\" title=\"限界上下文（ Bounded context）\"></a>限界上下文（ Bounded context）</h5><p>限界上下文是有明确边界的上下文。在 DDD 实践中领域模型会被限定在限界上下文当中。</p>\n<p>限界上下文强调概念的一致性。虽然传统的方法学已经在追求概念的一致性，但是忽略了系统的庞大性，不论系统多庞大，在系统任何位置同一概念通用。DDD 不追求全局的一致性，而是将系统拆成多块，在相同的上下文中实现概念一致性。</p>\n<p>识别上下文可以从概念的二义性着手，比如商品的概念在物流、交易、支付含义完全不一样，但具有不同内涵和外延，实际上他们处在不同上下文。</p>\n<p>界限上下文可以用于微服务划分、避免模型的不正确复用带来的问题。</p>\n<h5 id=\"实体（Entity）\"><a href=\"#实体（Entity）\" class=\"headerlink\" title=\"实体（Entity）\"></a>实体（Entity）</h5><p>实体（Entity）是在相同限界上下文中具有唯一标识的领域模型，可变，通过标识判断同一性。</p>\n<blockquote>\n<p>例：最简单的，公安系统的身份信息录入，对于人的模拟，即认为是实体，因为每个人是独一无二的，且其具有唯一标识（如公安系统分发的身份证号码）。</p>\n</blockquote>\n<ol>\n<li><strong>贫血模型</strong> ：贫血模型是指领域对象只具有数据属性，缺乏相关的行为逻辑。在贫血模型中，业务逻辑主要存在于服务层或者其它外部对象中，领域对象仅被视为被动的数据容器。这种模型在领域驱动设计（DDD）中被认为是反模式，因为它无法更好地体现领域的核心概念和规则。</li>\n<li><strong>失血模型</strong> ：和贫血模型相似，指的是领域对象缺少业务逻辑和领域行为，以至于数据和行为的重要部分都被丢失。这种模型经常出现在面向对象的开发中，尤其是基于关系数据库的实现中。</li>\n<li><strong>充血模型</strong> ：充血模型是在领域对象中充分体现了业务逻辑和行为的模型。充血模型积极地包含了数据和相关的行为逻辑，它使得领域对象能够更好地封装与之相关的业务规则和行为，提供了更加一致和抽象的编程接口。充血模型是DDD中推崇的设计模式，使得领域对象能够成为业务规则的中心。</li>\n<li><strong>涨血模型</strong> ：涨血模型是指在充血模型的基础上，进一步将领域对象的状态和行为扩展到前沿技术和新的设计模式中（有些理念力，涨血模型和充血模型的区别在于，涨血模型添加了持久层的行为）。</li>\n</ol>\n<blockquote>\n<p>充血模型虽然是DDD中推崇的设计模式，通过领域实体，一些关键行为和逻辑其实也能一起拿到了，但是在我的经验中，我更喜欢使用 贫血+充血的混合模型 （或者叫充血模型的简化版），因为这里涉及到一个标准的建立问题，如果只用充血模型的话，哪些行为和逻辑该下方到接口服务层，哪些又该收拢到实体中，这里面每个人的理念不一样。而我的标准是， 涉及到持久层和复杂行为都下放到服务层，简单行为放到实体模型中 。这样有个好处，随着业务的发展，如果只用充血模型，你的实体会越来越臃肿；如果只有贫血模型，自身又太单薄。所以一部分行为下放到服务层，我可以更细粒度的拆分服务接口，保证更优良的边界和代码可读性，同时也保证了模型自身的健壮性。<br>最后，不论哪种模型，都没有绝对的好坏，能够很好的定义出设计标准，同时基于自己的理解设计出符合业务扩展的实体和服务就是好的模型。</p>\n</blockquote>\n<h5 id=\"值对象（Value-Object）\"><a href=\"#值对象（Value-Object）\" class=\"headerlink\" title=\"值对象（Value Object）\"></a>值对象（Value Object）</h5><p>值对象 （Value Ojbect）是一种特殊的领域模型，不可变，通过值判断同一性。</p>\n<p>实体可以使用 ID 标识，但是值对象是用属性标识，任何属性的变化都视为新的值对象。比如一个银行账户，可以由 ID 唯一标识，币种和余额可以被修改但是还是同一个账户；交易单中的金额由币种和数值组成，无论修改哪一个属性，金额都不再是原来的金额。</p>\n<blockquote>\n<p>例：比如颜色信息，我们只需要知道{“name”:“黑色”，”css”:“#000000”}这样的值信息就能够满足要求了，这避免了我们对标识追踪带来的系统复杂性。</p>\n</blockquote>\n<p>值对象很重要，在习惯了使用数据库的数据建模后，很容易将所有对象看作实体。使用值对象，可以更好地做系统优化、精简设计。</p>\n<h5 id=\"聚合（Aggregate）\"><a href=\"#聚合（Aggregate）\" class=\"headerlink\" title=\"聚合（Aggregate）\"></a>聚合（Aggregate）</h5><p>聚合（Aggregate）是一组生命周期强一致，修改规则强关联的实体和值对象的集合，表达统一的业务意义。</p>\n<p>聚合的意义在于让业务统一、一致，在面向对象中有非常重要价值。比如，订单中有多个订单项，订单的总价是根据订单项目计算而来的。如果没有经验的开发者直接对订单项的做出修改，而不是由订单统一处理业务逻辑，会造成业务的一致性问题。</p>\n<p>聚合需要在相同的上下文中，不能跨上下文。</p>\n<h5 id=\"聚合根（-Aggregate-Root）\"><a href=\"#聚合根（-Aggregate-Root）\" class=\"headerlink\" title=\"聚合根（ Aggregate Root）\"></a>聚合根（ Aggregate Root）</h5><p>聚合根是聚合的根实体，它是一组相关对象的入口点，作为一个整体被外界访问，管理着聚合内其他对象的生命周期和完整性。聚合根通过封装聚合内部的对象，并定义了聚合的一致性边界，确保聚合内的对象之间的关系和约束得到维护。外部对象只能通过聚合根来访问和操作聚合内的对象，从而保证了聚合的完整性和一致性。</p>\n<blockquote>\n<p>聚合 = 聚合根实体 + 值对象 + 实体  组成。</p>\n</blockquote>\n<p>如何创建好的聚合？</p>\n<blockquote>\n<p>边界内的内容具有一致性：在一个事务中只修改一个聚合实例。如果你发现边界内很难接受强一致，不管是出于性能或产品需求的考虑，应该考虑剥离出独立的聚合，采用最终一致的方式。<br>设计小聚合：大部分的聚合都可以只包含根实体，而无需包含其他实体。即使一定要包含，可以考虑将其创建为值对象。<br>通过唯一标识来引用其他聚合或实体：当存在对象之间的关联时，建议引用其唯一标识而非引用其整体对象。如果是外部上下文中的实体，引用其唯一标识或将需要的属性构造值对象。 如果聚合创建复杂，推荐使用工厂方法来屏蔽内部复杂的创建逻辑。<br>聚合内部多个组成对象的关系可以用来指导数据库创建，但不可避免存在一定的抗阻。如聚合中存在List&lt;值对象&gt;，那么在数据库中建立1:N的关联需要将值对象单独建表，此时是有id的，建议不要将该id暴露到资源库外部，对外隐蔽。</p>\n</blockquote>\n<hr>\n<h4 id=\"2-4、软件设计类概念\"><a href=\"#2-4、软件设计类概念\" class=\"headerlink\" title=\"2.4、软件设计类概念\"></a>2.4、软件设计类概念</h4><p>软件设计中的一些常见术语、常见技术等概念。</p>\n<h5 id=\"模块（Module）\"><a href=\"#模块（Module）\" class=\"headerlink\" title=\"模块（Module）\"></a>模块（Module）</h5><p>模块（Module）一组类或者对象组成的集合。</p>\n<p>在 DDD 实践中推荐使用限界上下文和聚合来指导模块划分。同时，如果不是特别复杂的业务逻辑也可以不遵循该模式。</p>\n<h5 id=\"仓储（Repository）\"><a href=\"#仓储（Repository）\" class=\"headerlink\" title=\"仓储（Repository）\"></a>仓储（Repository）</h5><p>仓储（Repository）是以持久化领域模型为职责的类。</p>\n<p>仓储的目的是屏蔽业务逻辑和持久化基础设施的差异。例如，对于同样的持久化业务需求，在采用关系型数据库和非关系型数据库作为存储基础设施时的实现细节是有所不同的。</p>\n<p>软件的设计往往是围绕着对数据的修改完成的。经验不多的开发者往往会认为，软件的开发过程就是对数据库的增删改查。但实际上基于该认知的软件设计让软件难以维护。</p>\n<p>对于采用关系数据库作为存储基础设施的项目，仓库层可以被 ORM 实现。若不使用 ORM，则需自己实现仓库。</p>\n<h5 id=\"服务（Service）\"><a href=\"#服务（Service）\" class=\"headerlink\" title=\"服务（Service）\"></a>服务（Service）</h5><p>服务（Service）是领域模型的操作者，负责领域内的业务规则的实现。</p>\n<p>领域模型用于承载数据和系统状态，服务承载业务逻辑的实践。</p>\n<p>在实践中如果使用主、客体的思维来进行设计，则服务为主体，领域模型为客体。使用拟人化的方式来对服务进行命名，可以让开发者更容易理解。比如，一个维护客户数据的 CRM 应用中，客户数据被抽象为模型： Client，对应的服务可以设计为：ClientManager。</p>\n<h5 id=\"工厂（Factory）\"><a href=\"#工厂（Factory）\" class=\"headerlink\" title=\"工厂（Factory）\"></a>工厂（Factory）</h5><p>工厂（Factory）是以构建领域模型（实体或值对象）为职责的类或方法。</p>\n<p>工厂可以利用不同的业务参数构建不同的领域模型。对于简单的业务逻辑实现可以不使用工厂。工厂的实现不一定是类的形式，也可以是具备工厂功能的方法。</p>\n<p>在面向对象程序设计中，工厂是一种设计模式。在广义的工厂模式中，工厂可以根据不同的规则的业务需求构造不同的对象。例如在 Redis 连接客户端的实现中，可以使用 Redis 单机、哨兵、集群等不同的方式来构建 Redis 连接客户端。</p>\n<h5 id=\"策略（Strategy）\"><a href=\"#策略（Strategy）\" class=\"headerlink\" title=\"策略（Strategy）\"></a>策略（Strategy）</h5><p>策略（Strategy）是业务规则的实现方式。</p>\n<p>例如通知业务，可以使用不同的渠道来实现，不同渠道的实现逻辑可以认为是不同的策略。 在面向对象程序设计中，策略模式也是一种设计模式，是多态的一种实现模式。</p>\n<p>策略通常会搭配着接口来设计。如果说接口是一种契约，那策略就是契约的履约方式。</p>\n<h5 id=\"规格（Specification）\"><a href=\"#规格（Specification）\" class=\"headerlink\" title=\"规格（Specification）\"></a>规格（Specification）</h5><p>规格（Specification） 是一些特殊的业务规则。通常表现为用于校验（e.g. 数据格式，业务逻辑）、查询和搜索条件。</p>\n<p>在实践中，规格既可以被设计为灵活的查询或校验条件，也可以被抽象出来以便复用。</p>\n<p>例如，在 JPA、MongoDB、ElastiSearch和一些具有查询能力的 ORM 都大量使用这种设计方式，同样的在应用程序中我们也可以参考这种设计模式，把业务的规则提取出来。</p>\n<h5 id=\"分层架构（逻辑）\"><a href=\"#分层架构（逻辑）\" class=\"headerlink\" title=\"分层架构（逻辑）\"></a>分层架构（逻辑）</h5><p>分层架构是指在软件设计过程中按照既定的原则将不同的功能实现拆分到不同的层级进行实现的一种设计方式。每个层级有独立的职责，多个层次协同以提供完整功能。按照 DDD 的分层模型，通常可以划分为:接入层、应用层、领域层、基础设施层</p>\n<p>分层架构在具体的软件中可以表现为不同的形式。例如，在分布式系统中，不同层级的软件实现，可以表现为独立部署的服务。而在单体系统中，分层可以用不同的模块或包来实现。</p>\n<p>分层架构的设计理念与计算机网络的层级结构类似，上层依赖下层的实现，而下层实现无需关心上层实现。例如，HTTP 协议构建在 TCP 协议之上，TCP 协议只负责提供传输层的能力，而不需要知道具体的应用层协议。</p>\n<p>分层架构中层级的数量需要依照系统复杂度来定，并不需要死板地按照 DDD 推荐的四层来进行设计。在简单的系统中，可以通过减少分层来避免样板代码，减少冗余。例如，在 web 系统中有时候只有一种接入方式，接入层和应用层能力高度重叠，可以考虑直接使用应用层代替接入层。</p>\n<p>软件框架的使用，通常会引入新的层级，从而影响系统整体的分层架构。例如，ORM 框架本身就提供了对 Repository 的一层抽象。</p>\n<h5 id=\"接入层（Interface）\"><a href=\"#接入层（Interface）\" class=\"headerlink\" title=\"接入层（Interface）\"></a>接入层（Interface）</h5><p>接入层负责的是系统的输入和输出。</p>\n<p>接入层只关心沟通协议，不关心业务相关的数据校验。 接入层的实现是与业务应用强相关的，不同的业务应用有不同的实现方式。例如，对于普通的 Web 应用，基于 HTTP 协议的 API 是一种接入层实现方式；对于IoT传感器的数据上传业务，接入层的实现可能需要基于 websocket 或 MQTT 协议。</p>\n<p>接入层的特点：</p>\n<ul>\n<li>接入层对应用数据透明，只关心数据格式而不关心数据的内容</li>\n<li>在大部分单体系统中接入层通常被框架实现。例如，在 Spring Boot 框架中，HTTP 协议的 API 设计不需要关注 HTTP 协议本身。</li>\n<li>在分布式系统中接入层通常被网关实现。</li>\n</ul>\n<h5 id=\"应用层（Application）\"><a href=\"#应用层（Application）\" class=\"headerlink\" title=\"应用层（Application）\"></a>应用层（Application）</h5><p>应用层，组织业务场景，编排业务，隔离场景对领域层的差异。</p>\n<p>应用层遵循面向对象核心思想中的 “关注点分离” 理念。应用层的关注点在于业务场景的处理。例如，对于一个服务多种类型用户的应用，to C 的网页界面和后台管理界面对应的是不同的业务场景。对于新用户注册这个业务来说，通过 to C 的网页注册和通过后台管理界面进行后台注册是不同的业务场景。然而，“用户注册”在系统层面的基本逻辑是一样的。所以，“用户注册”的基本业务逻辑可以交由领域层来实现。而两种不同渠道进行用户注册所需要进行的身份验证等逻辑，可以设计在应用层进行实现。这样便能达到关注点分离，复用核心业务逻辑的目的。</p>\n<p>应用层的特点：</p>\n<ul>\n<li>关心处理完一个完整的业务</li>\n<li>该层只负责业务编排，对象转换，而具体的业务逻辑由领域层实现</li>\n<li>虽不关心请求从何处来，但关心谁来、做什么、有没有权限做</li>\n<li>利用不同的领域服务来解决问题</li>\n<li>对最终一致性有要求的业务和事务处理需要放到应用层来处理</li>\n<li>功能权限放到这层</li>\n</ul>\n<h5 id=\"领域层（Domain）\"><a href=\"#领域层（Domain）\" class=\"headerlink\" title=\"领域层（Domain）\"></a>领域层（Domain）</h5><p>领域层，实现具体的业务逻辑、规则，为应用层提供无差别的服务能力。</p>\n<p>实际处理业务的地方，领域层需要对应用层提供无差别的服务和能力。例如，对于用户注册的场景，用户既可以通过邮箱自己注册，也可以由管理员在后台进行添加。用户注册的核心逻辑可以由领域层完成，但是对于不同渠道进行用户注册的参数校验和权限验证等逻辑则由应用层实现。</p>\n<p>领域层的特点：</p>\n<ul>\n<li>不关心场景，关心模型完整性和业务规则</li>\n<li>不关心谁来，不关心场景完整的业务，关心当前上下文的业务完整</li>\n<li>强一致性事务放到这层，聚合的事务是 “理所当然的”</li>\n<li>对应到分布式系统中的 domain service、后台等概念</li>\n<li>领域层做业务规则验证</li>\n<li>数据权限放到这层（比如只允许删除自己创建的商品），因为数据权限涉及业务规则</li>\n<li>根据业务情况，参考反范式理论，跨上下文使用值对象做必要的数据冗余</li>\n</ul>\n<h5 id=\"基础设施层（Infrastructure）\"><a href=\"#基础设施层（Infrastructure）\" class=\"headerlink\" title=\"基础设施层（Infrastructure）\"></a>基础设施层（Infrastructure）</h5><p>基础设施层，提供具体的技术实现，比如存储，基础设施对业务保持透明。</p>\n<p>对于基础设施层来说，基础设施层并不是指 MySQL、Redis 等外部组件，而是外部组件的适配器，Hibernate、Mybatis、Redis Template 等，因此在 DDD 中适配器模式被多次提到，基础设施层往往不能单独存在，还是要依附于领域层。技术设施层的适配器还包括了外部系统的适配，互联网产品系统的外部系统非常多，常见的有活体监测、风控系统、税务发票等。</p>\n<p>技术设施层的特点：</p>\n<ul>\n<li>关心存储、通知、第三方系统等外部设施（防腐层隔离）</li>\n<li>基础设施的权限由配置到应用的凭证控制，例如数据库、对象存储的凭证，技术设施层不涉及用户的权限</li>\n</ul>\n<h5 id=\"部署架构（物理）\"><a href=\"#部署架构（物理）\" class=\"headerlink\" title=\"部署架构（物理）\"></a>部署架构（物理）</h5><p>部署架构是指具体的架构实现</p>\n<p>主要是在分布式系统、单体系统，甚至在客户端软件中体现。</p>\n<p>把逻辑架构和部署架构区分开可以很好的理解软件设计上和部署上的不同，对于应用构架来说，逻辑上的设计不一定对应部署结构。</p>\n<p>这样就很好理解 DDD 在不同场合中的使用方式，避免生搬硬套。当 DDD 的分层结构在单体应用中使用时，每层可能使用包、模块来表达，在微服务中使用时候，每层可能由不同角色的微服务来完成。</p>\n<h5 id=\"微服务（Micro-Service）\"><a href=\"#微服务（Micro-Service）\" class=\"headerlink\" title=\"微服务（Micro Service）\"></a>微服务（Micro Service）</h5><p>微服务是一种低耦合的分布式应用系统。</p>\n<p>维基百科的定义是：一种软件开发技术 - 面向服务的体系结构（SOA）架构样式的一种变体，将应用程序构造为一组松散耦合的服务。这个定义没有问题，但是忽略了一个重要的信息，微服务是一种分布式架构，微服务必须面对分布式系统的各种问题。</p>\n<p>分布式系统是通过计算机网络连接、协同工作的 IT 系统，因此在使用 DDD 时候，需要为这种系统做适配，而不是简单的做出切分。</p>\n<h5 id=\"单体（Monomer）\"><a href=\"#单体（Monomer）\" class=\"headerlink\" title=\"单体（Monomer）\"></a>单体（Monomer）</h5><p>单体是主要业务实现和部署在单一服务器上的应用。</p>\n<p>单体系统是相对于微服务来说的，其特点是主要的实现在单一的服务器中。</p>\n<h5 id=\"分布式应用系统（Distributed）\"><a href=\"#分布式应用系统（Distributed）\" class=\"headerlink\" title=\"分布式应用系统（Distributed）\"></a>分布式应用系统（Distributed）</h5><p>分布式应用系统是建立在计算机网络之上的应用软件系统，不同单元通过计算机网络集成。</p>\n<hr>\n<h4 id=\"2-5、事件风暴类概念\"><a href=\"#2-5、事件风暴类概念\" class=\"headerlink\" title=\"2.5、事件风暴类概念\"></a>2.5、事件风暴类概念</h4><h5 id=\"事件风暴（Event-Storming）\"><a href=\"#事件风暴（Event-Storming）\" class=\"headerlink\" title=\"事件风暴（Event Storming）\"></a>事件风暴（Event Storming）</h5><p>事件风暴是一种以工作坊的形式，使用 DDD 建模的方式。</p>\n<p>事件风暴的发明人是 Alberto Brandolini ，它来源于 Gamestorming，通过工作坊的方式将领域专家和技术专家拉到一起，进行建模。</p>\n<p>事件风暴是一种捕获行为需求的方法，类似传统软件的开发用例分析。所有人员（领域专家和技术专家） 对业务行为进行一次发散，并最终收敛达到业务的统一。</p>\n<h5 id=\"领域事件（Domain-Event）\"><a href=\"#领域事件（Domain-Event）\" class=\"headerlink\" title=\"领域事件（Domain Event）\"></a>领域事件（Domain Event）</h5><p>事件是系统状态发生的某种客观现象，领域事件是和领域有关的事件。</p>\n<p>领域事件（Domain Event），是在业务上真实发生的客观事实，这些事实对系统会产生关键影响，是观察业务系统变化的关键点。领域事件一般是领域专家关心的。</p>\n<p>事件的评价方式是系统状态是否发生变化。系统状态变化意味着领域模型被业务规则操作，这是观察系统业务的好方法。</p>\n<p>识别领域事件的线索有：</p>\n<ul>\n<li>是否产生了某种数据</li>\n<li>系统状态是否发生变化，无论这种状态存放到数据库还是内存</li>\n<li>是否对外发送了某些消息</li>\n</ul>\n<h5 id=\"业务规则（Policy）\"><a href=\"#业务规则（Policy）\" class=\"headerlink\" title=\"业务规则（Policy）\"></a>业务规则（Policy）</h5><p>业务规则是指对业务逻辑的定义和约束。</p>\n<p>不同的业务规则往往意味着不同的领域事件被触发，未来在技术实现时可能是一些分支条件，对应 DDD 实现中可能通过领域服务、规格、策略等方式实现。</p>\n<p>业务规则的识别是为了将数据和算法分开。</p>\n<h5 id=\"命令（Command）\"><a href=\"#命令（Command）\" class=\"headerlink\" title=\"命令（Command）\"></a>命令（Command）</h5><p>命令是执行者发起的操作，构成要件是执行者和行为。</p>\n<p>命令可以类比于 UML 分析中的业务用例，是某个场景中领域事件的触发动作。</p>\n<h5 id=\"执行者（Actor）\"><a href=\"#执行者（Actor）\" class=\"headerlink\" title=\"执行者（Actor）\"></a>执行者（Actor）</h5><p>执行者是指使用系统的主体，是导致系统状态变化的触发源。</p>\n<p>执行者有点像 UML 的涉众，不过区别是执行者不仅是用户，还包括外部系统和本系统。 在事件风暴中，执行者可以是：用户、外部系统、本系统、定时器。</p>\n<h5 id=\"用户（User）\"><a href=\"#用户（User）\" class=\"headerlink\" title=\"用户（User）\"></a>用户（User）</h5><p>用户是执行者的一种，是指使用软件或服务的人。</p>\n<p>用户可以有不同的角色，通常我们会把不同角色的相似行为作为不同的命令来处理，有可能得到同样的事件。比如系统出现了商品已添加的事件，有可能有多个触发的场景： 1. 系统管理员在后台中添加 2. 商户在自己的管理平台中添加 3. 导入任务在特定时间添加</p>\n<p>1 2 是用户的行为，不过是不同的角色。</p>\n<h5 id=\"外部系统（Out-System）\"><a href=\"#外部系统（Out-System）\" class=\"headerlink\" title=\"外部系统（Out System）\"></a>外部系统（Out System）</h5><p>外部系统是执行者的一种，系统开放 API 的调用发起者。</p>\n<p>有一些系统会提供对外的 API 给外部系统，这时候外部系统也会发出命令让系统产生事件，这里的外部系统特指作为执行者的外部系统。</p>\n<h5 id=\"本系统（System）\"><a href=\"#本系统（System）\" class=\"headerlink\" title=\"本系统（System）\"></a>本系统（System）</h5><p>本系统是执行者的一种，指系统本身。</p>\n<p>事件的触发可以由用户、外部系统、定时器触发，也可以由上一个事件触发，因此这里的触发者（主体）就是系统本身。</p>\n<h5 id=\"定时器（Timer）\"><a href=\"#定时器（Timer）\" class=\"headerlink\" title=\"定时器（Timer）\"></a>定时器（Timer）</h5><p>定时器是执行者的一种，通常是定时任务。</p>\n<p>定时器可以作为执行者，不过需要区别于本系统这个触发源。定时器可以看待为外部一个时间信号源，类似于计算机中主机中的振荡器。</p>\n<h5 id=\"参与人（Participants）\"><a href=\"#参与人（Participants）\" class=\"headerlink\" title=\"参与人（Participants）\"></a>参与人（Participants）</h5><p>作为工作坊的参与人员（应区别于执行者）。</p>\n<p>参与人只是一种角色，而非具体的一个人，可以是多个自然人做群体参与，也可以一人分饰不同的角色。</p>\n<p>在开始工作坊之前，参与人需要满足一些条件：</p>\n<ul>\n<li>参与人需要对解决的问题和产出目标达成共识</li>\n<li>参与人需要 DDD 的基本知识或接受过基本培训</li>\n<li>领域专家、技术专家需要能全程参加</li>\n</ul>\n<h5 id=\"领域专家（Domain-Expert）\"><a href=\"#领域专家（Domain-Expert）\" class=\"headerlink\" title=\"领域专家（Domain Expert）\"></a>领域专家（Domain Expert）</h5><p>领域专家是指熟悉业务规则的人，在工作坊中一般是能敲定业务规则的人。</p>\n<p>在实际的事件风暴工作坊中，领域专家是一个比技术专家更难获得人，一个合格的、能让工作坊进展下去的领域专家需要有几个要求：</p>\n<ul>\n<li>了解现有业务个情况</li>\n<li>能对具体的业务方向做出结论性的输出</li>\n<li>在做工作坊时，需要分清现状（As-IS）和目标（To-Be）业务，现状业务很多人都能说出来，不过真正的领域专家是能对目标业务做出描述的人。</li>\n</ul>\n<h5 id=\"技术专家（Tech-Expert）\"><a href=\"#技术专家（Tech-Expert）\" class=\"headerlink\" title=\"技术专家（Tech Expert）\"></a>技术专家（Tech Expert）</h5><p>技术专家是指熟悉技术方案和实现方式的人，能给出可行的技术方案和了解基础设计的限制条件。</p>\n<p>技术专家需要能对现有的技术做出描述，而未来的技术选型可能是动态的，能有一定预见性最好。技术专家往往是当前团队中最熟悉架构和代码的人。</p>\n<h5 id=\"主持人（Facilitator）\"><a href=\"#主持人（Facilitator）\" class=\"headerlink\" title=\"主持人（Facilitator）\"></a>主持人（Facilitator）</h5><p>主持人工作坊流程的推动者，以及 DDD 方法论的守护者。</p>\n<p>在一些工作坊中，主持人往往是外部的咨询师，他们有大量的实践经验，需要能对 DDD 的概念、方法有成体系的研究，并能推动工作坊进行。</p>\n<h3 id=\"三、DDD-的优势和应用场景\"><a href=\"#三、DDD-的优势和应用场景\" class=\"headerlink\" title=\"三、DDD 的优势和应用场景\"></a>三、DDD 的优势和应用场景</h3><p>优势</p>\n<ul>\n<li>紧密贴合业务需求：通过与领域专家合作构建领域模型，能够确保软件系统准确地反映业务规则，减少因对业务理解偏差导致的软件功能不符合实际需求的情况。</li>\n<li>提高软件的可维护性和可扩展性：分层架构和限界上下文的划分使得系统的各个部分职责明确，当业务需求发生变化时，可以在相应的层次或限界上下文中进行修改，而不会对整个系统造成太大的影响。</li>\n<li>促进团队协作：DDD 强调领域专家和软件开发者的协作，有助于团队成员更好地理解业务，特别是对于新加入团队的成员，可以通过领域模型和限界上下文快速了解业务领域和系统架构。</li>\n</ul>\n<p>应用场景</p>\n<ul>\n<li>复杂业务领域的系统开发：如金融、电信、物流等行业的核心业务系统，这些领域业务规则复杂、业务流程长，DDD 可以有效地帮助梳理业务逻辑，构建高质量的软件系统。</li>\n<li>企业级应用集成（EAI）：在整合多个不同的企业内部系统或外部系统时，DDD 可以通过明确各系统的领域模型和限界上下文，更好地实现系统之间的交互和集成。</li>\n</ul>\n<p>参考文章：<br><a href=\"https://domain-driven-design.org/zh/ddd-concept-reference.html\" target=\"_blank\" rel=\"noopener\">DDD 概念参考</a>        </p>"}],"PostAsset":[{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/jmap.png","slug":"jmap.png","post":"cm4gqpntv0005a13ktkdgg3om","modified":1,"renderable":0},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident/sqlsession-class-relation.jpg","slug":"sqlsession-class-relation.jpg","post":"cm4gqpntj0000a13k2k3brwas","modified":1,"renderable":0},{"_id":"source/_posts/2019-06-28-hadoop/文件读取.jpg","slug":"文件读取.jpg","post":"cm4gqpnuy000va13kssfnsm5e","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-03-hbase/hregion.png","slug":"hregion.png","post":"cm4gqpnut000ra13k74i47kzl","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-07-hbase梳理/hregion.png","slug":"hregion.png","post":"cm4gqpnw0001ia13k6k3twovz","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-07-hbase梳理/数据表格.png","slug":"数据表格.png","post":"cm4gqpnw0001ia13k6k3twovz","modified":1,"renderable":0},{"_id":"source/_posts/2024-04-10-性能优化-日志优化/磁盘利用率.jpeg","slug":"磁盘利用率.jpeg","post":"cm4gqpnxw004aa13k2vcl54ui","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-20-HIVE/HIVE架构.png","slug":"HIVE架构.png","post":"cm4gqpnuv000ua13k5fti9j56","modified":1,"renderable":0},{"_id":"source/_posts/2019-08-01-MQ对比/rocketmq-broker.png","slug":"rocketmq-broker.png","post":"cm4gqpnv90010a13kmo05w9ni","modified":1,"renderable":0},{"_id":"source/_posts/2019-08-19-RPC/server方法过程.png","slug":"server方法过程.png","post":"cm4gqpnve0013a13k3bk80slx","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-09-Linux-thread/internal.png","slug":"internal.png","post":"cm4gqpnww0025a13ka8vdvw92","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-12-线程池/线程池.png","slug":"线程池.png","post":"cm4gqpnx3002fa13k1dzolbyj","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-06-volatile/volatile-jvm.png","slug":"volatile-jvm.png","post":"cm4gqpnxg0035a13ku97w4boz","modified":1,"renderable":0},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/urm-1.png","slug":"urm-1.png","post":"cm4gqpnue000ca13kugxq9pjc","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/直接内存回收和分配.png","slug":"直接内存回收和分配.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-12-线程池/DelayedWorkQueue.png","slug":"DelayedWorkQueue.png","post":"cm4gqpnx3002fa13k1dzolbyj","modified":1,"renderable":0},{"_id":"source/_posts/2020-06-14-分布式主键ID/数据库水平拆分ID.png","slug":"数据库水平拆分ID.png","post":"cm4gqpnxi0039a13k9uc1irbh","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-11-类加载/类生命周期.png","slug":"类生命周期.png","post":"cm4gqpnxb002va13ku9v9lnms","modified":1,"renderable":0},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念/中间件改造.png","slug":"中间件改造.png","post":"cm4gqpny4004xa13kdrbkst6y","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-21-架构-三高/高可用衡量指标.png","slug":"高可用衡量指标.png","post":"cm4gqpnyd005qa13kvob13rrw","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/分层架构.png","slug":"分层架构.png","post":"cm4gqpnyf005ta13knrqs5xrz","modified":1,"renderable":0},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident/redis-cache.jpg","slug":"redis-cache.jpg","post":"cm4gqpntj0000a13k2k3brwas","modified":1,"renderable":0},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/uum-1.png","slug":"uum-1.png","post":"cm4gqpnue000ca13kugxq9pjc","modified":1,"renderable":0},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/jmap-heap.png","slug":"jmap-heap.png","post":"cm4gqpntv0005a13ktkdgg3om","modified":1,"renderable":0},{"_id":"source/_posts/2019-04-11-Linux-io模型/async-block.png","slug":"async-block.png","post":"cm4gqpnyk0065a13k5eqygezq","modified":1,"renderable":0},{"_id":"source/_posts/2019-04-11-Linux-io模型/sync-nonblock.png","slug":"sync-nonblock.png","post":"cm4gqpnyk0065a13k5eqygezq","modified":1,"renderable":0},{"_id":"source/_posts/2019-06-28-hadoop/文件写入.jpg","slug":"文件写入.jpg","post":"cm4gqpnuy000va13kssfnsm5e","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-07-hbase梳理/hfile结构.png","slug":"hfile结构.png","post":"cm4gqpnw0001ia13k6k3twovz","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-07-hbase梳理/keyvalue结构.png","slug":"keyvalue结构.png","post":"cm4gqpnw0001ia13k6k3twovz","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-04-cpu/CPU指令重排.png","slug":"CPU指令重排.png","post":"cm4gqpnwq001va13k9icksg7r","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-13-ThreadLocal/threadlocal.png","slug":"threadlocal.png","post":"cm4gqpnwy0027a13k3e9d9101","modified":1,"renderable":0},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/old-sso-out.png","slug":"old-sso-out.png","post":"cm4gqpnue000ca13kugxq9pjc","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-13-ThreadLocal/jvm-share.png","slug":"jvm-share.png","post":"cm4gqpnwy0027a13k3e9d9101","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-12-线程池/线程池状态.png","slug":"线程池状态.png","post":"cm4gqpnx3002fa13k1dzolbyj","modified":1,"renderable":0},{"_id":"source/_posts/2024-03-20-性能优化-服务RT上升/trace.png","slug":"trace.png","post":"cm4gqpnxu0046a13kdnncsydf","modified":1,"renderable":0},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/tair单元化.png","slug":"tair单元化.png","post":"cm4gqpnyj0062a13kxfa6nk1o","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-28-架构-DDD概念/什么是DDD.png","slug":"什么是DDD.png","post":"cm4gqpo2x00aka13ks9mlekgr","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/分层架构_系统架构.png","slug":"分层架构_系统架构.png","post":"cm4gqpnyf005ta13knrqs5xrz","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/DDD设计流程总览图.png","slug":"DDD设计流程总览图.png","post":"cm4gqpnyb005na13ksd8qmmff","modified":1,"renderable":0},{"_id":"source/_posts/2019-04-24-MySQL-连接异常问题/mysql-error.png","post":"cm4gqpnuh000da13knd69zcpj","slug":"mysql-error.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-05-18-bio/bio.png","post":"cm4gqpnuk000ga13k21m2lmbq","slug":"bio.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-06-14-nio/nio-common.png","post":"cm4gqpnun000ia13ktfx71f01","slug":"nio-common.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-12-22-tomcat-webxml解析/启动过程.png","slug":"启动过程.png","post":"cm4gqpnw5001la13kfdlutnhn","modified":1,"renderable":0},{"_id":"source/_posts/2020-03-29-磁盘局部性原理/磁盘.png","slug":"磁盘.png","post":"cm4gqpnw9001oa13kow4gwk3r","modified":1,"renderable":0},{"_id":"source/_posts/2019-12-22-tomcat请求过程/启动过程.png","slug":"启动过程.png","post":"cm4gqpnwu001za13kexfrmt44","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-10-linux-pagecache/27_file_page_device_block.png","post":"cm4gqpnwv0022a13k9rajnntq","slug":"27_file_page_device_block.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-05-10-JMM/jmm.png","slug":"jmm.png","post":"cm4gqpnx4002ha13krmhlilge","modified":1,"renderable":0},{"_id":"source/_posts/2024-05-29-稳定性-高可用建设/防.png","post":"cm4gqpny0004na13ksluavuds","slug":"防.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-06-29-稳定性-变更三板斧/可监控.png","post":"cm4gqpny3004ua13kq1xzarfm","slug":"可监控.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-03-性能优化-MySQL查询优化/异构索引表.png","post":"cm4gqpnxq003wa13kaevt6bnb","slug":"异构索引表.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-20-HIVE/HIVE架构.jpeg","post":"cm4gqpnuv000ua13k5fti9j56","slug":"HIVE架构.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/2020-05-11-类加载/类加载过程.png","slug":"类加载过程.png","post":"cm4gqpnxb002va13ku9v9lnms","modified":1,"renderable":0},{"_id":"source/_posts/2020-06-07-订单ES/常见问题及解决方案.png","post":"cm4gqpnxk003fa13k4yth221h","slug":"常见问题及解决方案.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-06-07-订单ES/数据同步方案.png","post":"cm4gqpnxk003fa13k4yth221h","slug":"数据同步方案.png","modified":1,"renderable":1},{"_id":"source/_posts/2021-01-04-springmvc/springmvc-handlermapping.png","slug":"springmvc-handlermapping.png","post":"cm4gqpnxo003pa13k47m3h8tj","modified":1,"renderable":0},{"_id":"source/_posts/2021-01-04-springmvc/springmvc-流程.png","post":"cm4gqpnxo003pa13k47m3h8tj","slug":"springmvc-流程.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-20-性能优化-服务RT上升/profiler.png","slug":"profiler.png","post":"cm4gqpnxu0046a13kdnncsydf","modified":1,"renderable":0},{"_id":"source/_posts/2024-05-04-系统重构-资产管理系统重构/MVC三层架构.png","slug":"MVC三层架构.png","post":"cm4gqpnxy004ga13kaa80yl72","modified":1,"renderable":0},{"_id":"source/_posts/2024-05-04-系统重构-资产管理系统重构/技术架构.png","post":"cm4gqpnxy004ga13kaa80yl72","slug":"技术架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-06-15-稳定性-线程池要设置多大/线程池参数配置方案.png","post":"cm4gqpny50051a13kt3zcmx9f","slug":"线程池参数配置方案.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-06-15-稳定性-线程池要设置多大/队列和流量的关系.png","post":"cm4gqpny50051a13kt3zcmx9f","slug":"队列和流量的关系.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-12-28-spring启动过程/ApplicationContext.png","post":"cm4gqpnyg005va13khs4g13d2","slug":"ApplicationContext.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-12-28-spring启动过程/beanDefination.png","slug":"beanDefination.png","post":"cm4gqpnyg005va13khs4g13d2","modified":1,"renderable":0},{"_id":"source/_posts/2019-12-20-tomcat启动过程/tomcat-starting-procedure.jpeg","post":"cm4gqpnvx001ga13kxmwzgl9u","slug":"tomcat-starting-procedure.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/2019-12-20-tomcat启动过程/启动过程.png","slug":"启动过程.png","post":"cm4gqpnvx001ga13kxmwzgl9u","modified":1,"renderable":0},{"_id":"source/_posts/2019-12-20-tomcat启动过程/连接器.png","slug":"连接器.png","post":"cm4gqpnvx001ga13kxmwzgl9u","modified":1,"renderable":0},{"_id":"source/_posts/2019-12-21-tomcat启动过程2/tomcat-starting-procedure.jpeg","post":"cm4gqpnwg001ra13k746lob2v","slug":"tomcat-starting-procedure.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/2019-12-21-tomcat启动过程2/启动过程.png","slug":"启动过程.png","post":"cm4gqpnwg001ra13k746lob2v","modified":1,"renderable":0},{"_id":"source/_posts/2019-12-21-tomcat启动过程2/连接器.png","slug":"连接器.png","post":"cm4gqpnwg001ra13k746lob2v","modified":1,"renderable":0},{"_id":"source/_posts/2020-06-14-分布式主键ID/数据库批量生成分配.png","slug":"数据库批量生成分配.png","post":"cm4gqpnxi0039a13k9uc1irbh","modified":1,"renderable":0},{"_id":"source/_posts/2020-06-14-分布式主键ID/雪花算法.png","slug":"雪花算法.png","post":"cm4gqpnxi0039a13k9uc1irbh","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-16-java对象/内存分配.png","slug":"内存分配.png","post":"cm4gqpnxj003ca13knspmqpb2","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-16-java对象/对象头.png","slug":"对象头.png","post":"cm4gqpnxj003ca13knspmqpb2","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-16-java对象/对象继承.png","slug":"对象继承.png","post":"cm4gqpnxj003ca13knspmqpb2","modified":1,"renderable":0},{"_id":"source/_posts/2024-06-03-稳定性-线程池监控/ThreadPoolExecutor加锁.png","post":"cm4gqpnxx004da13k59e5rrr2","slug":"ThreadPoolExecutor加锁.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-06-03-稳定性-线程池监控/总监控.png","post":"cm4gqpnxx004da13k59e5rrr2","slug":"总监控.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-06-03-稳定性-线程池监控/线程池监控大盘.png","post":"cm4gqpnxx004da13k59e5rrr2","slug":"线程池监控大盘.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-06-05-Linux-CPU负载和利用率/CPU利用率.png","post":"cm4gqpnxz004ka13ku8ndbm3h","slug":"CPU利用率.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-06-05-Linux-CPU负载和利用率/CPU负载示例.png","post":"cm4gqpnxz004ka13ku8ndbm3h","slug":"CPU负载示例.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-06-05-Linux-CPU负载和利用率/cpu负载.png","post":"cm4gqpnxz004ka13ku8ndbm3h","slug":"cpu负载.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-04-11-java-thread/jvm线程-Linux进程.png","slug":"jvm线程-Linux进程.png","post":"cm4gqpny70058a13kdzd21gk5","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-11-java-thread/线程状态流转.png","slug":"线程状态流转.png","post":"cm4gqpny70058a13kdzd21gk5","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-11-java-thread/线程进程关系.png","slug":"线程进程关系.png","post":"cm4gqpny70058a13kdzd21gk5","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-21-架构-三高/并发度公式.png","post":"cm4gqpnyd005qa13kvob13rrw","slug":"并发度公式.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-21-架构-三高/高可用设计.png","slug":"高可用设计.png","post":"cm4gqpnyd005qa13kvob13rrw","modified":1,"renderable":0},{"_id":"source/_posts/2019-04-11-Linux-io模型/sync-block.png","post":"cm4gqpnyk0065a13k5eqygezq","slug":"sync-block.png","modified":1,"renderable":1},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident/redis-connect.jpg","post":"cm4gqpntj0000a13k2k3brwas","slug":"redis-connect.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2018-12-11-Mybatis-online-accident/redis-io.jpg","post":"cm4gqpntj0000a13k2k3brwas","slug":"redis-io.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2019-03-05-单点登录现状/CAS基础协议.png","post":"cm4gqpntr0002a13kyhxx5tha","slug":"CAS基础协议.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-03-05-单点登录现状/cas-login.svg","post":"cm4gqpntr0002a13kyhxx5tha","slug":"cas-login.svg","modified":1,"renderable":1},{"_id":"source/_posts/2019-03-05-单点登录现状/cas-logout.svg","post":"cm4gqpntr0002a13kyhxx5tha","slug":"cas-logout.svg","modified":1,"renderable":1},{"_id":"source/_posts/2019-03-05-单点登录现状/uum现状.png","post":"cm4gqpntr0002a13kyhxx5tha","slug":"uum现状.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-04-13-ThreadLocal/jvm-thread-memory.png","slug":"jvm-thread-memory.png","post":"cm4gqpnwy0027a13k3e9d9101","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-13-ThreadLocal/threadlocal-memory.png","slug":"threadlocal-memory.png","post":"cm4gqpnwy0027a13k3e9d9101","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-06-volatile/cache_sync.png","post":"cm4gqpnxg0035a13ku97w4boz","slug":"cache_sync.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-04-06-volatile/volatile字节码.png","post":"cm4gqpnxg0035a13ku97w4boz","slug":"volatile字节码.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-04-06-volatile/volatile汇编代码.png","slug":"volatile汇编代码.png","post":"cm4gqpnxg0035a13ku97w4boz","modified":1,"renderable":0},{"_id":"source/_posts/2024-04-10-性能优化-日志优化/AsyncAppender.png","post":"cm4gqpnxw004aa13k2vcl54ui","slug":"AsyncAppender.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-04-10-性能优化-日志优化/日志入队列流程.png","slug":"日志入队列流程.png","post":"cm4gqpnxw004aa13k2vcl54ui","modified":1,"renderable":0},{"_id":"source/_posts/2024-04-10-性能优化-日志优化/日志框架_日志系统.png","slug":"日志框架_日志系统.png","post":"cm4gqpnxw004aa13k2vcl54ui","modified":1,"renderable":0},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念/什么是单元化.png","post":"cm4gqpny4004xa13kdrbkst6y","slug":"什么是单元化.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念/单元化产品组成.png","slug":"单元化产品组成.png","post":"cm4gqpny4004xa13kdrbkst6y","modified":1,"renderable":0},{"_id":"source/_posts/2024-07-11-稳定性-单元化概念/底层数据同步.png","slug":"底层数据同步.png","post":"cm4gqpny4004xa13kdrbkst6y","modified":1,"renderable":0},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控/延迟时间.png","post":"cm4gqpny60054a13k1xsw7mb8","slug":"延迟时间.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控/数据同步工作原理.png","post":"cm4gqpny60054a13k1xsw7mb8","slug":"数据同步工作原理.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控/数据处理流程.png","post":"cm4gqpny60054a13k1xsw7mb8","slug":"数据处理流程.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-27-系统重构-如何做数据同步延迟监控/数据迁移工作原理.png","post":"cm4gqpny60054a13k1xsw7mb8","slug":"数据迁移工作原理.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql-explain.png","post":"cm4gqpnu70007a13k0j0ez2l6","slug":"err-sql-explain.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/err-sql.png","post":"cm4gqpnu70007a13k0j0ez2l6","slug":"err-sql.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/mysql.png","post":"cm4gqpnu70007a13k0j0ez2l6","slug":"mysql.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-cos-time.png","post":"cm4gqpnu70007a13k0j0ez2l6","slug":"new-sql-cos-time.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-01-10-记一次MYSQL服务器CPU爆了问题/new-sql-explain.png","post":"cm4gqpnu70007a13k0j0ez2l6","slug":"new-sql-explain.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-03-hbase/HBASE存储.png","post":"cm4gqpnut000ra13k74i47kzl","slug":"HBASE存储.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-03-hbase/HBASE工作原理.png","post":"cm4gqpnut000ra13k74i47kzl","slug":"HBASE工作原理.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-03-hbase/businesslog.png","post":"cm4gqpnut000ra13k74i47kzl","slug":"businesslog.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-03-hbase/uumsize.jpg","post":"cm4gqpnut000ra13k74i47kzl","slug":"uumsize.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2019-08-19-RPC/RPC.png","post":"cm4gqpnve0013a13k3bk80slx","slug":"RPC.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-08-19-RPC/server线程模型.png","slug":"server线程模型.png","post":"cm4gqpnve0013a13k3bk80slx","modified":1,"renderable":0},{"_id":"source/_posts/2019-08-19-RPC/客户端架构.png","post":"cm4gqpnve0013a13k3bk80slx","slug":"客户端架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-08-19-RPC/方法调用过程.png","post":"cm4gqpnve0013a13k3bk80slx","slug":"方法调用过程.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-04-04-cpu/CPU缓存.png","slug":"CPU缓存.png","post":"cm4gqpnwq001va13k9icksg7r","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-04-cpu/基本组成.png","slug":"基本组成.png","post":"cm4gqpnwq001va13k9icksg7r","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-04-cpu/大概布局.png","slug":"大概布局.png","post":"cm4gqpnwq001va13k9icksg7r","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-04-cpu/缓存问题.png","slug":"缓存问题.png","post":"cm4gqpnwq001va13k9icksg7r","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-12-线程池/定时任务-数据结构.png","post":"cm4gqpnx3002fa13k1dzolbyj","slug":"定时任务-数据结构.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-04-12-线程池/定时任务.png","post":"cm4gqpnx3002fa13k1dzolbyj","slug":"定时任务.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-11-30-tomcat架构/connect-flow.jpeg","post":"cm4gqpnvs001da13kyprn6yhe","slug":"connect-flow.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/2019-11-30-tomcat架构/connect-framework.jpeg","post":"cm4gqpnvs001da13kyprn6yhe","slug":"connect-framework.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/2019-11-30-tomcat架构/container-framework.jpeg","post":"cm4gqpnvs001da13kyprn6yhe","slug":"container-framework.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/2019-11-30-tomcat架构/coyote-frame.png","post":"cm4gqpnvs001da13kyprn6yhe","slug":"coyote-frame.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-11-30-tomcat架构/tomcat-framework.jpg","post":"cm4gqpnvs001da13kyprn6yhe","slug":"tomcat-framework.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/GC日志.png","slug":"GC日志.png","post":"cm4gqpnxs0043a13k3w5jxill","modified":1,"renderable":0},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/classloader.png","slug":"classloader.png","post":"cm4gqpnxs0043a13k3w5jxill","modified":1,"renderable":0},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/metaspaceoom.png","post":"cm4gqpnxs0043a13k3w5jxill","slug":"metaspaceoom.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/业务日志.png","post":"cm4gqpnxs0043a13k3w5jxill","slug":"业务日志.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-07-性能优化-jvm优化/类视图.png","slug":"类视图.png","post":"cm4gqpnxs0043a13k3w5jxill","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-25-架构-常见架构/MVC和三层架构的联系与区别.png","slug":"MVC和三层架构的联系与区别.png","post":"cm4gqpnyb005ka13ka1bax7a0","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-25-架构-常见架构/MVC架构工作流程.png","post":"cm4gqpnyb005ka13ka1bax7a0","slug":"MVC架构工作流程.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-25-架构-常见架构/三层架构.png","post":"cm4gqpnyb005ka13ka1bax7a0","slug":"三层架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-25-架构-常见架构/系统架构-分布式架构.png","post":"cm4gqpnyb005ka13ka1bax7a0","slug":"系统架构-分布式架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-25-架构-常见架构/系统架构-单体架构.png","post":"cm4gqpnyb005ka13ka1bax7a0","slug":"系统架构-单体架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/DDD包结构.png","post":"cm4gqpnyh005ya13kwvbyypp4","slug":"DDD包结构.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/DDD包结构展开.png","post":"cm4gqpnyh005ya13kwvbyypp4","slug":"DDD包结构展开.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/DDD演进.png","slug":"DDD演进.png","post":"cm4gqpnyh005ya13kwvbyypp4","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/三层架构到DDD.png","post":"cm4gqpnyh005ya13kwvbyypp4","slug":"三层架构到DDD.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-13-架构-三层架构的演进到DDD/传统分层代码结构.png","post":"cm4gqpnyh005ya13kwvbyypp4","slug":"传统分层代码结构.png","modified":1,"renderable":1},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/jstat-GC情况.png","slug":"jstat-GC情况.png","post":"cm4gqpntv0005a13ktkdgg3om","modified":1,"renderable":0},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/redis-connect.jpg","post":"cm4gqpntv0005a13ktkdgg3om","slug":"redis-connect.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/redis-io.jpg","post":"cm4gqpntv0005a13ktkdgg3om","slug":"redis-io.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2018-12-11-统一登录线上事故排查过程/内存情况.png","post":"cm4gqpntv0005a13ktkdgg3om","slug":"内存情况.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-06-01-es/倒排索引.png","post":"cm4gqpnxf0032a13k3zyubj0u","slug":"倒排索引.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-06-01-es/倒排索引组成.png","post":"cm4gqpnxf0032a13k3zyubj0u","slug":"倒排索引组成.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-06-01-es/存储目录结构图.png","post":"cm4gqpnxf0032a13k3zyubj0u","slug":"存储目录结构图.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-06-01-es/数据逻辑结构.png","post":"cm4gqpnxf0032a13k3zyubj0u","slug":"数据逻辑结构.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-06-01-es/正排索引.png","post":"cm4gqpnxf0032a13k3zyubj0u","slug":"正排索引.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-06-01-es/集群架构.png","post":"cm4gqpnxf0032a13k3zyubj0u","slug":"集群架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-07-01-分库分表/方案一.png","post":"cm4gqpnxl003ja13k0d6kywuu","slug":"方案一.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-07-01-分库分表/方案一优缺点.png","post":"cm4gqpnxl003ja13k0d6kywuu","slug":"方案一优缺点.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-07-01-分库分表/方案一对比.png","post":"cm4gqpnxl003ja13k0d6kywuu","slug":"方案一对比.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-07-01-分库分表/方案二.png","post":"cm4gqpnxl003ja13k0d6kywuu","slug":"方案二.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-07-01-分库分表/方案二优缺点.png","post":"cm4gqpnxl003ja13k0d6kywuu","slug":"方案二优缺点.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-07-01-分库分表/方案二对比.png","post":"cm4gqpnxl003ja13k0d6kywuu","slug":"方案二对比.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-10-19-交易账单/业务模式.png","post":"cm4gqpnxm003ma13kzoywubny","slug":"业务模式.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-10-19-交易账单/交易流程图.png","post":"cm4gqpnxm003ma13kzoywubny","slug":"交易流程图.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-10-19-交易账单/交易状态流转.png","post":"cm4gqpnxm003ma13kzoywubny","slug":"交易状态流转.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-10-19-交易账单/表结构关系图.png","post":"cm4gqpnxm003ma13kzoywubny","slug":"表结构关系图.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-10-19-交易账单/表结构具体内容.png","post":"cm4gqpnxm003ma13kzoywubny","slug":"表结构具体内容.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-10-19-交易账单/账单状态流转.png","post":"cm4gqpnxm003ma13kzoywubny","slug":"账单状态流转.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-20-架构-架构/业务架构.png","slug":"业务架构.png","post":"cm4gqpny8005ba13kncj57a94","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-20-架构-架构/应用架构.png","slug":"应用架构.png","post":"cm4gqpny8005ba13kncj57a94","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-20-架构-架构/技术架构.png","slug":"技术架构.png","post":"cm4gqpny8005ba13kncj57a94","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-20-架构-架构/数据架构.png","slug":"数据架构.png","post":"cm4gqpny8005ba13kncj57a94","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-20-架构-架构/装饰者模式.png","post":"cm4gqpny8005ba13kncj57a94","slug":"装饰者模式.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-20-架构-架构/观察者模式.png","post":"cm4gqpny8005ba13kncj57a94","slug":"观察者模式.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/先双写后存量.png","post":"cm4gqpny9005ea13ke6blwqyl","slug":"先双写后存量.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/先存量后增量.png","slug":"先存量后增量.png","post":"cm4gqpny9005ea13ke6blwqyl","modified":1,"renderable":0},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/双写先.png","post":"cm4gqpny9005ea13ke6blwqyl","slug":"双写先.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/数据一致性_增量.png","post":"cm4gqpny9005ea13ke6blwqyl","slug":"数据一致性_增量.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/数据一致性_存量.png","post":"cm4gqpny9005ea13ke6blwqyl","slug":"数据一致性_存量.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-02-系统重构-系统重构和合并总结/项目管理流程.png","slug":"项目管理流程.png","post":"cm4gqpny9005ea13ke6blwqyl","modified":1,"renderable":0},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/new-permission.png","slug":"new-permission.png","post":"cm4gqpnue000ca13kugxq9pjc","modified":1,"renderable":0},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/new-sso-1.png","slug":"new-sso-1.png","post":"cm4gqpnue000ca13kugxq9pjc","modified":1,"renderable":0},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/old-permission.png","slug":"old-permission.png","post":"cm4gqpnue000ca13kugxq9pjc","modified":1,"renderable":0},{"_id":"source/_posts/2019-03-22-单点登录优化方案二/old-sso-1.png","slug":"old-sso-1.png","post":"cm4gqpnue000ca13kugxq9pjc","modified":1,"renderable":0},{"_id":"source/_posts/2019-08-01-MQ对比/kafka-broker.png","post":"cm4gqpnv90010a13kmo05w9ni","slug":"kafka-broker.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-08-01-MQ对比/kafka-consumer注册.jpeg","post":"cm4gqpnv90010a13kmo05w9ni","slug":"kafka-consumer注册.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/2019-08-01-MQ对比/mq-center.png","post":"cm4gqpnv90010a13kmo05w9ni","slug":"mq-center.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-08-01-MQ对比/rocketmq-messagequeue.jpeg","post":"cm4gqpnv90010a13kmo05w9ni","slug":"rocketmq-messagequeue.jpeg","modified":1,"renderable":1},{"_id":"source/_posts/2019-08-01-MQ对比/rocketmq_architecture_3.png","post":"cm4gqpnv90010a13kmo05w9ni","slug":"rocketmq_architecture_3.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-08-01-MQ对比/rocketmq_design_1.png","post":"cm4gqpnv90010a13kmo05w9ni","slug":"rocketmq_design_1.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/DDD完整设计流程.png","post":"cm4gqpnyb005na13ksd8qmmff","slug":"DDD完整设计流程.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/分层架构_代码指示.png","post":"cm4gqpnyb005na13ksd8qmmff","slug":"分层架构_代码指示.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/商品数据模型图.png","slug":"商品数据模型图.png","post":"cm4gqpnyb005na13ksd8qmmff","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/商品领域.png","post":"cm4gqpnyb005na13ksd8qmmff","slug":"商品领域.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/实施总结.png","slug":"实施总结.png","post":"cm4gqpnyb005na13ksd8qmmff","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-10-架构-DDD实施过程/战略战术结果.png","post":"cm4gqpnyb005na13ksd8qmmff","slug":"战略战术结果.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-06-28-hadoop/BlockManager.jpg","post":"cm4gqpnuy000va13kssfnsm5e","slug":"BlockManager.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2019-06-28-hadoop/hadoop-架构.png","post":"cm4gqpnuy000va13kssfnsm5e","slug":"hadoop-架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-06-28-hadoop/hdfs-整体图.jpg","post":"cm4gqpnuy000va13kssfnsm5e","slug":"hdfs-整体图.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2019-06-28-hadoop/hdfs-架构.png","post":"cm4gqpnuy000va13kssfnsm5e","slug":"hdfs-架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-06-28-hadoop/namespace.png","post":"cm4gqpnuy000va13kssfnsm5e","slug":"namespace.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-06-28-hadoop/namespace1.jpg","post":"cm4gqpnuy000va13kssfnsm5e","slug":"namespace1.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-24-DMQ/mq-center.png","post":"cm4gqpnvi0016a13ke2azn86f","slug":"mq-center.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-24-DMQ/mq-client-center.png","post":"cm4gqpnvi0016a13ke2azn86f","slug":"mq-client-center.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-24-DMQ/mq-client-server-3.png","post":"cm4gqpnvi0016a13ke2azn86f","slug":"mq-client-server-3.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-24-DMQ/mq-server-resend.png","post":"cm4gqpnvi0016a13ke2azn86f","slug":"mq-server-resend.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-24-DMQ/mq-server-send.png","post":"cm4gqpnvi0016a13ke2azn86f","slug":"mq-server-send.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-24-DMQ/mq-server-start.png","post":"cm4gqpnvi0016a13ke2azn86f","slug":"mq-server-start.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-24-DMQ/mq-server-sub.png","post":"cm4gqpnvi0016a13ke2azn86f","slug":"mq-server-sub.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-24-DMQ/mq-总结.png","post":"cm4gqpnvi0016a13ke2azn86f","slug":"mq-总结.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-04-09-Linux-thread/piepline.png","slug":"piepline.png","post":"cm4gqpnww0025a13ka8vdvw92","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-09-Linux-thread/slab.png","post":"cm4gqpnww0025a13ka8vdvw92","slug":"slab.png","modified":1,"renderable":1},{"_id":"source/_posts/2020-04-09-Linux-thread/stack.png","slug":"stack.png","post":"cm4gqpnww0025a13ka8vdvw92","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-09-Linux-thread/task_struct.png","slug":"task_struct.png","post":"cm4gqpnww0025a13ka8vdvw92","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-09-Linux-thread/thread-info.png","slug":"thread-info.png","post":"cm4gqpnww0025a13ka8vdvw92","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-09-Linux-thread/vm-实现.png","slug":"vm-实现.png","post":"cm4gqpnww0025a13ka8vdvw92","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-09-Linux-thread/vm.png","slug":"vm.png","post":"cm4gqpnww0025a13ka8vdvw92","modified":1,"renderable":0},{"_id":"source/_posts/2020-04-09-Linux-thread/缺页.png","slug":"缺页.png","post":"cm4gqpnww0025a13ka8vdvw92","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/DMA-优化.png","slug":"DMA-优化.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/DMA.png","slug":"DMA.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/jmm.png","slug":"jmm.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/mmp.png","slug":"mmp.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/sendfile.png","slug":"sendfile.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/sendfile_DMA.png","slug":"sendfile_DMA.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/基本方式.png","slug":"基本方式.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2020-05-07-零拷贝/直接内存.png","slug":"直接内存.png","post":"cm4gqpnx7002la13k391oce55","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-13-zookeeper/datastruct.png","slug":"datastruct.png","post":"cm4gqpnv5000za13kuwd0pacs","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-13-zookeeper/watch.png","post":"cm4gqpnv5000za13kuwd0pacs","slug":"watch.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-13-zookeeper/zk.png","slug":"zk.png","post":"cm4gqpnv5000za13kuwd0pacs","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-13-zookeeper/zknode-example.png","slug":"zknode-example.png","post":"cm4gqpnv5000za13kuwd0pacs","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-13-zookeeper/zknode.png","slug":"zknode.png","post":"cm4gqpnv5000za13kuwd0pacs","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-13-zookeeper/分布式锁.png","post":"cm4gqpnv5000za13kuwd0pacs","slug":"分布式锁.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-13-zookeeper/实现分布式锁流程.png","post":"cm4gqpnv5000za13kuwd0pacs","slug":"实现分布式锁流程.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-13-zookeeper/注册过程.png","slug":"注册过程.png","post":"cm4gqpnv5000za13kuwd0pacs","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-13-zookeeper/选举1.png","post":"cm4gqpnv5000za13kuwd0pacs","slug":"选举1.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-13-zookeeper/选举2.png","post":"cm4gqpnv5000za13kuwd0pacs","slug":"选举2.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-07-hbase梳理/HBASE存储.png","post":"cm4gqpnw0001ia13k6k3twovz","slug":"HBASE存储.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-07-hbase梳理/HBASE工作原理.png","post":"cm4gqpnw0001ia13k6k3twovz","slug":"HBASE工作原理.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-07-hbase梳理/businesslog.png","post":"cm4gqpnw0001ia13k6k3twovz","slug":"businesslog.png","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-07-hbase梳理/uumsize.jpg","post":"cm4gqpnw0001ia13k6k3twovz","slug":"uumsize.jpg","modified":1,"renderable":1},{"_id":"source/_posts/2019-07-07-hbase梳理/数据写入过程.png","slug":"数据写入过程.png","post":"cm4gqpnw0001ia13k6k3twovz","modified":1,"renderable":0},{"_id":"source/_posts/2019-07-07-hbase梳理/逻辑存储.png","slug":"逻辑存储.png","post":"cm4gqpnw0001ia13k6k3twovz","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/传统4层架构.png","post":"cm4gqpnyf005ta13knrqs5xrz","slug":"传统4层架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/六边形架构.png","slug":"六边形架构.png","post":"cm4gqpnyf005ta13knrqs5xrz","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/分层架构_代码指示.png","post":"cm4gqpnyf005ta13knrqs5xrz","slug":"分层架构_代码指示.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/分层架构_包结构划分.png","slug":"分层架构_包结构划分.png","post":"cm4gqpnyf005ta13knrqs5xrz","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/总的架构演进图.png","slug":"总的架构演进图.png","post":"cm4gqpnyf005ta13knrqs5xrz","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/整洁架构.png","slug":"整洁架构.png","post":"cm4gqpnyf005ta13knrqs5xrz","modified":1,"renderable":0},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/洋葱架构.png","post":"cm4gqpnyf005ta13knrqs5xrz","slug":"洋葱架构.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-09-03-架构-DDD应用架构/清晰架构.png","slug":"清晰架构.png","post":"cm4gqpnyf005ta13knrqs5xrz","modified":1,"renderable":0},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/4阶段.png","post":"cm4gqpnyj0062a13kxfa6nk1o","slug":"4阶段.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/切流方案.png","post":"cm4gqpnyj0062a13kxfa6nk1o","slug":"切流方案.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/切流流程.png","post":"cm4gqpnyj0062a13kxfa6nk1o","slug":"切流流程.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/常见的数据一致性方案.png","post":"cm4gqpnyj0062a13kxfa6nk1o","slug":"常见的数据一致性方案.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/数据库层.png","post":"cm4gqpnyj0062a13kxfa6nk1o","slug":"数据库层.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/消息通信层.png","slug":"消息通信层.png","post":"cm4gqpnyj0062a13kxfa6nk1o","modified":1,"renderable":0},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/现状.png","post":"cm4gqpnyj0062a13kxfa6nk1o","slug":"现状.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/目标.png","post":"cm4gqpnyj0062a13kxfa6nk1o","slug":"目标.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-07-18-稳定性-单元化改造示例/路由逻辑.png","post":"cm4gqpnyj0062a13kxfa6nk1o","slug":"路由逻辑.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/AsyncInitBeanFactoryPostProcessor-registerAsyncInitBean.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"AsyncInitBeanFactoryPostProcessor-registerAsyncInitBean.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/beanpostprocessor.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"beanpostprocessor.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/registerAsyncInitBean具体实现.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"registerAsyncInitBean具体实现.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/spring三级缓存.png","slug":"spring三级缓存.png","post":"cm4gqpnxp003ta13kv3huyqvk","modified":1,"renderable":0},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/spring初始化流程.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"spring初始化流程.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/spring实例初始化流程.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"spring实例初始化流程.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/启动加速-自动扫描异步类.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"启动加速-自动扫描异步类.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/异步化.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"异步化.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/性能效果.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"性能效果.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/注解解析.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"注解解析.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-03-01-性能优化-启动优化/编译发布流程图.png","post":"cm4gqpnxp003ta13kv3huyqvk","slug":"编译发布流程图.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-23-架构-常见技术框架性能/正反向代理.png","post":"cm4gqpo2w00aja13k2y56ld8e","slug":"正反向代理.png","modified":1,"renderable":1},{"_id":"source/_posts/2024-08-28-架构-DDD概念/DDD基本概念图.png","slug":"DDD基本概念图.png","post":"cm4gqpo2x00aka13ks9mlekgr","modified":1,"renderable":0}],"PostCategory":[{"post_id":"cm4gqpnue000ca13kugxq9pjc","category_id":"cm4gqpnud000aa13k22a7grsm","_id":"cm4gqpnun000ja13khackgaph"},{"post_id":"cm4gqpntr0002a13kyhxx5tha","category_id":"cm4gqpnud000aa13k22a7grsm","_id":"cm4gqpnuq000na13k9hak65jn"},{"post_id":"cm4gqpntj0000a13k2k3brwas","category_id":"cm4gqpntw0006a13k3jmzcm39","_id":"cm4gqpnvf0014a13kyaitgmte"},{"post_id":"cm4gqpntj0000a13k2k3brwas","category_id":"cm4gqpnut000sa13k9zrqbmsi","_id":"cm4gqpnvj0017a13kt0nduvk1"},{"post_id":"cm4gqpnub0008a13khvtj5g0k","category_id":"cm4gqpnud000aa13k22a7grsm","_id":"cm4gqpnvo001ba13kn3ilxh09"},{"post_id":"cm4gqpnuk000ga13k21m2lmbq","category_id":"cm4gqpnvj0018a13kwqeqde75","_id":"cm4gqpnw5001ka13kc9yblzih"},{"post_id":"cm4gqpnun000ia13ktfx71f01","category_id":"cm4gqpnvj0018a13kwqeqde75","_id":"cm4gqpnwg001pa13kkdttud9d"},{"post_id":"cm4gqpntv0005a13ktkdgg3om","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnwu001xa13k9486tegr"},{"post_id":"cm4gqpntv0005a13ktkdgg3om","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnwv0021a13ksns5t955"},{"post_id":"cm4gqpnve0013a13k3bk80slx","category_id":"cm4gqpnwr001wa13k4ojnoeqw","_id":"cm4gqpnwz0029a13kwiwi7lsz"},{"post_id":"cm4gqpnwy0027a13k3e9d9101","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnx6002ja13kpmb6vpoi"},{"post_id":"cm4gqpnwy0027a13k3e9d9101","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnx7002ma13kr7bsndt7"},{"post_id":"cm4gqpnvi0016a13ke2azn86f","category_id":"cm4gqpnwz0028a13k7ncjq662","_id":"cm4gqpnx9002pa13k4el131xi"},{"post_id":"cm4gqpnwz002aa13kmg6q1zkm","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxa002ta13kpwtixu05"},{"post_id":"cm4gqpnwz002aa13kmg6q1zkm","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnxc002wa13kwfn67rto"},{"post_id":"cm4gqpnx1002da13kfpucpy67","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxd0030a13km25hs1wh"},{"post_id":"cm4gqpnx1002da13kfpucpy67","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnxg0033a13k977nqgtr"},{"post_id":"cm4gqpnu70007a13k0j0ez2l6","category_id":"cm4gqpnuo000la13k8uzw230q","_id":"cm4gqpnxh0037a13kt7txackt"},{"post_id":"cm4gqpnu70007a13k0j0ez2l6","category_id":"cm4gqpnwg001qa13kzk7yy5fu","_id":"cm4gqpnxi003aa13knuz343bd"},{"post_id":"cm4gqpnu70007a13k0j0ez2l6","category_id":"cm4gqpnx2002ea13kut6u44p5","_id":"cm4gqpnxk003ea13kxspa633r"},{"post_id":"cm4gqpnwq001va13k9icksg7r","category_id":"cm4gqpnx6002ka13klrtm2szt","_id":"cm4gqpnxl003ha13kblifcv6h"},{"post_id":"cm4gqpnx8002oa13kegip255g","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxm003ka13k6v6p75mq"},{"post_id":"cm4gqpnx9002ra13kuatmivm2","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxn003na13k9tx7hh3c"},{"post_id":"cm4gqpnwv0022a13k9rajnntq","category_id":"cm4gqpnx6002ka13klrtm2szt","_id":"cm4gqpnxp003ra13k8umjqo5r"},{"post_id":"cm4gqpnxb002va13ku9v9lnms","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxq003ua13ki4jr9sqo"},{"post_id":"cm4gqpnxc002ya13kalnvsyh1","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxr003ya13kkdyrxyrj"},{"post_id":"cm4gqpnww0025a13ka8vdvw92","category_id":"cm4gqpnx6002ka13klrtm2szt","_id":"cm4gqpnxs0041a13kv4e0g6yd"},{"post_id":"cm4gqpnxg0035a13ku97w4boz","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnxt0044a13k6ey19py9"},{"post_id":"cm4gqpnxg0035a13ku97w4boz","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnxv0048a13k1hcnjxbd"},{"post_id":"cm4gqpnuh000da13knd69zcpj","category_id":"cm4gqpnuo000la13k8uzw230q","_id":"cm4gqpnxw004ba13kbn3uhbfx"},{"post_id":"cm4gqpnuh000da13knd69zcpj","category_id":"cm4gqpnwg001qa13kzk7yy5fu","_id":"cm4gqpnxy004fa13kh9otd52s"},{"post_id":"cm4gqpnuh000da13knd69zcpj","category_id":"cm4gqpnx2002ea13kut6u44p5","_id":"cm4gqpnxz004ia13k17vqyech"},{"post_id":"cm4gqpnx3002fa13k1dzolbyj","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpny0004la13kquclona8"},{"post_id":"cm4gqpnx3002fa13k1dzolbyj","category_id":"cm4gqpnxj003da13k14orzex6","_id":"cm4gqpny1004oa13kwb2cm18i"},{"post_id":"cm4gqpnx4002ha13krmhlilge","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpny2004sa13kljahfcu1"},{"post_id":"cm4gqpnx4002ha13krmhlilge","category_id":"cm4gqpnxm003la13kmd4qm25w","_id":"cm4gqpny3004va13kiyerxzw7"},{"post_id":"cm4gqpnxf0032a13k3zyubj0u","category_id":"cm4gqpnxp003sa13kvtxg9x65","_id":"cm4gqpny4004za13kvberwf3a"},{"post_id":"cm4gqpnxj003ca13knspmqpb2","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpny50052a13kdsrezhqs"},{"post_id":"cm4gqpnxj003ca13knspmqpb2","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpny60055a13kiol196nw"},{"post_id":"cm4gqpnxj003ca13knspmqpb2","category_id":"cm4gqpnxr003za13ktdyk41ng","_id":"cm4gqpny70059a13kuej97fzm"},{"post_id":"cm4gqpnxk003fa13k4yth221h","category_id":"cm4gqpnxp003sa13kvtxg9x65","_id":"cm4gqpny8005ca13kkzdmykhd"},{"post_id":"cm4gqpny70058a13kdzd21gk5","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnyb005la13kk3avieet"},{"post_id":"cm4gqpny70058a13kdzd21gk5","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnyc005oa13k0a1luu4l"},{"post_id":"cm4gqpnyk0065a13k5eqygezq","category_id":"cm4gqpnx6002ka13klrtm2szt","_id":"cm4gqpnyn006ba13knp00bgsa"},{"post_id":"cm4gqpnxo003pa13k47m3h8tj","category_id":"cm4gqpnxx004ea13k7g2kju5x","_id":"cm4gqpnyo006ea13kyw4yf3a9"},{"post_id":"cm4gqpnxo003pa13k47m3h8tj","category_id":"cm4gqpnyk0063a13kdkv4nuc9","_id":"cm4gqpnyp006ga13kp2d1kfz0"},{"post_id":"cm4gqpnxz004ka13ku8ndbm3h","category_id":"cm4gqpnx6002ka13klrtm2szt","_id":"cm4gqpnyq006ka13kf2s11fug"},{"post_id":"cm4gqpnxz004ka13ku8ndbm3h","category_id":"cm4gqpnyf005sa13ki8tlklgn","_id":"cm4gqpnyr006ma13k337h6zy0"},{"post_id":"cm4gqpny60054a13k1xsw7mb8","category_id":"cm4gqpnyw0073a13kwbdxwh8q","_id":"cm4gqpnyy007aa13k22nuwias"},{"post_id":"cm4gqpny9005ea13ke6blwqyl","category_id":"cm4gqpnyw0073a13kwbdxwh8q","_id":"cm4gqpnz0007la13kikwe5lnd"},{"post_id":"cm4gqpnyb005ka13ka1bax7a0","category_id":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnz1007ra13koikw1s9u"},{"post_id":"cm4gqpnya005ha13ko9590szt","category_id":"cm4gqpnxx004ea13k7g2kju5x","_id":"cm4gqpnz1007ua13k78dicv8d"},{"post_id":"cm4gqpnya005ha13ko9590szt","category_id":"cm4gqpntw0006a13k3jmzcm39","_id":"cm4gqpnz1007va13kbzugnmu2"},{"post_id":"cm4gqpnya005ha13ko9590szt","category_id":"cm4gqpnz0007na13krvmzf81p","_id":"cm4gqpnz2007xa13k715bds9v"},{"post_id":"cm4gqpnyg005va13khs4g13d2","category_id":"cm4gqpnxx004ea13k7g2kju5x","_id":"cm4gqpnz30082a13kx1qctr3p"},{"post_id":"cm4gqpnyg005va13khs4g13d2","category_id":"cm4gqpnz2007za13k8nwvsopw","_id":"cm4gqpnz30083a13k30yljoqq"},{"post_id":"cm4gqpnxx004da13k59e5rrr2","category_id":"cm4gqpnyf005sa13ki8tlklgn","_id":"cm4gqpnz30085a13ke70ntc3k"},{"post_id":"cm4gqpnxx004da13k59e5rrr2","category_id":"cm4gqpnz20080a13k93f8qyka","_id":"cm4gqpnz40087a13knm1cmuml"},{"post_id":"cm4gqpnxx004da13k59e5rrr2","category_id":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnz40088a13kzcyjq099"},{"post_id":"cm4gqpnyi0060a13kkuw45syr","category_id":"cm4gqpnz30084a13klnr0qt5c","_id":"cm4gqpnz4008aa13kbldk2cah"},{"post_id":"cm4gqpny0004na13ksluavuds","category_id":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnz5008ea13kca86ok37"},{"post_id":"cm4gqpny0004na13ksluavuds","category_id":"cm4gqpnz20080a13k93f8qyka","_id":"cm4gqpnz6008fa13ko5wgpsdu"},{"post_id":"cm4gqpny1004qa13ktdoklfpg","category_id":"cm4gqpnyf005sa13ki8tlklgn","_id":"cm4gqpnz7008ha13kii4i6ez8"},{"post_id":"cm4gqpny1004qa13ktdoklfpg","category_id":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnz7008ja13kq665puxv"},{"post_id":"cm4gqpny1004qa13ktdoklfpg","category_id":"cm4gqpnz4008ca13k3naw392e","_id":"cm4gqpnz7008ka13k6bk5ktcf"},{"post_id":"cm4gqpny1004qa13ktdoklfpg","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnz7008ma13k1bodougd"},{"post_id":"cm4gqpnxp003ta13kv3huyqvk","category_id":"cm4gqpnuo000la13k8uzw230q","_id":"cm4gqpnz8008na13k7bs746v6"},{"post_id":"cm4gqpnxp003ta13kv3huyqvk","category_id":"cm4gqpnwg001qa13kzk7yy5fu","_id":"cm4gqpnz8008pa13khxtlzs5z"},{"post_id":"cm4gqpnxp003ta13kv3huyqvk","category_id":"cm4gqpny0004ma13kxqrasbav","_id":"cm4gqpnz8008qa13kosootjya"},{"post_id":"cm4gqpnxp003ta13kv3huyqvk","category_id":"cm4gqpnyq006ja13k31ljmnq5","_id":"cm4gqpnz9008sa13ke4uz3w7g"},{"post_id":"cm4gqpnxp003ta13kv3huyqvk","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnz9008ta13kgliukuac"},{"post_id":"cm4gqpnxp003ta13kv3huyqvk","category_id":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnzd008va13kl48mpugj"},{"post_id":"cm4gqpny3004ua13kq1xzarfm","category_id":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnzd008wa13ka352q167"},{"post_id":"cm4gqpny3004ua13kq1xzarfm","category_id":"cm4gqpnz6008ga13kcmlzl4lz","_id":"cm4gqpnzd008xa13kntt6tdge"},{"post_id":"cm4gqpny3004ua13kq1xzarfm","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnze008za13k4m57wv2t"},{"post_id":"cm4gqpny4004xa13kdrbkst6y","category_id":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnze0090a13kcimumrte"},{"post_id":"cm4gqpny4004xa13kdrbkst6y","category_id":"cm4gqpnz7008ia13kikaps65e","_id":"cm4gqpnzf0092a13kafftfeke"},{"post_id":"cm4gqpny4004xa13kdrbkst6y","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnzf0093a13keffp3lg1"},{"post_id":"cm4gqpnxq003wa13kaevt6bnb","category_id":"cm4gqpnuo000la13k8uzw230q","_id":"cm4gqpnzg0095a13k7w9afzsj"},{"post_id":"cm4gqpnxq003wa13kaevt6bnb","category_id":"cm4gqpnwg001qa13kzk7yy5fu","_id":"cm4gqpnzg0096a13kmcww05ai"},{"post_id":"cm4gqpnxq003wa13kaevt6bnb","category_id":"cm4gqpny0004ma13kxqrasbav","_id":"cm4gqpnzg0098a13ka5hosktn"},{"post_id":"cm4gqpnxq003wa13kaevt6bnb","category_id":"cm4gqpnyq006ja13k31ljmnq5","_id":"cm4gqpnzg0099a13kevkd1mr9"},{"post_id":"cm4gqpnxq003wa13kaevt6bnb","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnzh009ba13kh2hmpd8d"},{"post_id":"cm4gqpny50051a13kt3zcmx9f","category_id":"cm4gqpnyf005sa13ki8tlklgn","_id":"cm4gqpnzh009ca13k39u287n6"},{"post_id":"cm4gqpny50051a13kt3zcmx9f","category_id":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnzh009ea13kwn17yq43"},{"post_id":"cm4gqpny50051a13kt3zcmx9f","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnzh009fa13kf8msqsec"},{"post_id":"cm4gqpnxr0040a13kubvx69de","category_id":"cm4gqpny40050a13k48j2lo8d","_id":"cm4gqpnzi009ha13k0o65jjwq"},{"post_id":"cm4gqpnxr0040a13kubvx69de","category_id":"cm4gqpnyw006za13k9qljlf7v","_id":"cm4gqpnzi009ia13k9ki1atiu"},{"post_id":"cm4gqpnxr0040a13kubvx69de","category_id":"cm4gqpnyq006ja13k31ljmnq5","_id":"cm4gqpnzj009ka13k9ejljslx"},{"post_id":"cm4gqpnxr0040a13kubvx69de","category_id":"cm4gqpnz8008ra13kt3orfibz","_id":"cm4gqpnzj009la13kwh8b2hlw"},{"post_id":"cm4gqpny8005ba13kncj57a94","category_id":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnzj009na13k29bs0iug"},{"post_id":"cm4gqpny8005ba13kncj57a94","category_id":"cm4gqpnz9008ua13krn5f7l0e","_id":"cm4gqpnzk009oa13ku9ufgazh"},{"post_id":"cm4gqpnxs0043a13k3w5jxill","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnzk009pa13k266tyl2x"},{"post_id":"cm4gqpnxs0043a13k3w5jxill","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnzk009qa13kr7jycn1z"},{"post_id":"cm4gqpnxs0043a13k3w5jxill","category_id":"cm4gqpny60057a13kay13xikf","_id":"cm4gqpnzk009ra13kd43gllqd"},{"post_id":"cm4gqpnxs0043a13k3w5jxill","category_id":"cm4gqpnyx0079a13k9l1lvapj","_id":"cm4gqpnzk009sa13kethofxal"},{"post_id":"cm4gqpnxs0043a13k3w5jxill","category_id":"cm4gqpnyq006ja13k31ljmnq5","_id":"cm4gqpnzk009ta13kwc77gj93"},{"post_id":"cm4gqpnxs0043a13k3w5jxill","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnzk009ua13kovcy5nsb"},{"post_id":"cm4gqpnxu0046a13kdnncsydf","category_id":"cm4gqpnuk000fa13k35r2uycm","_id":"cm4gqpnzk009va13k2ti7k6xe"},{"post_id":"cm4gqpnxu0046a13kdnncsydf","category_id":"cm4gqpnw4001ja13kkwz91n8m","_id":"cm4gqpnzk009wa13kkl549fem"},{"post_id":"cm4gqpnxu0046a13kdnncsydf","category_id":"cm4gqpny9005fa13k3afobg9k","_id":"cm4gqpnzk009xa13kcq8ffiun"},{"post_id":"cm4gqpnxu0046a13kdnncsydf","category_id":"cm4gqpnyz007ga13ky1ixom1s","_id":"cm4gqpnzl009ya13kwauoikwl"},{"post_id":"cm4gqpnxu0046a13kdnncsydf","category_id":"cm4gqpnyq006ja13k31ljmnq5","_id":"cm4gqpnzl009za13klvugg2aq"},{"post_id":"cm4gqpnxu0046a13kdnncsydf","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnzl00a0a13k3oyoyfxd"},{"post_id":"cm4gqpnyb005na13ksd8qmmff","category_id":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnzl00a1a13kpkvxi0iw"},{"post_id":"cm4gqpnyb005na13ksd8qmmff","category_id":"cm4gqpnzf0094a13kexf2bp1c","_id":"cm4gqpnzl00a2a13k90lm3c67"},{"post_id":"cm4gqpnyd005qa13kvob13rrw","category_id":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnzl00a3a13k210hg6wv"},{"post_id":"cm4gqpnyd005qa13kvob13rrw","category_id":"cm4gqpnzg0097a13koz9mpj17","_id":"cm4gqpnzl00a4a13k9dc0pqxs"},{"post_id":"cm4gqpnxw004aa13k2vcl54ui","category_id":"cm4gqpnyb005ma13kcuxb3br3","_id":"cm4gqpnzl00a5a13kqnq1jptj"},{"post_id":"cm4gqpnxw004aa13k2vcl54ui","category_id":"cm4gqpnyq006ja13k31ljmnq5","_id":"cm4gqpnzl00a6a13kkvxh57lo"},{"post_id":"cm4gqpnxw004aa13k2vcl54ui","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnzl00a7a13krjlrlxa9"},{"post_id":"cm4gqpnyf005ta13knrqs5xrz","category_id":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnzl00a8a13k6m7x9pd6"},{"post_id":"cm4gqpnyf005ta13knrqs5xrz","category_id":"cm4gqpnzf0094a13kexf2bp1c","_id":"cm4gqpnzl00a9a13ksnzykrwi"},{"post_id":"cm4gqpnyh005ya13kwvbyypp4","category_id":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpnzl00aaa13k6qm376ez"},{"post_id":"cm4gqpnyh005ya13kwvbyypp4","category_id":"cm4gqpnzf0094a13kexf2bp1c","_id":"cm4gqpnzl00aba13k696t0d6g"},{"post_id":"cm4gqpnyj0062a13kxfa6nk1o","category_id":"cm4gqpnym0067a13kj33t8fmq","_id":"cm4gqpnzl00aca13k6lpwi4ya"},{"post_id":"cm4gqpnyj0062a13kxfa6nk1o","category_id":"cm4gqpnz7008ia13kikaps65e","_id":"cm4gqpnzl00ada13k7f629ie3"},{"post_id":"cm4gqpnyj0062a13kxfa6nk1o","category_id":"cm4gqpnz5008da13kuu46gmbb","_id":"cm4gqpnzl00aea13kox0q02yc"},{"post_id":"cm4gqpnxy004ga13kaa80yl72","category_id":"cm4gqpnuo000la13k8uzw230q","_id":"cm4gqpnzl00afa13km3qxgroe"},{"post_id":"cm4gqpnxy004ga13kaa80yl72","category_id":"cm4gqpnyh005xa13khp9qwqul","_id":"cm4gqpnzl00aga13kvpvt10o5"},{"post_id":"cm4gqpnxy004ga13kaa80yl72","category_id":"cm4gqpnyw0073a13kwbdxwh8q","_id":"cm4gqpnzl00aha13kbaj6hufw"},{"post_id":"cm4gqpnxy004ga13kaa80yl72","category_id":"cm4gqpnz8008ra13kt3orfibz","_id":"cm4gqpnzl00aia13khk41hfn0"},{"post_id":"cm4gqpo2w00aja13k2y56ld8e","category_id":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpo3000ala13kq8wvvpes"},{"post_id":"cm4gqpo2x00aka13ks9mlekgr","category_id":"cm4gqpnyx0076a13k5j3upi8t","_id":"cm4gqpo3000ama13k9npvh8q8"},{"post_id":"cm4gqpo2x00aka13ks9mlekgr","category_id":"cm4gqpnzf0094a13kexf2bp1c","_id":"cm4gqpo3000ana13klkb2dqcs"}],"PostTag":[{"post_id":"cm4gqpntj0000a13k2k3brwas","tag_id":"cm4gqpntt0004a13k80v2huo3","_id":"cm4gqpnue000ba13ktxunzjhq"},{"post_id":"cm4gqpntr0002a13kyhxx5tha","tag_id":"cm4gqpnuc0009a13ke0unfaiy","_id":"cm4gqpnul000ha13kak4odo6p"},{"post_id":"cm4gqpntv0005a13ktkdgg3om","tag_id":"cm4gqpnui000ea13kafjzt846","_id":"cm4gqpnuq000oa13kwunei1r9"},{"post_id":"cm4gqpnu70007a13k0j0ez2l6","tag_id":"cm4gqpnuo000ka13k66500kj4","_id":"cm4gqpnuv000ta13knpal81pj"},{"post_id":"cm4gqpnub0008a13khvtj5g0k","tag_id":"cm4gqpnus000qa13k2t5q2nro","_id":"cm4gqpnv4000ya13k6y7te56j"},{"post_id":"cm4gqpnue000ca13kugxq9pjc","tag_id":"cm4gqpnuz000wa13korgx7bhx","_id":"cm4gqpnvf0015a13k2hnep0e0"},{"post_id":"cm4gqpnuh000da13knd69zcpj","tag_id":"cm4gqpnva0012a13k8fpmp3f2","_id":"cm4gqpnvp001ca13krl58mlie"},{"post_id":"cm4gqpnuk000ga13k21m2lmbq","tag_id":"cm4gqpnvn0019a13kmhfyw2uv","_id":"cm4gqpnw0001ha13keipocmsc"},{"post_id":"cm4gqpnun000ia13ktfx71f01","tag_id":"cm4gqpnvw001fa13kw3q27c6p","_id":"cm4gqpnw9001na13k3l05ad1m"},{"post_id":"cm4gqpnuo000ma13khtg8z0e1","tag_id":"cm4gqpnw5001ma13kif0h4bpl","_id":"cm4gqpnwl001ua13k6w6swq8e"},{"post_id":"cm4gqpnuv000ua13k5fti9j56","tag_id":"cm4gqpnwh001sa13kv0pdhfqx","_id":"cm4gqpnwv0020a13kq8q0qx79"},{"post_id":"cm4gqpnv90010a13kmo05w9ni","tag_id":"cm4gqpnwu001ya13ki2s0b73v","_id":"cm4gqpnwy0026a13kp8pzbh5w"},{"post_id":"cm4gqpnve0013a13k3bk80slx","tag_id":"cm4gqpnww0024a13k0rx6jenr","_id":"cm4gqpnx1002ca13ksx466jdu"},{"post_id":"cm4gqpnvs001da13kyprn6yhe","tag_id":"cm4gqpnx0002ba13kg0y4lumq","_id":"cm4gqpnx5002ia13k68xtwj2v"},{"post_id":"cm4gqpnvx001ga13kxmwzgl9u","tag_id":"cm4gqpnx4002ga13kcsgnew81","_id":"cm4gqpnx9002qa13klxykn88o"},{"post_id":"cm4gqpnw5001la13kfdlutnhn","tag_id":"cm4gqpnx4002ga13kcsgnew81","_id":"cm4gqpnxc002xa13k2qisuzw9"},{"post_id":"cm4gqpnw9001oa13kow4gwk3r","tag_id":"cm4gqpnxb002ua13kkpzsrxxg","_id":"cm4gqpnxg0034a13keafcwng0"},{"post_id":"cm4gqpnwg001ra13k746lob2v","tag_id":"cm4gqpnx4002ga13kcsgnew81","_id":"cm4gqpnxj003ba13kk3x4pw8y"},{"post_id":"cm4gqpnwl001ta13k667u9rwi","tag_id":"cm4gqpnxh0038a13kf023fqxw","_id":"cm4gqpnxl003ia13ka4k9k091"},{"post_id":"cm4gqpnwq001va13k9icksg7r","tag_id":"cm4gqpnxl003ga13kj6njx2ib","_id":"cm4gqpnxp003qa13kxuoxed7r"},{"post_id":"cm4gqpnwu001za13kexfrmt44","tag_id":"cm4gqpnx4002ga13kcsgnew81","_id":"cm4gqpnxr003xa13kbj2igakm"},{"post_id":"cm4gqpnwv0022a13k9rajnntq","tag_id":"cm4gqpnxq003va13ka7t33cgq","_id":"cm4gqpnxt0045a13krcjup2jg"},{"post_id":"cm4gqpnww0025a13ka8vdvw92","tag_id":"cm4gqpnxs0042a13k4eokzyiu","_id":"cm4gqpnxx004ca13ku6zgnuyq"},{"post_id":"cm4gqpnwy0027a13k3e9d9101","tag_id":"cm4gqpnxv0049a13k57ki4za3","_id":"cm4gqpnxz004ja13kdwq128lb"},{"post_id":"cm4gqpnwz002aa13kmg6q1zkm","tag_id":"cm4gqpnxz004ha13kmshy6q1w","_id":"cm4gqpny2004ra13kutx5u1tk"},{"post_id":"cm4gqpnx1002da13kfpucpy67","tag_id":"cm4gqpnxv0049a13k57ki4za3","_id":"cm4gqpny4004ya13k9ooa3n2m"},{"post_id":"cm4gqpnx3002fa13k1dzolbyj","tag_id":"cm4gqpny3004wa13kqxfcn13y","_id":"cm4gqpny60056a13kmz1iknj6"},{"post_id":"cm4gqpnx4002ha13krmhlilge","tag_id":"cm4gqpny50053a13kpai3pp8y","_id":"cm4gqpny8005da13kdsz6qeqy"},{"post_id":"cm4gqpny70058a13kdzd21gk5","tag_id":"cm4gqpnxz004ha13kmshy6q1w","_id":"cm4gqpny9005ga13kxpzdrb0c"},{"post_id":"cm4gqpnx8002oa13kegip255g","tag_id":"cm4gqpny7005aa13kq222r2qa","_id":"cm4gqpnya005ja13kgc835hfa"},{"post_id":"cm4gqpnxf0032a13k3zyubj0u","tag_id":"cm4gqpnya005ia13kuhiruyx7","_id":"cm4gqpnyf005ra13ki8v7xwnk"},{"post_id":"cm4gqpnxg0035a13ku97w4boz","tag_id":"cm4gqpnxv0049a13k57ki4za3","_id":"cm4gqpnyh005wa13kd2ui2jtn"},{"post_id":"cm4gqpnxi0039a13k9uc1irbh","tag_id":"cm4gqpnyg005ua13ksf8xgxbj","_id":"cm4gqpnyj0061a13kuzeofcov"},{"post_id":"cm4gqpnxj003ca13knspmqpb2","tag_id":"cm4gqpnyi005za13k55znuo3y","_id":"cm4gqpnyl0066a13kbw15si10"},{"post_id":"cm4gqpnxk003fa13k4yth221h","tag_id":"cm4gqpnya005ia13kuhiruyx7","_id":"cm4gqpnym0069a13kwi61797h"},{"post_id":"cm4gqpnxl003ja13k0d6kywuu","tag_id":"cm4gqpnym0068a13kgk60kba8","_id":"cm4gqpnyo006da13kpwk62tgm"},{"post_id":"cm4gqpnxm003ma13kzoywubny","tag_id":"cm4gqpnyn006ca13ktu560c46","_id":"cm4gqpnyq006ia13k8ndddomp"},{"post_id":"cm4gqpnxo003pa13k47m3h8tj","tag_id":"cm4gqpnyp006ha13ki6kbqkrh","_id":"cm4gqpnyr006na13k6ax9xdd2"},{"post_id":"cm4gqpnxp003ta13kv3huyqvk","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnyt006qa13kv1hsw1t2"},{"post_id":"cm4gqpnxq003wa13kaevt6bnb","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnyu006ta13kti2g8gu1"},{"post_id":"cm4gqpnxr0040a13kubvx69de","tag_id":"cm4gqpnyt006sa13k0uj46qna","_id":"cm4gqpnyv006xa13k7en9z6k6"},{"post_id":"cm4gqpnxs0043a13k3w5jxill","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnyw0070a13kdtxf6o1j"},{"post_id":"cm4gqpnxu0046a13kdnncsydf","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnyw0072a13klcpfcc4z"},{"post_id":"cm4gqpnxw004aa13k2vcl54ui","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnyx0075a13kl73o1m63"},{"post_id":"cm4gqpnxy004ga13kaa80yl72","tag_id":"cm4gqpnyt006sa13k0uj46qna","_id":"cm4gqpnyx0078a13k1o6yakit"},{"post_id":"cm4gqpny1004qa13ktdoklfpg","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnyy007ca13kmz045k2g"},{"post_id":"cm4gqpny3004ua13kq1xzarfm","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnyz007fa13k74s3hi36"},{"post_id":"cm4gqpny4004xa13kdrbkst6y","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnyz007ia13kdtzh6p3l"},{"post_id":"cm4gqpny50051a13kt3zcmx9f","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnz0007ma13kt3824eic"},{"post_id":"cm4gqpnyj0062a13kxfa6nk1o","tag_id":"cm4gqpnyq006la13kx784t2p2","_id":"cm4gqpnz1007pa13kxq6c5083"},{"post_id":"cm4gqpnyk0065a13k5eqygezq","tag_id":"cm4gqpnz0007oa13kxtmul01r","_id":"cm4gqpnz1007sa13kug080tm9"}],"Tag":[{"name":"Mybatis","_id":"cm4gqpntt0004a13k80v2huo3"},{"name":"CAS Shiro SSO 权限控制","_id":"cm4gqpnuc0009a13ke0unfaiy"},{"name":"jvm redis","_id":"cm4gqpnui000ea13kafjzt846"},{"name":"mysql","_id":"cm4gqpnuo000ka13k66500kj4"},{"name":"SSO CAS tomcat session","_id":"cm4gqpnus000qa13k2t5q2nro"},{"name":"Redis SSO 权限控制","_id":"cm4gqpnuz000wa13korgx7bhx"},{"name":"MySQL","_id":"cm4gqpnva0012a13k8fpmp3f2"},{"name":"bio","_id":"cm4gqpnvn0019a13kmhfyw2uv"},{"name":"nio","_id":"cm4gqpnvw001fa13kw3q27c6p"},{"name":"tcp socket","_id":"cm4gqpnw5001ma13kif0h4bpl"},{"name":"HIVE HDFS","_id":"cm4gqpnwh001sa13kv0pdhfqx"},{"name":"MQ","_id":"cm4gqpnwu001ya13ki2s0b73v"},{"name":"rpc","_id":"cm4gqpnww0024a13k0rx6jenr"},{"name":"tomcat","_id":"cm4gqpnx0002ba13kg0y4lumq"},{"name":"Tomcat","_id":"cm4gqpnx4002ga13kcsgnew81"},{"name":"Linux","_id":"cm4gqpnxb002ua13kkpzsrxxg"},{"name":"Tomcat netty","_id":"cm4gqpnxh0038a13kf023fqxw"},{"name":"Linux CPU","_id":"cm4gqpnxl003ga13kj6njx2ib"},{"name":"linux pagecache buffercache","_id":"cm4gqpnxq003va13ka7t33cgq"},{"name":"Linux Thread","_id":"cm4gqpnxs0042a13k4eokzyiu"},{"name":"jvm","_id":"cm4gqpnxv0049a13k57ki4za3"},{"name":"jvm thread","_id":"cm4gqpnxz004ha13kmshy6q1w"},{"name":"jvm ThreadPoll","_id":"cm4gqpny3004wa13kqxfcn13y"},{"name":"jvm JMM Java","_id":"cm4gqpny50053a13kpai3pp8y"},{"name":"Enum java","_id":"cm4gqpny7005aa13kq222r2qa"},{"name":"es","_id":"cm4gqpnya005ia13kuhiruyx7"},{"name":"snowflake UUID","_id":"cm4gqpnyg005ua13ksf8xgxbj"},{"name":"jvm java","_id":"cm4gqpnyi005za13k55znuo3y"},{"name":"Sharding-JDBC","_id":"cm4gqpnym0068a13kgk60kba8"},{"name":"交易","_id":"cm4gqpnyn006ca13ktu560c46"},{"name":"spring springmvc","_id":"cm4gqpnyp006ha13ki6kbqkrh"},{"name":"阿里","_id":"cm4gqpnyq006la13kx784t2p2"},{"name":"美团","_id":"cm4gqpnyt006sa13k0uj46qna"},{"name":"Linux IO","_id":"cm4gqpnz0007oa13kxtmul01r"}]}}
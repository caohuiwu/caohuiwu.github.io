---
title: HIVE
date: 2019-07-20 14:45:42
tags: HIVE HDFS
---
# 一、HIVE架构
![HIVE架构](2019-07-20-HIVE/HIVE架构.png)

## 1. 连接方式
* CLI：command line interface
* JDBC/ODBC
* WEBUI

## 2. 驱动器：Driver
* Parser：SQL解析器，将HQL转换成抽象语法树，AST tree
    * 对AST tree进行解析：例如表是否存在、字段是否存在、SQL语义是否有误。
* Planner：编译器， 对HQL语句进行词法、语法、语义的编译(需要跟元数据关联)，编译完成后会生成一个执行计划。 hive上就是编译成mapreduce的job。
* Optimizer：优化器， 将执行计划进行优化，减少不必要的列、使用分区、使用索引等。优化job。
* Execution：将优化后的执行计划提交给hadoop的yarn上执行。提交job。

## 3. 元数据：meta store
* 元数据包括：
    * 表名
    * 表所属的数据库
    * 表的拥有者
    * 列/分区字段
    * 表的类型
    * 表的数据所在目录

* 表类型
    * 内部表：create table xxx (xx xxx)
        * 默认创建的是默认表
        * 删除表的时候，数据和元数据都会被删除
        * 
    * 外边表：create external table xxx (xxx)
        * 删除外部表时原数据不会被删除
        * 外部表指向的数据发生变化的时候会自动更新，不用特殊处理
        * 外部表文件可以在外部系统上，只要有访问权限就可以
        * 外部表导入文件时不移动文件，仅仅是添加一个metadata

* 分区和桶
    * 分区：
        * 例如按天分区，只存储一个的数据
        * 一个Hive表在HDFS上是有一个对应的目录来存储数据，普通表的数据直接存储在这个目录下，而分区表数据存储时，是再划分子目录来存储的
    * 桶：分桶将整个数据内容安装某列属性值得hash值进行区分，按照取模结果对数据分桶            
    
    
## 4. 工作流程

1. 用户提交查询等任务给Driver。
2. 驱动程序将Hql发送编译器，检查语法和生成查询计划。
3. 编译器Compiler根据用户任务去MetaStore中获取需要的Hive的元数据信息。
4. 编译器Compiler得到元数据信息，对任务进行编译，先将HiveQL转换为抽象语法树，然后将抽象语法树 转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划 （MapReduce）, 最后选择最佳的策略。
5. 将最终的计划提交给Driver。到此为止，查询解析和编译完成。
6. Driver将计划Plan转交给ExecutionEngine去执行。
7. 在内部，执行作业的过程是一个MapReduce工作。执行引擎发送作业给JobTracker，在名称节点并把它 分配作业到TaskTracker，这是在数据节点。在这里，查询执行MapReduce工作。
    7.1. 与此同时,在执行时,执行引擎可以通过Metastore执行元数据操作。
8. 执行引擎接收来自数据节点的结果。
9. 执行引擎发送这些结果值给驱动程序。
10. 驱动程序将结果发送给Hive接口。    

    